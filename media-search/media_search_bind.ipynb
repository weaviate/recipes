{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Audio Video Search with Meta AI ImageBind\n",
    "This recipe demonstrates how build multi-modal search (image, audio, video) `Meta AI ImageBind` model ([multi2vec-bind](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/multi2vec-bind)).\n",
    "\n",
    "ImageBind allows us to search through text, image, audio and video.\n",
    "\n",
    "This recipe will focus on searching through image, audio, video (skipping searching through text):\n",
    "* [text-to-media search](#text-to-media-search) - provide text as input to search through media\n",
    "* [image-to-media search](#image-to-media-search) - provide image as input to search through media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weaviate Setup\n",
    "\n",
    "The ImageBind model is only available with local Weaviate deployments with Docker or Kubernetes.\n",
    "\n",
    "ImageBind is not supported with Weaviate Cloud Services (WCS).\n",
    "\n",
    "### Steps to deploy Weaviate locally with CLIP\n",
    "\n",
    "1. Get a docker compose file.\n",
    "    \n",
    "    Run the following command in your terminal:\n",
    "\n",
    "    ```\n",
    "    curl -o docker-compose.yml \"https://configuration.weaviate.io/v2/docker-compose/docker-compose.yml?bind_model=imagebind&generative_cohere=false&generative_openai=false&generative_palm=false&media_type=bind&modules=modules&ref2vec_centroid=false&reranker_cohere=false&reranker_transformers=false&runtime=docker-compose&weaviate_version=v1.21.8&weaviate_volume=named-volume\"\n",
    "    ```\n",
    "\n",
    "    This will download `docker-compose.yml` file for you.\n",
    "\n",
    "2. Run Weaviate+Bind with Docker Compose\n",
    "\n",
    "    > If you are new to `Docker Compose`, [here are instructions on how to install it](https://docs.docker.com/compose/install/).\n",
    "\n",
    "    To start the docker image defined in the `docker-compose.yml` file, call:\n",
    "\n",
    "    ```\n",
    "    docker compose up\n",
    "    ```\n",
    "    \n",
    "    > Note #1 - the first time you run the command, Docker will download a ~6GB image.\n",
    "    \n",
    "    > Note #2 â€“ to shut down a running docker image, press CMD+C or CTRL+C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install weaviate-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "# Connect to Weaviate\n",
    "client = weaviate.Client(\n",
    "  url=\"http://localhost:8080\",  # URL to your local Weaviate instance\n",
    ")\n",
    "\n",
    "client.is_ready() # Test the connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `Animals` collection\n",
    "\n",
    "The collection has the following key characteristics:\n",
    "1. Name: `\"Animals\"`\n",
    "2. Vectorizer: `multi2vec-clip`\n",
    "3. Image property: `\"img\"` - Weaviate will use values in \"img\" property to generate vectors. Note, you can call it anything you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created Animals collection.\n"
     ]
    }
   ],
   "source": [
    "# Delete the collection if it exists.\n",
    "# Note you should skip this step if you don't want to reimport the data every time.\n",
    "if client.schema.exists(\"Animals\"):\n",
    "    client.schema.delete_class(\"Animals\")\n",
    "\n",
    "animals = {\n",
    "    \"classes\": [\n",
    "        {\n",
    "            \"class\": \"Animals\",\n",
    "            \"vectorizer\": \"multi2vec-bind\",\n",
    "            \"moduleConfig\": {\n",
    "                \"multi2vec-bind\": {\n",
    "                    \"textFields\": [\"name\"],\n",
    "                    \"imageFields\": [\"image\"],\n",
    "                    \"audioFields\": [\"audio\"],\n",
    "                    \"videoFields\": [\"video\"],\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "client.schema.create(animals)\n",
    "print(\"Successfully created Animals collection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Media\n",
    "For every object, we will store:\n",
    "* `name` - the file name \n",
    "* `path` - path to the file, so that we could display returned images at query time.\n",
    "* (one of the following) media:\n",
    "    * `image` - a base64 representation of the image file, Weaviate will use it to generate a vector - see `imageFields`.\n",
    "    * `audio` - a base64 representation of the audio file, Weaviate will use it to generate a vector - see `audioFields`.\n",
    "    * `video` - a base64 representation of the video file, Weaviate will use it to generate a vector - see `videoFields`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import base64\n",
    "\n",
    "# Helper function to convert a file to base64 representation\n",
    "def toBase64(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        return base64.b64encode(file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding cat1.jpg\n",
      "Adding cat2.jpg\n",
      "Adding cat3.jpg\n",
      "Adding dog1.jpg\n",
      "Adding dog2.jpg\n",
      "Adding dog3.jpg\n",
      "Adding meerkat1.jpg\n",
      "Adding meerkat2.jpg\n",
      "Adding meerkat3.jpg\n"
     ]
    }
   ],
   "source": [
    "# List of source images \n",
    "source = [\"cat1.jpg\", \"cat2.jpg\", \"cat3.jpg\",\n",
    "          \"dog1.jpg\", \"dog2.jpg\", \"dog3.jpg\",\n",
    "          \"meerkat1.jpg\", \"meerkat2.jpg\", \"meerkat3.jpg\"]\n",
    "\n",
    "client.batch.configure(batch_size=3)  # Load images in batches of 3\n",
    "with client.batch as batch:\n",
    "\n",
    "    for name in source:\n",
    "        print(f\"Adding {name}\")\n",
    "\n",
    "        # Build the path to the image file\n",
    "        path = \"./source/image/\" + name\n",
    "\n",
    "        # Object to store in Weaviate\n",
    "        properties = {\n",
    "            \"name\": name,\n",
    "            \"path\": path,\n",
    "            \"image\": toBase64(path), # Weaviate will use the base64 representation of the file to generate a vector.\n",
    "            \"mediaType\": \"image\"\n",
    "        }\n",
    "\n",
    "        # Add the object to Weaviate\n",
    "        client.batch.add_data_object(properties, \"Animals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.batch.delete_objects(\n",
    "#     class_name='Animals',\n",
    "#     where={\n",
    "#         'path': ['mediaType'],\n",
    "#         'operator': 'Equal',\n",
    "#         'valueText': 'Video'\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "1. Add 4 audio files to `source/audio`\n",
    "2. Test import\n",
    "3. Then test the [audio-to-media-search](#audio-to-media-search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of source images \n",
    "source = [\n",
    "    # \"cat-A.mp3\", \"cat-B.mp3\",\n",
    "    # \"dog-A.mp3\", \"dog-B.mp3\",\n",
    "]\n",
    "\n",
    "client.batch.configure(batch_size=3)  # Load images in batches of 1, as these might be big files\n",
    "with client.batch as batch:\n",
    "\n",
    "    for name in source:\n",
    "        print(f\"Adding {name}\")\n",
    "\n",
    "        # Build the path to the image file\n",
    "        path = \"./source/audio/\" + name\n",
    "\n",
    "        # Object to store in Weaviate\n",
    "        properties = {\n",
    "            \"name\": name,\n",
    "            \"path\": path,\n",
    "            \"audio\": toBase64(path), # Weaviate will use the base64 representation of the file to generate a vector.\n",
    "            \"mediaType\": \"audio\"\n",
    "        }\n",
    "\n",
    "        # Add the object to Weaviate\n",
    "        client.batch.add_data_object(properties, \"Animals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding meerkat-dig.mp4\n",
      "Adding meerkat-watch.mp4\n"
     ]
    }
   ],
   "source": [
    "# List of source images \n",
    "source = [\n",
    "    \"cat-clean.mp4\", \"cat-play.mp4\",\n",
    "    \"dog-high-five.mp4\", \"dog-with-stick.mp4\",\n",
    "    \"meerkat-dig.mp4\", \"meerkat-watch.mp4\"\n",
    "]\n",
    "\n",
    "client.batch.configure(batch_size=1)  # Load images in batches of 1, as these might be big files\n",
    "with client.batch as batch:\n",
    "\n",
    "    for name in source:\n",
    "        print(f\"Adding {name}\")\n",
    "\n",
    "        # Build the path to the image file\n",
    "        path = \"./source/video/\" + name\n",
    "\n",
    "        # Object to store in Weaviate\n",
    "        properties = {\n",
    "            \"name\": name,\n",
    "            \"path\": path,\n",
    "            \"video\": toBase64(path), # Weaviate will use the base64 representation of the file to generate a vector.\n",
    "            \"mediaType\": \"video\"\n",
    "        }\n",
    "\n",
    "        # Add the object to Weaviate\n",
    "        client.batch.add_data_object(properties, \"Animals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check number of objects in the Animals collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'Aggregate': {'Animals': [{'meta': {'count': 10}}]}}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the number of objects in the Animals collection\n",
    "client.query.aggregate(\"Animals\").with_meta_count().do()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to display results\n",
    "import json\n",
    "from IPython.display import Image, Audio, Video\n",
    "\n",
    "def json_print(data):\n",
    "    print(json.dumps(data, indent=2))\n",
    "\n",
    "def display_media(item):\n",
    "    path = item[\"path\"]\n",
    "\n",
    "    if(item[\"mediaType\"] == \"image\"):\n",
    "        display(Image(path))\n",
    "\n",
    "    elif(item[\"mediaType\"] == \"video\"):\n",
    "        display(Video(path))\n",
    "        \n",
    "    elif(item[\"mediaType\"] == \"audio\"):\n",
    "        display(Audio(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to Media search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"mediaType\": \"video\",\n",
      "    \"name\": \"dog-with-stick.mp4\",\n",
      "    \"path\": \"./source/video/dog-with-stick.mp4\"\n",
      "  },\n",
      "  {\n",
      "    \"mediaType\": \"image\",\n",
      "    \"name\": \"dog2.jpg\",\n",
      "    \"path\": \"./source/image/dog2.jpg\"\n",
      "  },\n",
      "  {\n",
      "    \"mediaType\": \"image\",\n",
      "    \"name\": \"dog1.jpg\",\n",
      "    \"path\": \"./source/image/dog1.jpg\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"./source/video/dog-with-stick.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Search for media with \"dog with stick\", \"cat playing with mouse\", \"dog high five\", \"puppy\"\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"Animals\", \"name path mediaType\")\n",
    "    .with_near_text(\n",
    "        {\"concepts\": \"dog with stick\"}\n",
    "        # {\"concepts\": \"cat playing with mouse\"}\n",
    "        # {\"concepts\": \"dog high five\"}\n",
    "        # {\"concepts\": \"puppy\"}\n",
    "    )\n",
    "    .with_limit(3)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "# Print results\n",
    "result = response[\"data\"][\"Get\"][\"Animals\"]\n",
    "\n",
    "json_print(result)\n",
    "\n",
    "# Display the first result\n",
    "display_media(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image to Media search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"mediaType\": \"image\",\n",
      "    \"name\": \"cat1.jpg\",\n",
      "    \"path\": \"./source/image/cat1.jpg\"\n",
      "  },\n",
      "  {\n",
      "    \"mediaType\": \"image\",\n",
      "    \"name\": \"cat2.jpg\",\n",
      "    \"path\": \"./source/image/cat2.jpg\"\n",
      "  },\n",
      "  {\n",
      "    \"mediaType\": \"image\",\n",
      "    \"name\": \"cat3.jpg\",\n",
      "    \"path\": \"./source/image/cat3.jpg\"\n",
      "  },\n",
      "  {\n",
      "    \"mediaType\": \"video\",\n",
      "    \"name\": \"cat-clean.mp4\",\n",
      "    \"path\": \"./source/video/cat-clean.mp4\"\n",
      "  },\n",
      "  {\n",
      "    \"mediaType\": \"video\",\n",
      "    \"name\": \"cat-play.mp4\",\n",
      "    \"path\": \"./source/video/cat-play.mp4\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"./source/video/cat-play.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Search for images that are similar to the provided image of test-meerkat, test-dog, test-cat\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"Animals\", \"name path mediaType\")\n",
    "    .with_near_image(\n",
    "        # {\"image\": \"./test/test-meerkat.jpg\"}, # Use file path as the input for the query\n",
    "        # {\"image\": \"./test/test-dog.jpg\"}, # Use file path as the input for the query\n",
    "        {\"image\": \"./test/test-cat.jpg\"}, # Use file path as the input for the query\n",
    "    )\n",
    "    .with_limit(5)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "# Print results\n",
    "result = response[\"data\"][\"Get\"][\"Animals\"]\n",
    "json_print(result)\n",
    "\n",
    "# Display the first image\n",
    "display_media(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio to Media search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "1. Add `test-cat.mp3`, `test-dog.mp3` (or `.wav`) to `source/audio`\n",
    "2. Test each audio input works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for images that are similar to the provided image of test-meerkat, test-dog, test-cat\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"Animals\", \"name path mediaType\")\n",
    "    .with_near_audio(\n",
    "        {\"audio\": \"./test/test-cat.mp3\"}, # Use file path as the input for the query\n",
    "        # {\"audio\": \"./test/test-dog.mp3\"}, # Use file path as the input for the query\n",
    "        # {\"audio\": \"./test/test-meerkat.mp3\"}, # Use file path as the input for the query\n",
    "    )\n",
    "    .with_limit(5)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "# Print results\n",
    "result = response[\"data\"][\"Get\"][\"Animals\"]\n",
    "json_print(result)\n",
    "\n",
    "# Display the first image\n",
    "display_media(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video to Media search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"mediaType\": \"video\",\n",
      "    \"name\": \"meerkat-watch.mp4\",\n",
      "    \"path\": \"./source/video/meerkat-watch.mp4\"\n",
      "  },\n",
      "  {\n",
      "    \"mediaType\": \"video\",\n",
      "    \"name\": \"meerkat-dig.mp4\",\n",
      "    \"path\": \"./source/video/meerkat-dig.mp4\"\n",
      "  },\n",
      "  {\n",
      "    \"mediaType\": \"image\",\n",
      "    \"name\": \"meerkat3.jpg\",\n",
      "    \"path\": \"./source/image/meerkat3.jpg\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"./source/video/meerkat-watch.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Search for images that are similar to the provided image of test-meerkat, test-dog, test-cat\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"Animals\", \"name path mediaType\")\n",
    "    .with_near_video(\n",
    "        # {\"video\": \"./test/test-dog.mp4\"}, # Use file path as the input for the query\n",
    "        # {\"video\": \"./test/test-cat.mp4\"}, # Use file path as the input for the query\n",
    "        {\"video\": \"./test/test-meerkat.mp4\"}, # Use file path as the input for the query\n",
    "    )\n",
    "    .with_limit(3)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "# Print results\n",
    "result = response[\"data\"][\"Get\"][\"Animals\"]\n",
    "json_print(result)\n",
    "\n",
    "# Display the first image\n",
    "display_media(result[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
