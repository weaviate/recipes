{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Search with CLIP\n",
    "This recipe demonstrates how build image search with `CLIP` model ([multi2vec-clip](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/multi2vec-clip)).\n",
    "\n",
    "CLIP allows us to search through text and images.\n",
    "\n",
    "This recipe will focus on searching through images only (skipping searching through text):\n",
    "* [text-to-image search](#text-to-image-search) - provide text as input to search through images\n",
    "* [image-to-image search](#image-to-image-search) - provide image as input to search through images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weaviate Setup\n",
    "\n",
    "The CLIP model is only available with local Weaviate deployments with Docker or Kubernetes.\n",
    "\n",
    "CLIP is not supported with Weaviate Cloud Services (WCS).\n",
    "\n",
    "### Steps to deploy Weaviate locally with CLIP\n",
    "\n",
    "1. Get a docker compose file.\n",
    "    \n",
    "    Run the following command in your terminal:\n",
    "\n",
    "    ```\n",
    "    curl -o docker-compose.yml \"https://configuration.weaviate.io/v2/docker-compose/docker-compose.yml?clip_model=sentence-transformers-clip-ViT-B-32-multilingual-v1&generative_cohere=false&generative_openai=false&generative_palm=false&media_type=clip&modules=modules&ner_module=false&qna_module=false&ref2vec_centroid=false&reranker_cohere=false&reranker_transformers=false&runtime=docker-compose&spellcheck_module=false&sum_module=false&weaviate_version=v1.21.8&weaviate_volume=named-volume\"\n",
    "    ```\n",
    "\n",
    "    This will download `docker-compose.yml` file for you.\n",
    "\n",
    "2. Run Weaviate+CLIP with Docker Compose\n",
    "\n",
    "    > If you are new to `Docker Compose`, [here are instructions on how to install it](https://docs.docker.com/compose/install/).\n",
    "\n",
    "    To start the docker image defined in the `docker-compose.yml` file, call:\n",
    "\n",
    "    ```\n",
    "    docker compose up\n",
    "    ```\n",
    "    \n",
    "    > Note #1 - the first time you run the command, Docker will download a ~3GB image.\n",
    "    \n",
    "    > Note #2 â€“ to shut down a running docker image, press CMD+C or CTRL+C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install weaviate-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "\n",
    "# Connect to Weaviate\n",
    "client = weaviate.Client(\n",
    "  url=\"http://localhost:8080\",  # URL to your local Weaviate instance\n",
    ")\n",
    "\n",
    "client.is_ready() # Test the connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `Animals` collection\n",
    "\n",
    "The collection has the following key characteristics:\n",
    "1. Name: `\"Animals\"`\n",
    "2. Vectorizer: `multi2vec-clip`\n",
    "3. Image property: `\"image\"` - Weaviate will use values in \"image\" property to generate vectors. Note, you can call it anything you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the collection if it exists.\n",
    "# Note you should skip this step if you don't want to reimport the data every time.\n",
    "if client.schema.exists(\"Animals\"):\n",
    "    client.schema.delete_class(\"Animals\")\n",
    "\n",
    "animals = {\n",
    "    \"classes\": [\n",
    "        {\n",
    "            \"class\": \"Animals\",\n",
    "            \"vectorizer\": \"multi2vec-clip\",\n",
    "            \"moduleConfig\": {\n",
    "                \"multi2vec-clip\": {\n",
    "                    \"textFields\": [\"name\"],\n",
    "                    \"imageFields\": [\"image\"],\n",
    "                    \"weights\": {\n",
    "                        \"textFields\": [0], # ignore text in the search\n",
    "                        \"imageFields\": [1], # focus search on images\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "client.schema.create(animals)\n",
    "print(\"Successfully created Animals collection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Images\n",
    "For every object, we will store:\n",
    "* `name` - the file name \n",
    "* `path` - path to the file, so that we could display returned images at query time.\n",
    "* `image` - a base64 representation of the image file, Weaviate will use it to generate a vector - see `imageFields`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import base64\n",
    "\n",
    "# Helper function to convert a file to base64 representation\n",
    "def toBase64(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        return base64.b64encode(file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of source images \n",
    "source = [\"cat1.jpg\", \"cat2.jpg\", \"cat3.jpg\",\n",
    "          \"dog1.jpg\", \"dog2.jpg\", \"dog3.jpg\",\n",
    "          \"meerkat1.jpg\", \"meerkat2.jpg\", \"meerkat3.jpg\"]\n",
    "\n",
    "client.batch.configure(batch_size=3)  # Load images in batches of 3\n",
    "with client.batch as batch:\n",
    "\n",
    "    for name in source:\n",
    "        print(f\"Adding {name}\")\n",
    "\n",
    "        # Build the path to the image file\n",
    "        path = \"./source/image/\" + name\n",
    "\n",
    "        # Object to store in Weaviate\n",
    "        properties = {\n",
    "            \"name\": name,\n",
    "            \"path\": path,\n",
    "            \"image\": toBase64(path), # Weaviate will use the base64 representation of the file to generate a vector.\n",
    "        }\n",
    "\n",
    "        # Add the object to Weaviate\n",
    "        client.batch.add_data_object(properties, \"Animals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check number of objects in the Animals collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of objects in the Animals collection\n",
    "client.query.aggregate(\"Animals\").with_meta_count().do()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to display results\n",
    "import json\n",
    "from IPython.display import Image\n",
    "\n",
    "def json_print(data):\n",
    "    print(json.dumps(data, indent=2))\n",
    "\n",
    "def display_image(path):\n",
    "    display(Image(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to Image search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for images with \"dog\", \"dog with glasses\", \"dog with a sign\"\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"Animals\", \"name path\")\n",
    "    .with_near_text(\n",
    "        {\"concepts\": \"dog\"}\n",
    "        # {\"concepts\": \"dog with glasses\"}\n",
    "        # {\"concepts\": \"dog with a sign\"}\n",
    "    )\n",
    "    .with_limit(3)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "# Print results\n",
    "result = response[\"data\"][\"Get\"][\"Animals\"]\n",
    "json_print(result)\n",
    "\n",
    "# Display the first image\n",
    "display_image(result[0][\"path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image to Image search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for images that are similar to the provided image of test-meerkat, test-dog, test-cat\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"Animals\", \"name path\")\n",
    "    .with_near_image(\n",
    "        {\"image\": \"./test/test-meerkat.jpg\"}, # Use file path as the input for the query\n",
    "        # {\"image\": \"./test/test-dog.jpg\"}, # Use file path as the input for the query\n",
    "        # {\"image\": \"./test/test-cat.jpg\"}, # Use file path as the input for the query\n",
    "    )\n",
    "    .with_limit(3)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "# Print results\n",
    "result = response[\"data\"][\"Get\"][\"Animals\"]\n",
    "json_print(result)\n",
    "\n",
    "# Display the first image\n",
    "display_image(result[0][\"path\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
