{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/weaviate/recipes/weaviate-services/embedding-service/weaviate_embeddings_service.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weaviate Embedding Service\n",
    "\n",
    "[Weaviate Embeddings](https://weaviate.io/developers/wcs/embeddings) enables you to generate embeddings directly from a [Weaviate Cloud](https://console.weaviate.cloud/) database instance. \n",
    "\n",
    "*Please note this service is part of Weaviate Cloud and cannot be accessed through open-source. Additionally, this service is currently under technical preview, and you can request access [here](https://events.weaviate.io/embeddings-preview).*\n",
    "\n",
    "This notebook will show you how to:\n",
    "1. Define a Weaviate Collection\n",
    "1. Run a vector search query \n",
    "1. Run a hybrid search query\n",
    "1. Run a hybrid search query with metadata filters\n",
    "1. Run a generative search query (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "1. Weaviate Cloud (WCD) account: You can register [here](https://console.weaviate.cloud/)\n",
    "1. Create a cluster on WCD: A sandbox or serverless cluster is fine. You will need to grab the cluster URL and admin API key\n",
    "1. OpenAI key to access `GPT-4o mini`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --q weaviate-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show weaviate-client # you need to have the Python client version 4.9.5 or higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "import os\n",
    "import weaviate.classes.config as wc\n",
    "from weaviate.classes.query import Filter\n",
    "\n",
    "import requests, json\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "WCD_CLUSTER_URL = os.getenv(\"WCD_CLUSTER_URL\")\n",
    "WCD_CLUSTER_KEY = os.getenv(\"WCD_CLUSTER_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=WCD_CLUSTER_URL,\n",
    "    auth_credentials=Auth.api_key(WCD_CLUSTER_KEY),\n",
    "\n",
    "    headers={\n",
    "        \"X-OpenAI-Api-Key\": OPENAI_API_KEY,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(client.is_ready())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created collection: JeopardyQuestion.\n"
     ]
    }
   ],
   "source": [
    "# Note: This will delete your data stored in \"JeopardyQuestion\".and\n",
    "# It will require you to re-import again.\n",
    "\n",
    "# Delete the collection if it already exists\n",
    "if (client.collections.exists(\"JeopardyQuestion\")):\n",
    "    client.collections.delete(\"JeopardyQuestion\")\n",
    "\n",
    "client.collections.create(\n",
    "    name=\"JeopardyQuestion\",\n",
    "\n",
    "    vectorizer_config=wc.Configure.Vectorizer.text2vec_weaviate( # specify the vectorizer and model type you're using\n",
    "        model=\"Snowflake/snowflake-arctic-embed-l-v2.0\", # default model\n",
    "    ),\n",
    "\n",
    "    generative_config=wc.Configure.Generative.openai( \n",
    "        model=\"gpt-4o-mini\" # select model, default is gpt-3.5-turbo \n",
    "    ),\n",
    "\n",
    "    properties=[ # defining properties (data schema) is optional\n",
    "        wc.Property(name=\"Question\", data_type=wc.DataType.TEXT), \n",
    "        wc.Property(name=\"Answer\", data_type=wc.DataType.TEXT, skip_vectorization=True),\n",
    "        wc.Property(name=\"Category\", data_type=wc.DataType.TEXT, skip_vectorization=True),\n",
    "        wc.Property(name=\"Value\", data_type=wc.DataType.TEXT, skip_vectorization=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Successfully created collection: JeopardyQuestion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "We will use the small jeopardy dataset as an example. It has 1,000 objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/weaviate/weaviate-examples/main/jeopardy_small_dataset/jeopardy_small.csv'\n",
    "resp = requests.get(url)\n",
    "\n",
    "df = pd.read_csv(StringIO(resp.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert complete.\n"
     ]
    }
   ],
   "source": [
    "# Get a collection object for \"JeopardyQuestion\"\n",
    "collection = client.collections.get(\"JeopardyQuestion\")\n",
    "\n",
    "# Insert data objects with batch import\n",
    "with collection.batch.dynamic() as batch:\n",
    "    for _, row in df.iterrows():\n",
    "        properties = {\n",
    "            \"question\": row['Question'],\n",
    "            \"answer\": row['Answer'],\n",
    "            \"category\": row[\"Category\"],\n",
    "            \"value\": row[\"Value\"]\n",
    "        }\n",
    "        batch.add_object(properties)\n",
    "\n",
    "failed_objects = collection.batch.failed_objects\n",
    "if failed_objects:\n",
    "    print(f\"Number of failed imports: {len(failed_objects)}\")\n",
    "else:\n",
    "    print(\"Insert complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# count the number of objects\n",
    "\n",
    "collection = client.collections.get(\"JeopardyQuestion\")\n",
    "response = collection.aggregate.over_all(total_count=True)\n",
    "\n",
    "print(response.total_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: {\n",
      "  \"value\": \"NaN\",\n",
      "  \"answer\": \"the narwhal\",\n",
      "  \"question\": \"A part of this marine mammal was prized by medieval folk, who thought it belonged to a unicorn\",\n",
      "  \"category\": \"THE ANIMAL KINGDOM\"\n",
      "} \n",
      "\n",
      "Data: {\n",
      "  \"value\": \"$400\",\n",
      "  \"answer\": \"the walrus\",\n",
      "  \"question\": \"You could say this Arctic mammal, Odobenus rosmarus, has a Wilford Brimley mustache\",\n",
      "  \"category\": \"MAMMALS\"\n",
      "} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "collection = client.collections.get(\"JeopardyQuestion\")\n",
    "\n",
    "response = collection.query.near_text(\n",
    "    query=\"marine mamal with tusk\", \n",
    "    limit=2 # limit to only 2\n",
    ")\n",
    "\n",
    "for item in response.objects:\n",
    "    print(\"Data:\", json.dumps(item.properties, indent=2), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Search\n",
    "\n",
    "The goal of this notebook is to show you how to use the embedding service. For more information on hybrid search, check out [this folder](https://github.com/weaviate/recipes/tree/main/weaviate-features/hybrid-search) and/or the [documentation](https://weaviate.io/developers/weaviate/search/hybrid).\n",
    "\n",
    "The `alpha` parameter determines the weight given to the sparse and dense search methods. `alpha = 0` is pure sparse (bm25) search, whereas `alpha = 1` is pure dense (vector) search. \n",
    "\n",
    "Alpha is an optional parameter. The default is set to `0.75`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: {\n",
      "  \"value\": \"NaN\",\n",
      "  \"answer\": \"the narwhal\",\n",
      "  \"question\": \"A part of this marine mammal was prized by medieval folk, who thought it belonged to a unicorn\",\n",
      "  \"category\": \"THE ANIMAL KINGDOM\"\n",
      "} \n",
      "\n",
      "Data: {\n",
      "  \"value\": \"$400\",\n",
      "  \"answer\": \"the walrus\",\n",
      "  \"question\": \"You could say this Arctic mammal, Odobenus rosmarus, has a Wilford Brimley mustache\",\n",
      "  \"category\": \"MAMMALS\"\n",
      "} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "collection = client.collections.get(\"JeopardyQuestion\")\n",
    "\n",
    "response = collection.query.hybrid(\n",
    "    query=\"unicorn-like artic animal\",\n",
    "    alpha=0.7, \n",
    "    limit=2\n",
    ")\n",
    "\n",
    "for item in response.objects:\n",
    "    print(\"Data:\", json.dumps(item.properties, indent=2), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Objects with Metadata Filters\n",
    "\n",
    "Learn more about the different filter operators [here](https://weaviate.io/developers/weaviate/search/filters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: {\n",
      "  \"value\": \"$200\",\n",
      "  \"answer\": \"Disney\",\n",
      "  \"question\": \"This company operates the 4 most popular theme parks in North America\",\n",
      "  \"category\": \"BUSINESS & INDUSTRY\"\n",
      "} \n",
      "\n",
      "Data: {\n",
      "  \"value\": \"$400\",\n",
      "  \"answer\": \"Yamaha\",\n",
      "  \"question\": \"This firm began in 1897 as Nippon Gakki Company, an organ manufacturer; electronic organs came along in 1959\",\n",
      "  \"category\": \"BUSINESS & INDUSTRY\"\n",
      "} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "collection = client.collections.get(\"JeopardyQuestion\")\n",
    "\n",
    "response = collection.query.fetch_objects(\n",
    "    limit=2,\n",
    "    filters=Filter.by_property(\"category\").equal(\"BUSINESS & INDUSTRY\")\n",
    ")\n",
    "\n",
    "for item in response.objects:\n",
    "    print(\"Data:\", json.dumps(item.properties, indent=2), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Search (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated output: People thought these animals were unicorn-like for a few reasons:\n",
      "\n",
      "1. **Narwhal**: The narwhal is a marine mammal known for its long, spiral tusk, which can reach lengths of up to 10 feet. In medieval times, this tusk was often sold as a \"unicorn horn\" and was believed to possess magical properties. The resemblance of the narwhal's tusk to the mythical unicorn's horn led to the association between the two, as people were fascinated by the idea of unicorns and sought to find evidence of their existence in the natural world.\n",
      "\n",
      "2. **Walrus**: While the walrus does not have a direct connection to unicorns like the narwhal, its large tusks and unique appearance may have contributed to some fantastical interpretations. The walrus's tusks, which can be quite prominent, might have sparked the imagination of those who were already inclined to believe in mythical creatures. Additionally, the walrus's size and distinctive features could have led to comparisons with other legendary animals, including unicorns, in folklore and storytelling.\n",
      "\n",
      "Overall, the combination of physical characteristics and the cultural context of the time contributed to the perception of these animals as unicorn-like.\n"
     ]
    }
   ],
   "source": [
    "collection = client.collections.get(\"JeopardyQuestion\")\n",
    "\n",
    "response = collection.generate.hybrid(\n",
    "    query=\"unicorn-like artic animal\",\n",
    "    alpha=0.7, \n",
    "    grouped_task=\"Explain why people thought these animals were unicorn-like\",\n",
    "    limit=2\n",
    ")\n",
    "\n",
    "print(f\"Generated output: {response.generated}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
