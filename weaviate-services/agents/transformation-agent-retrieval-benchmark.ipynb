{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Arctic 2.0 vs. Arctic 1.5 with Synthetic RAG Evals\n",
    "\n",
    "Traditionally, AI system evaluation has relied heavily on human-written evaluation sets. Most notably, this process demands substantial time and resource investment, preventing most developers from creating and properly evaluating their AI systems.\n",
    "\n",
    "The Weaviate Transformation Agent offers a breakthrough in AI evaluation by enabling the rapid generation of synthetic evaluation datasets!\n",
    "\n",
    "In this notebook, we generate **2,100 synthetic questions for the Weaviate Blogs (1 for each) in 63 seconds!**\n",
    "\n",
    "We then use this dataset to report embedding recall (finding the source document in the haystack) between the Snowflake [Arctic 2.0](https://arxiv.org/abs/2412.04506) and [Arctic 1.5](https://arxiv.org/abs/2405.05374) embedding models. We find the following result:\n",
    "\n",
    "| Model      | Recall@1 | Recall@5 | Recall@100 |\n",
    "|------------|----------|----------|------------|\n",
    "| Arctic 1.5 | 0.7995   | 0.9245   | 0.9995     |\n",
    "| Arctic 2.0 | 0.8412   | 0.9546   | 0.9995     |\n",
    "\n",
    "The Arctic 2.0 model demonstrates superior performance, with particularly notable improvements in Recall @ 1 (4.17% increase) and Recall @ 5 (3.01% increase).\n",
    "\n",
    "## Here is an overview of what this notebook illustrates:\n",
    "\n",
    "![Embedding Benchmark with the Transformation Agent](./images/synthetic-query-overview-new.png \"Embedding Benchmark with the Transformation Agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import os\n",
    "from weaviate.classes.init import Auth\n",
    "import weaviate.classes.config as wvcc\n",
    "import re\n",
    "from weaviate.util import get_valid_uuid\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Connect to Weaviate Client\n",
    "\n",
    "WEAVIATE_URL = os.getenv(\"WEAVIATE_URL\")\n",
    "WEAVIATE_API_KEY = os.getenv(\"WEAVIATE_API_KEY\")\n",
    "\n",
    "weaviate_client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=WEAVIATE_URL,\n",
    "    auth_credentials=Auth.api_key(WEAVIATE_API_KEY)\n",
    ")\n",
    "\n",
    "print(weaviate_client.is_ready())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weaviate Named Vectors\n",
    "\n",
    "Create 2 HSNW indexes from the *same* property in Weaviate!!\n",
    "\n",
    "On top of that, you can set different embedding models for each!\n",
    "\n",
    "You can learn more about Weaviate Named Vectors [here](https://weaviate.io/developers/weaviate/config-refs/schema/multi-vector) and the Weaviate Embedding Service [here](https://weaviate.io/developers/wcs/embeddings)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogs_collection = weaviate_client.collections.create(\n",
    "    name=\"WeaviateBlogChunks\",\n",
    "    vectorizer_config=[\n",
    "        wvcc.Configure.NamedVectors.text2vec_weaviate(\n",
    "            name=\"content_arctic_1_5\",\n",
    "            model=\"Snowflake/snowflake-arctic-embed-m-v1.5\",\n",
    "            source_properties=[\"content\"],\n",
    "        ),\n",
    "        wvcc.Configure.NamedVectors.text2vec_weaviate(\n",
    "            name=\"content_arctic_2_0\",\n",
    "            model=\"Snowflake/snowflake-arctic-embed-l-v2.0\",\n",
    "            source_properties=[\"content\"],\n",
    "        )\n",
    "    ],\n",
    "    properties=[\n",
    "        wvcc.Property(name=\"content\", data_type=wvcc.DataType.TEXT),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Directory Parser to Load Weaviate's Blogs stored in Markdown Files into Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_list(lst, chunk_size):\n",
    "    \"\"\"Break a list into chunks of the specified size.\"\"\"\n",
    "    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    \"\"\"Split text into sentences using regular expressions.\"\"\"\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "    return [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "\n",
    "def read_and_chunk_index_files(main_folder_path):\n",
    "    \"\"\"Read index.md files from subfolders, split into sentences, and chunk every 5 sentences.\"\"\"\n",
    "    blog_chunks = []\n",
    "    for folder_name in os.listdir(main_folder_path):\n",
    "        subfolder_path = os.path.join(main_folder_path, folder_name)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            index_file_path = os.path.join(subfolder_path, 'index.mdx')\n",
    "            if os.path.isfile(index_file_path):\n",
    "                with open(index_file_path, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()\n",
    "                    sentences = split_into_sentences(content)\n",
    "                    sentence_chunks = chunk_list(sentences, 5)\n",
    "                    sentence_chunks = [' '.join(chunk) for chunk in sentence_chunks]\n",
    "                    blog_chunks.extend(sentence_chunks)\n",
    "    return blog_chunks\n",
    "\n",
    "# Example usage\n",
    "main_folder_path = \"blog\"\n",
    "blog_chunks = read_and_chunk_index_files(main_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have 2,160 blog chunks from Weaviate's Blog Posts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2160"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blog_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is an example of one of these blog chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "title: 'Accelerating Vector Search up to +40% with Intel’s latest Xeon CPU - Emerald Rapids'\n",
      "slug: intel\n",
      "authors: [zain, asdine, john]\n",
      "date: 2024-03-26\n",
      "image: ./img/hero.png\n",
      "tags: ['engineering', 'research']\n",
      "description: 'Boosting Weaviate using SIMD-AVX512, Loop Unrolling and Compiler Optimizations'\n",
      "---\n",
      "\n",
      "![HERO image](./img/hero.png)\n",
      "\n",
      "**Overview of Key Sections:**\n",
      "- [**Vector Distance Calculations**](#vector-distance-calculations) Different vector distance metrics popularly used in Weaviate. - [**Implementations of Distance Calculations in Weaviate**](#vector-distance-implementations) Improvements under the hood for implementation of Dot product and L2 distance metrics. - [**Intel’s 5th Gen Intel Xeon Processor, Emerald Rapids**](#enter-intel-emerald-rapids)  More on Intel's new 5th Gen Xeon processor. - [**Benchmarking Performance**](#lets-talk-numbers) Performance numbers on microbenchmarks along with simulated real-world usage scenarios. What’s the most important calculation a vector database needs to do over and over again?\n"
     ]
    }
   ],
   "source": [
    "print(blog_chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Import Blogs into Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 500 blog chunks... (Time elapsed: 2.26 seconds)\n",
      "Inserted 1000 blog chunks... (Time elapsed: 4.21 seconds)\n",
      "Inserted 1500 blog chunks... (Time elapsed: 4.64 seconds)\n",
      "Inserted 2000 blog chunks... (Time elapsed: 6.49 seconds)\n"
     ]
    }
   ],
   "source": [
    "blogs_collection = weaviate_client.collections.get(\"WeaviateBlogChunks\")\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "with blogs_collection.batch.dynamic() as batch:\n",
    "    for i, blog_chunk in enumerate(blog_chunks):\n",
    "        batch.add_object(\n",
    "            properties={\n",
    "                \"content\": blog_chunk\n",
    "            },\n",
    "        )\n",
    "\n",
    "        if (i + 1) % 500 == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Inserted {i + 1} blog chunks... (Time elapsed: {elapsed_time:.2f} seconds)\")\n",
    "\n",
    "failed_objects = blogs_collection.batch.failed_objects\n",
    "if failed_objects:\n",
    "    print(f\"Number of failed imports: {len(failed_objects)}\")\n",
    "    print(f\"First failed object: {failed_objects[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to retry failed objects...\n",
      "Retry complete. Successfully uploaded 0 previously failed objects. 0 objects still failed.\n"
     ]
    }
   ],
   "source": [
    "# Retry uploading failed objects with proper error handling\n",
    "print(\"Attempting to retry failed objects...\")\n",
    "success_count = 0\n",
    "error_count = 0\n",
    "\n",
    "for object in failed_objects:\n",
    "    try:\n",
    "        # Extract the properties from the BatchObject\n",
    "        properties = object.object_.properties\n",
    "\n",
    "        # Insert the object with proper error handling\n",
    "        blogs_collection.data.insert(\n",
    "            properties={\n",
    "                \"content\": properties[\"content\"]  # Use \"content\" instead of \"input_persona\"\n",
    "            }\n",
    "        )\n",
    "        success_count += 1\n",
    "\n",
    "        # Add a small delay to avoid overwhelming the server\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading object: {e}\")\n",
    "        error_count += 1\n",
    "\n",
    "    # Print progress every 50 objects\n",
    "    if (success_count + error_count) % 50 == 0:\n",
    "        print(f\"Progress: {success_count + error_count}/{len(failed_objects)} objects processed\")\n",
    "\n",
    "print(f\"Retry complete. Successfully uploaded {success_count} previously failed objects. {error_count} objects still failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Simluated User Queries with the Transformation Agent\n",
    "\n",
    "Weaviate Users may be interested in knowing what embedding model they should use for their documents.\n",
    "\n",
    "In order to know this, you will need some dataset of questions that you might expect your knowledge base to receive.\n",
    "\n",
    "This can now be achieved at scale super quickly (2.1K questions in **63 seconds**) with the Transformation Agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'workflow_id': 'TransformationWorkflow-e979d5f69b91575e7289ab61d559cafa', 'status': {'batch_count': 0, 'end_time': None, 'start_time': '2025-03-12 01:21:58', 'state': 'running', 'total_duration': None, 'total_items': 0}}\n"
     ]
    }
   ],
   "source": [
    "from weaviate.agents.transformation import TransformationAgent\n",
    "from weaviate.agents.classes import Operations\n",
    "from weaviate.collections.classes.config import DataType\n",
    "\n",
    "create_questions = Operations.append_property(\n",
    "    property_name=\"predicted_user_query\",\n",
    "    data_type=DataType.TEXT,\n",
    "    view_properties=[\"content\"],\n",
    "    instruction=\"Based on the content of this blog chunk, generate a thoughtful information-seeking question that a reader might have after reading this material. The question should be specific to the technical content, concepts, or use cases mentioned in the text. Make sure the question is clear, concise, and directly related to the content provided.\",\n",
    ")\n",
    "\n",
    "agent = TransformationAgent(\n",
    "    client=weaviate_client,\n",
    "    collection=\"WeaviateBlogChunks\",\n",
    "    operations=[create_questions],\n",
    ")\n",
    "\n",
    "response = agent.update_all()\n",
    "\n",
    "# The response is a TransformationResponse object\n",
    "print(agent.get_status(workflow_id=response.workflow_id))  # Use the workflow_id to check the status of the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'workflow_id': 'TransformationWorkflow-e979d5f69b91575e7289ab61d559cafa',\n",
       " 'status': {'batch_count': 9,\n",
       "  'end_time': '2025-03-12 01:23:01',\n",
       "  'start_time': '2025-03-12 01:21:58',\n",
       "  'state': 'completed',\n",
       "  'total_duration': 63.097952,\n",
       "  'total_items': 2160}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.get_status(workflow_id=response.workflow_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TransformationResponse(operation_name='predicted_user_query', workflow_id='TransformationWorkflow-e979d5f69b91575e7289ab61d559cafa')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Synthetic Queries produced from the Blog Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogs_collection = weaviate_client.collections.get(\"WeaviateBlogChunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mExample #1\u001b[0m\n",
      "\u001b[36mBlog Content:\u001b[0m\n",
      "\n",
      "\u001b[36m---\n",
      "title: 'Introducing the Weaviate Query Agent'\n",
      "slug: query-agent\n",
      "authors: [charles-pierse, tuana, alvin]\n",
      "date: 2025-03-05\n",
      "tags: ['concepts', 'agents', 'release']\n",
      "image: ./img/hero.png\n",
      "description: \"Learn about the Query Agent, our new agentic search service that redefines how you interact with Weaviate’s database!\"\n",
      "---\n",
      "![Introducing the Weaviate Query Agent](./img/hero.png)\n",
      "\n",
      "\n",
      "We’re incredibly excited to announce that we’ve released a brand new service for our [Serverless Weaviate Cloud](https://weaviate.io/deployment/serverless) users (including free Sandbox users) to preview, currently in Alpha: the _**Weaviate Query Agent!**_ Ready to use now, this new feature provides a simple interface for users to ask complex multi-stage questions about your data in Weaviate, using powerful foundation LLMs. In this blog, learn more about what the Weaviate Query Agent is, and discover how you can build your own!\n",
      "\n",
      "Let’s get started. :::note \n",
      "This blog comes with an accompanying [recipe](https://github.com/weaviate/recipes/tree/main/weaviate-services/agents/query-agent-get-started.ipynb) for those of you who’d like to get started. :::\n",
      "\n",
      "## What is the Weaviate Query Agent\n",
      "\n",
      "AI Agents are semi- or fully- autonomous systems that make use of LLMs as the brain of the operation. This allows you to build applications that are able to handle complex user queries that may need to access multiple data sources. And, over the past few years we’ve started to build such applications thanks to more and more powerful LLMs capable of function calling, frameworks that simplify the development process and more.\u001b[0m\n",
      "\u001b[32mPredicted User Query:\u001b[0m\n",
      "\n",
      "\u001b[32mHow can I integrate the Weaviate Query Agent with my existing application to access multiple data sources using LLMs?\u001b[0m\n",
      "\n",
      "\u001b[37mExample #2\u001b[0m\n",
      "\u001b[36mBlog Content:\u001b[0m\n",
      "\n",
      "\u001b[36m:::note \n",
      "To learn more about what AI Agents are, read our blog [”Agents Simplified: What we mean in the context of AI”](https://weaviate.io/blog/ai-agents). :::\n",
      "\n",
      "**With the Query Agent, we aim to provide an agent that is inherently capable of handling complex queries over multiple Weaviate collections.** The agent understands the structure of all of your collections, so knows when to run searches, aggregations or even both at the same time for you. Often, AI agents are described as LLMs that have access to various tools (adding more to its capabilities), which are also able to make a plan, and reason about the response. Our Query Agent is an AI agent that is provided access to multiple Weaviate collections within a cluster. Depending on the user’s query, it will be able to decide which collection or collections to perform searches on.\u001b[0m\n",
      "\u001b[32mPredicted User Query:\u001b[0m\n",
      "\n",
      "\u001b[32mHow does the Query Agent decide which Weaviate collections to perform searches on based on a user's query?\u001b[0m\n",
      "\n",
      "\u001b[37mExample #3\u001b[0m\n",
      "\u001b[36mBlog Content:\u001b[0m\n",
      "\n",
      "\u001b[36mSo, you can think of the Weaviate Query Agent as an AI agent that has tools in the form of Weaviate Collections. In addition to access to multiple collections, the Weaviate Query Agent also has access to two internal agentic search workflows:\n",
      "\n",
      "-   Regular [semantic search](/blog/vector-search-explained) with optional filters\n",
      "-   Aggregations\n",
      "\n",
      "In essence, we’ve released a multi-agent system that can route queries to one or the other and synthesise a final answer for the user. ![Query Agent](img/query-agent.png)\n",
      "\n",
      "### Routing to Search vs Aggregations\n",
      "\n",
      "Not all queries are the same. While some may require us to do semantic search using embeddings over a dataset, other queries may require us to make [aggregations](https://weaviate.io/developers/weaviate/api/graphql/aggregate) (such as counting objects, calculating the average value of a property and so on). We can demonstrate the difference with a simple example.\u001b[0m\n",
      "\u001b[32mPredicted User Query:\u001b[0m\n",
      "\n",
      "\u001b[32mHow do I decide when to use semantic search versus aggregations in the Weaviate Query Agent?\u001b[0m\n",
      "\n",
      "\u001b[37mExample #4\u001b[0m\n",
      "\u001b[36mBlog Content:\u001b[0m\n",
      "\n",
      "\u001b[36mThis allows you to provide the agent with instructions on how it should behave. For example, below we provide a system prompt which instructs the agent to always respond in the users language:\n",
      "\n",
      "```python\n",
      "multi_lingual_agent = QueryAgent(\n",
      "    client=client, collections=[\"Ecommerce\", \"Brands\"],\n",
      "    system_prompt=\"You are a helpful assistant that always generated the final response in the users language.\"\n",
      "    \" You may have to translate the user query to perform searches. But you must always respond to the user in their own language.\"\n",
      ")\n",
      "```\n",
      "\n",
      "## Summary\n",
      "\n",
      "The Weaviate Query Agent represents a significant step forward in making vector databases more accessible and powerful. By combining the capabilities of LLMs with Weaviate's own search and aggregation features, we've created a tool that can handle complex queries across multiple collections while maintaining context and supporting multiple languages. The resulting agent can be used on its own, as well as within a larger agentic or multi-agent application.\u001b[0m\n",
      "\u001b[32mPredicted User Query:\u001b[0m\n",
      "\n",
      "\u001b[32mHow do I integrate the Weaviate Query Agent with a larger agentic or multi-agent application?\u001b[0m\n",
      "\n",
      "\u001b[37mExample #5\u001b[0m\n",
      "\u001b[36mBlog Content:\u001b[0m\n",
      "\n",
      "\u001b[36mWhether you're building applications that require semantic search, complex aggregations, or both, the Query Agent simplifies the development process while providing the flexibility to customize its behavior through system prompts. As we continue to develop and enhance this feature, we look forward to seeing how our community will leverage it to build even more powerful AI-driven applications. Ready to get started? Check out our [recipe](https://colab.research.google.com/github/weaviate/recipes/blob/main/weaviate-services/agents/query-agent-get-started.ipynb), join the discussion in our forum, and start building with the Weaviate Query Agent today!\n",
      "\n",
      "import WhatsNext from '/_includes/what-next.mdx'\n",
      "\n",
      "<WhatsNext />\u001b[0m\n",
      "\u001b[32mPredicted User Query:\u001b[0m\n",
      "\n",
      "\u001b[32mHow can I customize the behavior of the Query Agent through system prompts?\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = blogs_collection.query.hybrid(\n",
    "    query=\"What is the Weaviate Query Agent?\",\n",
    "    target_vector=[\"content_arctic_2_0\"],\n",
    "    return_properties=[\"content\", \"predicted_user_query\"],\n",
    "    limit=5\n",
    ").objects\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"\\033[37mExample #{i}\\033[0m\")\n",
    "    print(\"\\033[36mBlog Content:\\033[0m\\n\")\n",
    "    print(f\"\\033[36m{result.properties['content']}\\033[0m\")\n",
    "    print(\"\\033[32mPredicted User Query:\\033[0m\\n\")\n",
    "    print(f\"\\033[32m{result.properties['predicted_user_query']}\\033[0m\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Generated Dataset can be found on HuggingFace [here](https://huggingface.co/datasets/weaviate/weaviate-blogs-with-synthetic-questions)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Recall at 1, 5, and 100 (Arctic 1.5 vs. Arctic 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation...\n",
      "Processed 500 items...\n",
      "  Current Arctic 1.5 - Recall@1: 0.8140, Recall@5: 0.9380\n",
      "  Current Arctic 2.0 - Recall@1: 0.8780, Recall@5: 0.9760\n",
      "Processed 1000 items...\n",
      "  Current Arctic 1.5 - Recall@1: 0.8040, Recall@5: 0.9290\n",
      "  Current Arctic 2.0 - Recall@1: 0.8630, Recall@5: 0.9660\n",
      "Processed 1500 items...\n",
      "  Current Arctic 1.5 - Recall@1: 0.8027, Recall@5: 0.9287\n",
      "  Current Arctic 2.0 - Recall@1: 0.8493, Recall@5: 0.9567\n",
      "Processed 2000 items...\n",
      "  Current Arctic 1.5 - Recall@1: 0.7980, Recall@5: 0.9235\n",
      "  Current Arctic 2.0 - Recall@1: 0.8390, Recall@5: 0.9540\n",
      "Evaluation complete! Processed 2160 total items.\n",
      "FINAL RESULTS:\n",
      "Arctic 1.5 - Recall@1: 0.7995, Recall@5: 0.9245, Recall@100: 0.9995\n",
      "Arctic 2.0 - Recall@1: 0.8412, Recall@5: 0.9546, Recall@100: 0.9995\n"
     ]
    }
   ],
   "source": [
    "recall_at_1_arctic_1_5, recall_at_1_arctic_2_0 = [], []\n",
    "recall_at_5_arctic_1_5, recall_at_5_arctic_2_0 = [], []\n",
    "recall_at_100_arctic_1_5, recall_at_100_arctic_2_0 = [], []\n",
    "\n",
    "# Add counters for logging\n",
    "total_items = 0\n",
    "log_interval = 500\n",
    "\n",
    "print(f\"Starting evaluation...\")\n",
    "\n",
    "for item in blogs_collection.iterator():\n",
    "    gold_id = item.uuid\n",
    "\n",
    "    # Query with Arctic 1.5 model\n",
    "    arctic_1_5_results = blogs_collection.query.hybrid(\n",
    "        query=item.properties[\"predicted_user_query\"],\n",
    "        target_vector=[\"content_arctic_1_5\"],\n",
    "        limit=100\n",
    "    ).objects\n",
    "\n",
    "    # Query with Arctic 2.0 model\n",
    "    arctic_2_0_results = blogs_collection.query.hybrid(\n",
    "        query=item.properties[\"predicted_user_query\"],\n",
    "        target_vector=[\"content_arctic_2_0\"],\n",
    "        limit=100\n",
    "    ).objects\n",
    "\n",
    "    # Extract IDs for easier comparison\n",
    "    arctic_1_5_ids = [result.uuid for result in arctic_1_5_results]\n",
    "    arctic_2_0_ids = [result.uuid for result in arctic_2_0_results]\n",
    "\n",
    "    # Calculate recall@1 (if the gold ID is the first result)\n",
    "    recall_at_1_arctic_1_5.append(1 if arctic_1_5_ids and arctic_1_5_ids[0] == gold_id else 0)\n",
    "    recall_at_1_arctic_2_0.append(1 if arctic_2_0_ids and arctic_2_0_ids[0] == gold_id else 0)\n",
    "\n",
    "    # Calculate recall@5 (if the gold ID is in the first 5 results)\n",
    "    recall_at_5_arctic_1_5.append(1 if gold_id in arctic_1_5_ids[:5] else 0)\n",
    "    recall_at_5_arctic_2_0.append(1 if gold_id in arctic_2_0_ids[:5] else 0)\n",
    "\n",
    "    # Calculate recall@100 (if the gold ID is in the results at all)\n",
    "    recall_at_100_arctic_1_5.append(1 if gold_id in arctic_1_5_ids else 0)\n",
    "    recall_at_100_arctic_2_0.append(1 if gold_id in arctic_2_0_ids else 0)\n",
    "\n",
    "    # Increment counter\n",
    "    total_items += 1\n",
    "\n",
    "    # Log progress at specified intervals\n",
    "    if total_items % log_interval == 0:\n",
    "        # Calculate current metrics\n",
    "        current_recall_at_1_arctic_1_5 = sum(recall_at_1_arctic_1_5) / len(recall_at_1_arctic_1_5)\n",
    "        current_recall_at_1_arctic_2_0 = sum(recall_at_1_arctic_2_0) / len(recall_at_1_arctic_2_0)\n",
    "\n",
    "        current_recall_at_5_arctic_1_5 = sum(recall_at_5_arctic_1_5) / len(recall_at_5_arctic_1_5)\n",
    "        current_recall_at_5_arctic_2_0 = sum(recall_at_5_arctic_2_0) / len(recall_at_5_arctic_2_0)\n",
    "\n",
    "        print(f\"Processed {total_items} items...\")\n",
    "        print(f\"  Current Arctic 1.5 - Recall@1: {current_recall_at_1_arctic_1_5:.4f}, Recall@5: {current_recall_at_5_arctic_1_5:.4f}\")\n",
    "        print(f\"  Current Arctic 2.0 - Recall@1: {current_recall_at_1_arctic_2_0:.4f}, Recall@5: {current_recall_at_5_arctic_2_0:.4f}\")\n",
    "\n",
    "print(f\"Evaluation complete! Processed {total_items} total items.\")\n",
    "\n",
    "# Calculate average recall metrics\n",
    "avg_recall_at_1_arctic_1_5 = sum(recall_at_1_arctic_1_5) / len(recall_at_1_arctic_1_5) if recall_at_1_arctic_1_5 else 0\n",
    "avg_recall_at_1_arctic_2_0 = sum(recall_at_1_arctic_2_0) / len(recall_at_1_arctic_2_0) if recall_at_1_arctic_2_0 else 0\n",
    "\n",
    "avg_recall_at_5_arctic_1_5 = sum(recall_at_5_arctic_1_5) / len(recall_at_5_arctic_1_5) if recall_at_5_arctic_1_5 else 0\n",
    "avg_recall_at_5_arctic_2_0 = sum(recall_at_5_arctic_2_0) / len(recall_at_5_arctic_2_0) if recall_at_5_arctic_2_0 else 0\n",
    "\n",
    "avg_recall_at_100_arctic_1_5 = sum(recall_at_100_arctic_1_5) / len(recall_at_100_arctic_1_5) if recall_at_100_arctic_1_5 else 0\n",
    "avg_recall_at_100_arctic_2_0 = sum(recall_at_100_arctic_2_0) / len(recall_at_100_arctic_2_0) if recall_at_100_arctic_2_0 else 0\n",
    "\n",
    "# Print final results\n",
    "print(f\"FINAL RESULTS:\")\n",
    "print(f\"Arctic 1.5 - Recall@1: {avg_recall_at_1_arctic_1_5:.4f}, Recall@5: {avg_recall_at_5_arctic_1_5:.4f}, Recall@100: {avg_recall_at_100_arctic_1_5:.4f}\")\n",
    "print(f\"Arctic 2.0 - Recall@1: {avg_recall_at_1_arctic_2_0:.4f}, Recall@5: {avg_recall_at_5_arctic_2_0:.4f}, Recall@100: {avg_recall_at_100_arctic_2_0:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arctic Embed\n",
    "Here are some more resources to learn about the Snowflake Arctic Embedding models!\n",
    "\n",
    "\n",
    "• [Arctic Embed on GitHub](https://github.com/Snowflake-Labs/arctic-embed) <br />\n",
    "• [Arctic Embed 2.0 Research Report](https://arxiv.org/abs/2412.04506) <br />\n",
    "• [Arctic Embed Research Report](https://arxiv.org/abs/2405.05374) <br />\n",
    "• [Weaviate Podcast #110 with Luke Merrick, Puxuan Yu, and Charles Pierse!](https://www.youtube.com/watch?v=Kjqv4uk3RCs)\n",
    "\n",
    "## Massive thanks to Luke and Puxuan for reviewing this notebook!\n",
    "\n",
    "![Arctic Embed on the Weaviate Podcast](./images/pod-110-thumbnail.png \"Arctic Embed on the Weaviate Podcast!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
