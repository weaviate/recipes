{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ac2b9c7",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/weaviate/recipes/blob/main/integrations/llm-agent-frameworks/mem0/quickstart_mem0_with_weaviate.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5333229",
   "metadata": {},
   "source": [
    "# Parallel and Weaviate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab06e1b9",
   "metadata": {},
   "source": [
    "This notebook will illustrate how to create an AI system with DSPy that uses Parallel's Chat with the Web API and Weaviate's Query Agent!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8969c62",
   "metadata": {},
   "source": [
    "### Chat with the Web with Parallel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea315399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel Web Systems is a technology company that focuses on adapting the web for artificial intelligences. It builds web data and APIs for AI agents, and its work spans innovations across crawling, indexing, ranking, retrieval, and reasoning systems. The company's initial product is a set of APIs for AIs to do more with web data, turning web search and knowledge tasks into programmable, enterprise-ready infrastructure. Parallel aims to build a new programmatic web specifically for AIs with declarative, composable layers built around reasoning and computation, verifiable provenance, and open markets. ([parallel.ai](https://parallel.ai/), [linkedin.com](https://www.linkedin.com/company/parallel-web), [crunchbase.com](https://www.crunchbase.com/organization/parallel-463d), [aws.amazon.com](https://aws.amazon.com/marketplace/seller-profile?id=seller-rqcgpu6w7coya), [builtinsf.com](https://www.builtinsf.com/company/parallel-web-systems))\n",
      "\n",
      "Parallel's APIs are priced per request and not per token, so the cost of a query is known before it is run. ([parallel.ai](https://parallel.ai/pricing))\n",
      "\n",
      "The company was founded in 2023 by Travers Nisbet and Parag Agrawal. ([tracxn.com](https://tracxn.com/d/companies/parallel-web-systems/__eVpx1ski9jq0qE9UGTlgZJmYjrdoDZhSQDYHGZf7Cdw), [cbinsights.com](https://www.cbinsights.com/company/parallel-web-systems))\n",
      "\n",
      "Parallel Web Systems is based in San Francisco, California. ([tracxn.com](https://tracxn.com/d/companies/parallel-web-systems/__eVpx1ski9jq0qE9UGTlgZJmYjrdoDZhSQDYHGZf7Cdw), [cbinsights.com](https://www.cbinsights.com/company/parallel-web-systems))\n",
      "\n",
      "**Summary:**\n",
      "Parallel Web Systems is creating web data and APIs for AI agents, offering tools for web search, knowledge retrieval, and reasoning. It was founded in 2023 and is based in San Francisco.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "parallel_client = OpenAI(\n",
    "    api_key=os.environ[\"PARALLEL_API_KEY\"],  # Your Parallel API key\n",
    "    base_url=\"https://api.parallel.ai\"  # Parallel's API beta endpoint\n",
    ")\n",
    "\n",
    "def get_parallel_response(\n",
    "    parallel_client: OpenAI,\n",
    "    query: str\n",
    ") -> str:\n",
    "    response = parallel_client.chat.completions.create(\n",
    "        model=\"speed\", # Parallel model name\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "response = get_parallel_response(parallel_client, \"What does Parallel Web Systems do?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e8ba67",
   "metadata": {},
   "source": [
    "### Chat with Data Stored in Weaviate with Weaviate's Query Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8bf3668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mâ•­â”€\u001b[0m\u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[36m ðŸ’¬ Ask Mode Response \u001b[0m\u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[36mâ”€â•®\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m                                                                              \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mHyDE (Hypothetical Document Embeddings) is a method designed for zero-shot \u001b[0m\u001b[36m \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mdense retrieval that does not require any supervised relevance labels. It \u001b[0m\u001b[36m  \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mworks by decomposing the retrieval task into two main components:\u001b[0m\u001b[36m           \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36m                                                                            \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36m1. **Generative Hypothetical Document Creation:**\u001b[0m\u001b[36m                           \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36m   Given a user query, an instruction-following large language model (LLM) \u001b[0m\u001b[36m \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36msuch as InstructGPT is prompted to generate a hypothetical document that \u001b[0m\u001b[36m   \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36m\"answers\" the query. This generated text is not a real document and may \u001b[0m\u001b[36m    \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mcontain hallucinated or factually inaccurate information, but it is intended\u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mto capture the relevance patterns of what a relevant document for that query\u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mmight look like.\u001b[0m\u001b[36m                                                            \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36m                                                                            \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36m2. **Encoding and Retrieval via Contrastive Encoder:**\u001b[0m\u001b[36m                      \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36m   This hypothetical document is then encoded into a dense vector using an \u001b[0m\u001b[36m \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36munsupervised contrastive text encoder (e.g., Contriever). Because \u001b[0m\u001b[36m          \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mcontrastive encoders are trained to capture document-to-document similarity \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36min an embedding space, this representation acts as a lossy compression that \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mfilters out inaccuracies from the generated document while preserving \u001b[0m\u001b[36m      \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36msemantic relevance.\u001b[0m\u001b[36m                                                         \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36m                                                                            \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mAfter encoding, the resulting hypothetical document embedding serves as the \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mquery vector. Retrieval is performed by finding real documents in the corpus\u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mwith embeddings close to this query embedding, leveraging \u001b[0m\u001b[36m                  \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mdocument-to-document similarity.\u001b[0m\u001b[36m                                            \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36m                                                                            \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36m**Key points about HyDE:**\u001b[0m\u001b[36m                                                  \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36m- HyDE does not explicitly model query-document relevance. Instead, it \u001b[0m\u001b[36m     \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mpivots the retrieval task into generating a relevance-capturing example \u001b[0m\u001b[36m    \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mdocument and performing document-to-document similarity matching.\u001b[0m\u001b[36m           \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36m- It works fully zero-shot without any training or fine-tuning specific to \u001b[0m\u001b[36m \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mthe retrieval task, using off-the-shelf LLMs and contrastive encoders.\u001b[0m\u001b[36m      \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36m- Experiments show that HyDE significantly outperforms state-of-the-art \u001b[0m\u001b[36m    \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36munsupervised dense retrievers like Contriever across a wide range of tasks \u001b[0m\u001b[36m \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36m(web search, QA, fact verification) and languages, and its performance \u001b[0m\u001b[36m     \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mrivals some supervised, fine-tuned models.\u001b[0m\u001b[36m                                  \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36m- Because the hypothetical documents are generated on the fly, HyDE may have\u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mhigher inference costs and latency than traditional encoders but offers \u001b[0m\u001b[36m    \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mstrong out-of-the-box capability, especially useful at the early stages of \u001b[0m\u001b[36m \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36msearch system development or for novel queries.\u001b[0m\u001b[36m                             \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36m- The use of an LLM to generate hypothetical documents effectively delegates\u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mrelevance modeling to a flexible generative model, eliminating the \u001b[0m\u001b[36m         \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mchallenging need to directly learn query-document relevance embeddings in \u001b[0m\u001b[36m  \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mzero-shot settings.\u001b[0m\u001b[36m                                                         \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36m                                                                            \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mIn summary, HyDE works by generating a hypothetical document that would \u001b[0m\u001b[36m    \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36manswer the query and then using dense retrieval to find corpus documents \u001b[0m\u001b[36m   \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36msimilar to this generated \"answer,\" thus leveraging generation and dense \u001b[0m\u001b[36m   \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m \u001b[0m\u001b[36mretrieval strengths in a unified zero-shot retrieval approach.\u001b[0m\u001b[36m              \u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ”‚\u001b[0m\u001b[36m                                                                              \u001b[0m\u001b[36mâ”‚\u001b[0m\n",
      "\u001b[36mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n",
      "\u001b[37mâ•­â”€\u001b[0m\u001b[37mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[37m ðŸ”­ Search 1/1 \u001b[0m\u001b[37mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[37mâ”€â•®\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m                                                                              \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m \u001b[0m\u001b[1;35mQueryResultWithCollectionNormalized\u001b[0m\u001b[1;37m(\u001b[0m\u001b[37m                                        \u001b[0m\u001b[37m \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m \u001b[0m\u001b[37m    \u001b[0m\u001b[33mquery\u001b[0m\u001b[37m=\u001b[0m\u001b[32m'HyDE explanation mechanism approach method'\u001b[0m\u001b[37m,\u001b[0m\u001b[37m                     \u001b[0m\u001b[37m \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m \u001b[0m\u001b[37m    \u001b[0m\u001b[33mfilters\u001b[0m\u001b[37m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[37m,\u001b[0m\u001b[37m                                                           \u001b[0m\u001b[37m \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m \u001b[0m\u001b[37m    \u001b[0m\u001b[33mcollection\u001b[0m\u001b[37m=\u001b[0m\u001b[32m'IRPapersText_Default'\u001b[0m\u001b[37m,\u001b[0m\u001b[37m                                      \u001b[0m\u001b[37m \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m \u001b[0m\u001b[37m    \u001b[0m\u001b[33msort_property\u001b[0m\u001b[37m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[37m                                                      \u001b[0m\u001b[37m \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m \u001b[0m\u001b[1;37m)\u001b[0m\u001b[37m                                                                           \u001b[0m\u001b[37m \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m                                                                              \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n",
      "\u001b[91mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
      "\u001b[91mâ”‚\u001b[0m\u001b[91m                                                                              \u001b[0m\u001b[91mâ”‚\u001b[0m\n",
      "\u001b[91mâ”‚\u001b[0m\u001b[91m \u001b[0m\u001b[91mðŸ“Š No Aggregations Run\u001b[0m\u001b[91m                                                      \u001b[0m\u001b[91m \u001b[0m\u001b[91mâ”‚\u001b[0m\n",
      "\u001b[91mâ”‚\u001b[0m\u001b[91m                                                                              \u001b[0m\u001b[91mâ”‚\u001b[0m\n",
      "\u001b[91mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n",
      "\u001b[37mâ•­â”€\u001b[0m\u001b[37mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[37m ðŸ“š Sources \u001b[0m\u001b[37mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[37mâ”€â•®\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m                                                                              \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m \u001b[0m\u001b[37m - object_id='47f51339-c053-4ef5-8f67-b7e09494fcb4' \u001b[0m\u001b[37m                        \u001b[0m\u001b[37m \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m \u001b[0m\u001b[37mcollection='IRPapersText_Default'\u001b[0m\u001b[37m                                           \u001b[0m\u001b[37m \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m \u001b[0m\u001b[37m - object_id='ad50efd6-926c-477d-b5ef-967d14f6e6c1' \u001b[0m\u001b[37m                        \u001b[0m\u001b[37m \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m \u001b[0m\u001b[37mcollection='IRPapersText_Default'\u001b[0m\u001b[37m                                           \u001b[0m\u001b[37m \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m \u001b[0m\u001b[37m - object_id='4dd52859-1dfe-4d2a-b7c7-855c72c41d3a' \u001b[0m\u001b[37m                        \u001b[0m\u001b[37m \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m \u001b[0m\u001b[37mcollection='IRPapersText_Default'\u001b[0m\u001b[37m                                           \u001b[0m\u001b[37m \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m \u001b[0m\u001b[37m - object_id='9ced8a70-8870-43e4-8e7e-95f147225a38' \u001b[0m\u001b[37m                        \u001b[0m\u001b[37m \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m \u001b[0m\u001b[37mcollection='IRPapersText_Default'\u001b[0m\u001b[37m                                           \u001b[0m\u001b[37m \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m \u001b[0m\u001b[37m - object_id='d1a893e5-e546-47be-ac7a-f0c35f30c643' \u001b[0m\u001b[37m                        \u001b[0m\u001b[37m \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m \u001b[0m\u001b[37mcollection='IRPapersText_Default'\u001b[0m\u001b[37m                                           \u001b[0m\u001b[37m \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m \u001b[0m\u001b[37m - object_id='5e9a878b-322a-4bb4-af25-78f2157f6407' \u001b[0m\u001b[37m                        \u001b[0m\u001b[37m \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m \u001b[0m\u001b[37mcollection='IRPapersText_Default'\u001b[0m\u001b[37m                                           \u001b[0m\u001b[37m \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ”‚\u001b[0m\u001b[37m                                                                              \u001b[0m\u001b[37mâ”‚\u001b[0m\n",
      "\u001b[37mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[3m        ðŸ“Š Usage Statistics        \u001b[0m\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ Model Units:             â”‚ 555  â”‚\n",
      "â”‚ Usage in Plan:           â”‚ True â”‚\n",
      "â”‚ Remaining Plan Requests: â”‚ -1   â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "\u001b[1;36mTotal Time Taken:\u001b[0m\u001b[36m \u001b[0m\u001b[1;36m11.\u001b[0m\u001b[36m92s\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "from weaviate.agents.query import QueryAgent\n",
    "\n",
    "weaviate_client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=os.getenv(\"WEAVIATE_URL\"),\n",
    "    auth_credentials=Auth.api_key(os.getenv(\"WEAVIATE_API_KEY\"))\n",
    ")\n",
    "\n",
    "query_agent = QueryAgent(\n",
    "    client=weaviate_client,\n",
    "    collections=[\"IRPapersText_Default\"]\n",
    ")\n",
    "\n",
    "response = query_agent.ask(\n",
    "    \"How does HyDE work?\"\n",
    ")\n",
    "\n",
    "response.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b10bd7b",
   "metadata": {},
   "source": [
    "### Combine Retrieval from Parallel and Weaviate with DSPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1c79ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello! How can I help you today? ðŸ˜Š']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "lm = dspy.LM(\n",
    "    \"openai/gpt-4.1\"\n",
    ")\n",
    "\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "lm(\"say hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d039b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyDE (Hypothetical Document Embeddings) is a zero-shot dense retrieval method that improves information retrieval by first prompting a large language model to generate a hypothetical document answering a query, then encoding this document into an embedding vector using a contrastive encoder. This embedding is used to retrieve similar real documents from a corpus, enabling effective retrieval without the need for relevance labels or supervised training.\n",
      "\n",
      "The original HyDE paper, \"Precise Zero-Shot Dense Retrieval without Relevance Labels,\" has 578 citations as of November 2025.\n"
     ]
    }
   ],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Assess the context and answer the question.\"\"\"\n",
    "\n",
    "    web_context = dspy.InputField(description=\"Context gathered from the web.\")\n",
    "    my_knowledge_base_context = dspy.InputField(description=\"Context gathered from my knowledge base.\")\n",
    "    question = dspy.InputField(description=\"The question to answer.\")\n",
    "\n",
    "    answer = dspy.OutputField(description=\"The answer to the question.\")\n",
    "\n",
    "class QASystem(dspy.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        parallel_client: OpenAI,\n",
    "        weaviate_client: weaviate.client.WeaviateClient,\n",
    "        weaviate_collections: list[str]\n",
    "    ):\n",
    "        self.parallel_client = parallel_client\n",
    "        self.weaviate_client = weaviate_client\n",
    "        self.weaviate_query_agent = QueryAgent(\n",
    "            client=self.weaviate_client,\n",
    "            collections=weaviate_collections\n",
    "        )\n",
    "\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "    \n",
    "    def _get_parallel_response(\n",
    "        self,\n",
    "        query: str\n",
    "    ) -> str:\n",
    "        response = self.parallel_client.chat.completions.create(\n",
    "            model=\"speed\", # Parallel model name\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": query}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def _get_weaviate_query_agent_response(\n",
    "        self,\n",
    "        query: str\n",
    "    ) -> str:\n",
    "        return self.weaviate_query_agent.ask(query).final_answer\n",
    "    \n",
    "    def __call__(\n",
    "        self,\n",
    "        question: str\n",
    "    ) -> str:\n",
    "        web_context = self._get_parallel_response(question)\n",
    "        my_knowledge_base_context = self._get_weaviate_query_agent_response(question)\n",
    "\n",
    "        answer = self.generate_answer(\n",
    "            web_context=web_context,\n",
    "            my_knowledge_base_context=my_knowledge_base_context,\n",
    "            question=question\n",
    "        )\n",
    "\n",
    "        return answer\n",
    "    \n",
    "qasystem = QASystem(\n",
    "    parallel_client=parallel_client,\n",
    "    weaviate_client=weaviate_client,\n",
    "    weaviate_collections=[\"IRPapersText_Default\"]\n",
    ")\n",
    "\n",
    "response = qasystem(\"What is HyDE and how many citations does it have?\")\n",
    "\n",
    "print(response.answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
