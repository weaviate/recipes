{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d9b9b8d",
   "metadata": {},
   "source": [
    "# Curate Web Datasets with Parallel to store in Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4a17be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Created. Run ID: trun_813763841ce54ca889b9a51e0964712e\n",
      "TaskRunJsonOutput(basis=[FieldBasis(field='security_and_robustness_challenges', reasoning='The finegrained field describes a data poisoning threat to RAG systems, where adversaries contaminate external knowledge bases or indices, causing the LLM to retrieve and generate based on false or malicious information. Excerpts that directly address this risk include statements that RAG architectures introduce new attack surfaces and security vulnerabilities when external data sources are integrated. Further, benchmarks like SafeRAG explicitly examine security in RAG pipelines and outline attack classes that can bypass retrievers, filters, or generators, which aligns with data-poisoning risk as a form of retrieval corruption. Several sources frame the problem within threat models and attack surfaces for RAG systems, highlighting that the integration of external knowledge corpora creates unique avenues for manipulation. Additionally, more general discussions on RAG security and privacy illustrate the broader context in which data poisoning would operate, including the need for robust defenses and evaluation strategies. Collectively, these excerpts support the field value by identifying the data-poisoning threat within RAG/Agentic RAG ecosystems and by outlining the architectural and evaluative spaces where such threats arise and are studied.', citations=[Citation(url='https://arxiv.org/html/2509.20324v1', excerpts=['AG systems introduce novel attack vectors for privacy and security breaches due to their hybrid architecture, which combines a retriever ‚Ñõ \\\\\\\\mathcal{R} that accesses data from an external knowledge base ùíü \\\\\\\\mathcal{D} with an LLM generator ùí¢ \\\\\\\\mathcal{G} . In a RAG architecture, attacks can emerge at different stages of the process. At Step 3, adversaries may attempt to compromise the integrity of the knowledge base, while Step 8 presents a privacy risk due to the leakage of retrieved verbatim conten', '## III Threat Model and Attack Surfaces'], title='RAG Security and Privacy: Formalizing the Threat Model ...'), Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=[' We reveal four attack tasks capable of bypassing the _retriever_ , _filter_ , and _generator_ .', 'First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.', 'The _indexing-retrieval-generation_ paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs). However, the incorporation of external and unverified knowledge increases the vulnerability of LLMs because attackers can perform attack tasks by manipulating knowledge.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['Logs might inadvertently\\n\\nstore sensitive user data'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)')], confidence='high'), FieldBasis(field='rag_advancements_analysis', reasoning='The top excerpts explicitly describe the evolution of RAG from static retrieval to agentic and modular forms. One excerpt frames agentic RAG as a late-2024 to 2025 shift where the agent plans actions, uses tools, and self-corrects, marking a clear transition from static retrieval to autonomous, self-directed reasoning. Another excerpt highlights a progression narrative: Modular RAG as a toolkit with interchangeable components enabling highly optimized, use-case-specific workflows, and SELF-RAG as a near-term advancement that introduces reflection and retrieval critique during the process. Additional excerpts discuss a taxonomy that differentiates Naive RAG, Advanced RAG, and Modular RAG, and notes that agentic RAG blurs the line between RAG and agent platforms, driven by planning and tool use. Together, these excerpts support the field value by detailing the concrete stages of RAG evolution (basic to advanced to agentic), the incorporation of reasoning into retrieval (self-critique, reflection tokens), and the architectural shift toward modularity and agency. Supporting statements also describe post-2023 developments (CRAG, self-reflection, and retrieval evaluators) that underpin robustness and reliability in later stages. The combination of historical context (pre-2023 basics) and contemporary advances (late 2023‚Äì2025 agentic/Modular RAG) aligns with the field value‚Äôs emphasis on evolution, autonomy, and integrated reasoning in RAG systems.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', '4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.'], title='Evolution of RAG from Static Knowledge to Agentic ...'), Citation(url='https://ragflow.io/blog/rag-at-the-crossroads-mid-2025-reflections-on-ai-evolution', excerpts=['Retrieval-Augmented Generation (RAG) as well: although academic papers on RAG continue to be plentiful, significant breakthroughs have been few and far between in recent months.', 'RAG‚Äôs value as a distinct architectural layer is now more pronounced than ever.'], title=\"RAG at the Crossroads - Mid-2025 Reflections on AI's Incremental ...\"), Citation(url='https://arxiv.org/html/2505.10468v1', excerpts=['The progression toward AI Agents is inseparable from the strategic integration of LLMs as reasoning engines and their augmentation through structured tool use. This synergy transforms static language models into dynamic cognitive entities capable of perceiving, planning, acting, and adapting setting the stage for multi-agent collaboration, persistent memory, and scalable autonomy.', 'These capabilities have opened pathways for more robust behavior of AI agents such as long-horizon planning, cross-tool coordination, and adaptive learning loops.', 'May 15, 2025 ‚Äî This review critically distinguishes between AI Agents and Agentic AI, offering a structured conceptual taxonomy, application mapping, and challenge analysis'], title='AI Agents vs. Agentic AI: A Conceptual Taxonomy, ...'), Citation(url='https://arxiv.org/abs/2506.00054', excerpts=['This survey provides a comprehensive synthesis of recent advances in RAG systems, offering a taxonomy that categorizes architectures into retriever-centric, generator-centric, hybrid, and robustness-oriented designs.', 'We systematically analyze enhancements across retrieval optimization, context filtering, decoding control, and efficiency improvements, supported by comparative performance analyses on short-form and multi-hop question answering tasks.', 'We conclude by identifying open challenges and future research directions, including adaptive retrieval architectures, real-time retrieval integration, structured reasoning over multi-hop evidence, and privacy-preserving retrieval mechanisms.', 'state-of-the-art evaluation frameworks and benchmarks, highlighting trends in retrieval-aware evaluation, robustness testing, and federated retrieval settings.', 'This survey aims to consolidate current knowledge in RAG research and serve as a foundation for the next generation of retrieval-augmented language modeling systems.'], title='[2506.00054] Retrieval-Augmented Generation')], confidence='high'), FieldBasis(field='influential_architectural_and_model_trends', reasoning='The most relevant excerpts describe Agentic RAG as a meaningful architectural shift where an LLM-based agent can plan sequences of actions, trigger external searches, reason over retrieved content, and self-correct. For example, one excerpt defines Agentic RAG as an architecture where an Agent plans a sequence of actions, can query, read, re-query, use tools, and self-correct, incorporating reflection, planning, tool use, and collaboration capabilities, which directly aligns with the stated trend name and its impact on web search. Related material highlights the integration of reasoning and acting via frameworks like ReAct and Search-o1, which are concrete implementations of agentic retrieval and reasoning, including when to invoke searches and how to distill retrieved content for answer generation. Additional excerpts discuss how such agentic approaches move beyond static retrieval by enabling multi-hop reasoning and autonomous web navigation, which is precisely the described impact on web search and agentic browsing. Several sources explicitly connect Agentic RAG to multi-step retrieval, dynamic querying of data sources, and the use of external tools (calculators, SQL, APIs), which corroborates the described cost, latency, and trade-offs while stressing the enhanced capabilities and organizational adoption in platforms like AutoGPT and enterprise solutions. Broader surveys and reviews trace the evolution from naive RAG toward advanced and agentic paradigms, including Self-RAG and context engineering, which further substantiates the field‚Äôs trajectory toward richer context management and grounded reasoning. Taken together, these excerpts support the field value by confirming the trend‚Äôs name, its defining capabilities (planning, tool use, reasoning, external querying), its impact on web search and agentic browsing (multi-hop, dynamic data gathering, grounding), and the practical considerations (latency and cost) associated with Agentic RAG implementations.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Large Reasoning Model-based : A growing trend in Agentic RAG workflow involves directly utilizing LLMs that possess inherently strong reasoning capabilities, often referred to as Large Reasoning Models (LRMs).', 'For Agentic RAG, function calling provides a straightforward and structured way for the LLM agent to invoke a search API when its internal analysis determines that external information is required to answer a prompt accurately.', 'This addresses a key limitation of many existing agents, whether prompt-engineered or trained in simulated/static RAG settings, which often struggle with the complexities of real-world web interaction.', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', ' ‚Äì Late 2022\\n\\n* ReAct is a seminal prompting paradigm that fundamentally enabled ‚Äúagentic‚Äù behavior in Large Language Models (LLMs). While not a Retrieval-Augmented Generation (RAG) method itself, ReAct provides the architectural foundation for advanced, multi-step RAG systems. * ReAct combines Reasoning (using Chain-of-Thought style prompts) with Acting (executing external actions like API calls or web searches) in a deliberately interleaved sequence:', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', 'Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. R', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. '], title='Evolution of RAG from Static Knowledge to Agentic ...'), Citation(url='https://arxiv.org/html/2505.10468v1', excerpts=['The progression toward AI Agents is inseparable from the strategic integration of LLMs as reasoning engines and their augmentation through structured tool use. This synergy transforms static language models into dynamic cognitive entities capable of perceiving, planning, acting, and adapting setting the stage for multi-agent collaboration, persistent memory, and scalable autonomy.', 'These capabilities have opened pathways for more robust behavior of AI agents such as long-horizon planning, cross-tool coordination, and adaptive learning loops.', 'May 15, 2025 ‚Äî This review critically distinguishes between AI Agents and Agentic AI, offering a structured conceptual taxonomy, application mapping, and challenge analysis'], title='AI Agents vs. Agentic AI: A Conceptual Taxonomy, ...'), Citation(url='https://arxiv.org/pdf/2503.22458?', excerpts=[' 11. A Roadmap of Evaluation of LLM-based Agents for Multi-turn Conversation. The blue line represents the development of\\n\\nmetrics and benchmark for Multi-turn Conversation. The orange line represents the development of Multi-turn Conversation\\n\\nand Le [216] introduced models that improved fluency and context understanding. New evaluation metrics like\\n\\nBLEU [ 165 ] and perplexity [ 90 ] emerged to measure generation quality over multiple turns. Researchers started\\n\\nrecognizing the limitations of purely reference-based metrics and began incorporating more contextual and\\n\\ndiversity-oriented frameworks (e.g., human preference ratings, embedding-based scores)'], title='Evaluating LLM-based Agents for Multi-Turn Conversations'), Citation(url='https://arxiv.org/html/2506.18959v3', excerpts=['In contrast, HLE focuses on presenting expert-level questions across diverse academic domains that cannot be solved through naive retrieval alone.', 'Equipped with TTS on reasoning and search, LLMs are set to drive a new search paradigm termed Agentic Deep Research systems, which are capable of autonomous re asoning , on-demand search ing , and iterative information synthesis.', 'Equipped with TTS on reasoning and search, LLMs are set to drive a new search paradigm termed Agentic Deep Research systems, which are capable of autonomous re asoning , on-demand search ing , and iterative information synthesis.'], title='From Web Search towards Agentic Deep Research'), Citation(url='https://arxiv.org/html/2506.18959v1', excerpts=['In contrast, HLE focuses on presenting expert-level questions across diverse academic domains that cannot be solved through naive retrieval alone.', 'Equipped with TTS on reasoning and search, LLMs are set to drive a new search paradigm termed Agentic Deep Research systems, which are capable of autonomous re asoning , on-demand search ing , and iterative information synthesis.', 'These agents learn to decompose complex tasks, plan query sequences, verify evidence, and adjust their strategies based on environment feedback.', 'These agents learn to decompose complex tasks, plan query sequences, verify evidence, and adjust their strategies based on environment feedback.'], title='From Web Search towards Agentic Deep ReSearch'), Citation(url='https://www.kdnuggets.com/7-free-web-search-apis-for-ai-agents', excerpts=['Sep 16, 2025 ‚Äî 2. Tavily. Tavily is a search engine for AI agents and LLMs that turns queries into vetted, LLM-ready insights in a single API call.'], title='7 Free Web Search APIs for AI Agents')], confidence='high'), FieldBasis(field='llm_powered_search_engine_integration', reasoning='The core value asserts that LLM-powered, generative search integrates large language models into the search process to retrieve and synthesize information from multiple web sources into a single, coherent response with citations, moving toward a zero-click experience. Excerpts explicitly describe generative search as retrieving pages and then generating a synthesized answer, often with citations, and contrast it with traditional ranked-result search. They also provide concrete platform examples (AI Overviews, Copilot, ChatGPT Search) and discuss implications for publishers and SEO. Additional excerpts show how major tech players (Google, Microsoft) describe their own implementations of web-grounded, citation-backed generation, which reinforces the claim that this integration is becoming a mainstream paradigm. Direct statements about zero-click futures, the role of citations, and the strategic shifts in search semantics (from listing links to providing synthesized answers) support the field value. Several excerpts further illustrate practical adoption and challenges (hallucination reduction, grounding in web data, re-ranking and clarifying questions) that align with the described generative search paradigm.', citations=[Citation(url='https://arxiv.org/html/2510.11560v1', excerpts=['In information-seeking contexts, retrieval-augmented generation (RAG) enhances LLMs with external knowledge to improve factuality (He et al., [2024](https://arxiv.org/html/2510.11560v1.bib15) ; Shi et al., [2025](https://arxiv.org/html/2510.11560v1.bib36) ; Jo et al., [2025](https://arxiv.org/html/2510.11560v1.bib21) ) .', 'lts also highlight the need for revisiting evaluation criteria for web search in the age of Generative AI.', 'Generative search differs from traditional web search along several key dimensions: (i) Different output format: The two search types result in differently formatted outputs.'], title='Characterizing Web Search in The Age of Generative AI'), Citation(url='https://blog.google/products/search/generative-ai-google-search-may-2024/', excerpts=[' Now, with generative AI, Search can do more than you ever imagined. So you can ask whatever‚Äôs on your mind or whatever you need to get done ‚Äî from researching to planning to brainstorming ‚Äî and Google will take care of the legwork. This is all made possible by a new Gemini model customized for Google Search. It brings together Gemini‚Äôs advanced capabilities ‚Äî including multi-step reasoning, planning and multimodality ‚Äî with our best-in-class Search systems. ', ' Get quick answers with AI Overviews\\n', ' So today, AI Overviews will begin rolling out to everyone in the U.S., with more countries coming soon. That means that this week, hundreds of millions of users will have access to AI Overviews, and we expect to bring them to over a billion people by the end of the year.\\n', '.\\nWith AI Overviews, people are visiting a greater diversity of websites for help with more complex questions. And we see that the links included in AI Overviews get more clicks than if the page had appeared as a traditional web listing for that query. As we expand this experience, we‚Äôll continue to focus on sending valuable traffic to publishers and creators. As always, ads will continue to appear in dedicated slots throughout the page, with clear labeling to distinguish between organic and sponsored results.', '. This is all made possible by a new Gemini model customized for Google Search. It brings together Gemini‚Äôs advanced capabilities ‚Äî including multi-step reasoning, planning and multimodality ‚Äî with our best-in-class Search systems.'], title='Generative AI in Search: Let Google do the searching for you'), Citation(url='https://sociallyin.com/gemini-ai-statistics/', excerpts=['Gemini 1.5 Pro shatters previous limitations with its **2 million token context wind', 'This is the longest of any large-scale foundation model currently available', '15 times larger** than GPT-4'], title='50+ Google Gemini AI Statistics for 2025 - Sociallyin'), Citation(url='https://learn.microsoft.com/en-us/copilot/overview', excerpts=['Nov 11, 2025 ‚Äî Copilot Chat is AI chat grounded in data from the web and powered by the latest large language models (LLMs). Copilot Chat lets users access agents and create\\xa0...'], title='Overview of Microsoft 365 Copilot Chat'), Citation(url='https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/microsoft/msc/documents/presentations/CSR/Responsible-AI-Transparency-Report-2025-vertical.pdf', excerpts=['Aug 19, 2025 ‚Äî Our report highlights new developments related to how we build and deploy. AI systems responsibly, how we support our customers and the broader ecosystem, and\\xa0...'], title='2025 Responsible AI Transparency Report'), Citation(url='https://learn.microsoft.com/en-us/compliance/anz/blueprint-copilot-servicecom', excerpts=[\"1. In a Microsoft 365 app, a user enters a prompt in Copilot. 2. Copilot preprocesses the input prompt using grounding and accesses Microsoft Graph in the user's tenant, or if enabled, from other platforms. 3. If web-grounding is enabled, Copilot gathers information from the Bing Index. 4. Copilot sends the grounded prompt to the LLM. The LLM uses the prompt to generate a response that is contextually relevant to the user's task. 5. Copilot returns the response to the app and the user. The prompt and the results are both logged and available for admins to view via the Data Security Posture Management (DSPM) for AI capability in Microsoft Purview. For more information on how the Microsoft 365 Copilot works, see the [architectural walkthrough](/en-us/copilot/microsoft-365/microsoft-365-copilot-architecture) .\", 'Microsoft 365 Copilot introduces an additional search indexing method to embed semantic understanding of concepts and language into the Microsoft Graph and enable Copilot and Microsoft 365 Search to better understand natural language expressions. This indexation method significantly improves the ability for Copilot to locate and use the most relevant content. This additional natural language data is called the [Semantic Index](/en-us/microsoftsearch/semantic-index-for-copilot) .', \"pilot/agents) are part of the Microsoft 365 Copilot ecosystem. They enhance productivity by automating tasks and processes through advanced AI capabilities. They're available in both Microsoft 365 Copilot and in Copilot Chat experiences. Copilot Agents connect to an organization‚Äôs knowledge and data sources. By doing so, they can access and utilize specific documents, databases, and other information repositories to provide accurate and contextually relevant responses. This connectivity is facilitated through APIs and connectors that link the agents to various data sources, ensuring that they can retrieve and process the necessary information in real-time.\", 'Plugins (Bing, etc.) are distinct from Connectors in that they run in real-time during the interaction execution to provide new skills and knowledge to Copilot. For example, the included Access to web content (Bing integration) Plugin allows real-time integration of public web content to enrich the knowledge available to Copilot. The web content plugin enables a new real-time query source for Copilot to include. It enables Copilot to search not only for the content from inside the Microsoft 365 organization (via the Microsoft Graph) but also web content (via Bing Index) in parallel. This capability can be useful for integrating public content on a subject with private knowledge contained within the Microso'], title='Service components for Copilot aligning to Blueprint'), Citation(url='https://techcommunity.microsoft.com/blog/microsoft365copilotblog/microsoft-365-copilot-web-search-delivering-multiple-layers-of-protection-and-co/4458224', excerpts=['When you ask Microsoft 365 Copilot or Copilot Chat a question about something that changes fast ‚Äì earnings updates, a regulatory shift, or a breaking news item ‚Äì access to current information is critical.', 'That‚Äôs why Copilot can ground its answers with current information from the web, closing knowledge gaps that every large language model (LLM) inevitably has based on its training data cutoff.', 'Traditional web search engines are optimized for broad consumer scenarios. Copilot‚Äôs web search is enterprise oriented and layered with controls that consumer search does not provide.', 'A Copilot interaction has three parts: your prompt, a web query (if needed), and the response.', ' The prompt remains inside the Microsoft 365 service boundary with enterprise data protection.\\n', 'That query is stripped of user and tenant identifiers, and does not include any files uploaded in the original prompt. The query is sent securely to the Bing Search Service; relevant web data is returned securely.', 'Response:** Copilot composes an answer grounded on approved enterprise content and the cited web results. In the UI, users see source citations and the exact keywords that were emitted as the web quer', \"ansparency by design:** Users can inspect both the citations and the exact keywords used for web grounding. Additionally, the user's prompts and Copilot's responses are stored within Microsoft 365 and never leave the service boundary for Copilot without customer direction.\", 'Copilot‚Äôs web search is designed with multiple layers of controls that administrators and users can rely on every time a web query is involved. These layers ‚Äì admin controls, user protections, query safeguards, and contractual commitments ‚Äì work together to provide secure, transparent, policy-driven handling of web search in Copilot:', '#### Admin Controls\\n\\nAdministrators have precise authority over how and when web search is permitted in Copilot.\\nThe Allow Web Search policy lets them scope access by user or group, and by mode (Work vs. Web). [Additionally, audit and eDiscovery capabilities provide transparency](https://aka.ms/IntroducingWebQueryTransparency) . Every emitted web query is logged and can be linked to the originating prompt and response. These [logs are accessible](https://learn.microsoft.com/en-us/copilot/microsoft-365/manage-public-web-access) through Microsoft Purview eDiscovery and Data Security Posture Management activity explorer, enabling targeted audits and investigations when needed', '### User Protections\\n\\nUsers also have control. In the Work tab, they can toggle web grounding on or off, choosing to stay ‚Äúwork only‚Äù or bring in the web when needed. This flexibility empowers users to tailor their experience based on context. Copilot also enforces responsible AI (RAI) protections, which automatically reject certain terms, phrases, or patterns that may pose risks. Transparency is built into the experience, so users see citations to sources and the exact keywords Copilot securely sends out when performing web grounding.', '#### Query Protections\\n\\nCopilot sends only the essential keywords needed to retrieve current information. It avoids transmitting the full prompt unless the prompt itself is very short. Before transmission, user and tenant identifiers are removed, and all queries are sent securely to Bing.\\nThe results are returned securely, and both the prompt and response remain within the Microsoft 365 service boundary', '#### Contractual Commitments\\n\\nMicrosoft‚Äôs product terms codify strict commitments around query data. Microsoft has no rights in query data beyond what‚Äôs needed to provide the service. Query data is not used to improve Bing, train generative AI foundation models, or create advertising profiles. It is not shared with advertisers or beyond Microsoft. Instead, it is treated as Customer Confidential Information, reinforcing Microsoft‚Äôs commitment to privacy and trust', \"**Transparency by design:** Users can inspect both the citations and the exact keywords used for web grounding. Additionally, the user's prompts and Copilot's responses are stored within Microsoft 365 and never leave the service boundary for Copilot without customer direction.\"], title='Microsoft 365 Copilot Web Search: Delivering Multiple ...')], confidence='high'), FieldBasis(field='evaluation_benchmarks_and_metrics', reasoning='The most directly relevant excerpts explicitly name and describe the benchmarks and metrics listed in the finegrained field value. Excerpts detailing FACTS Grounding describe a benchmark focused on grounding responses in provided documents and the use of a multi-judge factuality assessment, which aligns with the benchmark‚Äôs year, purpose, and dual-phase evaluation. Excerpts describing RAGAS outline its role as an evaluation framework measuring faithfulness, context precision, context recall, and answer relevance, which correspond to the listed metrics and evaluation goals. Excerpts on SafeRAG introduce a security benchmark for RAG pipelines, including attack classes and robustness focus, matching the benchmark‚Äôs placement in the field value. LiveResearchBench is described as a user-centric deep-research benchmark with metrics around citation association and rubric-tree accuracy, which supports the live-research aspect of the requested field. CURIE is noted as a benchmark for evaluating reasoning across long scientific documents, indicating its place among evaluation tools for complex documents. CRAG (Comprehensive RAG benchmark) is presented as a robust retrieval-evaluation dataset with a confidence scoring mechanism for retrieved documents and corrective actions, matching the broad evaluation theme. MTEB (Massive Text Embedding Benchmark) is described as a broad embedding-task benchmark spanning retrieval, reranking, classification, clustering, and summarization, underscoring its role in evaluating retriever components. RARE (Retrieval-Aware Robustness Evaluation) is introduced as a framework for robustness against noisy or imperfect inputs with Get/Set components and finance/policy-oriented benchmarks, aligning with robustness-focused benchmarks. CRAG (CRAG methodology) is described as enhancing robustness via retrieval evaluators and corrective actions, reinforcing the theme of evaluation under uncertainty. The later excerpts expand the landscape by mentioning additional benchmarks and evaluation ecosystems (LiveResearchBench, MTEB, CRAG, RARE, FACTS, etc.), illustrating the breadth of standardized metrics used to assess grounding, factuality, robustness, and citation integrity in RAG-enabled LLM systems. Collectively, these excerpts support the finegrained field value by detailing the benchmark names, purposes, and the key metrics used to evaluate grounding, factuality, and robustness in LLM-based retrieval-augmented systems.', citations=[Citation(url='https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/', excerpts=['To succeed on a given example, an LLM must synthesize the complex information in the document and generate a long-form response that is both a comprehensive answer to the user request and fully attributable to that document.', 'Second, responses are judged as factually accurate if they are fully grounded in information contained in the provided document, with no hallucinations.', 'The final score for the overall grounding task is the average of all judge models‚Äô scores across all examples.', 'A factually correct response that fails to properly address the user‚Äôs request fails the benchmarking example.', 'We selected a combination of different judges to mitigate any potential bias of a judge giving higher scores to the responses produced by a member of its own model family.', 'ind more details of our FACTS Grounding evaluation methodology [in our paper](https://goo.gle/FACTS_paper) .', 'Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations', 'Each example comprises a document, a system instruction requiring the LLM to exclusively reference the provided document, and an accompanying user request.', 'The user requests are similarly wide ranging, including requests for summarization, Q&A generation, and rewriting tasks.', 'FACTS_paper) , a comprehensive benchmark for evaluating the ability of LLMs to generate responses that are not only factually accurate with respect to given inputs, but also sufficiently detailed to provide satisfactory answers to user queries. W', 'To ensure a diversity of inputs, the FACTS Grounding examples include documents with a variety of lengths, up to a maximum of 32,000 tokens (roughly 20,000 words), covering domains such as finance, technology, retail, medicine, and law.', 'acts-grounding-examples) today so anyone can use it to evaluate an LLM. Of course, we know that issues of benchmark contamination and leaderboard hacking are important to protect against, so following standard industry practice, we are keeping the private evaluation set held out. T', 'three frontier LLM judges ‚Äî namely Gemini 1.5 Pro, GPT-4o, and Claude 3.5 Sonnet.', 'The automatic judge models were comprehensively evaluated against a held-out test set to find the best performing judging prompt templates and to verify agreement with human raters.', 'the FACTS Grounding dataset comprises 1,719 examples, each carefully crafted to require long-form responses grounded in the context document provided.', ' We‚Äôve already tested leading LLMs using FACTS Grounding and have populated the initial leaderboard with their grounding scores. '], title='FACTS Grounding: A new benchmark for evaluating the factuality of ...'), Citation(url='https://arxiv.org/html/2508.05618v1', excerpts=['We evaluate our method on six long-form factuality benchmarks, including LongFact (Wei et al., 2024) , FAVA (Mishra et al., 2024) , AlpacaFact ( ...'], title='Learning to Reason for Factuality - arXiv'), Citation(url='https://www.evidentlyai.com/llm-guide/llm-benchmarks', excerpts=['LLM benchmarks are standardized tests for LLM evaluations. This guide covers 30 benchmarks from MMLU to Chatbot Arena, with links to datasets and ...'], title='30 LLM evaluation benchmarks and how they work'), Citation(url='https://blog.ragas.io/all-about-evaluating-large-language-models', excerpts=['|Benchmark |Number of tasks |', '- | --- |\\n|[Beyond the Imitation Game Benchmark (BIG-bench)](https://github.com/google/BIG-bench/blob/main/bigbench/benchmark_tasks/README.md) |214 |\\n', '\\nOne of major concerns about usage of these benchmarks is that the model could have been exposed to datasets during training or finetuning stage. This violates the fundamental rule that test set should be exclusive of training data. [mention about first section feel free to jump to llm application eval or non traditional]', '\\n#### []( \"LLM leaderboards\") LLM leaderboards', '\\nLLM leaderboards provide a living benchmark for different foundational and instruction finetuned LLMs. While the foundational LLM are evaluated on the open datasets their instruction finetuned versions are mostly evaluated using an Elo based rating system. * Open LLM leaderboard : Provided a wrapper on top of LM evaluation harness', '\\n\\n* HELM : Evaluated Open LLMs on wide variety of open datasets and metrics.'], title='All about evaluating Large language models - Blog'), Citation(url='https://seosherpa.com/ai-overview/', excerpts=[\"Google's AI Overview is a new search feature that utilizes generative AI to provide a concise answer at the top of the results page.\"], title=\"What Is Google's AI Overview? A Deep Dive into the Future ...\"), Citation(url='https://fortune.com/2025/12/02/sam-altman-declares-code-red-google-gemini-ceo-sundar-pichai/', excerpts=[\"With Gemini 3's strong rollout and rising user base, Google suddenly has the edge, and OpenAI is racing to keep its dominance from slipping ...\"], title=\"Sam Altman declares 'Code Red' as Google's Gemini surges‚Äîthree ...\"), Citation(url='https://brassmonkey.ai/google-gemini-review/', excerpts=[\"The Gemini 1.0 version came out in late 2023, and by 2025, we now have Gemini 1.5 and Gemini Advanced. The Gemini project combines Google's AI research with ...\"], title=\"Google Gemini Review: Is Google's AI Really Worth the ...\"), Citation(url='https://adcellerant.com/blogs/ai-changing-organic-search-august-2025/', excerpts=['From the public release of ChatGPT in late 2022 to the full launch of Google‚Äôs AI Overviews in mid-2024, the landscape has shifted so much that search engine optimization (SEO) is now being referred to as ‚ÄúSearch Everywhere Optimization.‚Äù', 'Gemini is Google‚Äôs flagship LLM and the engine behind AI Overviews, AI Mode, and Google‚Äôs standalone chatbot experience.', 'Gemini is now embedded into Google Search through AI Overviews and AI Mode, accessible as a standalone chatbot, and integrated across the Google suite (Gmail, Docs, YouTube, etc.).', 'First launched in 2023 as a rebrand of ‚ÄúBard,‚Äù Gemini has evolved into an assistant across the Google ecosystem.\\nG', 'AI Overviews are Google‚Äôs way of quickly answering searches.', '-mode/) is Google‚Äôs latest step in reshaping how people search.', 'le is growing too. These tools aren‚Äôt replacing each other; they‚Äôre just giving people more ways to search.'], title='AI is Changing Organic Search: August 2025 Update - AdCellerant'), Citation(url='https://blog.google/products/search/generative-ai-google-search-may-2024/', excerpts=[' Now, with generative AI, Search can do more than you ever imagined. So you can ask whatever‚Äôs on your mind or whatever you need to get done ‚Äî from researching to planning to brainstorming ‚Äî and Google will take care of the legwork. This is all made possible by a new Gemini model customized for Google Search. It brings together Gemini‚Äôs advanced capabilities ‚Äî including multi-step reasoning, planning and multimodality ‚Äî with our best-in-class Search systems. '], title='Generative AI in Search: Let Google do the searching for you')], confidence='high'), FieldBasis(field='clarification_of_scope', reasoning='The field value frames web search for LLMs as three interconnected pillars. Excerpts that provide a comprehensive overview of Retrieval-Augmented Generation (RAG) and its role in grounding LLM outputs in external sources directly support the first pillar. When a source singles out RAG as a broad paradigm with various architectural designs and a focus on grounding information through retrieved documents, it reinforces the centrality of retrieval-based grounding to web-grounded LLMs. Excerpts describing RAG as a strategy to ground responses in up-to-date information, including discussions of modular, advanced, and agentic variants, further bolster the RAG-centric first pillar. Several passages explicitly discuss LLM-powered search capabilities that synthesize information across multiple web sources to provide cohesive answers with citations, aligning with the second pillar. For example, descriptions of embedding retrieval, context grounding, and the use of external knowledge bases to answer with grounded, source-backed responses illustrate how LLMs can act as search-oriented systems rather than mere question-answerers. Additional excerpts discuss agentic RAG and browsing-style capabilities where the LLMs plan, query, and retrieve information dynamically, enabling multi-step, tool-augmented workflows that resemble autonomous browsing agents. This triad is complemented by industry- and academia-focused discussions about safety, robustness, and evaluation of RAG-enabled web search, including how sources are used to ground outputs and how reformulation and self-critique mechanisms are used to improve reliability, all of which reinforce the third pillar around browsing agents/tools and real-time web grounding. Taken together, the excerpts map onto the three pillars by explicitly defining RAG grounding as external-retrieval grounded generation, describing LLM-powered search experiences with live-web grounding and citation, and detailing agentic/browsing-enabled workflows that query, synthesize, and reason over web content in multi-step pipelines.', citations=[Citation(url='https://arxiv.org/abs/2312.10997', excerpts=['This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the ...'], title='Retrieval-Augmented Generation for Large Language Models - arXiv'), Citation(url='https://arxiv.org/abs/2506.00054', excerpts=['This survey provides a comprehensive synthesis of recent advances in RAG systems, offering a taxonomy that categorizes architectures into retriever-centric, generator-centric, hybrid, and robustness-oriented designs.', 'We systematically analyze enhancements across retrieval optimization, context filtering, decoding control, and efficiency improvements, supported by comparative performance analyses on short-form and multi-hop question answering tasks.', 'We conclude by identifying open challenges and future research directions, including adaptive retrieval architectures, real-time retrieval integration, structured reasoning over multi-hop evidence, and privacy-preserving retrieval mechanisms.', 'state-of-the-art evaluation frameworks and benchmarks, highlighting trends in retrieval-aware evaluation, robustness testing, and federated retrieval settings.', 'This survey aims to consolidate current knowledge in RAG research and serve as a foundation for the next generation of retrieval-augmented language modeling systems.'], title='[2506.00054] Retrieval-Augmented Generation'), Citation(url='https://www.sciencedirect.com/science/article/pii/S1566253525006712', excerpts=['In Agentic AI systems, RAG serves as a shared grounding mechanism across agents.'], title='AI Agents vs. Agentic AI: A Conceptual taxonomy, applications and ...'), Citation(url='https://ragflow.io/blog/rag-at-the-crossroads-mid-2025-reflections-on-ai-evolution', excerpts=['Retrieval-Augmented Generation (RAG) as well: although academic papers on RAG continue to be plentiful, significant breakthroughs have been few and far between in recent months.', 'RAG‚Äôs value as a distinct architectural layer is now more pronounced than ever.'], title=\"RAG at the Crossroads - Mid-2025 Reflections on AI's Incremental ...\"), Citation(url='https://arxiv.org/html/2510.11560v1', excerpts=['The advent of LLMs has given rise to a new type of web search: Generative search, where LLMs retrieve web pages related to a query and generate a single, coherent text as a response.', 'In information-seeking contexts, retrieval-augmented generation (RAG) enhances LLMs with external knowledge to improve factuality (He et al., [2024](https://arxiv.org/html/2510.11560v1.bib15) ; Shi et al., [2025](https://arxiv.org/html/2510.11560v1.bib36) ; Jo et al., [2025](https://arxiv.org/html/2510.11560v1.bib21) ) .', 'lts also highlight the need for revisiting evaluation criteria for web search in the age of Generative AI.', 'Generative search differs from traditional web search along several key dimensions: (i) Different output format: The two search types result in differently formatted outputs.'], title='Characterizing Web Search in The Age of Generative AI'), Citation(url='https://learn.microsoft.com/en-us/copilot/overview', excerpts=['Nov 11, 2025 ‚Äî Copilot Chat is AI chat grounded in data from the web and powered by the latest large language models (LLMs). Copilot Chat lets users access agents and create\\xa0...'], title='Overview of Microsoft 365 Copilot Chat'), Citation(url='https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/microsoft/msc/documents/presentations/CSR/Responsible-AI-Transparency-Report-2025-vertical.pdf', excerpts=['Aug 19, 2025 ‚Äî Our report highlights new developments related to how we build and deploy. AI systems responsibly, how we support our customers and the broader ecosystem, and\\xa0...'], title='2025 Responsible AI Transparency Report'), Citation(url='https://learn.microsoft.com/en-us/compliance/anz/blueprint-copilot-servicecom', excerpts=[\"1. In a Microsoft 365 app, a user enters a prompt in Copilot. 2. Copilot preprocesses the input prompt using grounding and accesses Microsoft Graph in the user's tenant, or if enabled, from other platforms. 3. If web-grounding is enabled, Copilot gathers information from the Bing Index. 4. Copilot sends the grounded prompt to the LLM. The LLM uses the prompt to generate a response that is contextually relevant to the user's task. 5. Copilot returns the response to the app and the user. The prompt and the results are both logged and available for admins to view via the Data Security Posture Management (DSPM) for AI capability in Microsoft Purview. For more information on how the Microsoft 365 Copilot works, see the [architectural walkthrough](/en-us/copilot/microsoft-365/microsoft-365-copilot-architecture) .\", 'Microsoft 365 Copilot introduces an additional search indexing method to embed semantic understanding of concepts and language into the Microsoft Graph and enable Copilot and Microsoft 365 Search to better understand natural language expressions. This indexation method significantly improves the ability for Copilot to locate and use the most relevant content. This additional natural language data is called the [Semantic Index](/en-us/microsoftsearch/semantic-index-for-copilot) .', \"pilot/agents) are part of the Microsoft 365 Copilot ecosystem. They enhance productivity by automating tasks and processes through advanced AI capabilities. They're available in both Microsoft 365 Copilot and in Copilot Chat experiences. Copilot Agents connect to an organization‚Äôs knowledge and data sources. By doing so, they can access and utilize specific documents, databases, and other information repositories to provide accurate and contextually relevant responses. This connectivity is facilitated through APIs and connectors that link the agents to various data sources, ensuring that they can retrieve and process the necessary information in real-time.\", 'Plugins (Bing, etc.) are distinct from Connectors in that they run in real-time during the interaction execution to provide new skills and knowledge to Copilot. For example, the included Access to web content (Bing integration) Plugin allows real-time integration of public web content to enrich the knowledge available to Copilot. The web content plugin enables a new real-time query source for Copilot to include. It enables Copilot to search not only for the content from inside the Microsoft 365 organization (via the Microsoft Graph) but also web content (via Bing Index) in parallel. This capability can be useful for integrating public content on a subject with private knowledge contained within the Microso'], title='Service components for Copilot aligning to Blueprint'), Citation(url='https://techcommunity.microsoft.com/blog/microsoft365copilotblog/microsoft-365-copilot-web-search-delivering-multiple-layers-of-protection-and-co/4458224', excerpts=['When you ask Microsoft 365 Copilot or Copilot Chat a question about something that changes fast ‚Äì earnings updates, a regulatory shift, or a breaking news item ‚Äì access to current information is critical.', 'That‚Äôs why Copilot can ground its answers with current information from the web, closing knowledge gaps that every large language model (LLM) inevitably has based on its training data cutoff.'], title='Microsoft 365 Copilot Web Search: Delivering Multiple ...')], confidence='high'), FieldBasis(field='agentic_llm_evolution', reasoning='The core field value asserts a progression from passive retrieval to autonomous agentic web-searching LLMs, framed as Agentic RAG or Agentic RL, driven by reinforcement learning, tool-use protocols, and multi-step reasoning. Excerpts that explicitly name Agentic RAG and agentic retrieval-driven frameworks (such as Agentic RAG and the evolution toward agentic deep research) directly support the temporal arc and the mechanistic backbone (tool use, planning, reasoning) of this evolution. Descriptions of ReAct-style reasoning, planning with web queries, and the separation of reasoning from action (Model Context Protocol) further substantiate the mechanism by which agents transition from passive retrieval to proactive, autonomous information gathering and synthesis. Additional sources that discuss the shift in RAG architectures toward agentic configurations, or that place agentic capabilities within a broader survey of RL and RAG, provide corroborating evidence for the broader landscape and the trend towards autonomous web-grounded agents. The segment on simulated feedback, self-play, and online vs offline training reinforces how training paradigms have evolved to support robust, autonomous web-search behavior. Taken together, the selected excerpts form a coherent chain: they illustrate the problem space (need for autonomous, grounded web search), identify enabling architectures and protocols (ReAct, MCP, tool-use, multi-step reasoning), describe training paradigms that support agentic behavior (RL variants, self-supervised or simulated feedback), and place these developments within a broader agentic RAG / Agentic RL discourse, thereby validating the proposed finegrained field value.\\n', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', 'Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. R', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. '], title='Evolution of RAG from Static Knowledge to Agentic ...'), Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Large Reasoning Model-based : A growing trend in Agentic RAG workflow involves directly utilizing LLMs that possess inherently strong reasoning capabilities, often referred to as Large Reasoning Models (LRMs).', 'For Agentic RAG, function calling provides a straightforward and structured way for the LLM agent to invoke a search API when its internal analysis determines that external information is required to answer a prompt accurately.', 'This addresses a key limitation of many existing agents, whether prompt-engineered or trained in simulated/static RAG settings, which often struggle with the complexities of real-world web interaction.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://medium.com/@prxshetty/can-llms-really-do-web-research-and-why-your-agent-still-gets-stuck-d74598b44e45', excerpts=['\\n**Action Hallucinations:** When agents fabricate information in their tool calls that wasn‚Äôt present in their reasoning or previous observations. Surprisingly, hallucination rates haven‚Äôt decreased much across model generations. GPT-4 Turbo‚Äôs rate (0.019) is statistically similar to Claude 3.7 Sonnet‚Äôs (0.014), while DeepSeek R1 shows a concerning high rate (0.159).', 'The Deep Research Bench evaluates agents across eight distinct task categories, each designed to test specific research capabilities while exposing common failure patterns.'], title='Can LLMs really do web research? (and why your agent ...'), Citation(url='https://arxiv.org/html/2506.18959v3', excerpts=['the OpenAI Deep Research agent achieves significantly higher scores‚Äî51.5% on BrowseComp, 42.9% on BrowseComp-ZH, and 26.6% on HLE‚Äîd', 'By tightly integrating search and reasoning in a multi-step and interactive manner, these systems can progressively enhance the relevance and depth of retrieved knowledge and simultaneously refine the reasoning process underlying query interpretation, ultimately producing more accurate and contextually nuanced responses.', 'By tightly integrating search and reasoning in a multi-step and interactive manner, these systems can progressively enhance the relevance and depth of retrieved knowledge and simultaneously refine the reasoning process underlying query interpretation, ultimately producing more accurate and contextually nuanced responses.', 'Equipped with TTS on reasoning and search, LLMs are set to drive a new search paradigm termed Agentic Deep Research systems, which are capable of autonomous re asoning , on-demand search ing , and iterative information synthesis.', 'Equipped with TTS on reasoning and search, LLMs are set to drive a new search paradigm termed Agentic Deep Research systems, which are capable of autonomous re asoning , on-demand search ing , and iterative information synthesis.'], title='From Web Search towards Agentic Deep Research'), Citation(url='https://arxiv.org/html/2506.18959v1', excerpts=['Equipped with TTS on reasoning and search, LLMs are set to drive a new search paradigm termed Agentic Deep Research systems, which are capable of autonomous re asoning , on-demand search ing , and iterative information synthesis.'], title='From Web Search towards Agentic Deep ReSearch'), Citation(url='https://arxiv.org/html/2505.10468v1', excerpts=['The progression toward AI Agents is inseparable from the strategic integration of LLMs as reasoning engines and their augmentation through structured tool use. This synergy transforms static language models into dynamic cognitive entities capable of perceiving, planning, acting, and adapting setting the stage for multi-agent collaboration, persistent memory, and scalable autonomy.', 'These capabilities have opened pathways for more robust behavior of AI agents such as long-horizon planning, cross-tool coordination, and adaptive learning loops.', 'May 15, 2025 ‚Äî This review critically distinguishes between AI Agents and Agentic AI, offering a structured conceptual taxonomy, application mapping, and challenge analysis'], title='AI Agents vs. Agentic AI: A Conceptual Taxonomy, ...'), Citation(url='https://arxiv.org/pdf/2503.22458?', excerpts=[' 11. A Roadmap of Evaluation of LLM-based Agents for Multi-turn Conversation. The blue line represents the development of\\n\\nmetrics and benchmark for Multi-turn Conversation. The orange line represents the development of Multi-turn Conversation\\n\\nand Le [216] introduced models that improved fluency and context understanding. New evaluation metrics like\\n\\nBLEU [ 165 ] and perplexity [ 90 ] emerged to measure generation quality over multiple turns. Researchers started\\n\\nrecognizing the limitations of purely reference-based metrics and began incorporating more contextual and\\n\\ndiversity-oriented frameworks (e.g., human preference ratings, embedding-based scores)'], title='Evaluating LLM-based Agents for Multi-Turn Conversations')], confidence='high'), FieldBasis(field='major_industry_implementations', reasoning=\"The most directly supportive content names and describes the core deployments in the field value: Google AI Overviews, powered by a custom Gemini model with a 2 million token context window, and integrated with Google's web index and Search systems. It also conveys guardrails and attribution practices, including citations and enterprise-grade governance tools. The following passages complement this by detailing the grounding and integration strategy: grounding and real-time web data usage, semantic indexing over organizational data, and the use of a containment boundary that preserves privacy and security while enabling up-to-date information. These elements corroborate the claim about a major industry implementation with a Gemini-based backend and a sophisticated integration pattern designed to synthesize information from diverse web sources into a concise, quickly consumable answer, while maintaining traceability through citations. Similarly, excerpts describing Microsoft Copilot and Copilot Chat articulate a distinct major industry deployment in the enterprise space, featuring grounding via the Bing Index and internal data via the Microsoft Graph, a Semantic Index to improve content understanding, and multi-layer governance (RAI protections, citations, data handling terms). This supports the field value‚Äôs notion of a major industry implementation with a robust web-grounding workflow and enterprise governance. Excerpts mentioning OpenAI‚Äôs ChatGPT in browsing mode, the OpenAI Deep Research Agent, and agentic RAG frameworks (Search-o1, RAG-based mechanisms) provide contextual corroboration for the broader landscape of major deployments and their tool-use and self-correction capabilities, though they are comparatively less specific to a single product in this set. Collectively, the set of excerpts demonstrates three concrete industry-grade deployments and the corresponding integration patterns: Google‚Äôs AI Overviews with Gemini-based reasoning and web-grounded synthesis; Microsoft Copilot/Copilot Chat with grounding via web/internal data and semantic indexing plus governance; and OpenAI/Anthropic‚Äôs agentic RAG mechanisms and tool-use for live web search integration, all anchored by the central theme of grounding in external or internal data and presenting information with cited sources. This directly informs the fine-grained field value describing major industry implementations and their integration patterns, including underpinnings like context windows, semantic indexing, and guardrails. The surrounding excerpts add depth by illustrating how RAG and agentic architectures are evolving in parallel, providing context for the maturity and adoption of such systems in industry settings. Overall, the strongest support comes from entries that explicitly pair a named product with a concrete grounding architecture and governance stance, as these align tightly with the requested field value content.\", citations=[Citation(url='https://learn.microsoft.com/en-us/copilot/overview', excerpts=['Nov 11, 2025 ‚Äî Copilot Chat is AI chat grounded in data from the web and powered by the latest large language models (LLMs). Copilot Chat lets users access agents and create\\xa0...'], title='Overview of Microsoft 365 Copilot Chat'), Citation(url='https://learn.microsoft.com/en-us/copilot/microsoft-365/manage-public-web-access', excerpts=['ontrols and a user-level **Web content** toggle (only for Microsoft 365 Copilot) are available to [manage whether web search is enabled]() in your environment', 'osoft 365 **Copilot Search** is an additional, universal search experience that allows users with a Microsoft 365 Copilot license to search across all their Microsoft 365 and third-party data sources.', 'When web search is enabled, Microsoft 365 Copilot and Microsoft 365 Copilot Chat may fetch information from the Bing search service when information from the web helps to provide a better, more grounded response.', 'When web search is enabled, Microsoft 365 Copilot and Microsoft 365 Copilot Chat parse the user‚Äôs prompt and identifies terms where information from the web would improve the quality of the response.', 'generated search queries sent to the Bing search service to ground responses in web data. The way Microsoft handles these queries is identical in both services. Gen'], title='Data, privacy, and security for web search in Microsoft 365 ...'), Citation(url='https://www.linkedin.com/posts/rakeshgohel01_ai-agent-trends-have-drastically-changed-activity-7383841580014723072-PxZp', excerpts=[\"CUA and Agentic RAG aren't just cool demos anymore. They're solving real operational gaps, fast. This list nails the shift from experimentation to execution.\"], title='AI Agent Trends for 2025: New Innovations and Products'), Citation(url='https://seosherpa.com/ai-overview/', excerpts=[\"Google's AI Overview is a new search feature that utilizes generative AI to provide a concise answer at the top of the results page.\"], title=\"What Is Google's AI Overview? A Deep Dive into the Future ...\"), Citation(url='https://fortune.com/2025/12/02/sam-altman-declares-code-red-google-gemini-ceo-sundar-pichai/', excerpts=[\"With Gemini 3's strong rollout and rising user base, Google suddenly has the edge, and OpenAI is racing to keep its dominance from slipping ...\"], title=\"Sam Altman declares 'Code Red' as Google's Gemini surges‚Äîthree ...\"), Citation(url='https://brassmonkey.ai/google-gemini-review/', excerpts=[\"The Gemini 1.0 version came out in late 2023, and by 2025, we now have Gemini 1.5 and Gemini Advanced. The Gemini project combines Google's AI research with ...\"], title=\"Google Gemini Review: Is Google's AI Really Worth the ...\"), Citation(url='https://adcellerant.com/blogs/ai-changing-organic-search-august-2025/', excerpts=['From the public release of ChatGPT in late 2022 to the full launch of Google‚Äôs AI Overviews in mid-2024, the landscape has shifted so much that search engine optimization (SEO) is now being referred to as ‚ÄúSearch Everywhere Optimization.‚Äù', 'Gemini is Google‚Äôs flagship LLM and the engine behind AI Overviews, AI Mode, and Google‚Äôs standalone chatbot experience.', 'Gemini is now embedded into Google Search through AI Overviews and AI Mode, accessible as a standalone chatbot, and integrated across the Google suite (Gmail, Docs, YouTube, etc.).'], title='AI is Changing Organic Search: August 2025 Update - AdCellerant'), Citation(url='https://techcommunity.microsoft.com/blog/microsoft365copilotblog/microsoft-365-copilot-web-search-delivering-multiple-layers-of-protection-and-co/4458224', excerpts=['That‚Äôs why Copilot can ground its answers with current information from the web, closing knowledge gaps that every large language model (LLM) inevitably has based on its training data cutoff.', 'Traditional web search engines are optimized for broad consumer scenarios. Copilot‚Äôs web search is enterprise oriented and layered with controls that consumer search does not provide.', 'A Copilot interaction has three parts: your prompt, a web query (if needed), and the response.'], title='Microsoft 365 Copilot Web Search: Delivering Multiple ...')], confidence='high'), FieldBasis(field='representative_agentic_systems', reasoning='The most directly relevant parts of the excerpts explicitly reference named agentic systems or clearly delineate their methodological approach, which aligns with the field value‚Äôs emphasis on concrete system names and their core contributions. For example, one excerpt explicitly names a framework where a system is designed to incentivize and train LLMs to learn when to invoke a web search and how to use retrieved information, pointing to a well-known paper and its arXiv identifier. This directly supports the element of the field value describing a two-stage PPO-based strategy for learning search behavior and tool use. Another excerpt names a family of agentic RAG systems and describes a framework where an agent uses dynamic retrieval based on identified knowledge gaps, indicating the presence of concrete, named systems that follow this paradigm. Additional excerpts discuss multi-agent collaboration and self-critique mechanisms (Self-RAG) and modular RAG approaches, which map to the field value‚Äôs broader catalog of representative agentic systems and related architectures. Several excerpts explicitly connect to agentic RAG concepts (e.g., agentic RAG mechanisms, reasoning-in-documents modules, and end-to-end RL approaches for training search-enabled agents), which corroborate the field value‚Äôs listing of diverse representative systems and their core methodologies. Collectively, the named systems and the described methodologies in these excerpts provide direct evidence for the existence and characteristics of the representative_agentic_systems described in the field value, including their training strategies (e.g., PPO, RL, offline/self-supervised variations), their retrieval strategies (two-stage, dynamic, or agentic querying), and their collaborative or modular configurations. The surrounding discussion of related frameworks and architectural paradigms (Self-RAG, Modular RAG, and agentic RAG) further contextualizes the space of representative systems and reinforces the mapping between named systems and their reported core ideas.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. '], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='report_summary', reasoning='The most directly supportive content includes discussions of agentic RAG and retrieval-driven reasoning frameworks, which map closely to the described late-2023 to 2025 research focus on how LLMs perform web-grounded, multi-step tasks with external tools. For example, a survey of reasoning-agentic retrieval-augmented approaches outlines how function calling enables LLMs to trigger searches and orchestrate external tools, aligning with the reported shift toward autonomous web search and tool use. The same source also emphasizes the integration of search-guided reasoning and external modules as core to agentic RAG. Additional passages introduce the evolution of RAG architectures toward agentic and self-reflective paradigms, such as Self-RAG and CRAG, which critique, refine, or correct retrieved evidence before generation, matching the narrative of increasingly sophisticated, self-correcting web-grounded systems. Several entries trace the progression from naive, static retrieval to graph-aware and multimodal variants (GraphRAG, OmniSearch), showing how research moved to structured data, memory, and multimodal retrieval, which strongly supports the claim of architectural convergence around RAG, agentic search, and multimodal capabilities. There are also explicit surveys and compilations (e.g., Retrieval-Augmented Generation to Generate Knowledge, a comprehensive arXiv review) that situate these developments within the broader research landscape and provide formal taxonomies, validating the reported periodization. Moreover, multiple excerpts describe benchmarks (FACTS Grounding, SafeRAG, RAGAS) and evaluation frameworks that focus on factual grounding and security, corroborating the claim about growing attention to evaluation and safety in RAG-driven web search for LLMs. Industry integrations (Google AI Overviews, Microsoft Copilot) are cited as pragmatic manifestations of these research trends, illustrating how academic advances are translating into real-world web-search-enabled assistants. Taken together, the most relevant excerpts collectively substantiate the core elements of the fine-grained field value: (i) RAG and its evolution toward agentic, self-improving systems; (ii) graph-based and multimodal extensions; (iii) RL-driven or planner-based agentic search capabilities; (iv) formal evaluation and security concerns; and (v) industry adoption and practical grounding of these research trajectories.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component'], title='Evolution of RAG from Static Knowledge to Agentic ...'), Citation(url='https://arxiv.org/abs/2312.10997', excerpts=['This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the ...'], title='Retrieval-Augmented Generation for Large Language Models - arXiv'), Citation(url='https://arxiv.org/pdf/2408.02854', excerpts=['o et al. ( 2024 ) categorize the\\n\\nRAG research paradigm into three Naive RAG,\\n\\nAdvanced RAG, and Modular RAG.', 'n Naive RAG, there are three parts, i.e., indexing,\\n\\nretrieval, and generation.'], title='arXiv:2408.02854v4 [cs.IR] 18 Feb 2025'), Citation(url='https://arxiv.org/abs/2506.00054', excerpts=['This survey provides a comprehensive synthesis of recent advances in RAG systems, offering a taxonomy that categorizes architectures into retriever-centric, generator-centric, hybrid, and robustness-oriented designs.', 'We systematically analyze enhancements across retrieval optimization, context filtering, decoding control, and efficiency improvements, supported by comparative performance analyses on short-form and multi-hop question answering tasks.', 'We conclude by identifying open challenges and future research directions, including adaptive retrieval architectures, real-time retrieval integration, structured reasoning over multi-hop evidence, and privacy-preserving retrieval mechanisms.', 'state-of-the-art evaluation frameworks and benchmarks, highlighting trends in retrieval-aware evaluation, robustness testing, and federated retrieval settings.', 'This survey aims to consolidate current knowledge in RAG research and serve as a foundation for the next generation of retrieval-augmented language modeling systems.'], title='[2506.00054] Retrieval-Augmented Generation'), Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['The _indexing-retrieval-generation_ paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs). However, the incorporation of external and unverified knowledge increases the vulnerability of LLMs because attackers can perform attack tasks by manipulating knowledge.', 'Our main contributions are:', ' We reveal four attack tasks capable of bypassing the _retriever_ , _filter_ , and _generator_ .', 'Noise : Due to the limitation in retrieval accuracy, the retrieved contexts often contain large quantities of noisy texts that are at most merely similar to the query but do not actually contain the answer.', 'This paper introduces SafeRAG, a benchmark designed to assess the security vulnerabilities of RAG against data injection attacks.', 'We construct a comprehensive question-contexts safety evaluation dataset specifically tailored to the Chinese news domain, aiming to address the complex issues likely to arise in real-world applications.', 'In this paper, we focus on both the retrieval safety and generation safety of RAG to provide a more comprehensive evaluation perspective.', 'utilize traditional evaluation metrics (e.g., EM, F1, Recall, Precision, and Attack Success Rate) to assess the safety of generated content.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...')], confidence='high'), FieldBasis(field='mitigation_strategies_for_risks', reasoning='The most directly relevant content are passages that enumerate concrete mitigation techniques for RAG and agentic AI systems. For example, passages detailing retriever-level privacy protections (differential privacy applied to retrieval, noise addition to protect document-level privacy) directly map to the Data Handling category and discuss the privacy-utility tradeoff inherent in mitigation. Passages describing input sanitization and HTML stripping provide actionable Content Sanitization recommendations, highlighting how preprocessing of retrieved content reduces risk from malicious payloads and formatting issues, with tradeoffs in processing latency. Other passages discuss sandboxed browsing as a System Architecture mitigation, describing containment of agent actions to limit risk, as well as bias-control measures (embedding and query rewriting) under Bias Mitigation, which address fairness concerns at retrieval time. Additional excerpts cover broader security evaluations and threat models that contextualize why these mitigations are necessary (e.g., SafeRAG, threat models, and auditability), which supports the need for structured mitigation strategies though they may not describe a single technique in isolation. Overall, the most supportive content provides concrete techniques (differential privacy in retrieval, input sanitization/HTML stripping, sandboxed browsing, bias-controlled embedding and query rewriting) and discusses their tradeoffs, followed by excerpts that frame the broader security and evaluation landscape (threat models, SafeRAG, governance) which contextualize the need for such mitigations.', citations=[Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['Logs might inadvertently\\n\\nstore sensitive user data', 'Retrieved content may\\n\\ncontain sensitive or\\n\\noutdated information,\\n\\nwhich could be exposed\\n\\nin generated outp', 'nstead of\\n\\nembedding domain-specific knowledge into the model itself, RAG connects the model to an external\\n\\nknowledge base and retrieves relevant documents at runtime to ground its responses', 'al or third-party\\n\\nknowledge bases, user\\n\\nqueries may be logged or\\n\\nmonitored without\\n\\nconsent. \\uf0a7\\n\\nUse robust API security\\n\\nmeasures, including access\\n\\ncontrols, authentication,\\n\\nand rate limiting. \\uf0a7\\n\\nSanitize user input to\\n\\nprevent injection attacks. \\uf0a7\\n\\nMinimize API logging or\\n\\nensure logs are\\n\\nanonymized and protected\\n\\nby access controls. \\uf0a7\\n\\nRestrict retrieval sources to\\n\\napproved, privacy-screened\\n\\ndatasets (e.g., filtered CRM\\n\\ndata). \\uf0a7\\n\\nImplement relevance filters\\n\\nor scoring mechanisms to\\n\\nensure only appropriate\\n\\ncontent is passed to the\\n\\nLLM. \\uf0a7\\n\\nApply post-\\n\\nprocessing/output filters to\\n\\nremove or redact sensitive\\n\\ninformation from\\n\\nresponses. \\uf0a7\\n\\nUse internal retrieval\\n\\nsystems when possible; if\\n\\nthird-party search APIs are\\n\\nused, anonymize or', 'According to Article 25 of the AI Act, a deployer of a high risk AI system becomes a provider when they substantially modify an existing AI\\n\\nsystem, including by fine-tuning or adapting a pre-trained model for new applications'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)'), Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['Experiments conducted on 14 representative RAG components demonstrate that RAG exhibits significant vulnerability to all attack tasks and even the most apparent attack task can easily bypass existing retrievers, filters, or advanced LLMs, resulting in the degradation of RAG service quality.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2510.05310v1', excerpts=['In contrast, our work centered on evaluating guardrail models in the RAG settings. ## 3 Problem Setup and Robustness Metric'], title='RAG Makes Guardrails Unsafe? Investigating Robustness ...'), Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['We construct a comprehensive question-contexts safety evaluation dataset specifically tailored to the Chinese news domain, aiming to address the complex issues likely to arise in real-world applications.', 'Our main contributions are:'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://pmc.ncbi.nlm.nih.gov/articles/PMC12306375/', excerpts=['by AH AlSammarraie ¬∑ 2025 ¬∑ Cited by 2 ‚Äî To develop and evaluate an agentic retrieval augmented generation (ARAG) framework using open-source large language models (LLMs) for generating\\xa0...'], title='Development and evaluation of an agentic LLM based ...')], confidence='medium'), FieldBasis(field='open_problems_and_future_research_directions', reasoning='The most relevant excerpts explicitly outline forward-looking research agendas and evaluation frameworks for retrieval-augmented and agentic systems. For example, a comprehensive survey of Retrieval-Augmented Reasoning (CoRAG) describes how iterative retrieval and reasoning can improve multi-hop QA and exact-match performance, illustrating a concrete future path for improving RAG with stepwise retrieval and internal critique. This directly aligns with the need to advance evaluation criteria for complex reasoning and generative search in open problems. Relatedly, a companion discussion of a progressive RAG evaluation ecosystem (RAGAS and related metrics) emphasizes faithfulness, answer relevancy, context precision, and context recall as core evaluation axes, which map to the field‚Äôs call for robust, multi-faceted benchmarks for generated information and its grounding in sources. A survey on Retrieval-Augmented Generation consolidates current knowledge and outlines open challenges and directions, reinforcing the framing of open research questions in RAG/LLM grounding. Separately, a set of pieces on FACTS Grounding and grounded evaluation argue for fully anchored responses to external documents and explicit attribution, which strengthens the field‚Äôs emphasis on factuality, hallucination reduction, and reliable citation‚Äîcentral future directions. In addition, a study on the ‚ÄúCharacterizing Web Search in The Age of Generative AI‚Äù differentiates generative search from traditional web search and argues for revisiting evaluation criteria to assess synthesized outputs, signaling a direct alignment with the declared need for new evaluation standards. Other excerpts discuss security, privacy, and robustness (SafeRAG, retriever privacy, and related threat models), underscoring the open problems around defending agentic RAG systems against attacks and ensuring trustworthy deployments. Finally, excerpts that survey the broader state of RAG and agentic trends (e.g., GraphRAG, multimodal RAG, and agentic retrieval architectures) supply a backdrop for future directions and structures a cohesive research agenda. Taken together, these excerpts coherently map onto the field‚Äôs highlighted future directions: develop and standardize evaluation for complex reasoning and generative outputs; strengthen grounding, citation, and factuality; address security/privacy/robustness in agentic web search; optimize long-context and cost-effective architectures; and broaden multimodal and graph-based RAG capabilities with robust benchmarks and frameworks.\\n', citations=[Citation(url='https://www.sciencedirect.com/science/article/pii/S240595952500133X', excerpts=['Table 2 . Summary of top LLM models (Part I).', '[[90]]() propose CoRAG (Chain-of-Retrieval Augmented Generation), a novel framework designed to enhance traditional RAG models by incorporating iterative retrieval and reasoning steps before answer generation.', 'Empirical results across various benchmarks, including a notable improvement in exact match scores for multi-hop question answering and state-of-the-art performance on the KILT benchmark, validate the efficacy of CoRAG\\n'], title='Reasoning beyond limits: Advances and open problems for ...'), Citation(url='https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/', excerpts=['Second, responses are judged as factually accurate if they are fully grounded in information contained in the provided document, with no hallucinations.', 'ind more details of our FACTS Grounding evaluation methodology [in our paper](https://goo.gle/FACTS_paper) .'], title='FACTS Grounding: A new benchmark for evaluating the factuality of ...'), Citation(url='https://arxiv.org/abs/2312.10997', excerpts=['This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the ...'], title='Retrieval-Augmented Generation for Large Language Models - arXiv'), Citation(url='https://arxiv.org/html/2510.11560v1', excerpts=['The advent of LLMs has given rise to a new type of web search: Generative search, where LLMs retrieve web pages related to a query and generate a single, coherent text as a response.', 'Generative search differs from traditional web search along several key dimensions: (i) Different output format: The two search types result in differently formatted outputs.', 'lts also highlight the need for revisiting evaluation criteria for web search in the age of Generative AI.'], title='Characterizing Web Search in The Age of Generative AI'), Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['The _indexing-retrieval-generation_ paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs). However, the incorporation of external and unverified knowledge increases the vulnerability of LLMs because attackers can perform attack tasks by manipulating knowledge.', 'utilize traditional evaluation metrics (e.g., EM, F1, Recall, Precision, and Attack Success Rate) to assess the safety of generated content.', 'First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['Retrieved content may\\n\\ncontain sensitive or\\n\\noutdated information,\\n\\nwhich could be exposed\\n\\nin generated outp', 'Logs might inadvertently\\n\\nstore sensitive user data'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)')], confidence='high'), FieldBasis(field='security_and_robustness_challenges.challenge_area', reasoning='The most directly relevant material describes explicit threat models, attack surfaces, and security benchmarking within retrieval-augmented generation and LLM ecosystems. For example, discussions of threat models and attack surfaces outline where adversaries may target RAG systems, the integrity of knowledge bases, and privacy leakage risks, which directly inform the security posture of such systems. Several excerpts classify attack tasks and demonstrate how bypassing retrievers, filters, or generators can compromise security, illustrating concrete weaknesses and how they might be exploited. Others discuss how external, unverified knowledge can increase LLM vulnerability, underscoring how security and robustness concerns arise from the integration of external data. Additional excerpts address privacy risks and data logging implications, which, while primarily framed as privacy, nonetheless pertain to security considerations around data handling and potential leakage. Taken together, these excerpts map a continuum from explicit security/treatment of attack surfaces to related privacy leakage risks, all relevant to the assessed field value of Security within the given research context.', citations=[Citation(url='https://arxiv.org/html/2509.20324v1', excerpts=['## III Threat Model and Attack Surfaces', 'AG systems introduce novel attack vectors for privacy and security breaches due to their hybrid architecture, which combines a retriever ‚Ñõ \\\\\\\\mathcal{R} that accesses data from an external knowledge base ùíü \\\\\\\\mathcal{D} with an LLM generator ùí¢ \\\\\\\\mathcal{G} . In a RAG architecture, attacks can emerge at different stages of the process. At Step 3, adversaries may attempt to compromise the integrity of the knowledge base, while Step 8 presents a privacy risk due to the leakage of retrieved verbatim conten'], title='RAG Security and Privacy: Formalizing the Threat Model ...'), Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=[' We reveal four attack tasks capable of bypassing the _retriever_ , _filter_ , and _generator_ .', 'First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.', 'The _indexing-retrieval-generation_ paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs). However, the incorporation of external and unverified knowledge increases the vulnerability of LLMs because attackers can perform attack tasks by manipulating knowledge.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['Logs might inadvertently\\n\\nstore sensitive user data'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)')], confidence='high'), FieldBasis(field='user_experience_and_cognitive_impacts', reasoning='The most directly relevant excerpts describe the emergence of generative search as a new UX paradigm. They explain that generative search produces synthesized, conversational responses rather than giving a list of links, which aligns with the field value‚Äôs claim of a fundamental UX shift. For example, one excerpt discusses generative search in the age of generative AI, noting that this new approach differs from traditional link-based search and emphasizes unified, coherent answers. Another excerpt explicitly contrasts the traditional practice of clicking through ranked blue links with a conversational model that provides a single synthesized answer, which is the core of the UX shift described. Further, statements about AI Overviews and ChatGPT-style search illustrate concrete implementations of this shift and validate why users perceive these features as useful. Additional excerpts discuss user satisfaction signals related to Google‚Äôs AI Overviews, describing increased satisfaction and more frequent use of Search, which directly supports the positive side of the UX impact. On the enterprise side, Copilot‚Äôs grounding and web-search integration illustrate how this paradigm extends beyond consumer search, strengthening the argument that this is a broad, systemic UX change across contexts. Complementary excerpts cover grounding, evaluation, and multi-hop retrieval, which provide necessary context about how such systems maintain accuracy while delivering streamlined, synthesized results. Finally, newer discussions (self-evaluating, agentic, and multi-hop RAG frameworks) flesh out how these UX gains are achieved in practice, including mechanisms for maintaining relevance and reducing cognitive load, though with caveats about potential limitations and risks. Overall, the strongest support comes from explicit framing of generative search as a new UX modality and the empirical note that users report higher satisfaction with AI Overviews, followed by corroborating examples from enterprise and research contexts that illustrate the persistence and expansion of this UX shift.', citations=[Citation(url='https://arxiv.org/html/2510.11560v1', excerpts=['The advent of LLMs has given rise to a new type of web search: Generative search, where LLMs retrieve web pages related to a query and generate a single, coherent text as a response.', 'In information-seeking contexts, retrieval-augmented generation (RAG) enhances LLMs with external knowledge to improve factuality (He et al., [2024](https://arxiv.org/html/2510.11560v1.bib15) ; Shi et al., [2025](https://arxiv.org/html/2510.11560v1.bib36) ; Jo et al., [2025](https://arxiv.org/html/2510.11560v1.bib21) ) .', 'lts also highlight the need for revisiting evaluation criteria for web search in the age of Generative AI.', 'Generative search differs from traditional web search along several key dimensions: (i) Different output format: The two search types result in differently formatted outputs.'], title='Characterizing Web Search in The Age of Generative AI'), Citation(url='https://blog.google/products/search/generative-ai-google-search-may-2024/', excerpts=[' Now, with generative AI, Search can do more than you ever imagined. So you can ask whatever‚Äôs on your mind or whatever you need to get done ‚Äî from researching to planning to brainstorming ‚Äî and Google will take care of the legwork. This is all made possible by a new Gemini model customized for Google Search. It brings together Gemini‚Äôs advanced capabilities ‚Äî including multi-step reasoning, planning and multimodality ‚Äî with our best-in-class Search systems. ', ' Get quick answers with AI Overviews\\n', ' So today, AI Overviews will begin rolling out to everyone in the U.S., with more countries coming soon. That means that this week, hundreds of millions of users will have access to AI Overviews, and we expect to bring them to over a billion people by the end of the year.\\n', '.\\nWith AI Overviews, people are visiting a greater diversity of websites for help with more complex questions. And we see that the links included in AI Overviews get more clicks than if the page had appeared as a traditional web listing for that query. As we expand this experience, we‚Äôll continue to focus on sending valuable traffic to publishers and creators. As always, ads will continue to appear in dedicated slots throughout the page, with clear labeling to distinguish between organic and sponsored results.'], title='Generative AI in Search: Let Google do the searching for you'), Citation(url='https://learn.microsoft.com/en-us/copilot/overview', excerpts=['Nov 11, 2025 ‚Äî Copilot Chat is AI chat grounded in data from the web and powered by the latest large language models (LLMs). Copilot Chat lets users access agents and create\\xa0...'], title='Overview of Microsoft 365 Copilot Chat'), Citation(url='https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/microsoft/msc/documents/presentations/CSR/Responsible-AI-Transparency-Report-2025-vertical.pdf', excerpts=['Aug 19, 2025 ‚Äî Our report highlights new developments related to how we build and deploy. AI systems responsibly, how we support our customers and the broader ecosystem, and\\xa0...'], title='2025 Responsible AI Transparency Report'), Citation(url='https://learn.microsoft.com/en-us/compliance/anz/blueprint-copilot-servicecom', excerpts=[\"1. In a Microsoft 365 app, a user enters a prompt in Copilot. 2. Copilot preprocesses the input prompt using grounding and accesses Microsoft Graph in the user's tenant, or if enabled, from other platforms. 3. If web-grounding is enabled, Copilot gathers information from the Bing Index. 4. Copilot sends the grounded prompt to the LLM. The LLM uses the prompt to generate a response that is contextually relevant to the user's task. 5. Copilot returns the response to the app and the user. The prompt and the results are both logged and available for admins to view via the Data Security Posture Management (DSPM) for AI capability in Microsoft Purview. For more information on how the Microsoft 365 Copilot works, see the [architectural walkthrough](/en-us/copilot/microsoft-365/microsoft-365-copilot-architecture) .\", 'Microsoft 365 Copilot introduces an additional search indexing method to embed semantic understanding of concepts and language into the Microsoft Graph and enable Copilot and Microsoft 365 Search to better understand natural language expressions. This indexation method significantly improves the ability for Copilot to locate and use the most relevant content. This additional natural language data is called the [Semantic Index](/en-us/microsoftsearch/semantic-index-for-copilot) .', \"pilot/agents) are part of the Microsoft 365 Copilot ecosystem. They enhance productivity by automating tasks and processes through advanced AI capabilities. They're available in both Microsoft 365 Copilot and in Copilot Chat experiences. Copilot Agents connect to an organization‚Äôs knowledge and data sources. By doing so, they can access and utilize specific documents, databases, and other information repositories to provide accurate and contextually relevant responses. This connectivity is facilitated through APIs and connectors that link the agents to various data sources, ensuring that they can retrieve and process the necessary information in real-time.\", 'Plugins (Bing, etc.) are distinct from Connectors in that they run in real-time during the interaction execution to provide new skills and knowledge to Copilot. For example, the included Access to web content (Bing integration) Plugin allows real-time integration of public web content to enrich the knowledge available to Copilot. The web content plugin enables a new real-time query source for Copilot to include. It enables Copilot to search not only for the content from inside the Microsoft 365 organization (via the Microsoft Graph) but also web content (via Bing Index) in parallel. This capability can be useful for integrating public content on a subject with private knowledge contained within the Microso'], title='Service components for Copilot aligning to Blueprint'), Citation(url='https://techcommunity.microsoft.com/blog/microsoft365copilotblog/microsoft-365-copilot-web-search-delivering-multiple-layers-of-protection-and-co/4458224', excerpts=['When you ask Microsoft 365 Copilot or Copilot Chat a question about something that changes fast ‚Äì earnings updates, a regulatory shift, or a breaking news item ‚Äì access to current information is critical.', 'That‚Äôs why Copilot can ground its answers with current information from the web, closing knowledge gaps that every large language model (LLM) inevitably has based on its training data cutoff.'], title='Microsoft 365 Copilot Web Search: Delivering Multiple ...'), Citation(url='https://simonwillison.net/2025/Apr/21/ai-assisted-search/', excerpts=['Those 2023-era versions were promising but very disappointing. They had a strong tendency to hallucinate details that weren‚Äôt present in the search results, to the point that you couldn‚Äôt trust anything they told you. In this first half of 2025 I think these systems have finally crossed the line into being genuinely useful.', 'For the past two and a half years the feature I‚Äôve most wanted from LLMs is the ability to take on search-based research tasks on my behalf.'], title='AI assisted search-based research actually works now'), Citation(url='https://arxiv.org/html/2504.14891v1', excerpts=[' Mtrag: A multi-turn conversational benchmark for evaluating retrieval-augmented generation systems. arXiv preprint arXiv:2501.03468, 2025\\n'], title='Retrieval Augmented Generation Evaluation in the Era of ...')], confidence='medium'), FieldBasis(field='specific_rag_techniques', reasoning='Direct references describe Self-RAG as a self-reflective retrieval framework where the model retrieves on-demand and critiques its results, aligning with the core concept and benefits of SELF-RAG in the field value. The passages that explicitly name Self-RAG and discuss self-reflection, retrieval-directed adaptation, and improved factuality map precisely onto the listed SELF-RAG entry. Excerpts that discuss CRAG outline a corrective retrieval paradigm with a decomposed-then-recomposed workflow and a corrective retrieval process that triggers further searches when retrieved information is incorrect or ambiguous, matching the CRAG description. Several excerpts name or describe CRAG, its decomposition/recomposition strategy, and its goal of robustness to incorrect retrieval, which supports the CRAG item in the field value. Excerpts about GraphRAG and HyperGraphRAG describe using knowledge graphs to structure retrieval and enhance reasoning with graph-based representations, directly supporting the GraphRAG portion. References to Multimodal RAG (e.g., SAM-RAG, OmniSearch) show retrieval-augmented methods that handle non-text data and multi-hop reasoning, aligning with Multimodal RAG. Passages discussing RECOMP describe a compression technique that condenses retrieved content to reduce load on the LLM, matching the RECOMP item. Excerpts mentioning RAGAS cover evaluation metrics for grounding and contextual relevance, supporting the RAGAS entry. MS-RAG passages describe a multi-stage retrieval framework combining dense and sparse methods with RL optimization, which matches the MS-RAG item. SafeRAG passages introduce a security benchmark for RAG pipelines and attack taxonomies, which aligns with the SafeRAG item. Finally, broader discussions of CoRAG, Reactive/RAG evolution, and agentic retrieval contexts provide context linking these techniques into the modern agentic RAG landscape, supporting all listed techniques through concrete definitions and examples.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.'], title='Evolution of RAG from Static Knowledge to Agentic ...'), Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.', '1. **Generation with Decompose-then-Recompose Algorithm** :\\n\\nRetrieved documents are broken down into smaller components to focus on key insights while filtering out irrelevant or redundant details. The filtered information is recombined into a cohesive and concise dataset, optimizing the quality of data input for generation.', '#### **Advantages of CRAG**\\n\\n**Improved Accuracy** :\\n\\nBy evaluating and correcting retrieved data, CRAG ensures more reliable and factually accurate outputs.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)'), Citation(url='https://arxiv.org/abs/2503.21322', excerpts=[' HyperGraphRAG, a novel hypergraph-based RAG method that represents n-ary relational facts via hyperedges, and consists of knowledge hypergraph construction, retrieval, and generation. ', 'Experiments across medicine, agriculture, computer science, and law demonstrate that HyperGraphRAG outperforms both standard RAG and previous graph-based RAG methods in answer accuracy, retrieval efficiency, and generation quality.'], title='HyperGraphRAG: Retrieval-Augmented Generation via Hypergraph ...'), Citation(url='https://arxiv.org/html/2507.18910v1', excerpts=['Multimodal RAG breaks out: Where earlier RAG research was text-only, 2024 saw a surge in multimodal extensions. SAM-RAG and OmniSearch both combine text and image evidence', ' bibliometric snapshot counted more than 1,200 RAG-related papers on arXiv in 2024 alone ( [zhao2024retrieval,](https://arxiv.org/html/2507.18910v1.bib106) ) , compared with fewer than 100 the previous year, underscoring the field‚Äôs rapid maturation'], title='A Systematic Review of Key Retrieval-Augmented ...'), Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['In this paper, we introduce a benchmark named SafeRAG designed to evaluate the RAG security.', 'Code is available at: https://github.com/IAAR-Shanghai/SafeRAG.', 'The indexing-retrieval-generation paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs).', 'Experiments conducted on 14 representative RAG components demonstrate that RAG exhibits significant vulnerability to all attack tasks and even the most apparent attack task can easily bypass existing retrievers, filters, or advanced LLMs, resulting in the degradation of RAG service quality.', 'First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://scholar.google.com/citations?user=TxfCeEYAAAAJ&hl=zh-CN', excerpts=['Sep 20, 2024 ‚Äî Saferag: Benchmarking security in retrieval-augmented generation of large language model. X Liang, S Niu, Z Li, S Zhang, H Wang, F Xiong, Z Fan, B Tang, J Zhao,\\xa0...'], title='Hanyu Wang - Google Â≠¶ÊúØÊêúÁ¥¢'), Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['We construct a comprehensive question-contexts safety evaluation dataset specifically tailored to the Chinese news domain, aiming to address the complex issues likely to arise in real-world applications.', 'In this paper, we focus on both the retrieval safety and generation safety of RAG to provide a more comprehensive evaluation perspective.', 'utilize traditional evaluation metrics (e.g., EM, F1, Recall, Precision, and Attack Success Rate) to assess the safety of generated content.', 'The _indexing-retrieval-generation_ paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs). However, the incorporation of external and unverified knowledge increases the vulnerability of LLMs because attackers can perform attack tasks by manipulating knowledge.', 'First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2510.11560v1', excerpts=['The advent of LLMs has given rise to a new type of web search: Generative search, where LLMs retrieve web pages related to a query and generate a single, coherent text as a response.', 'In information-seeking contexts, retrieval-augmented generation (RAG) enhances LLMs with external knowledge to improve factuality (He et al., [2024](https://arxiv.org/html/2510.11560v1.bib15) ; Shi et al., [2025](https://arxiv.org/html/2510.11560v1.bib36) ; Jo et al., [2025](https://arxiv.org/html/2510.11560v1.bib21) ) .', 'lts also highlight the need for revisiting evaluation criteria for web search in the age of Generative AI.', 'Generative search differs from traditional web search along several key dimensions: (i) Different output format: The two search types result in differently formatted outputs.'], title='Characterizing Web Search in The Age of Generative AI'), Citation(url='https://arxiv.org/abs/2312.10997', excerpts=['This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the ...'], title='Retrieval-Augmented Generation for Large Language Models - arXiv'), Citation(url='https://magazine.sebastianraschka.com/p/llm-research-papers-2025-list-one', excerpts=['10 Mar, R1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning, <https://arxiv.org/abs/2503.05592>', '12 Mar, Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning, <https://arxiv.org/abs/2503.09516>', '10 Mar, LMM-R1: Empowering 3B LMMs with Strong Reasoning Abilities Through Two-Stage Rule-Based RL, <https://arxiv.org/abs/2503.07536>', 'Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning, <https://arxiv.org/abs/2503.09516>', 'R1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning, <https://arxiv.org/abs/2503.05592>', 'LMM-R1: Empowering 3B LMMs with Strong Reasoning Abilities Through Two-Stage Rule-Based RL, <https://arxiv.org/abs/2503.07536>', 'he categories I came up with are:\\n\\n1. Reasoning Models\\n   \\n   \\\\- 1a. Training Reasoning Models\\n   \\n   \\\\- 1b. Inference-Time Reasoning Strategies\\n   \\n   \\\\- 1c. Evaluating LLMs and/or Understanding Reasoning\\n2. Other Reinforcement Learning Methods for LLMs\\n3. Other Inference-Time Scaling Methods\\n4. Efficient Training & Architectures\\n5. Diffusion-Based Language Models\\n6. Multimodal & Vision-Language Models\\n7. Data & Pre-training Datasets', '30 Mar, RARE: Retrieval-Augmented Reasoning Modeling, <https://arxiv.org/abs/2503.23513>', '26 Mar, Understanding R1-Zero-Like Training: A Critical Perspective, <https://arxiv.org/abs/2503.20783>', 'A topic-organized collection of 200+ LLM research papers from 2025', '\\n# LLM Research Papers: The 2025 List (January to June)\\n'], title='LLM Research Papers: The 2025 List (January to June)'), Citation(url='https://www.mdpi.com/2076-3417/15/11/6247', excerpts=['by A James ¬∑ 2025 ¬∑ Cited by 2 ‚Äî The main contribution of this research focusses on the implementation of an RAG-based system to address a real-world scenario, based on the Baseline Review 2024 ...'], title='Retrieval-Augmented Generation to Generate Knowledge ...'), Citation(url='https://simonwillison.net/2025/Apr/21/ai-assisted-search/', excerpts=['Those 2023-era versions were promising but very disappointing. They had a strong tendency to hallucinate details that weren‚Äôt present in the search results, to the point that you couldn‚Äôt trust anything they told you. In this first half of 2025 I think these systems have finally crossed the line into being genuinely useful.', 'For the past two and a half years the feature I‚Äôve most wanted from LLMs is the ability to take on search-based research tasks on my behalf.'], title='AI assisted search-based research actually works now'), Citation(url='https://arxiv.org/html/2504.14891v1', excerpts=[' Mtrag: A multi-turn conversational benchmark for evaluating retrieval-augmented generation systems. arXiv preprint arXiv:2501.03468, 2025\\n'], title='Retrieval Augmented Generation Evaluation in the Era of ...'), Citation(url='https://aws.amazon.com/what-is/retrieval-augmented-generation/', excerpts=['RAG is the process of optimizing the output of a large language model, so it references an authoritative knowledge base outside of its training data sources ...'], title='What is RAG? - Retrieval-Augmented Generation AI Explained - AWS')], confidence='high'), FieldBasis(field='security_and_robustness_challenges.description', reasoning='The central claim is that data poisoning poses a significant threat to the integrity of LLMs in retrieval-augmented settings because adversaries can contaminate external knowledge bases, inject manipulated content, or craft retrieval-optimized injections, leading to false or malicious outputs. The most directly supporting material notes that the RAG paradigm increases vulnerability due to integration of external knowledge and highlights vulnerability when attackers manipulate knowledge within RAG systems. Additional excerpts discuss formal threat models and attack surfaces in RAG, illustrating concrete avenues for data manipulation and the propagation of poisoned information. Other excerpts describe attack tasks and security benchmarks that classify and demonstrate how retrieval, filtering, and generation can be bypassed, which aligns with the broader robustness concerns associated with data poisoning. Finally, several excerpts touch on privacy risks and logging of sensitive data, which provides contextual background on security/robustness concerns but are less directly about data poisoning than the RAG-specific threats. Overall, the strongest support comes from discussion of RAG vulnerabilities due to external knowledge sources, with supplementary support from threat models and attack-bypass frameworks, and weaker relevance from general privacy discussions.', citations=[Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['The _indexing-retrieval-generation_ paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs). However, the incorporation of external and unverified knowledge increases the vulnerability of LLMs because attackers can perform attack tasks by manipulating knowledge.', ' We reveal four attack tasks capable of bypassing the _retriever_ , _filter_ , and _generator_ .', 'First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2509.20324v1', excerpts=['AG systems introduce novel attack vectors for privacy and security breaches due to their hybrid architecture, which combines a retriever ‚Ñõ \\\\\\\\mathcal{R} that accesses data from an external knowledge base ùíü \\\\\\\\mathcal{D} with an LLM generator ùí¢ \\\\\\\\mathcal{G} . In a RAG architecture, attacks can emerge at different stages of the process. At Step 3, adversaries may attempt to compromise the integrity of the knowledge base, while Step 8 presents a privacy risk due to the leakage of retrieved verbatim conten', '## III Threat Model and Attack Surfaces'], title='RAG Security and Privacy: Formalizing the Threat Model ...'), Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['Logs might inadvertently\\n\\nstore sensitive user data'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)')], confidence='high'), FieldBasis(field='influential_architectural_and_model_trends.impact_on_web_search', reasoning='The target field describes a shift in web search for LLMs toward agentic, multi-step reasoning and autonomous action. Excerpts that discuss agentic retrieval-augmented generation (Agentic RAG), planning, decomposition of tasks, and tool use (search, calculators, APIs) directly map to transforming web search into a complex, multi-hop, action-enabled process. Phrases describing planning, sequencing of actions, self-critique, self-directed retrieval, and deep research frameworks illustrate the architectural and methodological trend. Excerpts that explain how function calling enables LLMs to trigger searches and use external resources provide concrete mechanisms for this transformation. Excerpts that summarize the evolution from static retrieval to agentic, real-world web interaction further contextualize the trend. Together, these excerpts substantiate the claim that web search for LLMs is moving beyond retrieval to integrated reasoning, planning, and action across multiple sources and tools.', citations=[Citation(url='https://arxiv.org/html/2506.18959v3', excerpts=['Equipped with TTS on reasoning and search, LLMs are set to drive a new search paradigm termed Agentic Deep Research systems, which are capable of autonomous re asoning , on-demand search ing , and iterative information synthesis.', 'Equipped with TTS on reasoning and search, LLMs are set to drive a new search paradigm termed Agentic Deep Research systems, which are capable of autonomous re asoning , on-demand search ing , and iterative information synthesis.', 'In contrast, HLE focuses on presenting expert-level questions across diverse academic domains that cannot be solved through naive retrieval alone.'], title='From Web Search towards Agentic Deep Research'), Citation(url='https://arxiv.org/html/2506.18959v1', excerpts=['Equipped with TTS on reasoning and search, LLMs are set to drive a new search paradigm termed Agentic Deep Research systems, which are capable of autonomous re asoning , on-demand search ing , and iterative information synthesis.', 'In contrast, HLE focuses on presenting expert-level questions across diverse academic domains that cannot be solved through naive retrieval alone.', 'These agents learn to decompose complex tasks, plan query sequences, verify evidence, and adjust their strategies based on environment feedback.', 'These agents learn to decompose complex tasks, plan query sequences, verify evidence, and adjust their strategies based on environment feedback.'], title='From Web Search towards Agentic Deep ReSearch'), Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'For Agentic RAG, function calling provides a straightforward and structured way for the LLM agent to invoke a search API when its internal analysis determines that external information is required to answer a prompt accurately.', 'This addresses a key limitation of many existing agents, whether prompt-engineered or trained in simulated/static RAG settings, which often struggle with the complexities of real-world web interaction.', 'Large Reasoning Model-based : A growing trend in Agentic RAG workflow involves directly utilizing LLMs that possess inherently strong reasoning capabilities, often referred to as Large Reasoning Models (LRMs).', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. R', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', ' ‚Äì Late 2022\\n\\n* ReAct is a seminal prompting paradigm that fundamentally enabled ‚Äúagentic‚Äù behavior in Large Language Models (LLMs). While not a Retrieval-Augmented Generation (RAG) method itself, ReAct provides the architectural foundation for advanced, multi-step RAG systems. * ReAct combines Reasoning (using Chain-of-Thought style prompts) with Acting (executing external actions like API calls or web searches) in a deliberately interleaved sequence:', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)'], title='Evolution of RAG from Static Knowledge to Agentic ...'), Citation(url='https://arxiv.org/html/2505.10468v1', excerpts=['The progression toward AI Agents is inseparable from the strategic integration of LLMs as reasoning engines and their augmentation through structured tool use. This synergy transforms static language models into dynamic cognitive entities capable of perceiving, planning, acting, and adapting setting the stage for multi-agent collaboration, persistent memory, and scalable autonomy.', 'These capabilities have opened pathways for more robust behavior of AI agents such as long-horizon planning, cross-tool coordination, and adaptive learning loops.', 'May 15, 2025 ‚Äî This review critically distinguishes between AI Agents and Agentic AI, offering a structured conceptual taxonomy, application mapping, and challenge analysis'], title='AI Agents vs. Agentic AI: A Conceptual Taxonomy, ...'), Citation(url='https://arxiv.org/pdf/2503.22458?', excerpts=[' 11. A Roadmap of Evaluation of LLM-based Agents for Multi-turn Conversation. The blue line represents the development of\\n\\nmetrics and benchmark for Multi-turn Conversation. The orange line represents the development of Multi-turn Conversation\\n\\nand Le [216] introduced models that improved fluency and context understanding. New evaluation metrics like\\n\\nBLEU [ 165 ] and perplexity [ 90 ] emerged to measure generation quality over multiple turns. Researchers started\\n\\nrecognizing the limitations of purely reference-based metrics and began incorporating more contextual and\\n\\ndiversity-oriented frameworks (e.g., human preference ratings, embedding-based scores)'], title='Evaluating LLM-based Agents for Multi-Turn Conversations'), Citation(url='https://www.kdnuggets.com/7-free-web-search-apis-for-ai-agents', excerpts=['Sep 16, 2025 ‚Äî 2. Tavily. Tavily is a search engine for AI agents and LLMs that turns queries into vetted, LLM-ready insights in a single API call.'], title='7 Free Web Search APIs for AI Agents')], confidence='high'), FieldBasis(field='influential_architectural_and_model_trends.trend_name', reasoning='The field value identifies a trend name that combines Agentic RAG and AI Agent Systems. Excerpts that explicitly reference Agentic RAG or AI agents align most closely with this trend name. The top excerpts describe how function calling enables LLMs to perform real-time searches, access external systems, and trigger structured API calls‚Äîcore aspects of Agentic RAG and AI Agent Systems. Additional excerpts directly address the Agentic RAG workflow, including an agentic mechanism for triggering searches and a Reason-in-Documents module to distill relevant information, which strengthens the connection to the trend. Excerpts discussing AI Agents and the conceptual taxonomy of AI Agents vs. Agentic AI further substantiate the broader shift toward agentic capabilities in AI systems, which is consistent with the trend name. Related passages about the evolution of RAG, modular architectures, self-reflection, and Self-RAG provide contextual backbone showing how agentic approaches emerged and expanded, supporting the identification of the trend at a system level. excerpts describing ReAct-style reasoning and self-directed retrieval also reinforce the notion of agent-centric architectures driving modern web-search‚Äìaugmented reasoning. Overall, the strongest support comes from explicit discussions of Agentic RAG and AI Agent systems, with corroborating context from adjacent discussions on architecture, evaluation, and taxonomy.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'For Agentic RAG, function calling provides a straightforward and structured way for the LLM agent to invoke a search API when its internal analysis determines that external information is required to answer a prompt accurately.', 'This addresses a key limitation of many existing agents, whether prompt-engineered or trained in simulated/static RAG settings, which often struggle with the complexities of real-world web interaction.', 'Large Reasoning Model-based : A growing trend in Agentic RAG workflow involves directly utilizing LLMs that possess inherently strong reasoning capabilities, often referred to as Large Reasoning Models (LRMs).', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2505.10468v1', excerpts=['The progression toward AI Agents is inseparable from the strategic integration of LLMs as reasoning engines and their augmentation through structured tool use. This synergy transforms static language models into dynamic cognitive entities capable of perceiving, planning, acting, and adapting setting the stage for multi-agent collaboration, persistent memory, and scalable autonomy.', 'These capabilities have opened pathways for more robust behavior of AI agents such as long-horizon planning, cross-tool coordination, and adaptive learning loops.', 'May 15, 2025 ‚Äî This review critically distinguishes between AI Agents and Agentic AI, offering a structured conceptual taxonomy, application mapping, and challenge analysis'], title='AI Agents vs. Agentic AI: A Conceptual Taxonomy, ...'), Citation(url='https://arxiv.org/html/2506.18959v3', excerpts=['In contrast, HLE focuses on presenting expert-level questions across diverse academic domains that cannot be solved through naive retrieval alone.', 'Equipped with TTS on reasoning and search, LLMs are set to drive a new search paradigm termed Agentic Deep Research systems, which are capable of autonomous re asoning , on-demand search ing , and iterative information synthesis.', 'Equipped with TTS on reasoning and search, LLMs are set to drive a new search paradigm termed Agentic Deep Research systems, which are capable of autonomous re asoning , on-demand search ing , and iterative information synthesis.'], title='From Web Search towards Agentic Deep Research'), Citation(url='https://arxiv.org/html/2506.18959v1', excerpts=['In contrast, HLE focuses on presenting expert-level questions across diverse academic domains that cannot be solved through naive retrieval alone.', 'Equipped with TTS on reasoning and search, LLMs are set to drive a new search paradigm termed Agentic Deep Research systems, which are capable of autonomous re asoning , on-demand search ing , and iterative information synthesis.', 'These agents learn to decompose complex tasks, plan query sequences, verify evidence, and adjust their strategies based on environment feedback.', 'These agents learn to decompose complex tasks, plan query sequences, verify evidence, and adjust their strategies based on environment feedback.'], title='From Web Search towards Agentic Deep ReSearch'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', ' ‚Äì Late 2022\\n\\n* ReAct is a seminal prompting paradigm that fundamentally enabled ‚Äúagentic‚Äù behavior in Large Language Models (LLMs). While not a Retrieval-Augmented Generation (RAG) method itself, ReAct provides the architectural foundation for advanced, multi-step RAG systems. * ReAct combines Reasoning (using Chain-of-Thought style prompts) with Acting (executing external actions like API calls or web searches) in a deliberately interleaved sequence:', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', 'Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. R', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. '], title='Evolution of RAG from Static Knowledge to Agentic ...'), Citation(url='https://www.kdnuggets.com/7-free-web-search-apis-for-ai-agents', excerpts=['Sep 16, 2025 ‚Äî 2. Tavily. Tavily is a search engine for AI agents and LLMs that turns queries into vetted, LLM-ready insights in a single API call.'], title='7 Free Web Search APIs for AI Agents')], confidence='high'), FieldBasis(field='security_and_robustness_challenges.specific_threat', reasoning='The strongest support comes from excerpts that explicitly describe vulnerabilities in retrieval-augmented architectures due to external or unverified knowledge and the possibility of attackers manipulating that knowledge to induce failures or mislead the model. This directly maps to data poisoning as a concrete mechanism where adversaries corrupt or influence the knowledge base or retrieved content, thereby polluting the data the system relies on. Additional support comes from excerpts that outline threat-model style analyses and attack tasks that bypass or compromise critical components (retriever, filter, generator), which are compatible with data-poisoning scenarios since poisoned data can propagate through these stages. Supporting context also appears in excerpts discussing the integrity of knowledge bases and the broader security risks in RAG systems, reinforcing the relevance of data poisoning as a concrete threat surface. Less directly supportive excerpts discuss privacy risks or high-level threat surfaces, which provide background context but do not specifically demonstrate data-poisoning behavior.', citations=[Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['The _indexing-retrieval-generation_ paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs). However, the incorporation of external and unverified knowledge increases the vulnerability of LLMs because attackers can perform attack tasks by manipulating knowledge.', ' We reveal four attack tasks capable of bypassing the _retriever_ , _filter_ , and _generator_ .', 'First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2509.20324v1', excerpts=['## III Threat Model and Attack Surfaces', 'AG systems introduce novel attack vectors for privacy and security breaches due to their hybrid architecture, which combines a retriever ‚Ñõ \\\\\\\\mathcal{R} that accesses data from an external knowledge base ùíü \\\\\\\\mathcal{D} with an LLM generator ùí¢ \\\\\\\\mathcal{G} . In a RAG architecture, attacks can emerge at different stages of the process. At Step 3, adversaries may attempt to compromise the integrity of the knowledge base, while Step 8 presents a privacy risk due to the leakage of retrieved verbatim conten'], title='RAG Security and Privacy: Formalizing the Threat Model ...'), Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='evaluation_benchmarks_and_metrics.9', reasoning='The field value describes a formal benchmark (Deep Research Bench) with offline evaluation (RetroSearch) and explicit metrics (grounded accuracy, citation/grounding rates, latency, action budgets). Excerpts that directly address benchmark design and evaluation for LLMs align with these concepts: the idea that responses must be grounded in provided documents and be fully attributable to source material supports the notion of measured grounding accuracy and citation fidelity. The mention of a comprehensive benchmark and online leaderboard provides a concrete example of how such evaluations are structured and scored, which resonates with the described purpose and metrics of the Deep Research Bench. Discussions of judging prompts, bias mitigation, and the need for ground-truth grounding align with the intent to quantify reliability, grounding, and latency in an offline evaluation setting. Collectively, these excerpts establish a framework for what constitutes a rigorous benchmark for deep research tasks, including grounding requirements, scoring criteria, and evaluation infrastructure, all of which map onto the described Deep Research Bench and its measurement goals. The most relevant pieces explicitly tie benchmarking to grounding in documents, scoring consistency, and leaderboard-based assessment, which are core to understanding how such a Deep Research Bench might be operationalized. The less direct but still relevant pieces emphasize broad benchmarking practices and the role of multiple judges to ensure fair evaluation, which complements the overall benchmarking narrative. Overall, these excerpts provide a coherent backdrop for evaluating agentic LLMs on deep research tasks by grounding, scoring, and benchmarking semantics, even though none explicitly mention RetroSearch or the exact Deep Research Bench name.', citations=[Citation(url='https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/', excerpts=['To succeed on a given example, an LLM must synthesize the complex information in the document and generate a long-form response that is both a comprehensive answer to the user request and fully attributable to that document.', 'Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations', 'the FACTS Grounding dataset comprises 1,719 examples, each carefully crafted to require long-form responses grounded in the context document provided.', 'A factually correct response that fails to properly address the user‚Äôs request fails the benchmarking example.', 'Second, responses are judged as factually accurate if they are fully grounded in information contained in the provided document, with no hallucinations.', 'Each example comprises a document, a system instruction requiring the LLM to exclusively reference the provided document, and an accompanying user request.', 'The automatic judge models were comprehensively evaluated against a held-out test set to find the best performing judging prompt templates and to verify agreement with human raters.', ' We‚Äôve already tested leading LLMs using FACTS Grounding and have populated the initial leaderboard with their grounding scores. '], title='FACTS Grounding: A new benchmark for evaluating the factuality of ...')], confidence='medium'), FieldBasis(field='security_and_robustness_challenges.affected_systems', reasoning=\"The finegrained field value points to two kinds of systems: Retrieval-Augmented Generation (RAG) and Agentic Browsing. Explicit discussion of RAG and its security implications directly supports identifying affected systems as RAG-based architectures. One excerpt explicitly describes the 'indexing-retrieval-generation paradigm of retrieval-augmented generation (RAG)' and notes that integrating external knowledge increases vulnerability, which aligns with the notion of affected systems being RAG-based. Another excerpt explicitly discusses 'RAG architecture' combining a retriever that accesses external data with an LLM generator, identifying RAG as a system with distinct attack surfaces. Additional excerpts describe threat models, attack surfaces, and tasks that bypass key components of RAG pipelines (the retriever, the filter, and the generator), further substantiating that RAG-based systems are indeed within the scope of security and robustness concerns. Collectively, these excerpts directly connect to the finegrained field value by detailing how RAG pipelines are exposed to privacy and integrity risks, which supports categorizing RAG as an affected system. While there is mention of agentic browsing conceptually in the field value, none of the excerpts explicitly define agentic browsing; however, the detailed discussions of RAG-related vulnerabilities provide strong support for the RAG portion of the field value. The privacy-focused excerpts provide broader context but do not contradict the relevance of RAG security discussions.\", citations=[Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['The _indexing-retrieval-generation_ paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs). However, the incorporation of external and unverified knowledge increases the vulnerability of LLMs because attackers can perform attack tasks by manipulating knowledge.', ' We reveal four attack tasks capable of bypassing the _retriever_ , _filter_ , and _generator_ .', 'First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2509.20324v1', excerpts=['AG systems introduce novel attack vectors for privacy and security breaches due to their hybrid architecture, which combines a retriever ‚Ñõ \\\\\\\\mathcal{R} that accesses data from an external knowledge base ùíü \\\\\\\\mathcal{D} with an LLM generator ùí¢ \\\\\\\\mathcal{G} . In a RAG architecture, attacks can emerge at different stages of the process. At Step 3, adversaries may attempt to compromise the integrity of the knowledge base, while Step 8 presents a privacy risk due to the leakage of retrieved verbatim conten', '## III Threat Model and Attack Surfaces'], title='RAG Security and Privacy: Formalizing the Threat Model ...'), Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['Logs might inadvertently\\n\\nstore sensitive user data'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)')], confidence='medium'), FieldBasis(field='timeline_of_milestones', reasoning='The milestone about introducing a reference-free suite of metrics for automated evaluation of RAG quality directly aligns with mentions of RAGAS-style metrics that assess faithfulness and answer relevancy without requiring reference data. The cited material describes a framework for evaluating grounding and fidelity of retrieved-and-generated content, which maps to that milestone. The milestone describing a seminal paper where an LLM learns to retrieve on-demand and critique its own generations corresponds to Self-RAG and related self-reflection concepts, which are explicitly discussed as self-critique mechanisms within retrieval-augmented workflows. The milestone noting a launch or maturation of a multimodal, next-generation foundation model (e.g., Gemini) is reflected in discussions of grounding, tool use, and web-enabled reasoning within agentic systems, illustrating the era‚Äôs shift toward autonomous, grounded reasoning and retrieval. The 2024 milestone around a robustness-enhancing retrieval approach that triggers web searches for self-correction maps to Corrective Retrieval Augmented Generation (CRAG), which is explicitly described as a self-correcting retriever design. The 2025 milestone reflecting a comprehensive evaluation suite for ‚Äòdeep research‚Äô tasks and the broader shift to agentic RAG is echoed in discussions of agentic frameworks and live evaluation methodologies that emphasize iterative retrieval, validation, and evidence integration. The included CRAG and adaptive retrieval discussions provide concrete architectural and methodological steps that underlie these milestones, including decomposition of queries, adaptive retrieval, and multi-stage grounding. Additionally, multiple excerpts reiterate the RAGAS-style metrics ecosystem (context precision, faithfulness, answer relevancy, etc.) and emphasize their role in evaluating grounding quality, aligning with the milestone of reference-free, multi-dimensional evaluation. Overall, the selected excerpts directly support the milestones by detailing the evaluation frameworks (RAGAS), the self-reflective/self-correcting paradigms (Self-RAG/CRAG), and the strategic shift toward agentic, tool-enabled, retrieval-augmented reasoning that characterizes the 2023‚Äì2025 milestones in this field.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', 'Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. R', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. '], title='Evolution of RAG from Static Knowledge to Agentic ...'), Citation(url='https://www.giskard.ai/knowledge/rag-benchmarking-for-ai-evaluation', excerpts=['RAGAS (Retrieval-Augmented Generation Assessment System) is an evaluation framework offering various metrics to measure the quality of a RAG model‚Äôs responses. Below is an explanation of these metrics along with usage examples:', ' **Answer Relevancy  \\n   ** Answer relevancy evaluates whether the model‚Äôs response is relevant to the question, even if it is not entirely accurate or detail', '*Faithfulness  \\n   ** Faithfulness assesses the extent to which the model‚Äôs response is supported by information in the reference document. The response must align with the source or reference document without introducing unsupported information'], title='RAG Benchmarking: Comparing RAGAS, BERTScore, and ...'), Citation(url='https://www.patronus.ai/llm-testing/rag-evaluation-metrics', excerpts=['Five key metrics are used to evaluate RAG performance: context relevance, context sufficiency, answer relevance, answer correctness and answer hallucination.'], title='Best Practices for Evaluating RAG Systems'), Citation(url='https://dkaarthick.medium.com/ragas-for-rag-in-llms-a-comprehensive-guide-to-evaluation-metrics-3aca142d6e38', excerpts=['RAGAS introduces several metrics that provide a more holistic evaluation of RAG models, focusing on aspects like faithfulness, answer relevancy, context precision, and context recall.', 'aithfulness** measures the factual accuracy of the generated response based on the retrieved documents. **Formul', 'Answer Relevancy** evaluates how relevant the generated response is to the original query. **Formu'], title='RAGAS for RAG in LLMs: A Comprehensive Guide to ...'), Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.', '1. **Generation with Decompose-then-Recompose Algorithm** :\\n\\nRetrieved documents are broken down into smaller components to focus on key insights while filtering out irrelevant or redundant details. The filtered information is recombined into a cohesive and concise dataset, optimizing the quality of data input for generation.', '#### **Advantages of CRAG**\\n\\n**Improved Accuracy** :\\n\\nBy evaluating and correcting retrieved data, CRAG ensures more reliable and factually accurate outputs.', '**Dynamic Adaptability** :\\n\\nThe integration of large-scale web searches allows CRAG to expand beyond static knowledge bases, providing up-to-date and diverse information.', '**Efficient Data Utilization** :\\n\\nThe decompose-then-recompose algorithm reduces noise and focuses on critical insights, ensuring the generated responses are both concise and relevant.', '**Better Robustness** :\\n\\nCRAG mitigates the risk of generating incorrect knowledge by dynamically addressing errors in the retrieval process.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='medium'), FieldBasis(field='influential_architectural_and_model_trends.representative_models_or_systems', reasoning='The field value asserts that the Agentic RAG trend is embodied by various frameworks and models, with a foundational role for the ReAct (Reason + Act) prompting paradigm. The most directly supportive content describes how function calling enables LLMs to invoke searches or external actions, which underpins agentic retrieval behavior. Specifically, the statement that an Agentic RAG framework uses a formatted mechanism for an LLM to trigger a search API aligns with the cited passages on function calling and external tool use. The Search-o1 framework is explicitly identified as designed to enhance LRMs with agentic retrieval, linking to self-assessed knowledge gaps and a Reason-in-Documents module that distills relevant information for robust reasoning, which corroborates the notion of agentic, multi-step, live-information-enhanced workflows. Additional content mentions ReAct as a seminal paradigm integrating reasoning with external actions, which directly supports the foundational role of ReAct in agentic systems. A nearby excerpt reiterates the broader discussion of agentic RAG progress and contextualizes it within a web-search/agentic-research narrative, reinforcing the relevance of the composite idea. Overall, the strongest support centers on ReAct and the Search-o1 framework, with function calling as the operational mechanism for external retrieval, while AutoGPT and explicit Microsoft product references are not evidenced in the provided excerpts.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['For Agentic RAG, function calling provides a straightforward and structured way for the LLM agent to invoke a search API when its internal analysis determines that external information is required to answer a prompt accurately.', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' ‚Äì Late 2022\\n\\n* ReAct is a seminal prompting paradigm that fundamentally enabled ‚Äúagentic‚Äù behavior in Large Language Models (LLMs). While not a Retrieval-Augmented Generation (RAG) method itself, ReAct provides the architectural foundation for advanced, multi-step RAG systems. * ReAct combines Reasoning (using Chain-of-Thought style prompts) with Acting (executing external actions like API calls or web searches) in a deliberately interleaved sequence:'], title='Evolution of RAG from Static Knowledge to Agentic ...'), Citation(url='https://arxiv.org/html/2506.18959v1', excerpts=['These agents learn to decompose complex tasks, plan query sequences, verify evidence, and adjust their strategies based on environment feedback.', 'These agents learn to decompose complex tasks, plan query sequences, verify evidence, and adjust their strategies based on environment feedback.'], title='From Web Search towards Agentic Deep ReSearch')], confidence='medium'), FieldBasis(field='major_industry_implementations.1', reasoning='The finegrained field describes Microsoft‚Äôs Copilot integration in an enterprise context with emphasis on grounding, real-time web information via Bing, data privacy within the Microsoft 365 boundary, and layered governance/controls. Excerpts that explicitly state Copilot‚Äôs web-grounding behavior, its enterprise-oriented design, and the use of Bing as a grounding source provide direct support. Additionally, passages detailing the three-part Copilot workflow (prompt, web query if needed, response) and the layered protection/governance architecture map well to the described integration pattern, where enterprise controls and semantic indexing enable secure access to internal and web data. Other excerpts that mention web search toggles, how prompts are parsed to identify web-enhanced terms, and how search queries are sent to Bing further corroborate the grounding and privacy controls described, anchoring the field value in concrete operational practices. Collectively, these excerpts align with the specified field value by illustrating enterprise-focused grounding, web data utilization via Bing, privacy-bound data handling within Microsoft 365, and governance mechanisms that regulate how Copilot accesses and cites information. ', citations=[Citation(url='https://techcommunity.microsoft.com/blog/microsoft365copilotblog/microsoft-365-copilot-web-search-delivering-multiple-layers-of-protection-and-co/4458224', excerpts=['That‚Äôs why Copilot can ground its answers with current information from the web, closing knowledge gaps that every large language model (LLM) inevitably has based on its training data cutoff.', 'A Copilot interaction has three parts: your prompt, a web query (if needed), and the response.', 'Traditional web search engines are optimized for broad consumer scenarios. Copilot‚Äôs web search is enterprise oriented and layered with controls that consumer search does not provide.'], title='Microsoft 365 Copilot Web Search: Delivering Multiple ...'), Citation(url='https://learn.microsoft.com/en-us/copilot/overview', excerpts=['Nov 11, 2025 ‚Äî Copilot Chat is AI chat grounded in data from the web and powered by the latest large language models (LLMs). Copilot Chat lets users access agents and create\\xa0...'], title='Overview of Microsoft 365 Copilot Chat'), Citation(url='https://learn.microsoft.com/en-us/copilot/microsoft-365/manage-public-web-access', excerpts=['When web search is enabled, Microsoft 365 Copilot and Microsoft 365 Copilot Chat may fetch information from the Bing search service when information from the web helps to provide a better, more grounded response.', 'generated search queries sent to the Bing search service to ground responses in web data. The way Microsoft handles these queries is identical in both services. Gen', 'When web search is enabled, Microsoft 365 Copilot and Microsoft 365 Copilot Chat parse the user‚Äôs prompt and identifies terms where information from the web would improve the quality of the response.', 'ontrols and a user-level **Web content** toggle (only for Microsoft 365 Copilot) are available to [manage whether web search is enabled]() in your environment', 'osoft 365 **Copilot Search** is an additional, universal search experience that allows users with a Microsoft 365 Copilot license to search across all their Microsoft 365 and third-party data sources.'], title='Data, privacy, and security for web search in Microsoft 365 ...')], confidence='high'), FieldBasis(field='evaluation_benchmarks_and_metrics.3', reasoning='The field value describes a 2025-era live research benchmark for evaluating LLMs, with a focus on iterative evidence-seeking, validation, and integration, measured via a DeepEval-like suite including presentation, consistency, depth, and citation-coverage metrics. Excerpts that discuss the FACTS Grounding benchmark align closely with this concept: they explain that the evaluation aims to measure how well responses are grounded in provided documents, how factually accurate outputs are, and how performance is judged against a grounded standard rather than hallucinations. Specific passages describe the benchmark‚Äôs purpose to evaluate grounding accuracy in responses, the requirement that responses be fully grounded in documents, and the use of a leaderboard and diverse judges to assess grounding quality. Other excerpts outline the construction of the benchmark (document, system instruction to reference only the document, user request) and the dataset size (the FACTS Grounding dataset with many examples), which all map to the notion of a structured evaluation framework with defined metrics. Collectively, these excerpts support the idea of an organized benchmarking effort with criteria that resemble the stated field value‚Äôs emphasis on depth, citation association, and rubric-like assessment, even though they do not mention LiveResearchBench or DeepEval by name. The most directly supportive content emphasizes that a factually correct response must be grounded in provided material, and that scoring involves judging grounding quality and consistency across examples, which corresponds to the described evaluation metrics in the field value.', citations=[Citation(url='https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/', excerpts=['Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations', 'A factually correct response that fails to properly address the user‚Äôs request fails the benchmarking example.', 'To succeed on a given example, an LLM must synthesize the complex information in the document and generate a long-form response that is both a comprehensive answer to the user request and fully attributable to that document.', 'Second, responses are judged as factually accurate if they are fully grounded in information contained in the provided document, with no hallucinations.', 'Each example comprises a document, a system instruction requiring the LLM to exclusively reference the provided document, and an accompanying user request.', 'the FACTS Grounding dataset comprises 1,719 examples, each carefully crafted to require long-form responses grounded in the context document provided.', 'We selected a combination of different judges to mitigate any potential bias of a judge giving higher scores to the responses produced by a member of its own model family.', 'The final score for the overall grounding task is the average of all judge models‚Äô scores across all examples.', 'three frontier LLM judges ‚Äî namely Gemini 1.5 Pro, GPT-4o, and Claude 3.5 Sonnet.', ' We‚Äôve already tested leading LLMs using FACTS Grounding and have populated the initial leaderboard with their grounding scores. '], title='FACTS Grounding: A new benchmark for evaluating the factuality of ...')], confidence='medium'), FieldBasis(field='market_and_publisher_ecosystem_impact', reasoning='The field value centers on how the integration of LLM-based web search features‚Äîparticularly AI Overviews and agentic web search‚Äîalters the digital market and the publisher ecosystem, including shifts in traffic and revenue models. Excerpts describing Google‚Äôs Generative AI in Search and AI Overviews indicate that search results can present synthesized answers at the top of the results page, which reduces the need for users to click through to individual source sites and thereby shifts referral dynamics that publishers rely on. For example, passages note that AI Overviews provide quick answers and are deployed within Google Search, illustrating how such features change user behavior and the information landscape. This directly informs the potential for traffic displacement from publishers and the broader ad-supported ecosystem described in the target field value. Additional passages discuss the rollout of AI Overviews in 2024 and the proliferation of web-grounded capabilities, establishing a context in which publishers would experience traffic and monetization pressures. Moreover, excerpts about enterprise web-grounding and Copilot‚Äôs web search grounding illustrate how organizations manage and constrain web-derived information, which is relevant to understanding the broader ecosystem where AI-grounded search operates and how it may affect content exposure and distribution in both consumer and enterprise settings. The combination of: (a) top-of-page synthesized AI responses, (b) rollout timelines and adoption signals, and (c) enterprise grounding controls, provides direct support for the claimed market/publisher ecosystem impacts and the zero-click dynamic described in the field value. While the excerpts do not all provide exact CTR figures, they collectively corroborate the mechanisms and market context driving such outcomes, enabling a reasoned interpretation of the field value. The strongest support comes from explicit statements about AI Overviews enabling synthesized top-of-results answers and the rollout, which underpin the zero-click/traffic-displacement narrative. The surrounding passages about enterprise grounding and transparency enrich understanding of how the ecosystem responds to such changes and how publishers‚Äô visibility could be affected in different deployment contexts. ', citations=[Citation(url='https://blog.google/products/search/generative-ai-google-search-may-2024/', excerpts=[' Now, with generative AI, Search can do more than you ever imagined. So you can ask whatever‚Äôs on your mind or whatever you need to get done ‚Äî from researching to planning to brainstorming ‚Äî and Google will take care of the legwork. This is all made possible by a new Gemini model customized for Google Search. It brings together Gemini‚Äôs advanced capabilities ‚Äî including multi-step reasoning, planning and multimodality ‚Äî with our best-in-class Search systems. ', ' Get quick answers with AI Overviews\\n', ' So today, AI Overviews will begin rolling out to everyone in the U.S., with more countries coming soon. That means that this week, hundreds of millions of users will have access to AI Overviews, and we expect to bring them to over a billion people by the end of the year.\\n', '.\\nWith AI Overviews, people are visiting a greater diversity of websites for help with more complex questions. And we see that the links included in AI Overviews get more clicks than if the page had appeared as a traditional web listing for that query. As we expand this experience, we‚Äôll continue to focus on sending valuable traffic to publishers and creators. As always, ads will continue to appear in dedicated slots throughout the page, with clear labeling to distinguish between organic and sponsored results.'], title='Generative AI in Search: Let Google do the searching for you'), Citation(url='https://techcommunity.microsoft.com/blog/microsoft365copilotblog/microsoft-365-copilot-web-search-delivering-multiple-layers-of-protection-and-co/4458224', excerpts=['That‚Äôs why Copilot can ground its answers with current information from the web, closing knowledge gaps that every large language model (LLM) inevitably has based on its training data cutoff.', '#### Admin Controls\\n\\nAdministrators have precise authority over how and when web search is permitted in Copilot.\\nThe Allow Web Search policy lets them scope access by user or group, and by mode (Work vs. Web). [Additionally, audit and eDiscovery capabilities provide transparency](https://aka.ms/IntroducingWebQueryTransparency) . Every emitted web query is logged and can be linked to the originating prompt and response. These [logs are accessible](https://learn.microsoft.com/en-us/copilot/microsoft-365/manage-public-web-access) through Microsoft Purview eDiscovery and Data Security Posture Management activity explorer, enabling targeted audits and investigations when needed', '### User Protections\\n\\nUsers also have control. In the Work tab, they can toggle web grounding on or off, choosing to stay ‚Äúwork only‚Äù or bring in the web when needed. This flexibility empowers users to tailor their experience based on context. Copilot also enforces responsible AI (RAI) protections, which automatically reject certain terms, phrases, or patterns that may pose risks. Transparency is built into the experience, so users see citations to sources and the exact keywords Copilot securely sends out when performing web grounding.', '#### Query Protections\\n\\nCopilot sends only the essential keywords needed to retrieve current information. It avoids transmitting the full prompt unless the prompt itself is very short. Before transmission, user and tenant identifiers are removed, and all queries are sent securely to Bing.\\nThe results are returned securely, and both the prompt and response remain within the Microsoft 365 service boundary', '#### Contractual Commitments\\n\\nMicrosoft‚Äôs product terms codify strict commitments around query data. Microsoft has no rights in query data beyond what‚Äôs needed to provide the service. Query data is not used to improve Bing, train generative AI foundation models, or create advertising profiles. It is not shared with advertisers or beyond Microsoft. Instead, it is treated as Customer Confidential Information, reinforcing Microsoft‚Äôs commitment to privacy and trust', \"**Transparency by design:** Users can inspect both the citations and the exact keywords used for web grounding. Additionally, the user's prompts and Copilot's responses are stored within Microsoft 365 and never leave the service boundary for Copilot without customer direction.\"], title='Microsoft 365 Copilot Web Search: Delivering Multiple ...')], confidence='medium'), FieldBasis(field='influential_architectural_and_model_trends.description', reasoning='The fine-grained field value describes Agentic RAG as a significant architectural evolution from earlier retrieval-augmented models, highlighting autonomous perception, reasoning, planning, and action, with capabilities to query data sources, use tools, read and synthesize results, re-query, and self-correct. It also emphasizes Context Engineering as a key concept within this trend. Several excerpts directly address these ideas: one excerpt defines Agentic RAG as an evolution from static approaches and outlines its core components (planning, tool use, and autonomous retrieval and reasoning), which aligns with the stated paradigm shift and timeframe. A second excerpt discusses the function-calling mechanism and its role in enabling LLMs to invoke searches and APIs, which supports the autonomous, tool-using aspect of Agentic RAG. Additional excerpts describe broader trajectories toward agentic behavior in LLMs, including self-critique, planning, and collaboration with sub-agents, as well as the evolution narrative from earlier ReAct-inspired systems to Agentic RAG. These sources collectively corroborate the field value‚Äôs claim of a late-2024 to 2025 shift toward autonomous, intelligent agentic retrieval and reasoning, and they elaborate on Context Engineering as the practice of curating the model‚Äôs context to support dynamic decision-making. The strongest support comes from passages that explicitly frame Agentic RAG as a paradigm shift and as a successor to static RAG, followed by passages detailing the enabling mechanisms (planning, tool use, environment interaction) and the evolution narrative. Supporting passages that discuss related concepts like ReAct, Self-RAG, modular architectures, and agent-like AI taxonomy provide contextual reinforcement but are slightly less direct about the exact Agentic RAG paradigm described in the field value.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. '], title='Evolution of RAG from Static Knowledge to Agentic ...'), Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'This addresses a key limitation of many existing agents, whether prompt-engineered or trained in simulated/static RAG settings, which often struggle with the complexities of real-world web interaction.', 'For Agentic RAG, function calling provides a straightforward and structured way for the LLM agent to invoke a search API when its internal analysis determines that external information is required to answer a prompt accurately.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2506.18959v3', excerpts=['In contrast, HLE focuses on presenting expert-level questions across diverse academic domains that cannot be solved through naive retrieval alone.', 'Equipped with TTS on reasoning and search, LLMs are set to drive a new search paradigm termed Agentic Deep Research systems, which are capable of autonomous re asoning , on-demand search ing , and iterative information synthesis.', 'Equipped with TTS on reasoning and search, LLMs are set to drive a new search paradigm termed Agentic Deep Research systems, which are capable of autonomous re asoning , on-demand search ing , and iterative information synthesis.'], title='From Web Search towards Agentic Deep Research'), Citation(url='https://arxiv.org/html/2506.18959v1', excerpts=['In contrast, HLE focuses on presenting expert-level questions across diverse academic domains that cannot be solved through naive retrieval alone.', 'Equipped with TTS on reasoning and search, LLMs are set to drive a new search paradigm termed Agentic Deep Research systems, which are capable of autonomous re asoning , on-demand search ing , and iterative information synthesis.', 'These agents learn to decompose complex tasks, plan query sequences, verify evidence, and adjust their strategies based on environment feedback.', 'These agents learn to decompose complex tasks, plan query sequences, verify evidence, and adjust their strategies based on environment feedback.'], title='From Web Search towards Agentic Deep ReSearch'), Citation(url='https://arxiv.org/html/2505.10468v1', excerpts=['The progression toward AI Agents is inseparable from the strategic integration of LLMs as reasoning engines and their augmentation through structured tool use. This synergy transforms static language models into dynamic cognitive entities capable of perceiving, planning, acting, and adapting setting the stage for multi-agent collaboration, persistent memory, and scalable autonomy.', 'These capabilities have opened pathways for more robust behavior of AI agents such as long-horizon planning, cross-tool coordination, and adaptive learning loops.', 'May 15, 2025 ‚Äî This review critically distinguishes between AI Agents and Agentic AI, offering a structured conceptual taxonomy, application mapping, and challenge analysis'], title='AI Agents vs. Agentic AI: A Conceptual Taxonomy, ...')], confidence='medium'), FieldBasis(field='major_industry_implementations.0', reasoning=\"The finegrained field value centers on Google‚Äôs AI Overviews and its underlying Gemini-based LLM integration within Google Search. The most relevant excerpt explicitly states that Gemini is embedded into Google Search through AI Overviews and that AI Overviews are integrated with Google‚Äôs existing search systems, which directly supports the core claim about the architecture and integration pattern. The second relevant excerpt is a dedicated piece on Google‚Äôs AI Overview, providing a focused description of the feature itself and its role in Google‚Äôs search stack, which reinforces the context and capabilities of AI Overviews. The third relevant excerpt discusses Gemini‚Äôs role and versions, which aligns with the reference to the underlying Gemini model and its capabilities behind AI Overviews. The fourth and fifth excerpts discuss Google‚Äôs Gemini in the context of search and AI Overviews, thereby supporting the linkage between the Gemini model and AI Overviews within Google Search. The sixth excerpt mentions the broader Gemini surge in the context of Google‚Äôs search ecosystem, providing supporting background on the model's prominence, though it is less directly about AI Overviews than the others. Collectively, these excerpts substantiate the value proposition, integration pattern, and underlying model powering Google AI Overviews.\", citations=[Citation(url='https://adcellerant.com/blogs/ai-changing-organic-search-august-2025/', excerpts=['Gemini is now embedded into Google Search through AI Overviews and AI Mode, accessible as a standalone chatbot, and integrated across the Google suite (Gmail, Docs, YouTube, etc.).', 'From the public release of ChatGPT in late 2022 to the full launch of Google‚Äôs AI Overviews in mid-2024, the landscape has shifted so much that search engine optimization (SEO) is now being referred to as ‚ÄúSearch Everywhere Optimization.‚Äù', 'Gemini is Google‚Äôs flagship LLM and the engine behind AI Overviews, AI Mode, and Google‚Äôs standalone chatbot experience.'], title='AI is Changing Organic Search: August 2025 Update - AdCellerant'), Citation(url='https://seosherpa.com/ai-overview/', excerpts=[\"Google's AI Overview is a new search feature that utilizes generative AI to provide a concise answer at the top of the results page.\"], title=\"What Is Google's AI Overview? A Deep Dive into the Future ...\"), Citation(url='https://brassmonkey.ai/google-gemini-review/', excerpts=[\"The Gemini 1.0 version came out in late 2023, and by 2025, we now have Gemini 1.5 and Gemini Advanced. The Gemini project combines Google's AI research with ...\"], title=\"Google Gemini Review: Is Google's AI Really Worth the ...\"), Citation(url='https://fortune.com/2025/12/02/sam-altman-declares-code-red-google-gemini-ceo-sundar-pichai/', excerpts=[\"With Gemini 3's strong rollout and rising user base, Google suddenly has the edge, and OpenAI is racing to keep its dominance from slipping ...\"], title=\"Sam Altman declares 'Code Red' as Google's Gemini surges‚Äîthree ...\")], confidence='high'), FieldBasis(field='evaluation_benchmarks_and_metrics.1', reasoning='The finegrained field value describes a retrieval-augmented generation evaluation system (RAGAS) that uses reference-free metrics such as Faithfulness, Context Precision, Context Recall, and Answer Relevance, with an overall factuality score, and is used within a LangChain pipeline to penalize hallucinations. The most directly relevant excerpts define and discuss a FACTS Grounding benchmark for evaluating factuality and grounding of LLM responses. They explain that a response must be fully grounded in the provided document to be considered factually accurate, and that the final score is an aggregate across judge models, which aligns with how a RAGAS-style system would quantify factuality. Additional excerpts describe the structure of each evaluation example (document, instruction to reference only the provided document, user request), which is central to retrieval-augmented evaluation. They also discuss the dataset size and diversity, the existence of an online leaderboard, and evaluation methodology details (judges, templates, and human agreement checks). Taken together, these excerpts illustrate the components and scoring approaches that would support the stated RAGAS evaluation goals, even though they do not mention RAGAS by name. They collectively underpin how faithfulness and grounding are defined, measured, and aggregated in practice, which is the core of the finegrained field value.', citations=[Citation(url='https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/', excerpts=['To succeed on a given example, an LLM must synthesize the complex information in the document and generate a long-form response that is both a comprehensive answer to the user request and fully attributable to that document.', 'Second, responses are judged as factually accurate if they are fully grounded in information contained in the provided document, with no hallucinations.', 'A factually correct response that fails to properly address the user‚Äôs request fails the benchmarking example.', 'Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations', 'FACTS_paper) , a comprehensive benchmark for evaluating the ability of LLMs to generate responses that are not only factually accurate with respect to given inputs, but also sufficiently detailed to provide satisfactory answers to user queries. W', 'the FACTS Grounding dataset comprises 1,719 examples, each carefully crafted to require long-form responses grounded in the context document provided.', ' We‚Äôve already tested leading LLMs using FACTS Grounding and have populated the initial leaderboard with their grounding scores. ', 'Each example comprises a document, a system instruction requiring the LLM to exclusively reference the provided document, and an accompanying user request.', 'three frontier LLM judges ‚Äî namely Gemini 1.5 Pro, GPT-4o, and Claude 3.5 Sonnet.', 'To ensure a diversity of inputs, the FACTS Grounding examples include documents with a variety of lengths, up to a maximum of 32,000 tokens (roughly 20,000 words), covering domains such as finance, technology, retail, medicine, and law.', 'acts-grounding-examples) today so anyone can use it to evaluate an LLM. Of course, we know that issues of benchmark contamination and leaderboard hacking are important to protect against, so following standard industry practice, we are keeping the private evaluation set held out. T', 'We selected a combination of different judges to mitigate any potential bias of a judge giving higher scores to the responses produced by a member of its own model family.', 'The user requests are similarly wide ranging, including requests for summarization, Q&A generation, and rewriting tasks.', 'ind more details of our FACTS Grounding evaluation methodology [in our paper](https://goo.gle/FACTS_paper) .', 'The final score for the overall grounding task is the average of all judge models‚Äô scores across all examples.'], title='FACTS Grounding: A new benchmark for evaluating the factuality of ...')], confidence='high'), FieldBasis(field='representative_agentic_systems.1', reasoning='The most relevant passages describe core ideas that underpin the target field value: first, the idea that function calling enables LLMs to access real-time information and interact with external systems and APIs, which aligns with the use of live web search APIs and tool interaction in the field value. Second, the discussion of a concrete framework that uses Agentic RAG and a Reason-in-Documents module signals a structured approach to retrieving and processing external content to improve reasoning, mirroring the RL-driven, tool-using behavior described in the field value. Third, architectural and process-level descriptions of Agentic RAG, including planning steps, tool use (such as search engines and calculators), and autonomous retrieval, provide direct conceptual support for the type of autonomous, interactive search behavior highlighted in the field value. Fourth, references to Self-RAG and self-critique during retrieval/generation relate to emergent cognitive behaviors and reliability considerations that the field value implies through reinforcement learning-driven interaction with live data. Collectively, these excerpts sketch the landscape in which a Search-R1-like system would operate, including live data access, tool-enabled interaction, and self-improvement through reflective reasoning. They do not reproduce the exact system name or year, but they map closely to the mechanisms (agentic retrieval, tool use, live data access, reinforcement learning guidance) described in the field value.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='evaluation_benchmarks_and_metrics.0', reasoning=\"The most directly relevant passages describe FACTS Grounding as a benchmark to evaluate LLMs for factual accuracy with respect to provided source material and to ground responses in the document. They state that a model‚Äôs answer must be fully grounded in the given document and that a factually correct response must address the user‚Äôs request, which aligns with the finegrained field value focusing on factual grounding and evaluation. Additional passages outline the use of a multi-judge evaluation setup and an online leaderboard to measure grounding quality, which supports the field‚Äôs emphasis on objective, comparative factuality assessment across models. Other excerpts describe the structure of a typical FACTS example‚Äîcomprising a document, a system instruction to reference only that document, and a user request‚Äîillustrating how the benchmark operationalizes the grounding task. Several excerpts discuss the diversity of inputs, the existence of an accompanying paper, and the overall goal of improving factuality and reducing hallucinations, all of which reinforce the described benchmark's purpose and usage. Taken together, these excerpts substantiate the field value‚Äôs claims about purpose, evaluation criteria, judging, and leaderboard presence. Quotes such as the need for responses to be fully grounded in the document, the importance of addressing the user‚Äôs request, and the use of an ensemble of judges directly support the stated finegrained field value. Other statements about the benchmark‚Äôs dataset size, variety of domains, and the inclusion of a paper provide additional corroboration about the benchmark‚Äôs scope and validation framework, further aligning with the described evaluation use case.\", citations=[Citation(url='https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/', excerpts=['To succeed on a given example, an LLM must synthesize the complex information in the document and generate a long-form response that is both a comprehensive answer to the user request and fully attributable to that document.', 'Second, responses are judged as factually accurate if they are fully grounded in information contained in the provided document, with no hallucinations.', 'A factually correct response that fails to properly address the user‚Äôs request fails the benchmarking example.', 'Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations', 'We selected a combination of different judges to mitigate any potential bias of a judge giving higher scores to the responses produced by a member of its own model family.', 'Each example comprises a document, a system instruction requiring the LLM to exclusively reference the provided document, and an accompanying user request.', 'FACTS_paper) , a comprehensive benchmark for evaluating the ability of LLMs to generate responses that are not only factually accurate with respect to given inputs, but also sufficiently detailed to provide satisfactory answers to user queries. W', 'the FACTS Grounding dataset comprises 1,719 examples, each carefully crafted to require long-form responses grounded in the context document provided.', ' We‚Äôve already tested leading LLMs using FACTS Grounding and have populated the initial leaderboard with their grounding scores. ', 'To ensure a diversity of inputs, the FACTS Grounding examples include documents with a variety of lengths, up to a maximum of 32,000 tokens (roughly 20,000 words), covering domains such as finance, technology, retail, medicine, and law.', 'acts-grounding-examples) today so anyone can use it to evaluate an LLM. Of course, we know that issues of benchmark contamination and leaderboard hacking are important to protect against, so following standard industry practice, we are keeping the private evaluation set held out. T', 'three frontier LLM judges ‚Äî namely Gemini 1.5 Pro, GPT-4o, and Claude 3.5 Sonnet.', 'The automatic judge models were comprehensively evaluated against a held-out test set to find the best performing judging prompt templates and to verify agreement with human raters.', 'ind more details of our FACTS Grounding evaluation methodology [in our paper](https://goo.gle/FACTS_paper) .', 'The final score for the overall grounding task is the average of all judge models‚Äô scores across all examples.', 'The user requests are similarly wide ranging, including requests for summarization, Q&A generation, and rewriting tasks.'], title='FACTS Grounding: A new benchmark for evaluating the factuality of ...')], confidence='high'), FieldBasis(field='representative_agentic_systems.4', reasoning='The fine-grained field value references a WebThinker system that embeds a Deep Web Explorer into a think-search-draft loop and uses Direct Preference Optimization guided by human feedback to align behavior with preferences. The excerpts collectively describe a broader trend toward agentic RAG and related mechanisms that enable LLMs to actively search, reason about results, plan steps, and refine outputs. Specifically, passages that outline an Agentic RAG mechanism where the model dynamically triggers searches based on knowledge gaps, and passages that describe a Reason-in-Documents module for distilling relevant information and reducing noise map well to a think-search-draft loop and the core idea of iterative refinement guided by evaluation or feedback. Discussions of planning, tool use (search engines, calculators, APIs), and collaboration among sub-agents further align with the concept of an integrated retrieval-and-generation workflow that could incorporate human feedback signals via optimization techniques like DPO. While none of the excerpts mention WebThinker, Deep Web Explorer, or DPO explicitly, they establish the architectural and methodological context (agentic search, iterative refinement, human-aligned optimization) that underpins the stated field value. Therefore, the most directly relevant content is the set of excerpts describing agentic retrieval augmentation, dynamic searching, reasoning-in-documents, modular RAG, and self-critique components, which collectively support the feasibility and design pattern of a system like WebThinker.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', '4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='influential_architectural_and_model_trends.cost_and_latency_implications', reasoning='The fine-grained field value posits that Agentic RAG inherently incurs higher cost and latency because the LLM must think, plan, and perform sequential tool calls, with each step potentially triggering an additional LLM call and consuming more tokens. The most directly relevant excerpt states that function calling provides a straightforward way for the LLM to invoke a search API when external information is required, which implies extra rounds of interaction and token usage beyond simple generation. Relatedly, another excerpt explains that function calling significantly expands LLM capabilities by enabling them to access real-time information and convert requests into structured API calls, which implies added operational steps and overhead. A third excerpt highlights planning, tool use, and collaboration as core aspects of Agentic RAG, reinforcing the idea that this architectural paradigm adds complexity, steps, and potential latency through iterative actions. An excerpt noting that there are key limitations in real-world web interaction further supports the notion that practical deployment involves overhead and performance considerations. The remaining excerpt provides broader context about capabilities and architectural shifts but does not directly articulate latency or cost implications; however, it corroborates the underlying trend toward more complex, tool-driven workflows which align with the cost/latency tradeoffs described in the field value.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['For Agentic RAG, function calling provides a straightforward and structured way for the LLM agent to invoke a search API when its internal analysis determines that external information is required to answer a prompt accurately.', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'This addresses a key limitation of many existing agents, whether prompt-engineered or trained in simulated/static RAG settings, which often struggle with the complexities of real-world web interaction.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='representative_agentic_systems.0', reasoning='The most relevant material discusses agentic retrieval-augmented architectures that explicitly address when an LLM should perform a search and how retrieved content should be processed or utilized. In particular, an excerpt describing an Agentic RAG mechanism where the model dynamically triggers search queries based on self-assessed knowledge gaps directly aligns with the idea of a system that learns when to invoke web search. It also mentions a Reason-in-Documents module that distills relevant information into a refined format, which supports the notion of effectively using retrieved data, a component that would be central to a two-stage decision process in an RL-based search strategy. Additional related material describes Self-Reflective RAG and modular RAG, which emphasize planning, tool use, and iterative refinement‚Äîthese concepts provide theoretical and methodological underpinnings for designing a system that decides not only when to search but how to incorporate and critique results, which are relevant to a reinforcement-learning-based, two-step approach to search activation and information usage. While none of the excerpts explicitly name the R1-Searcher system, PPO-based training, or the exact two-stage cold-start strategy, they collectively illuminate the architectural and procedural elements (dynamic search triggering, tool use, structured processing of retrieved content, self-critique) that such a system would likely employ. The absence of explicit references to R1-Searcher or the PPO framework means the evidence supports the general design space but not the exact specification of the field value.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', '4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='representative_agentic_systems.7', reasoning='The most relevant content directly characterizes agentic and self-directed retrieval frameworks, which align with the idea of an autonomous system for long-horizon search tasks. One excerpt explicitly notes that agentic RAG represents a shift to autonomous, self-directed retrieval and reasoning, which supports the concept of an advanced ASearcher-like system operating with long-horizon planning and tool use. Additional excerpts discuss modular and agentic RAG architectures, including planning, tool use, and collaboration, which provide context for how an ASearcher-style system might orchestrate asynchronous RL and QA data to tackle extended sequences of tool interactions. Further excerpts describe the evolution from static knowledge to agentic and self-reflective RAG, reinforcing the broader methodological landscape that the finegrained field value sits within. Other excerpts touch on real-time information access and structured reasoning enhancements, which corroborate the general direction of the domain but are less specific to the ASearcher-like system details. Taken together, the positioned excerpts build a coherent backdrop for a system employing agentic, self-directed retrieval with planning and multi-step tool usage to manage long-horizon tasks.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', '4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.'], title='Evolution of RAG from Static Knowledge to Agentic ...'), Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='representative_agentic_systems.3', reasoning='The field value describes a concrete system that combines supervised guidance from human browsing trajectories with reinforcement learning fine-tuning to produce autonomous ReAct-style agents for web navigation, and notes its 2025 benchmarking against GAIA and WebWalkerQA. The excerpts most pertinent to this are those that discuss agentic retrieval-augmented generation (RAG) and autonomous, self-directed retrieval and reasoning, as well as modules that enable tool use, planning, and self-reflection. Specifically, passages that describe an Agentic RAG paradigm where an agent plans actions, triggers searches, reads and distills content, and uses external tools align with the claimed methodology of WebDancer. They also reference Self-RAG and autonomous, self-directed reasoning, which conceptually supports the idea of autonomous agents navigating the web. While there is no explicit mention of WebDancer or the exact 2025 benchmarks, the described capabilities‚ÄîAgentic RAG, planning, tool use, and autonomous web interaction‚Äîdirectly support the type of system described in the field value, albeit without direct corroboration from the excerpts. The strongest support comes from statements about an agentic framework that plans actions and uses tools to retrieve and distill information, and from notes that such an agent can operate autonomously with self-directed reasoning. Other excerpts discuss related architectural paradigms (modular RAG, Self-Reflective RAG) and the broader shift toward autonomous retrieval-and-reasoning, which provides contextual support but less direct alignment with the exact system description.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', '4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n'], title='Evolution of RAG from Static Knowledge to Agentic ...'), Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='representative_agentic_systems.8', reasoning='The finegrained field value describes a hypothetical self-supervised, offline, self-search system (SSRL) for training LLMs that reduces reliance on external live web APIs and uses a distilled pseudo search engine. The most relevant excerpts explicitly discuss Self-RAG, where the LLM performs self-critique during retrieval and generation, and Agentic RAG concepts that include self-directed planning, tool use, and autonomous retrieval. These directly map to the idea of offline or distillation-based self-search mechanisms and to reduced dependence on live external data during model training, which aligns with the core methodology and key contribution described. Excerpts that mention planning, tool use, and autonomous retrieval further support the notion of an agentic, self-guided system, while broader discussions of modular RAG and general agentic retrieval augmentation provide contextual background but are less directly tied to the offline/self-supervised angle. Collectively, the strongest support comes from explicit Self-RAG descriptions, with supporting context from agentic planning and tool-use narratives, and even broader summaries of agentic RAG progression when needed to frame the landscape.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n'], title='Evolution of RAG from Static Knowledge to Agentic ...'), Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='high'), FieldBasis(field='specific_rag_techniques.2', reasoning='The fine-grained value describes an active retrieval framework that times and selects retrieval actions based on predictions to optimize efficiency and effectiveness. An excerpt that highlights Adaptive Knowledge Retrieval explicitly states that for incorrect or ambiguous data, additional retrieval actions (often web searches) are triggered to augment the original data, which aligns with the notion of activating retrieval at opportune moments to balance cost and quality. Another excerpt discusses Corrective RAG, where the system triggers additional retrieval actions to improve robustness when retrieved data may be inaccurate, reflecting the same overarching principle of dynamically deciding when to retrieve. Although neither excerpt uses the exact FLARE terminology or the 2023 origin, they concretely exemplify the core concept of forward-looking, triggered retrieval to improve efficiency and accuracy in RAG systems, which supports the field value‚Äôs emphasis on timing and relevance of retrieval actions and the claimed 30‚Äì50% cost reduction without sacrificing performance.', citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.', '#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='medium'), FieldBasis(field='representative_agentic_systems.5', reasoning=\"The finegrained field value describes a representative agentic system named 'Search-o1' that uses an agentic RAG mechanism integrated with large reasoning models to enable dynamic, inference-time retrieval triggered by identified knowledge gaps. Excerpt content directly supporting this includes an explicit reference to the Search-o1 framework designed to enhance LLMs by addressing knowledge insufficiency during long reasoning chains, with components described as an Agentic RAG Mechanism that dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that distills retrieved content to maintain reasoning integrity. This directly aligns with the field value‚Äôs emphasis on dynamic, gap-driven retrieval and integration with LRMs. Additionally, a second excerpt notes that function calling expands LLM capabilities to access real-time information, interact with external systems, and convert natural language requests into structured API calls, which reinforces the general mechanism of dynamic retrieval and external resource use described in the field value, though it is less specific about the agentic reasoning architecture. Together, these excerpts substantiate the core elements of the field value: agentic, self-guided retrieval integrated with LRMs, triggered by knowledge gaps, to enable dynamic information gathering and processing. The remaining excerpts discuss broader RAG evolutions and modular approaches without mentioning the specific Search-o1 system or its agentic mechanism details, making them less relevant to the precise field value.\", citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='high'), FieldBasis(field='mitigation_strategies_for_risks.0', reasoning='The fine-grained field value describes a mitigation strategy centered on restricting the RAG system‚Äôs retrieval sources to a pre-approved, privacy-screened set, with a preference for internal retrieval systems and anonymization when third-party APIs are used. The most relevant excerpt directly states to restrict retrieval sources to approved, privacy-screened datasets and to implement relevance filters, while also noting the option to use internal retrieval systems and anonymize third-party queries. This aligns exactly with the described domain whitelisting and restricted retrieval sources, confirming the core technique and its privacy-focused rationale. A secondary excerpt discusses that retrieval architectures often rely on external knowledge bases and that grounding responses requires careful handling of sources, which supports why restricting sources can mitigate risk. Additional related material mentions broader defenses like sanitizing inputs, limiting logging, and anonymization, which provide supportive context for a defense-in-depth strategy but do not specify the exact retrieval-source restriction details. Collectively, these excerpts corroborate the presence and rationale of a retrieval hardening approach via restricted, privacy-screened sources and internal-first retrieval, with anonymization as a deployed safeguard when external sources are necessary.', citations=[Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['al or third-party\\n\\nknowledge bases, user\\n\\nqueries may be logged or\\n\\nmonitored without\\n\\nconsent. \\uf0a7\\n\\nUse robust API security\\n\\nmeasures, including access\\n\\ncontrols, authentication,\\n\\nand rate limiting. \\uf0a7\\n\\nSanitize user input to\\n\\nprevent injection attacks. \\uf0a7\\n\\nMinimize API logging or\\n\\nensure logs are\\n\\nanonymized and protected\\n\\nby access controls. \\uf0a7\\n\\nRestrict retrieval sources to\\n\\napproved, privacy-screened\\n\\ndatasets (e.g., filtered CRM\\n\\ndata). \\uf0a7\\n\\nImplement relevance filters\\n\\nor scoring mechanisms to\\n\\nensure only appropriate\\n\\ncontent is passed to the\\n\\nLLM. \\uf0a7\\n\\nApply post-\\n\\nprocessing/output filters to\\n\\nremove or redact sensitive\\n\\ninformation from\\n\\nresponses. \\uf0a7\\n\\nUse internal retrieval\\n\\nsystems when possible; if\\n\\nthird-party search APIs are\\n\\nused, anonymize or', 'nstead of\\n\\nembedding domain-specific knowledge into the model itself, RAG connects the model to an external\\n\\nknowledge base and retrieves relevant documents at runtime to ground its responses', 'Logs might inadvertently\\n\\nstore sensitive user data', 'Retrieved content may\\n\\ncontain sensitive or\\n\\noutdated information,\\n\\nwhich could be exposed\\n\\nin generated outp'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)'), Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['Experiments conducted on 14 representative RAG components demonstrate that RAG exhibits significant vulnerability to all attack tasks and even the most apparent attack task can easily bypass existing retrievers, filters, or advanced LLMs, resulting in the degradation of RAG service quality.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='specific_rag_techniques.1', reasoning='The finegrained field value centers on Corrective Retrieval Augmented Generation (CRAG) as a 2024 concept. The most directly relevant excerpt questions and defines CRAG as a framework for RAG designed to improve robustness when retrieved data is inaccurate, which aligns with the core concept of CRAG. Supporting excerpts elaborate on the mechanics: CRAG uses adaptive data handling where correct data is used directly, and when data is incorrect or ambiguous, it triggers additional retrieval actions (often web searches) to augment the original dataset. This directly corresponds to the field‚Äôs description of triggering corrective actions and performing corrective retrieval. The Decompose-then-Recompose algorithm is described as a method for breaking retrieved docs into components, filtering, and recombining to improve input quality for generation, which matches the core concept of filtering and synthesizing knowledge. Collectively, these excerpts provide clear, complementary evidence for CRAG‚Äôs definition, triggering corrective retrieval, and the Decompose-then-Recompose process, underpinning the stated benefits of robustness and improved factuality.', citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.', '1. **Generation with Decompose-then-Recompose Algorithm** :\\n\\nRetrieved documents are broken down into smaller components to focus on key insights while filtering out irrelevant or redundant details. The filtered information is recombined into a cohesive and concise dataset, optimizing the quality of data input for generation.', '#### **Advantages of CRAG**\\n\\n**Improved Accuracy** :\\n\\nBy evaluating and correcting retrieved data, CRAG ensures more reliable and factually accurate outputs.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='high'), FieldBasis(field='representative_agentic_systems.2', reasoning='The most relevant content directly describes agentic and self-directed retrieval architectures that align with the field value‚Äôs emphasis on autonomous, end-to-end decision-making in search and retrieval. For instance, explicit statements about Agentic RAG expanding capabilities to trigger searches, use tools, and convert requests into structured actions reflect core components of an autonomous system like the one described in the field value. Likewise, discussions of a Reason-in-Documents module and self-critique or self-reflection capture mechanisms that would support a fully autonomous agentic approach. Additional entries describe modular RAG and Self-RAG as architectural approaches that enable autonomous, instrumented retrieval and reasoning workflows, which are compatible with a 2025 paradigm of trained autonomous search agents. While none of the excerpts confirm the exact system name, year, or PPO-based end-to-end RL methodology, they collectively illustrate the architectural and methodological landscape (agentic planning, tool use, self-critique, modularization) that the finegrained field value invokes. Therefore, the most relevant information centers on agentic retrieval augmentation, self-critique, and modular approaches, which collectively underpin an RL-enabled autonomous search agent concept. More tangentially, the self-reflective and planning-oriented descriptions provide context for an end-to-end autonomous learning loop, even though explicit PPO and the specific system name are not stated in the excerpts.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='representative_agentic_systems.6', reasoning='The most relevant excerpts directly discuss agentic retrieval-augmented generation and multi-agent collaboration. An excerpt that explicitly notes collaboration among specialized sub-agents for different tasks aligns with a multi-agent, coordinated system and autonomous workflow described for DeepResearch. Another excerpt emphasizes autonomous, self-directed retrieval and reasoning, which supports the core autonomy aspect of the DeepResearch field value. Additional excerpts describe an agentic mechanism and a Reason-in-Documents module, which illustrate concrete components that would enable a system to plan, query, evaluate, and distill information, matching the core methodology described. Supporting points about broader evolution toward agentic and reflective retrieval further corroborate the context, even though they may be slightly peripheral to the precise DeepResearch name or exact year, they reinforce the feasibility and shift toward such architectures in recent literature. The combination of multi-agent collaboration, autonomous reasoning, and agentic mechanisms respectively aligns with the described DeepResearch attributes, while references to API-style tooling and modular RAG provide peripheral context about the ecosystem in which such a system would operate.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n'], title='Evolution of RAG from Static Knowledge to Agentic ...'), Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='specific_rag_techniques.4', reasoning='The field value describes Multimodal RAG as an extension of RAG to handle multimodal data (text, images, etc.), with systems like SAM-RAG and OmniSearch. It notes that Multimodal RAG emerged in 2024 and emphasizes benefits such as grounding and reasoning over multiple data types, including visual evidence and multi-hop retrieval. The excerpt explicitly states that multimodal RAG breaks out as a 2024 development and names SAM-RAG and OmniSearch as examples, directly supporting the technique name, year introduced, and core concepts. It provides the strongest, direct linkage between the field value and the textual evidence. There are no other excerpts that discuss multimodal RAG or name SAM-RAG/OmniSearch, so none others provide additional corroboration beyond this direct match. ', citations=[Citation(url='https://arxiv.org/html/2507.18910v1', excerpts=['Multimodal RAG breaks out: Where earlier RAG research was text-only, 2024 saw a surge in multimodal extensions. SAM-RAG and OmniSearch both combine text and image evidence'], title='A Systematic Review of Key Retrieval-Augmented ...')], confidence='high'), FieldBasis(field='specific_rag_techniques.6', reasoning='The target fine-grained field value concerns RAGAS (Retrieval-Augmented Generation Assessment), a framework for automated, reference-free evaluation of RAG systems, focusing on measures such as faithfulness, context precision/recall, and answer relevance, as described in the cited year-2023 work. To determine relevance, I looked for excerpts that discuss either (a) automated or benchmarked evaluation of RAG systems, (b) structured evaluation benchmarks or metrics for RAG, or (c) foundational explanations of RAG enabling evaluation environments. The most directly relevant excerpt introduces a multi-turn benchmark explicitly crafted to evaluate retrieval-augmented generation systems, signaling a formal assessment framework aligned with RAGAS goals. Additional excerpts describe benchmarking/security-focused evaluations of RAG (using metrics like EM, F1, Recall, and Precision) and general discussions of evaluating RAG systems, including evaluation criteria for web search in the era of Generative AI and general RAG overviews. A later-excerpt clarifies what RAG is in practice, grounding the concept as optimizing LLM outputs with external knowledge sources. Together, these excerpts collectively support the idea of a formal, automated evaluation framework for RAG like RAGAS and related benchmarking/evaluation approaches, even if they do not reproduce the exact RAGAS paper. The most directly supportive content is the benchmark-focused item describing a multi-turn evaluation framework for RAG systems, followed by entries detailing evaluation benchmarks and metrics associated with RAG, and then general RAG overviews that provide context for how such evaluations fit into the broader RAG landscape.', citations=[Citation(url='https://arxiv.org/html/2504.14891v1', excerpts=[' Mtrag: A multi-turn conversational benchmark for evaluating retrieval-augmented generation systems. arXiv preprint arXiv:2501.03468, 2025\\n'], title='Retrieval Augmented Generation Evaluation in the Era of ...'), Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/abs/2312.10997', excerpts=['This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the ...'], title='Retrieval-Augmented Generation for Large Language Models - arXiv'), Citation(url='https://aws.amazon.com/what-is/retrieval-augmented-generation/', excerpts=['RAG is the process of optimizing the output of a large language model, so it references an authoritative knowledge base outside of its training data sources ...'], title='What is RAG? - Retrieval-Augmented Generation AI Explained - AWS'), Citation(url='https://arxiv.org/html/2510.11560v1', excerpts=['lts also highlight the need for revisiting evaluation criteria for web search in the age of Generative AI.'], title='Characterizing Web Search in The Age of Generative AI')], confidence='medium'), FieldBasis(field='specific_rag_techniques.8', reasoning=\"The most directly relevant content explicitly states that SafeRAG is a benchmark designed to evaluate the security of retrieval-augmented generation systems and that attack tasks are classified into specific categories. In particular, one excerpt describes classifying attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service, which aligns precisely with the finegrained field value's four-attack catalog. Another excerpt confirms SafeRAG as a benchmark for security in retrieval-augmented generation, underscoring its role in testing robustness. Additional SafeRAG-focused excerpts expand on the benchmarking context by discussing security aspects, benchmarks, and tooling (e.g., code availability), which supports the interpretation of SafeRAG as the first security benchmark in this space. An excerpt mentioning vulnerability to attack tasks further reinforces the security-centric framing, while another excerpt reiterates the advantages of benchmarking security in RAG. Collectively, these excerpts support the notion that SafeRAG is a security benchmark with a defined taxonomy of attack classes and serves to systematically test and improve RAG robustness against adversarial manipulation.\", citations=[Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.', 'In this paper, we introduce a benchmark named SafeRAG designed to evaluate the RAG security.', 'Code is available at: https://github.com/IAAR-Shanghai/SafeRAG.', 'The indexing-retrieval-generation paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs).', 'Experiments conducted on 14 representative RAG components demonstrate that RAG exhibits significant vulnerability to all attack tasks and even the most apparent attack task can easily bypass existing retrievers, filters, or advanced LLMs, resulting in the degradation of RAG service quality.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.', 'The _indexing-retrieval-generation_ paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs). However, the incorporation of external and unverified knowledge increases the vulnerability of LLMs because attackers can perform attack tasks by manipulating knowledge.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...')], confidence='high'), FieldBasis(field='specific_rag_techniques.0', reasoning='The core field value describes Self-RAG as an approach where the LLM is trained to self-critique during retrieval and generation, performing self-directed reflection to decide when to retrieve and to evaluate the quality and relevance of retrieved passages before generating a response. The most directly supportive content states that Self-RAG is an advanced framework where the LLM is trained to perform self-critique during the retrieval and generation process, which aligns with the self-reflection and adaptive retrieval aspects of the field value. Another excerpt explicitly notes Self-RAG as a term associated with late 2023, confirming the temporal introduction mentioned in the field value. A third excerpt reiterates that Self-RAG involves the LLM generating self-critique during retrieval/generation, reinforcing the mechanism described (self-reflection, on-demand retrieval, and evaluation prior to response). Collectively, these excerpts directly substantiate the existence, mechanism, and timing of Self-RAG as defined in the field value.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='high'), FieldBasis(field='specific_rag_techniques.7', reasoning='The most relevant content points to a Decompose-then-Recompose approach, which mirrors a multi-stage processing pattern that MS-RAG would plausibly adopt to split retrieval tasks into focused components and then reassemble results for generation. This directly supports the notion of a multi-stage pipeline that aims to improve data quality and efficiency before final generation. Additional excerpts discuss broader multi-faceted advancements in retrieval-augmented generation, such as corrective Retrieval-Augmented Generation (CRAG) and adaptive retrieval strategies, which provide contextual evidence that the field increasingly combines multiple retrieval and verification steps to improve accuracy and reduce hallucinations. These provide indirect support for the existence and value of a multi-stage framework like MS-RAG, even though they do not name the MS-RAG technique specifically. The remaining excerpts cover adjacent topics (self-RAG, security benchmarks, and general RAG evolution) that help situate the MS-RAG concept within the wider trajectory of RAG research but do not specifically substantiate MS-RAG‚Äôs components or year of introduction.', citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['1. **Generation with Decompose-then-Recompose Algorithm** :\\n\\nRetrieved documents are broken down into smaller components to focus on key insights while filtering out irrelevant or redundant details. The filtered information is recombined into a cohesive and concise dataset, optimizing the quality of data input for generation.', '#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.', '#### **Advantages of CRAG**\\n\\n**Improved Accuracy** :\\n\\nBy evaluating and correcting retrieved data, CRAG ensures more reliable and factually accurate outputs.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)'), Citation(url='https://arxiv.org/abs/2312.10997', excerpts=['This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the ...'], title='Retrieval-Augmented Generation for Large Language Models - arXiv'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='mitigation_strategies_for_risks.3', reasoning='The fine-grained field value specifies a system-architecture level mitigation technique: Sandboxed Browsing. While none of the excerpts explicitly name sandboxed browsing, several excerpts discuss concrete mitigation strategies within retrieval-augmented or agentic LLM contexts. One excerpt lists a sequence of concrete safeguards for retrieval and generation pipelines, including implementing relevance filters, post-processing/output filters, sanitizing input, minimizing and anonymizing logs, and using internal retrieval systems, all of which reflect a design intent to contain and control the execution and data flow in LLM-enabled systems. This aligns with the general principle of constraining agent actions within safer, contained environments, and it directly informs a family of architectural mitigations (e.g., sandboxing as a containment strategy). Other excerpts discuss the vulnerabilities and the importance of guardrails, safety datasets, and secure retrieval architectures in RAG systems, underscoring the same overarching goal of architecture-level mitigation. When evaluating the specific field value, the strongest connection is to the idea of containment and controlled execution at the system-architecture level, which these excerpts substantiate through concrete architectural safeguards and post-processing controls. However, because none of the excerpts explicitly call out the term ‚Äúsandboxed browsing,‚Äù the exact phrasing of the target technique cannot be confirmed from the provided text. The evidence supports a broad, architecture-centric mitigation approach that would include sandboxed browsing as a plausible implementation, but does not definitively prove its specific use in the described context.', citations=[Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['al or third-party\\n\\nknowledge bases, user\\n\\nqueries may be logged or\\n\\nmonitored without\\n\\nconsent. \\uf0a7\\n\\nUse robust API security\\n\\nmeasures, including access\\n\\ncontrols, authentication,\\n\\nand rate limiting. \\uf0a7\\n\\nSanitize user input to\\n\\nprevent injection attacks. \\uf0a7\\n\\nMinimize API logging or\\n\\nensure logs are\\n\\nanonymized and protected\\n\\nby access controls. \\uf0a7\\n\\nRestrict retrieval sources to\\n\\napproved, privacy-screened\\n\\ndatasets (e.g., filtered CRM\\n\\ndata). \\uf0a7\\n\\nImplement relevance filters\\n\\nor scoring mechanisms to\\n\\nensure only appropriate\\n\\ncontent is passed to the\\n\\nLLM. \\uf0a7\\n\\nApply post-\\n\\nprocessing/output filters to\\n\\nremove or redact sensitive\\n\\ninformation from\\n\\nresponses. \\uf0a7\\n\\nUse internal retrieval\\n\\nsystems when possible; if\\n\\nthird-party search APIs are\\n\\nused, anonymize or', 'Logs might inadvertently\\n\\nstore sensitive user data', 'Retrieved content may\\n\\ncontain sensitive or\\n\\noutdated information,\\n\\nwhich could be exposed\\n\\nin generated outp', 'nstead of\\n\\nembedding domain-specific knowledge into the model itself, RAG connects the model to an external\\n\\nknowledge base and retrieves relevant documents at runtime to ground its responses', 'According to Article 25 of the AI Act, a deployer of a high risk AI system becomes a provider when they substantially modify an existing AI\\n\\nsystem, including by fine-tuning or adapting a pre-trained model for new applications'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)'), Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['Experiments conducted on 14 representative RAG components demonstrate that RAG exhibits significant vulnerability to all attack tasks and even the most apparent attack task can easily bypass existing retrievers, filters, or advanced LLMs, resulting in the degradation of RAG service quality.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2510.05310v1', excerpts=['In contrast, our work centered on evaluating guardrail models in the RAG settings. ## 3 Problem Setup and Robustness Metric'], title='RAG Makes Guardrails Unsafe? Investigating Robustness ...'), Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['We construct a comprehensive question-contexts safety evaluation dataset specifically tailored to the Chinese news domain, aiming to address the complex issues likely to arise in real-world applications.', 'Our main contributions are:'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://pmc.ncbi.nlm.nih.gov/articles/PMC12306375/', excerpts=['by AH AlSammarraie ¬∑ 2025 ¬∑ Cited by 2 ‚Äî To develop and evaluate an agentic retrieval augmented generation (ARAG) framework using open-source large language models (LLMs) for generating\\xa0...'], title='Development and evaluation of an agentic LLM based ...')], confidence='medium'), FieldBasis(field='specific_rag_techniques.5', reasoning='The specific field value centers on a compression-based technique that condenses retrieved documents into concise summaries before feeding them to the LLM. The closest supporting information is the Decompose-then-Recompose algorithm, which explains breaking retrieved documents into smaller components and recombining them into a cohesive, concise dataset to optimize data input for generation. This directly mirrors the idea of preparing compressed, focused context for the LLM. Other excerpts discuss higher-level RAG improvements (Self-RAG, CRAG, adaptive retrieval) that aim to improve robustness, accuracy, or retrieval quality, which are thematically related to efficient information handling in RAG but do not directly describe compression or summarization steps. Therefore, the decomposition/recomposition concept provides direct, relevant support to the notion of condensing retrieved information prior to LLM processing, while the CRAG- and adaptive retrieval-related excerpts offer contextual relevance about related improvements in the RAG landscape.', citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['1. **Generation with Decompose-then-Recompose Algorithm** :\\n\\nRetrieved documents are broken down into smaller components to focus on key insights while filtering out irrelevant or redundant details. The filtered information is recombined into a cohesive and concise dataset, optimizing the quality of data input for generation.', '#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.', '#### **Advantages of CRAG**\\n\\n**Improved Accuracy** :\\n\\nBy evaluating and correcting retrieved data, CRAG ensures more reliable and factually accurate outputs.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='medium'), FieldBasis(field='mitigation_strategies_for_risks.2', reasoning='The finegrained field value focuses on a data handling mitigation for privacy in retrieval-augmented generation, specifically Differential Privacy at the retriever level and the tradeoffs between privacy and utility. The most directly relevant excerpts discuss privacy-preserving measures and safeguards in retrieval contexts. For example, one excerpt enumerates concrete mitigation actions for RAG systems to protect against data exposure and leakage, including sanitizing inputs, limiting logs, restricting retrieval sources, applying relevance filters, and using internal retrieval systems with post-processing to redact sensitive information. These items map to the broader category of data handling safeguards essential for privacy-preserving retrieval, which is the backbone of differential privacy approaches in RAG. Other excerpts describe privacy risk considerations for LLMs, such as risks of storing or exposing sensitive data and the general need for robust security and access control in API usage, which provide contextual support for why data handling mitigations (like DP-based retrieval protections) are necessary. Additional excerpts discuss retrieval augmentation, guardrails, and safety benchmarks for RAG systems, which, while not detailing differential privacy, underscore the environment where DP techniques would be applied to protect document-level privacy and maintain utility. There is also reference to regulatory or governance perspectives on AI systems and deployment, which helps frame the broader governance context in which differential privacy-based mitigations would operate. In total, the strongest alignment comes from explicit mitigation-oriented excerpts about protecting data in retrieval and limiting exposure, with supporting context from related privacy-risk discussions and RAG safety work, all of which substantiate the need for privacy-preserving retrieval techniques like differential privacy, though they do not spell out differential privacy in technical detail.', citations=[Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['al or third-party\\n\\nknowledge bases, user\\n\\nqueries may be logged or\\n\\nmonitored without\\n\\nconsent. \\uf0a7\\n\\nUse robust API security\\n\\nmeasures, including access\\n\\ncontrols, authentication,\\n\\nand rate limiting. \\uf0a7\\n\\nSanitize user input to\\n\\nprevent injection attacks. \\uf0a7\\n\\nMinimize API logging or\\n\\nensure logs are\\n\\nanonymized and protected\\n\\nby access controls. \\uf0a7\\n\\nRestrict retrieval sources to\\n\\napproved, privacy-screened\\n\\ndatasets (e.g., filtered CRM\\n\\ndata). \\uf0a7\\n\\nImplement relevance filters\\n\\nor scoring mechanisms to\\n\\nensure only appropriate\\n\\ncontent is passed to the\\n\\nLLM. \\uf0a7\\n\\nApply post-\\n\\nprocessing/output filters to\\n\\nremove or redact sensitive\\n\\ninformation from\\n\\nresponses. \\uf0a7\\n\\nUse internal retrieval\\n\\nsystems when possible; if\\n\\nthird-party search APIs are\\n\\nused, anonymize or', 'Logs might inadvertently\\n\\nstore sensitive user data', 'Retrieved content may\\n\\ncontain sensitive or\\n\\noutdated information,\\n\\nwhich could be exposed\\n\\nin generated outp', 'nstead of\\n\\nembedding domain-specific knowledge into the model itself, RAG connects the model to an external\\n\\nknowledge base and retrieves relevant documents at runtime to ground its responses', 'According to Article 25 of the AI Act, a deployer of a high risk AI system becomes a provider when they substantially modify an existing AI\\n\\nsystem, including by fine-tuning or adapting a pre-trained model for new applications'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)'), Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['Experiments conducted on 14 representative RAG components demonstrate that RAG exhibits significant vulnerability to all attack tasks and even the most apparent attack task can easily bypass existing retrievers, filters, or advanced LLMs, resulting in the degradation of RAG service quality.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['We construct a comprehensive question-contexts safety evaluation dataset specifically tailored to the Chinese news domain, aiming to address the complex issues likely to arise in real-world applications.', 'Our main contributions are:'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2510.05310v1', excerpts=['In contrast, our work centered on evaluating guardrail models in the RAG settings. ## 3 Problem Setup and Robustness Metric'], title='RAG Makes Guardrails Unsafe? Investigating Robustness ...'), Citation(url='https://pmc.ncbi.nlm.nih.gov/articles/PMC12306375/', excerpts=['by AH AlSammarraie ¬∑ 2025 ¬∑ Cited by 2 ‚Äî To develop and evaluate an agentic retrieval augmented generation (ARAG) framework using open-source large language models (LLMs) for generating\\xa0...'], title='Development and evaluation of an agentic LLM based ...')], confidence='medium'), FieldBasis(field='mitigation_strategies_for_risks.1', reasoning='The field value describes a mitigation strategy focused on content sanitization, including input sanitization to detect and neutralize malicious prompts and HTML stripping to remove potentially harmful scripts or formatting from retrieved content. The most relevant excerpt explicitly lists several concrete measures that align with this, including sanitizing user input to prevent injection attacks and applying post-processing/output filters to remove or redact sensitive information from responses. It also discusses minimizing logging or anonymizing logs and restricting retrieval sources, which are related but secondary protections in the broader sanitization/filtering framework. The connection is that this excerpt directly documents the concrete sanitization techniques and the need for filtering/processing before content is exposed by the LLM, matching the described mitigation strategy category and its described trade-offs (e.g., potential latency from added defenses).', citations=[Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['al or third-party\\n\\nknowledge bases, user\\n\\nqueries may be logged or\\n\\nmonitored without\\n\\nconsent. \\uf0a7\\n\\nUse robust API security\\n\\nmeasures, including access\\n\\ncontrols, authentication,\\n\\nand rate limiting. \\uf0a7\\n\\nSanitize user input to\\n\\nprevent injection attacks. \\uf0a7\\n\\nMinimize API logging or\\n\\nensure logs are\\n\\nanonymized and protected\\n\\nby access controls. \\uf0a7\\n\\nRestrict retrieval sources to\\n\\napproved, privacy-screened\\n\\ndatasets (e.g., filtered CRM\\n\\ndata). \\uf0a7\\n\\nImplement relevance filters\\n\\nor scoring mechanisms to\\n\\nensure only appropriate\\n\\ncontent is passed to the\\n\\nLLM. \\uf0a7\\n\\nApply post-\\n\\nprocessing/output filters to\\n\\nremove or redact sensitive\\n\\ninformation from\\n\\nresponses. \\uf0a7\\n\\nUse internal retrieval\\n\\nsystems when possible; if\\n\\nthird-party search APIs are\\n\\nused, anonymize or'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)')], confidence='medium'), FieldBasis(field='specific_rag_techniques.3', reasoning='The finegrained field value centers on GraphRAG, a 2024 technique that fuses structured graph knowledge with text retrieval to enhance reasoning and handle diverse queries, including improved retrieval of n-ary relational facts. The most directly supportive evidence comes from a 2025 study presenting HyperGraphRAG, a hypergraph-based RAG approach that explicitly uses a knowledge graph structure (knowledge hypergraph construction) to guide retrieval and generation, highlighting the value of graph-augmented retrieval for accurate answers across domains. This aligns with the field value‚Äôs emphasis on leveraging graph-structured knowledge to bridge gaps between queries and documents and to improve relational fact retrieval. The next closest support is a general Retrieval-Augmented Generation survey, which confirms the broader context and evolution of RAG techniques, including graph-rotated variants, without guaranteeing GraphRAG specifics. Although the GraphRAG 2024 work is not explicitly cited in the excerpts, the graph-based RAG advancements depicted in HyperGraphRAG corroborate the trend and core concept of integrating graphs with text retrieval to boost LLM reasoning and retrieval fidelity.', citations=[Citation(url='https://arxiv.org/abs/2503.21322', excerpts=['Experiments across medicine, agriculture, computer science, and law demonstrate that HyperGraphRAG outperforms both standard RAG and previous graph-based RAG methods in answer accuracy, retrieval efficiency, and generation quality.', ' HyperGraphRAG, a novel hypergraph-based RAG method that represents n-ary relational facts via hyperedges, and consists of knowledge hypergraph construction, retrieval, and generation. '], title='HyperGraphRAG: Retrieval-Augmented Generation via Hypergraph ...'), Citation(url='https://arxiv.org/abs/2312.10997', excerpts=['This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the ...'], title='Retrieval-Augmented Generation for Large Language Models - arXiv')], confidence='medium'), FieldBasis(field='timeline_of_milestones.0', reasoning='The target field describes a milestone introducing a reference-free suite of metrics to evaluate RAG quality across multiple dimensions, explicitly including faithfulness and answer relevance, and associates this with the RAGAS framework. Excerpts discussing the RAGAS framework and its metrics provide direct support for the existence and scope of such evaluation tools. For instance, one excerpt explains that RAGAS is an evaluation framework with metrics to measure the quality of a RAG model‚Äôs responses, which aligns with the milestone‚Äôs reference-free metrics concept. Additional excerpts define key evaluation dimensions such as Answer Relevancy and Faithfulness, detailing how relevance and factual alignment are assessed in RAG outputs. Another excerpt notes that a guide discusses metrics focusing on faithfulness, answer relevancy, context precision, and context recall, which map to the multidimensional evaluation described in the milestone. Together, these excerpts corroborate the field value by confirming the presence of a metric suite around RAGAS and the specific dimensions of faithfulness and answer relevancy.', citations=[Citation(url='https://www.giskard.ai/knowledge/rag-benchmarking-for-ai-evaluation', excerpts=['RAGAS (Retrieval-Augmented Generation Assessment System) is an evaluation framework offering various metrics to measure the quality of a RAG model‚Äôs responses. Below is an explanation of these metrics along with usage examples:', ' **Answer Relevancy  \\n   ** Answer relevancy evaluates whether the model‚Äôs response is relevant to the question, even if it is not entirely accurate or detail', '*Faithfulness  \\n   ** Faithfulness assesses the extent to which the model‚Äôs response is supported by information in the reference document. The response must align with the source or reference document without introducing unsupported information'], title='RAG Benchmarking: Comparing RAGAS, BERTScore, and ...'), Citation(url='https://dkaarthick.medium.com/ragas-for-rag-in-llms-a-comprehensive-guide-to-evaluation-metrics-3aca142d6e38', excerpts=['RAGAS introduces several metrics that provide a more holistic evaluation of RAG models, focusing on aspects like faithfulness, answer relevancy, context precision, and context recall.', 'Answer Relevancy** evaluates how relevant the generated response is to the original query. **Formu', 'aithfulness** measures the factual accuracy of the generated response based on the retrieved documents. **Formul'], title='RAGAS for RAG in LLMs: A Comprehensive Guide to ...')], confidence='high'), FieldBasis(field='major_industry_implementations.2', reasoning=\"The most relevant piece directly references the concept of Agentic RAG and how AI agents are moving from demos to real-world problem solving, which aligns with the field's mention of agentic RAG patterns and advanced agent systems. The next most relevant pieces discuss grounding AI responses with current web information and the architectural aspects of web-search integration in AI copilots: one describes Copilot Chat grounded in web data and powered by modern LLMs, another explains that web-search-enabled Copilot can fetch information from a web search service to ground responses, and another notes that prompts are parsed to identify terms where web information improves quality. These excerpts collectively illustrate the practical methods by which web data is integrated into AI systems (search-grounded responses, three-part interaction, and layered protections), which supports the broader OpenAI-style concept of browsing-enabled agents and their operating patterns. Additional excerpts describe enterprise web-search controls and multi-layer protections, underscoring the implementation considerations around web-grounded AI systems. While none of the excerpts explicitly describe OpenAI‚Äôs exact implementations (ChatGPT browsing, o1 model, Deep Research Agent), they collectively provide evidence of the architectural and procedural patterns (web grounding, agentic search, multi-layer safeguards) that the fine-grained field value references. Therefore, the cited excerpts are relevant to understanding how OpenAI-like systems might implement web search and agentic reasoning patterns in practice.\", citations=[Citation(url='https://www.linkedin.com/posts/rakeshgohel01_ai-agent-trends-have-drastically-changed-activity-7383841580014723072-PxZp', excerpts=[\"CUA and Agentic RAG aren't just cool demos anymore. They're solving real operational gaps, fast. This list nails the shift from experimentation to execution.\"], title='AI Agent Trends for 2025: New Innovations and Products'), Citation(url='https://learn.microsoft.com/en-us/copilot/overview', excerpts=['Nov 11, 2025 ‚Äî Copilot Chat is AI chat grounded in data from the web and powered by the latest large language models (LLMs). Copilot Chat lets users access agents and create\\xa0...'], title='Overview of Microsoft 365 Copilot Chat'), Citation(url='https://techcommunity.microsoft.com/blog/microsoft365copilotblog/microsoft-365-copilot-web-search-delivering-multiple-layers-of-protection-and-co/4458224', excerpts=['A Copilot interaction has three parts: your prompt, a web query (if needed), and the response.', 'That‚Äôs why Copilot can ground its answers with current information from the web, closing knowledge gaps that every large language model (LLM) inevitably has based on its training data cutoff.', 'Traditional web search engines are optimized for broad consumer scenarios. Copilot‚Äôs web search is enterprise oriented and layered with controls that consumer search does not provide.'], title='Microsoft 365 Copilot Web Search: Delivering Multiple ...'), Citation(url='https://learn.microsoft.com/en-us/copilot/microsoft-365/manage-public-web-access', excerpts=['When web search is enabled, Microsoft 365 Copilot and Microsoft 365 Copilot Chat parse the user‚Äôs prompt and identifies terms where information from the web would improve the quality of the response.', 'When web search is enabled, Microsoft 365 Copilot and Microsoft 365 Copilot Chat may fetch information from the Bing search service when information from the web helps to provide a better, more grounded response.', 'generated search queries sent to the Bing search service to ground responses in web data. The way Microsoft handles these queries is identical in both services. Gen', 'ontrols and a user-level **Web content** toggle (only for Microsoft 365 Copilot) are available to [manage whether web search is enabled]() in your environment', 'osoft 365 **Copilot Search** is an additional, universal search experience that allows users with a Microsoft 365 Copilot license to search across all their Microsoft 365 and third-party data sources.'], title='Data, privacy, and security for web search in Microsoft 365 ...')], confidence='medium'), FieldBasis(field='evaluation_benchmarks_and_metrics.9.key_metrics', reasoning='The central goal is to evaluate how current benchmarks measure grounding and factuality in LLM outputs. Claims within the excerpts indicate that the benchmark provides a comprehensive measure of grounding accuracy by ensuring responses are fully grounded in the provided documents and by using an online leaderboard to track grounding scores. This aligns with the notion of grounded accuracy, citation/grounding integrity, and relative performance against benchmarks. The description of facts-grounding as requiring long-form responses that are fully attributable to source documents reinforces the importance of reliable grounding and factual correctness in evaluation, which connects directly to the requested metrics. The fact that the benchmark includes a sizable, carefully crafted dataset designed to require grounded long-form responses further supports the relevance to evaluating success rates, grounding reliability, and related metrics. The presence of a judging process that compares automated judgments with human raters also underpins the reliability of reported metrics such as grounding accuracy and factuality, which are components of the requested field value. While not every individual metric (e.g., latency or action budgets) is explicitly named in these excerpts, their collective emphasis on grounding fidelity, citation accuracy, and leaderboard-based evaluation provides a coherent foundation for describing current advancements in evaluation benchmarks for grounding in web-search-oriented LLM research.', citations=[Citation(url='https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/', excerpts=['Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations', 'Second, responses are judged as factually accurate if they are fully grounded in information contained in the provided document, with no hallucinations.', ' We‚Äôve already tested leading LLMs using FACTS Grounding and have populated the initial leaderboard with their grounding scores. ', 'The automatic judge models were comprehensively evaluated against a held-out test set to find the best performing judging prompt templates and to verify agreement with human raters.', 'the FACTS Grounding dataset comprises 1,719 examples, each carefully crafted to require long-form responses grounded in the context document provided.', 'To succeed on a given example, an LLM must synthesize the complex information in the document and generate a long-form response that is both a comprehensive answer to the user request and fully attributable to that document.', 'A factually correct response that fails to properly address the user‚Äôs request fails the benchmarking example.', 'Each example comprises a document, a system instruction requiring the LLM to exclusively reference the provided document, and an accompanying user request.'], title='FACTS Grounding: A new benchmark for evaluating the factuality of ...')], confidence='medium'), FieldBasis(field='evaluation_benchmarks_and_metrics.9.main_finding_or_use_case', reasoning='The finegrained field value asserts that the evaluation benchmark is used to assess advanced agents, outperforming standard LLMs on tasks requiring synthesis from obscure sources. The most directly relevant excerpt states that succeeding on an example requires synthesizing complex document information and attributing it properly, which captures the essence of evaluating advanced agents on sourcing-based synthesis. Supporting this are excerpts describing FACTS Grounding as a comprehensive benchmark with an online leaderboard to measure factual grounding and reduce hallucinations, which defines the evaluation mechanism for such agents. Further support comes from passages noting that the judge models are evaluated against held-out sets and that leading LLMs have been tested and their grounding scores populated on a leaderboard, illustrating how the benchmark operationalizes its use case to compare agent performance. Together, these excerpts establish the benchmark‚Äôs purpose (grounding evidence from documents) and its use in evaluating and ranking advanced agents against standard models, aligning with the stated field value.', citations=[Citation(url='https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/', excerpts=['To succeed on a given example, an LLM must synthesize the complex information in the document and generate a long-form response that is both a comprehensive answer to the user request and fully attributable to that document.', 'Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations', 'Second, responses are judged as factually accurate if they are fully grounded in information contained in the provided document, with no hallucinations.', 'The automatic judge models were comprehensively evaluated against a held-out test set to find the best performing judging prompt templates and to verify agreement with human raters.', ' We‚Äôve already tested leading LLMs using FACTS Grounding and have populated the initial leaderboard with their grounding scores. ', 'the FACTS Grounding dataset comprises 1,719 examples, each carefully crafted to require long-form responses grounded in the context document provided.', 'Each example comprises a document, a system instruction requiring the LLM to exclusively reference the provided document, and an accompanying user request.', 'A factually correct response that fails to properly address the user‚Äôs request fails the benchmarking example.'], title='FACTS Grounding: A new benchmark for evaluating the factuality of ...')], confidence='medium'), FieldBasis(field='major_industry_implementations.1.company', reasoning='Relevant excerpts directly reference Microsoft in the context of Copilot products and web search capabilities, which aligns with identifying the company associated with major industry implementations of web-enabled search for LLMs. The most relevant statements explicitly describe Copilot‚Äôs ability to ground answers with current information from the web and the enterprise-oriented, layered web search designed for Microsoft 365 Copilot, establishing a direct Microsoft focus. Additional excerpts discuss web search management and data handling within Microsoft 365 Copilot, reinforcing the association with Microsoft as the implementing company. Other excerpts describe Copilot‚Äôs interaction flow and enterprise search characteristics, which further support Microsoft as the company implementing these features in a business context. In sum, these excerpts collectively confirm that the company associated with major industry implementations of web-enabled search for LLMs is Microsoft, through products like Microsoft 365 Copilot and Copilot Chat, and the related data handling and web-query processes. ', citations=[Citation(url='https://techcommunity.microsoft.com/blog/microsoft365copilotblog/microsoft-365-copilot-web-search-delivering-multiple-layers-of-protection-and-co/4458224', excerpts=['That‚Äôs why Copilot can ground its answers with current information from the web, closing knowledge gaps that every large language model (LLM) inevitably has based on its training data cutoff.', 'A Copilot interaction has three parts: your prompt, a web query (if needed), and the response.', 'Traditional web search engines are optimized for broad consumer scenarios. Copilot‚Äôs web search is enterprise oriented and layered with controls that consumer search does not provide.'], title='Microsoft 365 Copilot Web Search: Delivering Multiple ...'), Citation(url='https://learn.microsoft.com/en-us/copilot/microsoft-365/manage-public-web-access', excerpts=['When web search is enabled, Microsoft 365 Copilot and Microsoft 365 Copilot Chat may fetch information from the Bing search service when information from the web helps to provide a better, more grounded response.', 'generated search queries sent to the Bing search service to ground responses in web data. The way Microsoft handles these queries is identical in both services. Gen', 'When web search is enabled, Microsoft 365 Copilot and Microsoft 365 Copilot Chat parse the user‚Äôs prompt and identifies terms where information from the web would improve the quality of the response.', 'ontrols and a user-level **Web content** toggle (only for Microsoft 365 Copilot) are available to [manage whether web search is enabled]() in your environment', 'osoft 365 **Copilot Search** is an additional, universal search experience that allows users with a Microsoft 365 Copilot license to search across all their Microsoft 365 and third-party data sources.'], title='Data, privacy, and security for web search in Microsoft 365 ...')], confidence='high'), FieldBasis(field='timeline_of_milestones.3', reasoning='The milestone centers on a 2024 paper introducing a RAG method with a self-correcting retriever that assesses retrieval quality and triggers web searches for self-correction, under the umbrella of Corrective Retrieval Augmented Generation (CRAG). The most directly supportive excerpt asks the question What is Corrective RAG (CRAG) and explains that CRAG is a framework designed to improve robustness when dealing with inaccuracies in retrieved data, which directly aligns with the milestone‚Äôs core concept. Another excerpt describes Adaptive Knowledge Retrieval, stating that correct data is used while incorrect or ambiguous data triggers additional retrieval actions‚Äîoften web searches‚Äîto augment the dataset with more reliable information; this directly matches the self-correction mechanism highlighted in the milestone. Excerpts noting Dynamic Adaptability discuss how CRAG leverages large-scale web searches to stay up-to-date and provide diverse information, which corroborates the idea of using external searches as part of the self-correcting loop. Additional excerpts emphasize Better Robustness by addressing retrieval errors dynamically, further supporting the CRAG framework‚Äôs goals described in the milestone. A related excerpt on Generation with Decompose-then-Recompose explains how retrieved documents are parsed and recombined to focus on key insights, which complements the CRAG approach by detailing data handling steps that could support robust retrieval and correction. Collectively, these excerpts map well to a 2024 CRAG paper that proposes a self-correcting retriever and an integrated workflow to enhance robustness and up-to-date information via web queries.', citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.', '**Dynamic Adaptability** :\\n\\nThe integration of large-scale web searches allows CRAG to expand beyond static knowledge bases, providing up-to-date and diverse information.', '**Better Robustness** :\\n\\nCRAG mitigates the risk of generating incorrect knowledge by dynamically addressing errors in the retrieval process.', '**Efficient Data Utilization** :\\n\\nThe decompose-then-recompose algorithm reduces noise and focuses on critical insights, ensuring the generated responses are both concise and relevant.', '#### **Advantages of CRAG**\\n\\n**Improved Accuracy** :\\n\\nBy evaluating and correcting retrieved data, CRAG ensures more reliable and factually accurate outputs.', '1. **Generation with Decompose-then-Recompose Algorithm** :\\n\\nRetrieved documents are broken down into smaller components to focus on key insights while filtering out irrelevant or redundant details. The filtered information is recombined into a cohesive and concise dataset, optimizing the quality of data input for generation.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='high'), FieldBasis(field='timeline_of_milestones.6', reasoning=\"The target field concerns a benchmarking effort focused on grounding model outputs in source documents and reducing hallucinations. Excerpts that describe evaluation metrics for RAG systems‚Äîsuch as answer relevancy, faithfulness, and context relevance/recall‚Äîdirectly relate to assessing grounding fidelity in generated responses. Excerpts that outline RAG evaluation frameworks (RAGAS, related metrics) provide a structured approach to quantify grounding performance, which is precisely the kind of evidence one would expect in a benchmark of grounding. Excerpts mentioning corrective or robust RAG frameworks also align with improving grounding reliability, further supporting the field value's concept of benchmarking grounding accuracy. Excerpts discussing general best practices for evaluating RAG systems and the importance of faithfulness and relevance reinforce the contextual basis for a grounding benchmark, even if they do not state the exact December 2024 event. Overall, these excerpts collectively support the notion of evaluating how well LLMs ground their outputs to sources and avoid hallucinations, which is the essence of the finegrained field value.\", citations=[Citation(url='https://www.giskard.ai/knowledge/rag-benchmarking-for-ai-evaluation', excerpts=['RAGAS (Retrieval-Augmented Generation Assessment System) is an evaluation framework offering various metrics to measure the quality of a RAG model‚Äôs responses. Below is an explanation of these metrics along with usage examples:', ' **Answer Relevancy  \\n   ** Answer relevancy evaluates whether the model‚Äôs response is relevant to the question, even if it is not entirely accurate or detail', '*Faithfulness  \\n   ** Faithfulness assesses the extent to which the model‚Äôs response is supported by information in the reference document. The response must align with the source or reference document without introducing unsupported information'], title='RAG Benchmarking: Comparing RAGAS, BERTScore, and ...'), Citation(url='https://www.patronus.ai/llm-testing/rag-evaluation-metrics', excerpts=['Five key metrics are used to evaluate RAG performance: context relevance, context sufficiency, answer relevance, answer correctness and answer hallucination.'], title='Best Practices for Evaluating RAG Systems'), Citation(url='https://dkaarthick.medium.com/ragas-for-rag-in-llms-a-comprehensive-guide-to-evaluation-metrics-3aca142d6e38', excerpts=['RAGAS introduces several metrics that provide a more holistic evaluation of RAG models, focusing on aspects like faithfulness, answer relevancy, context precision, and context recall.', 'aithfulness** measures the factual accuracy of the generated response based on the retrieved documents. **Formul', 'Answer Relevancy** evaluates how relevant the generated response is to the original query. **Formu'], title='RAGAS for RAG in LLMs: A Comprehensive Guide to ...'), Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.', '1. **Generation with Decompose-then-Recompose Algorithm** :\\n\\nRetrieved documents are broken down into smaller components to focus on key insights while filtering out irrelevant or redundant details. The filtered information is recombined into a cohesive and concise dataset, optimizing the quality of data input for generation.', '#### **Advantages of CRAG**\\n\\n**Improved Accuracy** :\\n\\nBy evaluating and correcting retrieved data, CRAG ensures more reliable and factually accurate outputs.', '**Dynamic Adaptability** :\\n\\nThe integration of large-scale web searches allows CRAG to expand beyond static knowledge bases, providing up-to-date and diverse information.', '**Efficient Data Utilization** :\\n\\nThe decompose-then-recompose algorithm reduces noise and focuses on critical insights, ensuring the generated responses are both concise and relevant.', '**Better Robustness** :\\n\\nCRAG mitigates the risk of generating incorrect knowledge by dynamically addressing errors in the retrieval process.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='medium'), FieldBasis(field='evaluation_benchmarks_and_metrics.3.purpose', reasoning=\"The finegrained field value describes a user-centric benchmark designed to evaluate an LLM's ability to iteratively seek, validate, and integrate evidence for complex tasks requiring up-to-date information. The most relevant excerpts describe FACTS Grounding as a comprehensive benchmark that measures how accurately LLMs ground their responses in provided source material and avoid hallucinations, and emphasize long-form, comprehensive, and fully attributable answers grounded in documents. This directly aligns with the idea of a benchmark focused on rigorous evidence gathering, integration, and attribution. Additional high-relevance content notes that successful responses must synthesize information from the document and be fully grounded in it, which supports the iterative, evidence-seeking, and integration aspects of the target field value. Other excerpts describe the benchmark format (a document, a system instruction to reference only that document, and a user request) and the existence of an initial leaderboard with grounding scores, which reinforces the focus on structured evaluation and evidence-based responses. Collectively, these excerpts support the notion of a user-centric benchmarking framework aimed at testing an LLM‚Äôs ability to find, validate, and weave together evidence from a source document to address complex tasks, while ensuring factual grounding and attribution. They also imply the need for up-to-date, document-grounded responses, though the explicit framing of ‚Äúup-to-date information‚Äù as a requirement is inferred from the grounding and attribution emphasis rather than stated verbatim in all excerpts.\", citations=[Citation(url='https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/', excerpts=['Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations', 'To succeed on a given example, an LLM must synthesize the complex information in the document and generate a long-form response that is both a comprehensive answer to the user request and fully attributable to that document.', 'Second, responses are judged as factually accurate if they are fully grounded in information contained in the provided document, with no hallucinations.', 'Each example comprises a document, a system instruction requiring the LLM to exclusively reference the provided document, and an accompanying user request.', ' We‚Äôve already tested leading LLMs using FACTS Grounding and have populated the initial leaderboard with their grounding scores. ', 'the FACTS Grounding dataset comprises 1,719 examples, each carefully crafted to require long-form responses grounded in the context document provided.', 'We selected a combination of different judges to mitigate any potential bias of a judge giving higher scores to the responses produced by a member of its own model family.', 'The final score for the overall grounding task is the average of all judge models‚Äô scores across all examples.', 'three frontier LLM judges ‚Äî namely Gemini 1.5 Pro, GPT-4o, and Claude 3.5 Sonnet.', 'A factually correct response that fails to properly address the user‚Äôs request fails the benchmarking example.'], title='FACTS Grounding: A new benchmark for evaluating the factuality of ...')], confidence='medium'), FieldBasis(field='major_industry_implementations.1.product_name', reasoning='The finegrained field value identifies the product_name for Copilot variants (including Microsoft 365 Copilot and Copilot Chat). Excerpts that explicitly reference Copilot or Copilot Chat in the context of web-grounded information, enterprise search, or Copilot‚Äôs integration with Microsoft 365 data directly support this product identity. For example, a passage stating that Copilot can ground its answers with current web information directly supports the notion that the product_name is Copilot (and its variants). Another passage describes Copilot Chat as AI chat grounded in data from the web and powered by the latest LLMs, which aligns precisely with the product_NAME family mentioned. Additional excerpts discuss how Copilot interacts with web search, prompts, and enterprise controls, further corroborating that the relevant product name under the specified path is indeed Copilot (including Microsoft 365 Copilot and Copilot Chat). Excerpts that mention Copilot in general or as part of related features (like Copilot Search or enterprise data sources) also support the overall product identity, though slightly less directly than those that explicitly tie Copilot to web-grounded responses and Microsoft 365 context.', citations=[Citation(url='https://learn.microsoft.com/en-us/copilot/overview', excerpts=['Nov 11, 2025 ‚Äî Copilot Chat is AI chat grounded in data from the web and powered by the latest large language models (LLMs). Copilot Chat lets users access agents and create\\xa0...'], title='Overview of Microsoft 365 Copilot Chat'), Citation(url='https://techcommunity.microsoft.com/blog/microsoft365copilotblog/microsoft-365-copilot-web-search-delivering-multiple-layers-of-protection-and-co/4458224', excerpts=['That‚Äôs why Copilot can ground its answers with current information from the web, closing knowledge gaps that every large language model (LLM) inevitably has based on its training data cutoff.', 'A Copilot interaction has three parts: your prompt, a web query (if needed), and the response.', 'Traditional web search engines are optimized for broad consumer scenarios. Copilot‚Äôs web search is enterprise oriented and layered with controls that consumer search does not provide.'], title='Microsoft 365 Copilot Web Search: Delivering Multiple ...'), Citation(url='https://learn.microsoft.com/en-us/copilot/microsoft-365/manage-public-web-access', excerpts=['When web search is enabled, Microsoft 365 Copilot and Microsoft 365 Copilot Chat may fetch information from the Bing search service when information from the web helps to provide a better, more grounded response.', 'osoft 365 **Copilot Search** is an additional, universal search experience that allows users with a Microsoft 365 Copilot license to search across all their Microsoft 365 and third-party data sources.', 'generated search queries sent to the Bing search service to ground responses in web data. The way Microsoft handles these queries is identical in both services. Gen', 'When web search is enabled, Microsoft 365 Copilot and Microsoft 365 Copilot Chat parse the user‚Äôs prompt and identifies terms where information from the web would improve the quality of the response.', 'ontrols and a user-level **Web content** toggle (only for Microsoft 365 Copilot) are available to [manage whether web search is enabled]() in your environment'], title='Data, privacy, and security for web search in Microsoft 365 ...')], confidence='high'), FieldBasis(field='timeline_of_milestones.9', reasoning='The most relevant content centers on explicit evaluation frameworks and metrics for RAG and LLM information retrieval tasks. Excerpts describing RAGAS, which evaluates aspects such as faithfulness, answer relevancy, context precision, and context recall, align closely with the concept of a comprehensive evaluation suite for deep research tasks. Additional support comes from references to general evaluation best practices (e.g., assessing relevance, faithfulness, and correctness) and the notion of corrective retrieval and robustness (CRAG), which together describe the components and rationale behind a formalized benchmarking suite. Other excerpts discuss the broader landscape of RAG evaluation metrics and frameworks, reinforcing that a structured, multi-metric evaluation suite is a reasonable and expected advancement in 2025 for deep web-search-enabled research tasks. Specifically, mentions of comprehensive guides to RAG evaluation, the role of multiple metrics (faithfulness, answer relevancy, context precision/recall), and the CRAG paradigm provide direct alignment with the requested 2025 Q2 milestone for LiveResearchBench and DeepEval-style evaluation frameworks.', citations=[Citation(url='https://dkaarthick.medium.com/ragas-for-rag-in-llms-a-comprehensive-guide-to-evaluation-metrics-3aca142d6e38', excerpts=['RAGAS introduces several metrics that provide a more holistic evaluation of RAG models, focusing on aspects like faithfulness, answer relevancy, context precision, and context recall.', 'Answer Relevancy** evaluates how relevant the generated response is to the original query. **Formu', 'aithfulness** measures the factual accuracy of the generated response based on the retrieved documents. **Formul'], title='RAGAS for RAG in LLMs: A Comprehensive Guide to ...'), Citation(url='https://www.giskard.ai/knowledge/rag-benchmarking-for-ai-evaluation', excerpts=['RAGAS (Retrieval-Augmented Generation Assessment System) is an evaluation framework offering various metrics to measure the quality of a RAG model‚Äôs responses. Below is an explanation of these metrics along with usage examples:'], title='RAG Benchmarking: Comparing RAGAS, BERTScore, and ...'), Citation(url='https://www.patronus.ai/llm-testing/rag-evaluation-metrics', excerpts=['Five key metrics are used to evaluate RAG performance: context relevance, context sufficiency, answer relevance, answer correctness and answer hallucination.'], title='Best Practices for Evaluating RAG Systems'), Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.', '**Dynamic Adaptability** :\\n\\nThe integration of large-scale web searches allows CRAG to expand beyond static knowledge bases, providing up-to-date and diverse information.', '**Better Robustness** :\\n\\nCRAG mitigates the risk of generating incorrect knowledge by dynamically addressing errors in the retrieval process.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='medium'), FieldBasis(field='timeline_of_milestones.10', reasoning='The finegrained field value describes a 2025 mid-period milestone focusing on a shift from static, passive retrieval to autonomous, agentic retrieval and reasoning workflows within RAG, labeled as Agentic RAG. The most relevant excerpt states: ‚ÄúAgentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance.‚Äù This directly corroborates the year/period, the nature of the shift (Agentic RAG, autonomous retrieval and reasoning), and the highlighted challenges. The field value‚Äôs associated_work is Agentic RAG and category is Research Trend, which are both reflected by this description in the excerpt. Therefore, this excerpt provides clear, direct support for the finegrained field value.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. '], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='high'), FieldBasis(field='major_industry_implementations.0.technical_integration_pattern', reasoning='The most relevant excerpts describe concrete integration: AI Overviews embedded into Google Search and AI Mode, with the Gemini architecture powering these features across Google‚Äôs suite. These excerpts explicitly state that AI Overviews are integrated into the Search ecosystem and that Gemini serves as the engine behind AI Overviews, AI Mode, and the standalone chatbot experience, directly supporting the finegrained field value about tight integration and the Gemini-based, multi-feature search augmentation. Additional excerpts that discuss Google‚Äôs AI Overview as a top-of-page concise answer further corroborate the integration level and user-facing behavior. Excerpts that mention Gemini‚Äôs version history (1.0/1.5/Advanced) show the model lineage and capabilities but are somewhat less directly tied to the concrete integration claim, though they still support the context of a Gemini-powered integration. The least relevant item discusses broader industry context or timely leadership news rather than technical integration specifics, and thus provides little direct support for the field value.', citations=[Citation(url='https://adcellerant.com/blogs/ai-changing-organic-search-august-2025/', excerpts=['Gemini is now embedded into Google Search through AI Overviews and AI Mode, accessible as a standalone chatbot, and integrated across the Google suite (Gmail, Docs, YouTube, etc.).', 'Gemini is Google‚Äôs flagship LLM and the engine behind AI Overviews, AI Mode, and Google‚Äôs standalone chatbot experience.', 'From the public release of ChatGPT in late 2022 to the full launch of Google‚Äôs AI Overviews in mid-2024, the landscape has shifted so much that search engine optimization (SEO) is now being referred to as ‚ÄúSearch Everywhere Optimization.‚Äù'], title='AI is Changing Organic Search: August 2025 Update - AdCellerant'), Citation(url='https://seosherpa.com/ai-overview/', excerpts=[\"Google's AI Overview is a new search feature that utilizes generative AI to provide a concise answer at the top of the results page.\"], title=\"What Is Google's AI Overview? A Deep Dive into the Future ...\"), Citation(url='https://brassmonkey.ai/google-gemini-review/', excerpts=[\"The Gemini 1.0 version came out in late 2023, and by 2025, we now have Gemini 1.5 and Gemini Advanced. The Gemini project combines Google's AI research with ...\"], title=\"Google Gemini Review: Is Google's AI Really Worth the ...\"), Citation(url='https://fortune.com/2025/12/02/sam-altman-declares-code-red-google-gemini-ceo-sundar-pichai/', excerpts=[\"With Gemini 3's strong rollout and rising user base, Google suddenly has the edge, and OpenAI is racing to keep its dominance from slipping ...\"], title=\"Sam Altman declares 'Code Red' as Google's Gemini surges‚Äîthree ...\")], confidence='high'), FieldBasis(field='timeline_of_milestones.8', reasoning='The target field describes a 2025 Q1 milestone introducing a security-focused benchmark for RAG pipelines. While none of the excerpts state a SafeRAG benchmark outright, several excerpts directly address components essential to such a benchmark. Excerpts that discuss Corrective RAG (CRAG) and robustness provide concrete mechanisms for improving or testing resilience against incorrect or adversarial data, which are core to security benchmarking. Excerpts detailing evaluation metrics‚Äîsuch as faithfulness, answer relevancy, context precision, and context recall‚Äîsupply the measurement framework necessary for a security-focused benchmark. Excerpts describing adaptive knowledge retrieval and the decomposition-recompose approach illustrate how robustness and attack surfaces can be probed during benchmarking. Collectively, these excerpts establish the foundational elements (robustness, corrective strategies, and evaluative metrics) that a security-focused RAG benchmark would likely include and assess in 2025 Q1.', citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '**Dynamic Adaptability** :\\n\\nThe integration of large-scale web searches allows CRAG to expand beyond static knowledge bases, providing up-to-date and diverse information.', '**Better Robustness** :\\n\\nCRAG mitigates the risk of generating incorrect knowledge by dynamically addressing errors in the retrieval process.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)'), Citation(url='https://dkaarthick.medium.com/ragas-for-rag-in-llms-a-comprehensive-guide-to-evaluation-metrics-3aca142d6e38', excerpts=['RAGAS introduces several metrics that provide a more holistic evaluation of RAG models, focusing on aspects like faithfulness, answer relevancy, context precision, and context recall.', 'Answer Relevancy** evaluates how relevant the generated response is to the original query. **Formu'], title='RAGAS for RAG in LLMs: A Comprehensive Guide to ...'), Citation(url='https://www.patronus.ai/llm-testing/rag-evaluation-metrics', excerpts=['Five key metrics are used to evaluate RAG performance: context relevance, context sufficiency, answer relevance, answer correctness and answer hallucination.'], title='Best Practices for Evaluating RAG Systems'), Citation(url='https://www.giskard.ai/knowledge/rag-benchmarking-for-ai-evaluation', excerpts=['*Faithfulness  \\n   ** Faithfulness assesses the extent to which the model‚Äôs response is supported by information in the reference document. The response must align with the source or reference document without introducing unsupported information'], title='RAG Benchmarking: Comparing RAGAS, BERTScore, and ...')], confidence='medium'), FieldBasis(field='major_industry_implementations.0.company', reasoning='The most relevant excerpt directly states that Gemini is Google‚Äôs flagship LLM and the engine behind AI Overviews, AI Mode, and Google‚Äôs standalone chatbot experience, clearly tying the company to the described major implementation. Other highly relevant excerpts explicitly describe Google‚Äôs search-related innovations, such as embedding Gemini into Google Search, Google‚Äôs AI Overview feature, and the broader rollout of Gemini variants, all of which establish Google as the central company behind these web-search‚Äìoriented LLM implementations. Additional excerpts reference Google by name in the context of AI Overviews and Google Gemini‚Äôs ongoing development and public reception, reinforcing the linkage between the company and the major industry implementations. The remaining excerpt discusses the same ecosystem (Google‚Äôs AI Overviews, Gemini) and confirms Google as the driving entity in this space. The common thread across these excerpts is a clear attribution of major web-search‚Äìrelated LLM implementations and evolutions to Google and its Gemini/AI Overviews products.', citations=[Citation(url='https://adcellerant.com/blogs/ai-changing-organic-search-august-2025/', excerpts=['Gemini is Google‚Äôs flagship LLM and the engine behind AI Overviews, AI Mode, and Google‚Äôs standalone chatbot experience.', 'Gemini is now embedded into Google Search through AI Overviews and AI Mode, accessible as a standalone chatbot, and integrated across the Google suite (Gmail, Docs, YouTube, etc.).', 'From the public release of ChatGPT in late 2022 to the full launch of Google‚Äôs AI Overviews in mid-2024, the landscape has shifted so much that search engine optimization (SEO) is now being referred to as ‚ÄúSearch Everywhere Optimization.‚Äù'], title='AI is Changing Organic Search: August 2025 Update - AdCellerant'), Citation(url='https://brassmonkey.ai/google-gemini-review/', excerpts=[\"The Gemini 1.0 version came out in late 2023, and by 2025, we now have Gemini 1.5 and Gemini Advanced. The Gemini project combines Google's AI research with ...\"], title=\"Google Gemini Review: Is Google's AI Really Worth the ...\"), Citation(url='https://seosherpa.com/ai-overview/', excerpts=[\"Google's AI Overview is a new search feature that utilizes generative AI to provide a concise answer at the top of the results page.\"], title=\"What Is Google's AI Overview? A Deep Dive into the Future ...\"), Citation(url='https://fortune.com/2025/12/02/sam-altman-declares-code-red-google-gemini-ceo-sundar-pichai/', excerpts=[\"With Gemini 3's strong rollout and rising user base, Google suddenly has the edge, and OpenAI is racing to keep its dominance from slipping ...\"], title=\"Sam Altman declares 'Code Red' as Google's Gemini surges‚Äîthree ...\")], confidence='high'), FieldBasis(field='evaluation_benchmarks_and_metrics.0.benchmark_name', reasoning='The finegrained field value identifies the benchmark name as FACTS Grounding within the evaluation_benchmarks_and_metrics section. Excerpts that explicitly mention FACTS Grounding as a benchmark and describe its purpose (measuring factual grounding of LLMs, grounding in provided documents, and avoiding hallucinations) directly support this value. Several excerpts describe the FACTS Grounding dataset, its size, its goal of evaluating long-form responses grounded in a context document, and the existence of a leaderboard and evaluation methodology. These details collectively corroborate that the benchmark name is FACTS Grounding and that the excerpts consistently discuss its characteristics and purpose, aligning with the field value.', citations=[Citation(url='https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/', excerpts=['To succeed on a given example, an LLM must synthesize the complex information in the document and generate a long-form response that is both a comprehensive answer to the user request and fully attributable to that document.', 'Second, responses are judged as factually accurate if they are fully grounded in information contained in the provided document, with no hallucinations.', 'A factually correct response that fails to properly address the user‚Äôs request fails the benchmarking example.', 'Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations', 'We selected a combination of different judges to mitigate any potential bias of a judge giving higher scores to the responses produced by a member of its own model family.', 'Each example comprises a document, a system instruction requiring the LLM to exclusively reference the provided document, and an accompanying user request.', 'FACTS_paper) , a comprehensive benchmark for evaluating the ability of LLMs to generate responses that are not only factually accurate with respect to given inputs, but also sufficiently detailed to provide satisfactory answers to user queries. W', 'the FACTS Grounding dataset comprises 1,719 examples, each carefully crafted to require long-form responses grounded in the context document provided.', ' We‚Äôve already tested leading LLMs using FACTS Grounding and have populated the initial leaderboard with their grounding scores. ', 'To ensure a diversity of inputs, the FACTS Grounding examples include documents with a variety of lengths, up to a maximum of 32,000 tokens (roughly 20,000 words), covering domains such as finance, technology, retail, medicine, and law.', 'acts-grounding-examples) today so anyone can use it to evaluate an LLM. Of course, we know that issues of benchmark contamination and leaderboard hacking are important to protect against, so following standard industry practice, we are keeping the private evaluation set held out. T', 'three frontier LLM judges ‚Äî namely Gemini 1.5 Pro, GPT-4o, and Claude 3.5 Sonnet.', 'The automatic judge models were comprehensively evaluated against a held-out test set to find the best performing judging prompt templates and to verify agreement with human raters.', 'ind more details of our FACTS Grounding evaluation methodology [in our paper](https://goo.gle/FACTS_paper) .', 'The final score for the overall grounding task is the average of all judge models‚Äô scores across all examples.', 'The user requests are similarly wide ranging, including requests for summarization, Q&A generation, and rewriting tasks.'], title='FACTS Grounding: A new benchmark for evaluating the factuality of ...')], confidence='high'), FieldBasis(field='representative_agentic_systems.1.system_name', reasoning=\"The field value represents a specific agentic search system name within a nested structure. The most directly relevant information across the excerpts is the mention of a named search framework integrated with LLMs to trigger searches and convert natural language requests into structured queries, which is conceptually aligned with a system like 'Search-R1'. The first excerpt states that function calling significantly expands LLM capabilities to access real-time information and convert requests into API calls or database queries, which supports the idea of an agentic, search-enabled system. The second excerpt explicitly mentions a named framework, the 'Search-o1' framework, designed to enhance retrieval-augmented LMs by enabling an Agentic RAG mechanism that triggers searches based on knowledge gaps and processes retrieved content to distill relevant information for the LLM's reasoning. These parts together directly connect to the notion of a dedicated, agentic search system (similar to the target field value) and explain how such a system operates within the broader context of agentic retrieval and reasoning. Other excerpts discuss agentic RAG more generally (planning, tool use, self-critique) and thus provide supportive context but do not address the specific system name as clearly.\", citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='timeline_of_milestones.11', reasoning='The fine-grained field value expresses a critical view on the depth and originality of knowledge when LLMs summarize information that is sourced from the web. Excerpts that address faithfulness (how well a response is supported by sources) and answer relevancy (alignment with the user query) are directly relevant because they pertain to the trustworthiness and depth of the generated summaries. Excerpts describing evaluation metrics for RAG systems (covering context relevance, answer relevance, and correctness) are also pertinent since they provide a framework for assessing whether web-sourced summaries truly add original insight or merely echo retrieved documents. Additionally, sections discussing corrective or adaptive retrieval approaches (CRAG) and dynamic web searching highlight how up-to-date and reliable the information can be, which influences the perceived depth and originality of knowledge. Collectively, these excerpts map onto the concern that web-linked LLM outputs may not always preserve depth or original interpretation, and they offer evaluation and architectural perspectives on mitigating these risks.', citations=[Citation(url='https://www.giskard.ai/knowledge/rag-benchmarking-for-ai-evaluation', excerpts=['*Faithfulness  \\n   ** Faithfulness assesses the extent to which the model‚Äôs response is supported by information in the reference document. The response must align with the source or reference document without introducing unsupported information', ' **Answer Relevancy  \\n   ** Answer relevancy evaluates whether the model‚Äôs response is relevant to the question, even if it is not entirely accurate or detail'], title='RAG Benchmarking: Comparing RAGAS, BERTScore, and ...'), Citation(url='https://www.patronus.ai/llm-testing/rag-evaluation-metrics', excerpts=['Five key metrics are used to evaluate RAG performance: context relevance, context sufficiency, answer relevance, answer correctness and answer hallucination.'], title='Best Practices for Evaluating RAG Systems'), Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '**Better Robustness** :\\n\\nCRAG mitigates the risk of generating incorrect knowledge by dynamically addressing errors in the retrieval process.', '**Dynamic Adaptability** :\\n\\nThe integration of large-scale web searches allows CRAG to expand beyond static knowledge bases, providing up-to-date and diverse information.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)'), Citation(url='https://dkaarthick.medium.com/ragas-for-rag-in-llms-a-comprehensive-guide-to-evaluation-metrics-3aca142d6e38', excerpts=['RAGAS introduces several metrics that provide a more holistic evaluation of RAG models, focusing on aspects like faithfulness, answer relevancy, context precision, and context recall.'], title='RAGAS for RAG in LLMs: A Comprehensive Guide to ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='evaluation_benchmarks_and_metrics.1.purpose', reasoning='The field value centers on evaluating retrieval-augmented generation by measuring how well generated content aligns with retrieved documents. Excerpts that describe a benchmark designed to evaluate factuality and grounding in LLM outputs, and that emphasize anchoring responses to provided documents, directly support this. For example, a piece explains that success requires responses to be grounded in the supplied document and that the benchmark offers a measure of grounding accuracy to avoid hallucinations. Others describe the FACTS Grounding dataset and its role as a comprehensive evaluation with a leaderboard, highlighting how grounding scores are used to assess alignment between generated content and source material. Additional excerpts outline the scope of the evaluation, including diverse document lengths and domains, and mention methodology details like using multiple judges to mitigate bias, all of which illuminate how the evaluation is designed to test factual alignment in RAG-like pipelines. Collectively, these excerpts provide direct support for understanding how the finegrained field value would be evaluated and measured in practice, including the emphasis on grounding in the retrieved documents and the use of structured benchmarks and scoring to quantify alignment.', citations=[Citation(url='https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/', excerpts=['To succeed on a given example, an LLM must synthesize the complex information in the document and generate a long-form response that is both a comprehensive answer to the user request and fully attributable to that document.', 'Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations', 'the FACTS Grounding dataset comprises 1,719 examples, each carefully crafted to require long-form responses grounded in the context document provided.', ' We‚Äôve already tested leading LLMs using FACTS Grounding and have populated the initial leaderboard with their grounding scores. ', 'Each example comprises a document, a system instruction requiring the LLM to exclusively reference the provided document, and an accompanying user request.', 'To ensure a diversity of inputs, the FACTS Grounding examples include documents with a variety of lengths, up to a maximum of 32,000 tokens (roughly 20,000 words), covering domains such as finance, technology, retail, medicine, and law.', 'FACTS_paper) , a comprehensive benchmark for evaluating the ability of LLMs to generate responses that are not only factually accurate with respect to given inputs, but also sufficiently detailed to provide satisfactory answers to user queries. W', 'The user requests are similarly wide ranging, including requests for summarization, Q&A generation, and rewriting tasks.', 'The final score for the overall grounding task is the average of all judge models‚Äô scores across all examples.'], title='FACTS Grounding: A new benchmark for evaluating the factuality of ...')], confidence='high'), FieldBasis(field='major_industry_implementations.1.technical_integration_pattern', reasoning='The most relevant information shows that Copilot grounds its responses using current web information and does so in an enterprise context with layered protections. This is evidenced by the statement that Copilot can ground answers with web data to close knowledge gaps, which directly supports the idea of a grounding-enabled integration pattern. Further, enterprise-focused web search is described as having controls and being different from consumer search, aligning with a robust integration pattern that prioritizes governance and security. Specific mentions that web search fetches information from the Bing service when enabled, and that queries are generated to query Bing with user/tenant identifiers handled in a way that keeps data within the Microsoft 365 boundary, provide concrete details about how the integration operates safely and within enterprise domains. The notes that web search parsing identifies terms to improve response quality, and that Copilot search spans across Microsoft 365 and third-party data sources, extend the picture to how data sources are connected and exposed via APIs or search interfaces. Taken together, these excerpts describe the essential components of the technical integration pattern: grounding via web data, enterprise-oriented controls, data privacy protections, and cross-source data connectivity within the Microsoft ecosystem. They collectively support the field value‚Äôs emphasis on an enterprise-focused, security-conscious, and data-source-integrated web search implementation.', citations=[Citation(url='https://techcommunity.microsoft.com/blog/microsoft365copilotblog/microsoft-365-copilot-web-search-delivering-multiple-layers-of-protection-and-co/4458224', excerpts=['That‚Äôs why Copilot can ground its answers with current information from the web, closing knowledge gaps that every large language model (LLM) inevitably has based on its training data cutoff.', 'Traditional web search engines are optimized for broad consumer scenarios. Copilot‚Äôs web search is enterprise oriented and layered with controls that consumer search does not provide.', 'A Copilot interaction has three parts: your prompt, a web query (if needed), and the response.'], title='Microsoft 365 Copilot Web Search: Delivering Multiple ...'), Citation(url='https://learn.microsoft.com/en-us/copilot/microsoft-365/manage-public-web-access', excerpts=['When web search is enabled, Microsoft 365 Copilot and Microsoft 365 Copilot Chat may fetch information from the Bing search service when information from the web helps to provide a better, more grounded response.', 'generated search queries sent to the Bing search service to ground responses in web data. The way Microsoft handles these queries is identical in both services. Gen', 'When web search is enabled, Microsoft 365 Copilot and Microsoft 365 Copilot Chat parse the user‚Äôs prompt and identifies terms where information from the web would improve the quality of the response.', 'osoft 365 **Copilot Search** is an additional, universal search experience that allows users with a Microsoft 365 Copilot license to search across all their Microsoft 365 and third-party data sources.', 'ontrols and a user-level **Web content** toggle (only for Microsoft 365 Copilot) are available to [manage whether web search is enabled]() in your environment'], title='Data, privacy, and security for web search in Microsoft 365 ...'), Citation(url='https://learn.microsoft.com/en-us/copilot/overview', excerpts=['Nov 11, 2025 ‚Äî Copilot Chat is AI chat grounded in data from the web and powered by the latest large language models (LLMs). Copilot Chat lets users access agents and create\\xa0...'], title='Overview of Microsoft 365 Copilot Chat')], confidence='high'), FieldBasis(field='major_industry_implementations.0.product_name', reasoning=\"The finegrained field value seeks information about 'AI Overviews' as a product or feature within Google's ecosystem. The most relevant excerpts directly mention 'AI Overviews' as a feature integrated into Google Search and as part of Google's AI suite (e.g., 'AI Overviews and AI Mode' embedded in Google Search). These passages explicitly confirm the existence and role of AI Overviews, aligning with the field value. Additional relevant content describes AI Overviews in the broader product context (for example, as part of the engine behind the AI features and in historical evolution), which further supports the field value by situating AI Overviews within Google's offerings. An excerpt mentioning a closely related term 'AI Overview' (singular) provides partial relevance by indicating the general concept but does not directly confirm the exact plural product name. Another excerpt discusses the landscape around AI-driven search features and references 'AI Overviews' in a historical timeline, reinforcing the association with Google's AI Overviews. An excerpt about Gemini or other unrelated topics is less directly supportive of the exact field value but still relevant to the broader topic of AI-driven search features and Google's ecosystem.\", citations=[Citation(url='https://adcellerant.com/blogs/ai-changing-organic-search-august-2025/', excerpts=['Gemini is now embedded into Google Search through AI Overviews and AI Mode, accessible as a standalone chatbot, and integrated across the Google suite (Gmail, Docs, YouTube, etc.).', 'Gemini is Google‚Äôs flagship LLM and the engine behind AI Overviews, AI Mode, and Google‚Äôs standalone chatbot experience.', 'From the public release of ChatGPT in late 2022 to the full launch of Google‚Äôs AI Overviews in mid-2024, the landscape has shifted so much that search engine optimization (SEO) is now being referred to as ‚ÄúSearch Everywhere Optimization.‚Äù'], title='AI is Changing Organic Search: August 2025 Update - AdCellerant'), Citation(url='https://seosherpa.com/ai-overview/', excerpts=[\"Google's AI Overview is a new search feature that utilizes generative AI to provide a concise answer at the top of the results page.\"], title=\"What Is Google's AI Overview? A Deep Dive into the Future ...\")], confidence='high'), FieldBasis(field='major_industry_implementations.1.quality_control_mechanism', reasoning='- The most directly supportive content states that Copilot can ground its answers with current web information, addressing knowledge gaps and implying layered protections to ensure accuracy, which aligns with multi-layer quality controls and real-time grounding described in the target field value. It also frames the grounding as a mechanism to mitigate hallucinations, which directly matches the stated safety and grounding objectives. \\n- The next excerpt emphasizes that Copilot interactions involve a web query and a response, highlighting the workflow that enables the grounding and controlled retrieval of information, reinforcing the notion of controlled web-based QA and quality controls. \\n- Additional excerpts describe that when web search is used, information is fetched from a search service to ground responses, illustrating the practical grounding mechanism and data provenance, which are core elements of the quality-control framework. \\n- Further content notes that the system uses parsing to identify terms where web information would improve answer quality, indicating active quality optimization during prompt processing and web sourcing, which supports the proactive quality-control aspect. \\n- There is also mention of generated search queries being sent to the search service and the uniform handling of those queries across Copilot products, reinforcing standardized quality controls and governance over data handling in web-grounded responses. \\n- Governance- and privacy-related content describes web-content toggles and administrative controls, which underpin policy-enforced quality and safety practices in deployed environments. \\n- Finally, references to universal search across organizational data sources and privacy commitments that enterprise query data is not used for training or advertising reinforce external governance and data-use policies that are part of the broader quality-control and risk-management framework.', citations=[Citation(url='https://techcommunity.microsoft.com/blog/microsoft365copilotblog/microsoft-365-copilot-web-search-delivering-multiple-layers-of-protection-and-co/4458224', excerpts=['That‚Äôs why Copilot can ground its answers with current information from the web, closing knowledge gaps that every large language model (LLM) inevitably has based on its training data cutoff.'], title='Microsoft 365 Copilot Web Search: Delivering Multiple ...'), Citation(url='https://learn.microsoft.com/en-us/copilot/overview', excerpts=['Nov 11, 2025 ‚Äî Copilot Chat is AI chat grounded in data from the web and powered by the latest large language models (LLMs). Copilot Chat lets users access agents and create\\xa0...'], title='Overview of Microsoft 365 Copilot Chat'), Citation(url='https://learn.microsoft.com/en-us/copilot/microsoft-365/manage-public-web-access', excerpts=['When web search is enabled, Microsoft 365 Copilot and Microsoft 365 Copilot Chat may fetch information from the Bing search service when information from the web helps to provide a better, more grounded response.', 'When web search is enabled, Microsoft 365 Copilot and Microsoft 365 Copilot Chat parse the user‚Äôs prompt and identifies terms where information from the web would improve the quality of the response.', 'generated search queries sent to the Bing search service to ground responses in web data. The way Microsoft handles these queries is identical in both services. Gen', 'ontrols and a user-level **Web content** toggle (only for Microsoft 365 Copilot) are available to [manage whether web search is enabled]() in your environment', 'osoft 365 **Copilot Search** is an additional, universal search experience that allows users with a Microsoft 365 Copilot license to search across all their Microsoft 365 and third-party data sources.'], title='Data, privacy, and security for web search in Microsoft 365 ...')], confidence='high'), FieldBasis(field='timeline_of_milestones.1', reasoning='The most directly supportive content is a description of Self-RAG as an advanced framework where the LLM is trained to perform self-critique during retrieval and generation, which directly aligns with the idea of an LLM learning to retrieve on-demand and critique its own generations to improve quality and factuality. The mention that Self-RAG is a framework and that it appears in late 2023 corroborates the qualifying milestone in the field value. Additional excerpts explicitly reference Self-RAG in context, including notes that Self-RAG is related to the broader evolution of RAG and its emphasis on self-critique during the retrieval/generation loop, further supporting the claim that this represents a seminal contribution in 2023. An excerpt describing Agentic RAG as a shift toward autonomous, self-directed retrieval and reasoning also reinforces the surrounding context of more capable, self-guiding retrieval paradigms, which is consistent with the milestone description of Self-RAG‚Äôs aim to enhance reliability and reduce hallucinations through internal critique and retrieval control. Direct quotes from the relevant excerpts include indicating Self-RAG as a late-2023 concept, the autonomous/self- directed retrieval angle, and the explicit definition of Self-RAG as an advanced framework where the LLM is trained to perform self-critique during retrieval and generation. Taken together, these excerpts support the finegrained field value describing a seminal 2023 framework where an LLM learns to retrieve on-demand and critique its own generations to enhance quality and reduce hallucinations.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. '], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='high'), FieldBasis(field='major_industry_implementations.0.underlying_llm', reasoning=\"The targeted field value describes a Custom Gemini model, specifically highlighting Gemini 1.5 Pro with a 2 million token context window. Excerpts that reference Gemini‚Äôs evolution to Gemini 1.5 and Gemini Advanced/Pro indicate that Google‚Äôs Gemini line has evolved into more capable variants, which aligns with the notion of a customized, higher-capacity model. Excerpts explicitly identifying Gemini as Google's flagship LLM and the engine behind AI Overviews demonstrate that Gemini is the underlying technology commonly referenced in related documents, supporting the idea of a specialized variant within the Gemini family. While none of the excerpts state a 2 million token window or a ‚ÄòPro‚Äô tier by name with that exact spec, they collectively corroborate the existence and progression of high-capacity Gemini models and their role in Google‚Äôs product ecosystem, which is consistent with the described field value of a Custom Gemini model with advanced capabilities.\", citations=[Citation(url='https://brassmonkey.ai/google-gemini-review/', excerpts=[\"The Gemini 1.0 version came out in late 2023, and by 2025, we now have Gemini 1.5 and Gemini Advanced. The Gemini project combines Google's AI research with ...\"], title=\"Google Gemini Review: Is Google's AI Really Worth the ...\"), Citation(url='https://adcellerant.com/blogs/ai-changing-organic-search-august-2025/', excerpts=['Gemini is Google‚Äôs flagship LLM and the engine behind AI Overviews, AI Mode, and Google‚Äôs standalone chatbot experience.', 'Gemini is now embedded into Google Search through AI Overviews and AI Mode, accessible as a standalone chatbot, and integrated across the Google suite (Gmail, Docs, YouTube, etc.).', 'From the public release of ChatGPT in late 2022 to the full launch of Google‚Äôs AI Overviews in mid-2024, the landscape has shifted so much that search engine optimization (SEO) is now being referred to as ‚ÄúSearch Everywhere Optimization.‚Äù'], title='AI is Changing Organic Search: August 2025 Update - AdCellerant'), Citation(url='https://seosherpa.com/ai-overview/', excerpts=[\"Google's AI Overview is a new search feature that utilizes generative AI to provide a concise answer at the top of the results page.\"], title=\"What Is Google's AI Overview? A Deep Dive into the Future ...\"), Citation(url='https://fortune.com/2025/12/02/sam-altman-declares-code-red-google-gemini-ceo-sundar-pichai/', excerpts=[\"With Gemini 3's strong rollout and rising user base, Google suddenly has the edge, and OpenAI is racing to keep its dominance from slipping ...\"], title=\"Sam Altman declares 'Code Red' as Google's Gemini surges‚Äîthree ...\")], confidence='medium'), FieldBasis(field='evaluation_benchmarks_and_metrics.0.purpose', reasoning='The field value asserts a focus on factual accuracy relative to source material and sufficient detail to avoid hallucinations, with a contextual cap of up to 32k tokens. Excerpts that explicitly state responses must be fully grounded in the information from the provided document and be factually accurate support this aim. Additionally, references to long-form responses grounded in the context document, and to an evaluation framework that measures grounding accuracy and attempts to minimize hallucinations, directly corroborate the purpose of the benchmark. The detail about handling documents with up to 32,000 tokens further confirms the token-length aspect of the field value. Together, these excerpts collectively establish the goal of evaluating LLM outputs for factual grounding against source material, with emphasis on thoroughness and avoidance of hallucinations, including support for long-form responses.', citations=[Citation(url='https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/', excerpts=['To succeed on a given example, an LLM must synthesize the complex information in the document and generate a long-form response that is both a comprehensive answer to the user request and fully attributable to that document.', 'Second, responses are judged as factually accurate if they are fully grounded in information contained in the provided document, with no hallucinations.', 'Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations', 'the FACTS Grounding dataset comprises 1,719 examples, each carefully crafted to require long-form responses grounded in the context document provided.', 'To ensure a diversity of inputs, the FACTS Grounding examples include documents with a variety of lengths, up to a maximum of 32,000 tokens (roughly 20,000 words), covering domains such as finance, technology, retail, medicine, and law.', 'A factually correct response that fails to properly address the user‚Äôs request fails the benchmarking example.'], title='FACTS Grounding: A new benchmark for evaluating the factuality of ...')], confidence='high'), FieldBasis(field='major_industry_implementations.0.quality_control_mechanism', reasoning=\"The fine-grained field value discusses Google's approach to safety and governance in its AI-assisted search features (algorithmic and manual guardrails), a rollout timeline (May 2024), and performance metrics in high-stakes domains (fact-checking, hallucinations) as well as attribution/citation mechanisms. The provided excerpts primarily describe Google‚Äôs AI-enabled search features and the Gemini family, including references to an AI Overview feature and the Gemini project with multiple iterations. These excerpts establish the broader context that Google developed AI-driven search capabilities (overviews, mode, standalone chatbot) and that Gemini is integral to these services, including historical context about releases and evolutions. However, none of the excerpts contain the specific guardrail design details, rollout critique data, or explicit attribution/citation metrics described in the fine-grained field value. As a result, the excerpts collectively offer contextual relevance (describing the same platform and family of products) but do not provide direct evidence for the precise claims about policy guardrails, early rollout criticisms with percentages, high-stakes domain hallucination rates, or attribution mechanisms as stated. The strongest connection is with excerpts that discuss Google‚Äôs AI-driven search features (AI Overviews, Gemini integration) and the evolution of the Gemini lineup, which helps situate the field value but does not fully substantiate it.\", citations=[Citation(url='https://seosherpa.com/ai-overview/', excerpts=[\"Google's AI Overview is a new search feature that utilizes generative AI to provide a concise answer at the top of the results page.\"], title=\"What Is Google's AI Overview? A Deep Dive into the Future ...\"), Citation(url='https://brassmonkey.ai/google-gemini-review/', excerpts=[\"The Gemini 1.0 version came out in late 2023, and by 2025, we now have Gemini 1.5 and Gemini Advanced. The Gemini project combines Google's AI research with ...\"], title=\"Google Gemini Review: Is Google's AI Really Worth the ...\"), Citation(url='https://adcellerant.com/blogs/ai-changing-organic-search-august-2025/', excerpts=['Gemini is Google‚Äôs flagship LLM and the engine behind AI Overviews, AI Mode, and Google‚Äôs standalone chatbot experience.', 'Gemini is now embedded into Google Search through AI Overviews and AI Mode, accessible as a standalone chatbot, and integrated across the Google suite (Gmail, Docs, YouTube, etc.).', 'From the public release of ChatGPT in late 2022 to the full launch of Google‚Äôs AI Overviews in mid-2024, the landscape has shifted so much that search engine optimization (SEO) is now being referred to as ‚ÄúSearch Everywhere Optimization.‚Äù'], title='AI is Changing Organic Search: August 2025 Update - AdCellerant'), Citation(url='https://fortune.com/2025/12/02/sam-altman-declares-code-red-google-gemini-ceo-sundar-pichai/', excerpts=[\"With Gemini 3's strong rollout and rising user base, Google suddenly has the edge, and OpenAI is racing to keep its dominance from slipping ...\"], title=\"Sam Altman declares 'Code Red' as Google's Gemini surges‚Äîthree ...\")], confidence='low'), FieldBasis(field='evaluation_benchmarks_and_metrics.1.main_finding_or_use_case', reasoning=\"The finegrained field value describes a use-case where a faithfulness or factuality score below a threshold signals hallucinations in retrieval-augmented generation (RAG) systems, and notes a composable evaluation node within LangChain pipelines. Excerpts show that FACTS Grounding is a comprehensive benchmark designed to evaluate how factually accurate and grounded an LLM's response is with respect to a provided document, and that responses are judged by whether they are fully grounded in the source, with a leaderboard tracking grounding performance. This directly supports the notion of a use-case where hallucination is penalized or identified through a factuality grounding score, as the benchmark explicitly aims to measure grounding accuracy and to penalize unsupported claims. Additionally, statements about the benchmark requiring long-form responses that are attributable to documents, and about scoring across multiple judges and models, reinforce the idea of a structured evaluation node that quantifies faithfulness and penalizes hallucinations within a LangChain-like pipeline. The remaining excerpts reinforce the context by describing the diversity of inputs, the scale of the evaluation, and the existence of an online leaderboard, all of which are consistent with a RAG-faithfulness evaluation framework.\", citations=[Citation(url='https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/', excerpts=['Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations', 'To succeed on a given example, an LLM must synthesize the complex information in the document and generate a long-form response that is both a comprehensive answer to the user request and fully attributable to that document.', 'Second, responses are judged as factually accurate if they are fully grounded in information contained in the provided document, with no hallucinations.', ' We‚Äôve already tested leading LLMs using FACTS Grounding and have populated the initial leaderboard with their grounding scores. ', 'Each example comprises a document, a system instruction requiring the LLM to exclusively reference the provided document, and an accompanying user request.', 'The final score for the overall grounding task is the average of all judge models‚Äô scores across all examples.', 'To ensure a diversity of inputs, the FACTS Grounding examples include documents with a variety of lengths, up to a maximum of 32,000 tokens (roughly 20,000 words), covering domains such as finance, technology, retail, medicine, and law.', 'The user requests are similarly wide ranging, including requests for summarization, Q&A generation, and rewriting tasks.', 'A factually correct response that fails to properly address the user‚Äôs request fails the benchmarking example.', 'We selected a combination of different judges to mitigate any potential bias of a judge giving higher scores to the responses produced by a member of its own model family.', 'FACTS_paper) , a comprehensive benchmark for evaluating the ability of LLMs to generate responses that are not only factually accurate with respect to given inputs, but also sufficiently detailed to provide satisfactory answers to user queries. W', 'the FACTS Grounding dataset comprises 1,719 examples, each carefully crafted to require long-form responses grounded in the context document provided.', 'three frontier LLM judges ‚Äî namely Gemini 1.5 Pro, GPT-4o, and Claude 3.5 Sonnet.', 'acts-grounding-examples) today so anyone can use it to evaluate an LLM. Of course, we know that issues of benchmark contamination and leaderboard hacking are important to protect against, so following standard industry practice, we are keeping the private evaluation set held out. T'], title='FACTS Grounding: A new benchmark for evaluating the factuality of ...')], confidence='high'), FieldBasis(field='representative_agentic_systems.1.key_contribution', reasoning='The most directly supportive content notes that function calling expands LLM capabilities to access real-time information, interact with external systems, automate tasks, and translate requests into API calls or queries. This aligns with the notion of training LLMs to learn sophisticated tool interaction strategies. Additionally, descriptions of an Agentic RAG mechanism that dynamically triggers searches based on knowledge gaps, plus a Reason-in-Documents module that distills information into a refined format, directly map to training LLMs to effectively interact with tools and manage information for deep research tasks. Broad statements about agentic architectures‚Äîwhere an Agent plans a sequence of actions, uses tools, self-corrects, and collaborates with sub-agents‚Äîfurther support the idea of emergent cognitive behaviors and structured tool use. Finally, references to self-critique frameworks within Self-RAG indicate mechanisms that can shape higher-order cognitive processes during retrieval and generation. Collectively, these excerpts corroborate the field value by illustrating how agentic systems are designed to train LLMs in tool interaction and to foster sophisticated, higher-level cognitive behaviors for complex research tasks.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='high'), FieldBasis(field='evaluation_benchmarks_and_metrics.3.main_finding_or_use_case', reasoning='The field value asserts that even leading systems have difficulties with citation reliability and depth of analysis when producing evidence-grounded reports. The most directly relevant passages state that responses are judged as factually accurate only if they are fully grounded in information from the document and contain no hallucinations, indicating a high standard for citation reliability. Related passages emphasize the need to synthesize information from documents and generate long-form responses that are fully attributable to the source, which aligns with the claim about analytical depth and proper attribution. Additional excerpts describe the purpose of the benchmarking setup, which is to measure grounding accuracy and reduce hallucinations, and note that outputs should exclusively reference the provided document, underscoring the evaluation of citation reliability. Collectively, these excerpts support the notion that current systems are evaluated on how well they ground, attribute, and reason about sources, which corresponds to the stated concern about state-of-the-art systems struggling with reliable citations and deep analysis.', citations=[Citation(url='https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/', excerpts=['Second, responses are judged as factually accurate if they are fully grounded in information contained in the provided document, with no hallucinations.', 'To succeed on a given example, an LLM must synthesize the complex information in the document and generate a long-form response that is both a comprehensive answer to the user request and fully attributable to that document.', 'Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations', 'A factually correct response that fails to properly address the user‚Äôs request fails the benchmarking example.', 'Each example comprises a document, a system instruction requiring the LLM to exclusively reference the provided document, and an accompanying user request.', ' We‚Äôve already tested leading LLMs using FACTS Grounding and have populated the initial leaderboard with their grounding scores. ', 'three frontier LLM judges ‚Äî namely Gemini 1.5 Pro, GPT-4o, and Claude 3.5 Sonnet.', 'the FACTS Grounding dataset comprises 1,719 examples, each carefully crafted to require long-form responses grounded in the context document provided.', 'We selected a combination of different judges to mitigate any potential bias of a judge giving higher scores to the responses produced by a member of its own model family.', 'The final score for the overall grounding task is the average of all judge models‚Äô scores across all examples.'], title='FACTS Grounding: A new benchmark for evaluating the factuality of ...')], confidence='high'), FieldBasis(field='representative_agentic_systems.4.year', reasoning='The target field value encodes a year for a representative agentic system. The excerpt that references a 2025a bibliography entry directly ties to a year annotation in scholarly context, which is the most direct support for a concrete year value in a research-system context. Other excerpts discuss the architecture, capabilities, and evolution of Agentic RAG but do not provide explicit year data for the field, so they serve as contextual support rather than direct evidence for the exact year value. Therefore, the year-bearing excerpt is the primary source supporting the field value, while the others help establish the broader research landscape around agentic retrieval and reasoning.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='evaluation_benchmarks_and_metrics.0.key_metrics', reasoning='The field value specifies a two-phased evaluation conducted by an ensemble of LLM judges, with Phase 1 Eligibility (does the response address the request?) and Phase 2 Factual Accuracy (is the response fully grounded in the document). Excerpts describing a frontline ensemble of judges (including named models) directly corroborate the two-phase, multi-judge framework. Statements that responses must be grounded in the provided document and judged for factual accuracy validate the emphasis on grounding and accuracy assessment. References to a comprehensive benchmark and an online leaderboard establish the broader evaluation ecosystem, while mentions of using a combination of judges to mitigate bias elsewhere reinforce the reliability of an ensemble approach. Passages that discuss evaluation prompts or instructions ensuring responses reference only the provided document further connect to the mechanism by which eligibility and grounding are enforced. Taken together, these excerpts substantiate the concept of a two-phased, ensemble-judge evaluation process focused on addressing user requests and ensuring factual grounding in source material.', citations=[Citation(url='https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/', excerpts=['three frontier LLM judges ‚Äî namely Gemini 1.5 Pro, GPT-4o, and Claude 3.5 Sonnet.', 'A factually correct response that fails to properly address the user‚Äôs request fails the benchmarking example.', 'Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations', 'FACTS_paper) , a comprehensive benchmark for evaluating the ability of LLMs to generate responses that are not only factually accurate with respect to given inputs, but also sufficiently detailed to provide satisfactory answers to user queries. W', 'Each example comprises a document, a system instruction requiring the LLM to exclusively reference the provided document, and an accompanying user request.', 'The automatic judge models were comprehensively evaluated against a held-out test set to find the best performing judging prompt templates and to verify agreement with human raters.', 'Second, responses are judged as factually accurate if they are fully grounded in information contained in the provided document, with no hallucinations.', 'We selected a combination of different judges to mitigate any potential bias of a judge giving higher scores to the responses produced by a member of its own model family.', 'the FACTS Grounding dataset comprises 1,719 examples, each carefully crafted to require long-form responses grounded in the context document provided.', ' We‚Äôve already tested leading LLMs using FACTS Grounding and have populated the initial leaderboard with their grounding scores. ', 'To ensure a diversity of inputs, the FACTS Grounding examples include documents with a variety of lengths, up to a maximum of 32,000 tokens (roughly 20,000 words), covering domains such as finance, technology, retail, medicine, and law.', 'acts-grounding-examples) today so anyone can use it to evaluate an LLM. Of course, we know that issues of benchmark contamination and leaderboard hacking are important to protect against, so following standard industry practice, we are keeping the private evaluation set held out. T', 'ind more details of our FACTS Grounding evaluation methodology [in our paper](https://goo.gle/FACTS_paper) .', 'The final score for the overall grounding task is the average of all judge models‚Äô scores across all examples.', 'The user requests are similarly wide ranging, including requests for summarization, Q&A generation, and rewriting tasks.'], title='FACTS Grounding: A new benchmark for evaluating the factuality of ...')], confidence='high'), FieldBasis(field='representative_agentic_systems.1.associated_paper', reasoning='The target field value describes a research work that combines reasoning by LLMs with the use of search engines and reinforcement learning. Excerpt content that directly discusses expanding LLM capabilities to access real-time information through function calls and external tools supports the core idea of leveraging search or retrieval within LLM workflows. Excerpt content that outlines the Search-o1 framework, which is designed to enhance LLM reasoning by enabling self-assessed knowledge gaps, dynamic triggering of searches, and processing retrieved content to distill relevant information, most closely aligns with the RFRL (reasoning with search and reinforcement) paradigm described by the target paper. Excerpts that describe Agentic RAG as a shift to autonomous, self-directed retrieval and reasoning, and that emphasize planning, tool use (including search engines), and collaboration among sub-agents, provide strong contextual support for the general approach of training or configuring LLMs to reason with search and external tools under reinforcement-like guidance. Collectively, these excerpts support the notion of integrating search-enabled reasoning and reinforcement-inspired mechanisms into LLM workflows, which is the essence of the targeted field value, even though the exact paper title is not stated in the excerpts.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='representative_agentic_systems.4.key_contribution', reasoning='The target field value emphasizes alignment of agent behavior with human preferences to improve usefulness for complex report generation. The most directly relevant material describes an Agentic RAG mechanism that dynamically triggers searches based on knowledge gaps and a Reason-in-Documents module that distills information to reduce noise and maintain reasoning quality, which collectively contribute to outputs that better match user needs. Additional relevance comes from descriptions of planning sub-goals, tool use, and collaboration among sub-agents to execute tasks, which are mechanisms that can steer behavior toward user-aligned outcomes. Self-critique during retrieval and generation is another relevant capability, as it directly supports correcting deviations from desired behavior and improving alignment with goals. While none of the excerpts state the exact alignment claim, they collectively illustrate architectural features and practices that enable outputs to be more useful and better aligned with user tasks, such as report generation, by improving search efficiency, information distillation, and self-correction.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='evaluation_benchmarks_and_metrics.1.key_metrics', reasoning='The finegrained field value describes a set of reference-free metrics used to evaluate factuality and grounding quality, specifically mentioning components like Faithfulness, Context Precision, Context Recall, and Answer Relevance, and notes that a combined factuality score can be computed from these. The most directly relevant excerpts discuss the purpose and nature of FACTS Grounding as a benchmark: one excerpt states that the benchmark provides a measure of how accurately LLMs ground their responses in provided source material and helps avoid hallucinations, which aligns with the idea of evaluating faithfulness and grounding without external references. Another excerpt explains that the evaluation targets responses that are factually accurate with respect to given inputs and are detailed, which corresponds to components like Faithfulness and Context Relevance, and implies a composite assessment. A third excerpt explicitly links fact-based grounding to factual accuracy grounded in the provided document, reinforcing the link between grounding and factuality. A fourth excerpt mentions the final score for grounding as an average across judge models, connecting to the idea of a single aggregate metric derived from multiple evaluations. The remaining excerpt reinforces the general grounding/testing framework by describing the benchmark‚Äôs role in measuring grounding quality and reducing hallucinations. Collectively, these excerpts support the notion that the field value pertains to a structured, multi-metric, reference-free evaluation of factuality and grounding quality, culminating in a composite score derived from multiple judgments. ', citations=[Citation(url='https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/', excerpts=['Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations', 'FACTS_paper) , a comprehensive benchmark for evaluating the ability of LLMs to generate responses that are not only factually accurate with respect to given inputs, but also sufficiently detailed to provide satisfactory answers to user queries. W', 'Second, responses are judged as factually accurate if they are fully grounded in information contained in the provided document, with no hallucinations.', 'The final score for the overall grounding task is the average of all judge models‚Äô scores across all examples.', 'To succeed on a given example, an LLM must synthesize the complex information in the document and generate a long-form response that is both a comprehensive answer to the user request and fully attributable to that document.'], title='FACTS Grounding: A new benchmark for evaluating the factuality of ...')], confidence='medium'), FieldBasis(field='representative_agentic_systems.0.key_contribution', reasoning='The most relevant passages explicitly describe agentic or self-directed retrieval and the use of tools or external information sources. The strongest support comes from passages that state the LLM can dynamically trigger searches based on knowledge gaps and integrate search results into its reasoning process. For example, the concept of an Agentic RAG mechanism that triggers search queries based on self-assessed knowledge gaps directly maps to the idea of teaching the model when to invoke a web search. Additionally, statements about function calling expanding capabilities to access real-time information and reliably convert natural language requests into structured API calls illustrate how retrieved data can be acted upon and integrated. Further support comes from discussions of planning, tool use, and self-critique within an agentic framework, which show how the model should organize steps, decide what to retrieve, and how to use the retrieved content to reach a task goal. Self-reflective and modular RAG discussions provide context on how learning when to search and how to utilize results can be embedded into training and architecture, reinforcing the field value. Taken together, these excerpts coherently describe both the when-to-search decision (triggered by self-assessed gaps or planning) and the how-to-use retrieved information (planning, tool use, reading and distilling results, and leveraging external resources).', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. '], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='high'), FieldBasis(field='representative_agentic_systems.7.year', reasoning='The finegrained field value specifies a year of 2025.0 for a representative agentic system entry. The most relevant excerpt explicitly references a 2025 citation label (the bibliographic tag [2025a]), which indicates the content or discussion is anchored to the year 2025 in the context of agentic retrieval-augmented methods. This direct link to a 2025 reference provides the strongest support for associating a 2025 timeframe with the representative agentic system entry. Other excerpts describe concepts such as agentic RAG, self-critique, planning, tool use, and modules, but they do not provide explicit 2025-year anchors or numerically confirm a 2025 value for the field, making them less directly supportive for the exact year field.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='representative_agentic_systems.4.associated_paper', reasoning='The field value posits that agentic LLMs are mentioned in 2025 research. The most directly supportive content describes an Agentic RAG Mechanism where the model dynamically triggers searches and a Reason-in-Documents module that distills retrieved content, which clearly aligns with agentic LLM research framing. Additional support comes from statements that agentic RAG represents a shift toward autonomous, self-directed retrieval and reasoning, which is exactly the central theme of agentic LLM research. The surrounding excerpts expand on these concepts by explaining planning, reflection, tool use, and collaboration among sub-agents, all of which are characteristic of agentic LLM research and implementations discussed in contemporary 2025-era literature. Further excerpts place this in the evolution of RAG and Self-RAG, which are common threads in 2025 discourse on making LLMs more autonomous and capable of self-critique and self-improvement during retrieval and reasoning. Collectively, the excerpts articulate a research milieu in which agentic LLMs and associated RAG paradigms are actively studied and described, which supports the field value that such concepts are mentioned in 2025 research contexts.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='high'), FieldBasis(field='representative_agentic_systems.8.year', reasoning='The field value represents a year (2025.0) within a nested structure about representative agentic systems. Among the excerpts, the one that explicitly engages with a 2025 timeframe is the note citing a 2025a reference in the bibliography, which aligns with a 2025 publication year context for agentic RAG developments. This excerpt also discusses a framework and components (Agentic RAG mechanism and Reason-in-Documents) that fit the theme of current, forward-looking advancements in agentic retrieval-augmented generation, thereby supporting the expectation of a 2025 temporal alignment in the field. Other excerpts describe earlier years (e.g., 2023, 2022) or do not mention a year, offering less direct support for a 2025 timestamp in the same nested field. Overall, the strongest, most relevant support for a 2025 year value comes from the excerpt that explicitly references 2025 in the context of agentic RAG research.)', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='representative_agentic_systems.0.year', reasoning=\"The fine-grained field value represents a specific year (2025.0) for a subfield inside representative_agentic_systems.0.0. The excerpt that explicitly references a 2025 bibliographic tag ('2025a') provides the clearest alignment with a 2025 timeframe, directly supporting the notion that near-term or current research in this space is anchored around 2025. Other excerpts discuss the evolution and capabilities of agentic RAG and related architectures, which establish the topic context but do not provide explicit 2025-year evidence. Thus, the most relevant content is the one tying the discussion to a 2025 reference, while the rest supply supportive context regarding ongoing trends in agentic retrieval-augmented generation.\", citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='representative_agentic_systems.7.key_contribution', reasoning='The most directly relevant content is a discussion of long, step-by-step reasoning chains and the agentically driven triggering of searches, which aligns with enabling an agent to manage long-horizon tasks involving many sequential steps and tool uses. Excerpts that describe Agentic RAG as an architecture where an Agent plans a sequence of actions, can query, read, re-query, and use tools, and where planning and breaking down complex queries into sub-goals are central, provide strong support for the field value about handling long series of tool calls. Additional support comes from references to tool use (e.g., external resources like search engines, calculators, or APIs) and autonomous, self-directed retrieval, which underpin the capacity for hundreds of potential tool interactions if needed. Excerpts that emphasize modular complexity and the augmentation of reasoning with external data further reinforce the idea that long-horizon tasks are supported by composing multiple modules and external calls. While some excerpts discuss broader architectural themes (e.g., modular RAG, self-critique frameworks) rather than explicitly stating the number of sequential tool calls, they still corroborate the overarching capability of sustained, multi-step retrieval and action sequences, which is central to the field value. Overall, the strongest alignment is with content that frames long-horizon planning and multi-step tool usage, followed by excerpts detailing planning, tool use, and autonomous querying, with architectural overviews providing contextual support.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='representative_agentic_systems.3.key_contribution', reasoning='The target fine-grained field value describes a system that produces autonomous, ReAct-style agents that learn effective web navigation and interaction strategies from expert human behavior. The most relevant excerpts explicitly discuss autonomous, agentic RAG systems that plan actions, query and re-query, and use tools in an autonomous loop, which aligns with the idea of autonomous agents learning through self-directed reasoning and strategy development. Specifically, the excerpts describe: (a) Agentic RAG as an architecture where an Agent plans a sequence of actions, queries, reads, and uses tools, moving beyond static retrieval to self-directed retrieval and reasoning; (b) planning, breaking down queries into sub-goals, and tool use as core components of the agentic flow; (c) a framework where search triggers are driven by self-assessed knowledge gaps and content is processed to distill relevant information, which demonstrates learning-like behavior during reasoning; (d) explicit mentions of Self-RAG as a framework for self-critique during retrieval and generation, indicating an emphasis on iterative improvement in agents; (e) additional context about modular or evolving agentic architectures that support flexible, autonomous decision-making. Together, these excerpts support the concept of autonomous ReAct-style agent behavior and the evolution of reasoning strategies (planning, tool use, self-critique) that could underpin learning effective web navigation and interaction strategies. While none may state the exact wording of ‚Äúlearning from expert human behavior‚Äù verbatim, the emphasis on autonomous planning, tool use, and self-reflection captures the core mechanisms by which such behavior could be learned, inferred from expert-like patterns in the presented material.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n'], title='Evolution of RAG from Static Knowledge to Agentic ...'), Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='evaluation_benchmarks_and_metrics.0.main_finding_or_use_case', reasoning='The most relevant content directly describes a comprehensive benchmark for evaluating the factuality of LLM outputs and highlights that the benchmark includes an online leaderboard to measure grounding accuracy. This directly supports the idea that such benchmarks are used to drive improvements in factual grounding and to publicly track model performance. Excerpts that mention testing leading LLMs against the benchmark and populating an initial leaderboard reinforce that the field value‚Äôs claim about ongoing public performance tracking is grounded in the provided material. References to frontier judges, including named models, corroborate the association between benchmarking activity and high performance or evaluation of factual grounding, which aligns with the field value‚Äôs statement about initial high factuality scores for specific model families. Additional excerpts discuss the breadth of the dataset and methodology, which underpin how the benchmark facilitates industry-wide progress by providing a structured evaluation framework. The Kaggle-specific detail in the field value is not explicitly confirmed in the excerpts, so I treat that portion as an inferred attribute rather than an evidenced claim within this excerpt set.', citations=[Citation(url='https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/', excerpts=['Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations', ' We‚Äôve already tested leading LLMs using FACTS Grounding and have populated the initial leaderboard with their grounding scores. ', 'three frontier LLM judges ‚Äî namely Gemini 1.5 Pro, GPT-4o, and Claude 3.5 Sonnet.', 'the FACTS Grounding dataset comprises 1,719 examples, each carefully crafted to require long-form responses grounded in the context document provided.', 'To succeed on a given example, an LLM must synthesize the complex information in the document and generate a long-form response that is both a comprehensive answer to the user request and fully attributable to that document.', 'Second, responses are judged as factually accurate if they are fully grounded in information contained in the provided document, with no hallucinations.', 'A factually correct response that fails to properly address the user‚Äôs request fails the benchmarking example.', 'FACTS_paper) , a comprehensive benchmark for evaluating the ability of LLMs to generate responses that are not only factually accurate with respect to given inputs, but also sufficiently detailed to provide satisfactory answers to user queries. W', 'The automatic judge models were comprehensively evaluated against a held-out test set to find the best performing judging prompt templates and to verify agreement with human raters.', 'The final score for the overall grounding task is the average of all judge models‚Äô scores across all examples.', 'The user requests are similarly wide ranging, including requests for summarization, Q&A generation, and rewriting tasks.', 'We selected a combination of different judges to mitigate any potential bias of a judge giving higher scores to the responses produced by a member of its own model family.', 'Each example comprises a document, a system instruction requiring the LLM to exclusively reference the provided document, and an accompanying user request.', 'To ensure a diversity of inputs, the FACTS Grounding examples include documents with a variety of lengths, up to a maximum of 32,000 tokens (roughly 20,000 words), covering domains such as finance, technology, retail, medicine, and law.'], title='FACTS Grounding: A new benchmark for evaluating the factuality of ...')], confidence='high'), FieldBasis(field='representative_agentic_systems.3.system_name', reasoning='The finegrained field value represents a specific system name within a broader nested structure about agentic retrieval systems. Excerpts that discuss function calling to access real-time information and to interact with external systems establish the capability class that a web-search-oriented system would require, making them directly relevant to the concept of a web-search-enabled agent. The excerpt describing the Search-o1 framework explicitly targets enhancing large language models with dynamic searches and a reasoning module to distill relevant information, which aligns with the idea of a web-search-augmented system. The Modular RAG excerpt describes a flexible, component-based architecture that would support a web-search workflow by allowing interchangeable search and processing modules. Other excerpts that emphasize the evolution of RAG toward agentic, self-reflective, or self-critiquing styles provide necessary background context about the terrain in which a web-search-oriented system would operate, but they are less directly tied to the concrete web-search capability. While none of the excerpts name the specific system WebDancer, they collectively map the features, architectures, and mechanisms (real-time querying, external tool use, dynamic information retrieval, and modular composition) that a system like WebDancer would need to embody.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', '4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='low'), FieldBasis(field='representative_agentic_systems.7.core_methodology', reasoning='To evaluate relevance to the fine-grained field value, I focus on excerpts that discuss agentic approaches and how LLMs interact with the environment to perform tasks. Excerpt describing function calling and the expansion of capabilities of LLMs through dynamic querying, real-time information access, external tool use, and API/database interactions directly align with building agentic systems and could underpin an asynchronous RL workflow that trains or guides the agent via interactions with external systems. Excerpts that emphasize planning, reflection, and tool use demonstrate the architectural characteristics of agentic systems, which are prerequisites or supportive strategies for implementing large-scale RL with synthesized QA data. Although the excerpts do not state the exact method (asynchronous RL with synthesized QA data), the identified passages provide the core concepts (agentic planning, tool use, self-directed retrieval, and reasoning modules) that would be involved in such a methodology. Therefore, those excerpts are more relevant than others that describe related but less directly connected ideas (e.g., self-critique in a generic sense or modular architectures without RL context).', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. '], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='low'), FieldBasis(field='representative_agentic_systems.3.year', reasoning='The most relevant excerpt directly references a citation labeled 2025a, which strongly indicates a 2025 date in the associated literature. This aligns with the target year 2025.0 for the field value. The next most relevant item notes a timeframe described as Late 2023, which situates the discussion in a near-contemporary period and provides proximate temporal context that supports the notion of evolving agentic RAG architectures around that era, though it does not confirm 2025 itself. Other excerpts discuss the evolution and capabilities of Agentic RAG, including the use of planning, tool use, and reasoning modules, which help contextualize why a 2025 date would be plausible for further maturations and publications in this domain. Collectively, these excerpts support that 2025 is a relevant year within the discourse on representative agentic systems and RAG, with the strongest anchor being the explicit 2025a citation. The surrounding years (2022, 2023) provide background context illustrating a progression toward 2025, but do not contradict the target year. ', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', '4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='representative_agentic_systems.8.system_name', reasoning='The target field value specifies a very particular system name: SSRL (Self-Supervised RL). Among the excerpts, the strongest direct matches describe Self-RAG and Agentic RAG, which are conceptually adjacent to self-supervised or autonomous retrieval and reasoning frameworks but do not provide the exact SSRL nomenclature or confirmation. For example, one excerpt explicitly states that Self-RAG is an advanced framework where the LLM is trained to perform self-critique during retrieval and generation, which aligns with the general theme of self-driven improvement in retrieval-augmented systems, yet it does not name SSRL. Another excerpt notes that Agentic RAG represents a shift toward autonomous, self-directed retrieval and reasoning, which again is thematically relevant but not the requested SSRL system name. Other excerpts discuss modular RAG and reasoning-in-documents modules, which are related architectural concepts but do not mention SSRL either. Consequently, while these excerpts help contextualize the landscape around self-directed and agentic retrieval-augmented generation, they do not substantiate the exact finegrained field value SSRL (Self-Supervised RL). The most relevant information thus points to related concepts (Self-RAG and Agentic RAG) rather than to a direct SSRL identification.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', '4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n'], title='Evolution of RAG from Static Knowledge to Agentic ...'), Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='low'), FieldBasis(field='representative_agentic_systems.5.system_name', reasoning=\"The target field value is the system name at representative_agentic_systems.5, which should be 'Search-o1'. The most direct support comes from an excerpt describing the 'Search-o1 framework' by Li et al., which explicitly uses the name 'Search-o1' in the context of an Agentic Retrieval-Augmented approach to improve LLM reasoning. This directly confirms the presence of the system name in question. Another excerpt discusses function calling enhancing LLM capabilities but does not mention the specific system name, therefore it does not substantively support the exact field value and is less relevant to the precise field being analyzed.\", citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='high'), FieldBasis(field='representative_agentic_systems.0.system_name', reasoning='The most relevant excerpt directly describes a Search-o1 framework that uses an Agentic RAG mechanism to dynamically trigger searches based on knowledge gaps and to distill retrieved content into a refined format, which aligns with a named system that would be responsible for search-driven agentic retrieval. This establishes a clear pattern of an automated search-oriented module within an RAG architecture. The next excerpt explains that function calling expands LLM capabilities to access real-time, dynamic information and execute structured queries, which reinforces the notion of a system designed to perform external information retrieval and tool use‚Äîkey aspects of a search-oriented agent. Subsequent excerpts elaborate on the broader concept of Agentic RAG, including planning, tool use, reflection, and orchestration of sub-agents, which contextualizes the architectural role of a system that manages retrieval and reasoning in an autonomous manner. Additional excerpts describe Self-RAG and Modular RAG as variants and extensions of the same overarching paradigm, highlighting different design philosophies (self-critique, modular components) that a system like R1-Searcher could embody or interact with. Although none of the excerpts explicitly state the exact field value (R1-Searcher), they collectively support the concept of a named, search-centric agentic system used to perform retrieval-augmented reasoning. The progression from static to agentic retrieval and the emphasis on dynamic querying and tool-use are the aspects most relevant to interpreting a field that would store a system name for such a component. In sum, the excerpts collectively map onto the domain and functional characteristics implied by a field representing a search-oriented agentic system, even though the explicit name is not present.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. '], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='representative_agentic_systems.5.core_methodology', reasoning='The field value specifies an agentic RAG mechanism integrated with LRMs that enables dynamic, inference-time retrieval driven by identified knowledge gaps. The most directly supporting excerpt explicitly describes an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and it mentions a Reason-in-Documents module that distills retrieved content to extract relevant information, aligning closely with the notion of dynamic, knowledge-gap‚Äìdriven retrieval and processing. The second excerpt references function calling to enable real-time, external access and API/database interactions, which is thematically related to dynamic information retrieval in LLMs but does not explicitly describe the agentic RAG mechanism or the knowledge-gap-driven triggering process; it provides contextual support about enabling external information access in LLMs, making it a secondary, supportive source.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='high'), FieldBasis(field='representative_agentic_systems.7.associated_paper', reasoning='The field value asserts that the associated paper is mentioned in research on agentic LLMs in 2025. The most directly supportive material comes from excerpts that explicitly discuss agentic retrieval-augmented architectures and their capabilities, including enabling real-time information access, dynamic querying, and structured API/DB interactions, with a publication reference dating to 2025. This alignment strongly supports the field value, as it confirms the presence of agentic LLM research within the 2025 timeframe. Additional supporting context comes from passages describing planning, tool use, and self-directed retrieval‚Äîcore elements of agentic RAG‚Äîwhich further corroborate the 2025 research focus on agentic LLMs. Excerpts that discuss Self-RAG and related frameworks reinforce the broader narrative of agentic capabilities but may be less explicit about the 2025 publication context, though they remain relevant for establishing the agentic research landscape. Overall, the strongest alignment is with the excerpts that tie agentic retrieval-augmented approaches to LLM capabilities and to a 2025 arXiv publication, followed by excerpts that describe related agentic concepts and related years.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', '4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='high'), FieldBasis(field='specific_rag_techniques.1.technique_name', reasoning='The field value identifies a precise technique name: Corrective Retrieval Augmented Generation (CRAG). The most directly supportive content explicitly states that CRAG is a framework within Retrieval-Augmented Generation designed to improve robustness against inaccuracies in retrieved data. This confirms both the existence and purpose of CRAG as described by the field value. Additionally, content that discusses the advantages of CRAG, notably improved accuracy and more reliable outputs through corrective retrieval, reinforces the relevance and real-world benefits associated with this exact technique name. Excerpts that discuss general RAG features or other subcomponents (like decomposing or adaptive retrieval) provide contextual background but do not directly name CRAG, making them less central to validating the specific field value.', citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '#### **Advantages of CRAG**\\n\\n**Improved Accuracy** :\\n\\nBy evaluating and correcting retrieved data, CRAG ensures more reliable and factually accurate outputs.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='high'), FieldBasis(field='specific_rag_techniques.1.key_benefit', reasoning='The finegrained field value asserts that robustness against inaccurate or low-quality retrieved information is enhanced, leading to better factuality and reliability of RAG outputs. The most directly supporting information appears in the excerpt that discusses the advantages of CRAG and explicitly mentions improved accuracy through evaluating and correcting retrieved data, which aligns with strengthening factuality and reliability. Additional support comes from the excerpt introducing Corrective RAG (CRAG) as a framework designed to improve robustness when dealing with inaccuracies in retrieved data, directly addressing robustness against faulty data. Further relevance is added by passages describing adaptive knowledge retrieval, which triggers extra retrieval actions to augment the dataset with more reliable information, and by the decomposition-recompose approach that focuses on key insights and removes noise, both of which contribute to higher quality inputs and, consequently, more reliable outputs. Collectively, these excerpts provide direct support for enhancing robustness and factuality of RAG systems in the face of low-quality retrieved information.', citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['#### **Advantages of CRAG**\\n\\n**Improved Accuracy** :\\n\\nBy evaluating and correcting retrieved data, CRAG ensures more reliable and factually accurate outputs.', '#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.', '1. **Generation with Decompose-then-Recompose Algorithm** :\\n\\nRetrieved documents are broken down into smaller components to focus on key insights while filtering out irrelevant or redundant details. The filtered information is recombined into a cohesive and concise dataset, optimizing the quality of data input for generation.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='high'), FieldBasis(field='representative_agentic_systems.5.key_contribution', reasoning='The most directly relevant content describes an Agentic RAG (Retrieval-Augmented) mechanism where a language model dynamically triggers search queries based on self-assessed knowledge gaps, coupled with a Reason-in-Documents module that distills relevant information from retrieved content to maintain reasoning quality. This directly supports the idea of enhancing reasoning by actively and selectively seeking external knowledge and processing it for use in reasoning. Additionally, the other excerpt highlights that function calling expands LLM capabilities to access real-time information, interact with external systems and databases, and convert natural language requests into structured API calls or queries. This corroborates the notion of dynamic external knowledge access and processing as part of strengthening reasoning capabilities in powerful models. Together, these excerpts provide clear, complementary support for the finegrained field value by illustrating concrete mechanisms for dynamic search and processing of external information to improve reasoning.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='high'), FieldBasis(field='representative_agentic_systems.8.associated_paper', reasoning='The target field value asserts a mention of agentic LLM research within 2025. The most direct support comes from excerpts that reference 2025-era citations and the use of agentic mechanisms in large language models, including explicit year mentions and arXiv-era framing. In particular, a passage discussing a 2025 arXiv entry and a 2025a bibliography reference demonstrates a concrete 2025 research anchor for agentic RAG developments. Closely related are passages that describe agentic RAG as a shift toward autonomous, self-directed retrieval and reasoning, including planning, tool use, and collaboration among sub-agents, which provide the conceptual backdrop for the 2025 research landscape. Additional excerpts that outline the capabilities of function calling and real-time information access extend the context, showing the practical instantiations of agentic LLMs that would be studied in 2025. Earlier notes about Self-RAG and late-2023 timelines contribute historical context but are less directly tied to a 2025 research mention, thus they are supportive but not as strong as the year-specific items.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='specific_rag_techniques.2.core_concept', reasoning='The target fine-grained field describes an active retrieval method that uses a forecast of the next sentence to form queries and retrieve relevant documents, with a mechanism to decide when retrieval should occur to balance cost and effectiveness. The first excerpt discusses a retrieval approach where correct data is used directly for response generation, and, crucially, that for incorrect or ambiguous data, additional retrieval actions are triggered‚Äîoften web searches‚Äîto augment the dataset. This supports a core aspect of active retrieval: employing retrieval actions as needed to improve answer quality. The second excerpt describes Corrective Retrieval-Augmented Generation (CRAG) as a framework that improves robustness when dealing with inaccuracies in retrieved data, which aligns with the idea of dynamically managing retrieval to maintain answer reliability. While neither excerpt explicitly states the exact predictive querying of upcoming sentences, together they substantiate the general idea of an active, decision-driven retrieval process and its role in balancing efficiency with answer quality, which is the spirit of the described fine-grained field value.', citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.', '#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='medium'), FieldBasis(field='representative_agentic_systems.5.associated_paper', reasoning='The target field value is the exact title of a paper described in the excerpts. The first excerpt discusses a framework called the Search-o1 framework by Li et al. and mentions an Agentic RAG Mechanism and a Reason-in-Documents Module, which directly aligns with the idea of an ‚ÄúAgentic RAG Mechanism for Large Reasoning Models.‚Äù The second excerpt reinforces this by noting that function calling expands capabilities of LLMs and enables real-time information access, which is consistent with the integration of external retrieval mechanisms to support large reasoning models. Taken together, these pieces of information directly support the existence and characterization of the agentic RAG framework associated with Li et al., matching the fine-grained field value. The content implies that the paper being referenced is the one introducing an agentic retrieval-augmented approach for LLMs and aligns with the provided paper title and authors.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='high'), FieldBasis(field='mitigation_strategies_for_risks.0.strategy_category', reasoning='Retrieval hardening focuses on making retrieval-based systems more secure and robust against attacks and leakage of sensitive content. The most directly relevant material discusses that retrieval-augmented components exhibit significant vulnerabilities to attacks and that existing retrievers and filters can be bypassed, which motivates hardening retrieval processes to maintain service quality. Additional relevance comes from statements about connecting models to external knowledge bases and grounding responses via retrieved documents, which implicates how retrieval pathways are used and safeguarded. Further support comes from explicit mentions of strengthening security measures around retrieval systems, including anonymizing or limiting data exposure, sanitizing user input, and applying post-processing to remove sensitive information. Mentions of logs potentially storing sensitive user data and the need to minimize or protect such logs also align with protective measures around data retrieved and used during the retrieval process. The content about retrieved content potentially containing sensitive or outdated information underscores the importance of filtering and controlling what is exposed through retrieval. Collectively, these points map to a focus on strengthening the retrieval path, filtering, and data handling to reduce risk, which aligns with the retrieval hardening concept.', citations=[Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['Experiments conducted on 14 representative RAG components demonstrate that RAG exhibits significant vulnerability to all attack tasks and even the most apparent attack task can easily bypass existing retrievers, filters, or advanced LLMs, resulting in the degradation of RAG service quality.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['al or third-party\\n\\nknowledge bases, user\\n\\nqueries may be logged or\\n\\nmonitored without\\n\\nconsent. \\uf0a7\\n\\nUse robust API security\\n\\nmeasures, including access\\n\\ncontrols, authentication,\\n\\nand rate limiting. \\uf0a7\\n\\nSanitize user input to\\n\\nprevent injection attacks. \\uf0a7\\n\\nMinimize API logging or\\n\\nensure logs are\\n\\nanonymized and protected\\n\\nby access controls. \\uf0a7\\n\\nRestrict retrieval sources to\\n\\napproved, privacy-screened\\n\\ndatasets (e.g., filtered CRM\\n\\ndata). \\uf0a7\\n\\nImplement relevance filters\\n\\nor scoring mechanisms to\\n\\nensure only appropriate\\n\\ncontent is passed to the\\n\\nLLM. \\uf0a7\\n\\nApply post-\\n\\nprocessing/output filters to\\n\\nremove or redact sensitive\\n\\ninformation from\\n\\nresponses. \\uf0a7\\n\\nUse internal retrieval\\n\\nsystems when possible; if\\n\\nthird-party search APIs are\\n\\nused, anonymize or', 'nstead of\\n\\nembedding domain-specific knowledge into the model itself, RAG connects the model to an external\\n\\nknowledge base and retrieves relevant documents at runtime to ground its responses', 'Retrieved content may\\n\\ncontain sensitive or\\n\\noutdated information,\\n\\nwhich could be exposed\\n\\nin generated outp', 'Logs might inadvertently\\n\\nstore sensitive user data'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)')], confidence='high'), FieldBasis(field='mitigation_strategies_for_risks.0.tradeoff', reasoning='The most relevant excerpt directly discusses restricting retrieval sources to approved, privacy-screened datasets and applying safeguards to ensure only appropriate content is passed to the LLM, which aligns with the described tradeoff between security/safety and the breadth of information the system can access. This excerpt explicitly mentions limiting sources as a mitigation strategy, which is at the heart of the tradeoff between safety and coverage. The second excerpt discusses that retrieval-augmented generation connects the model to an external knowledge base and retrieves documents at runtime to ground responses, which is related to how retrieval sources influence information grounding but does not explicitly frame the tradeoff between breadth and safety to the same degree as the first excerpt. Together, they support the notion that choosing retrieval sources and safeguards impacts both security/privacy and the information reach of the system, with the first excerpt providing the strongest alignment to the exact tradeoff described in the field value.', citations=[Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['al or third-party\\n\\nknowledge bases, user\\n\\nqueries may be logged or\\n\\nmonitored without\\n\\nconsent. \\uf0a7\\n\\nUse robust API security\\n\\nmeasures, including access\\n\\ncontrols, authentication,\\n\\nand rate limiting. \\uf0a7\\n\\nSanitize user input to\\n\\nprevent injection attacks. \\uf0a7\\n\\nMinimize API logging or\\n\\nensure logs are\\n\\nanonymized and protected\\n\\nby access controls. \\uf0a7\\n\\nRestrict retrieval sources to\\n\\napproved, privacy-screened\\n\\ndatasets (e.g., filtered CRM\\n\\ndata). \\uf0a7\\n\\nImplement relevance filters\\n\\nor scoring mechanisms to\\n\\nensure only appropriate\\n\\ncontent is passed to the\\n\\nLLM. \\uf0a7\\n\\nApply post-\\n\\nprocessing/output filters to\\n\\nremove or redact sensitive\\n\\ninformation from\\n\\nresponses. \\uf0a7\\n\\nUse internal retrieval\\n\\nsystems when possible; if\\n\\nthird-party search APIs are\\n\\nused, anonymize or', 'nstead of\\n\\nembedding domain-specific knowledge into the model itself, RAG connects the model to an external\\n\\nknowledge base and retrieves relevant documents at runtime to ground its responses'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)')], confidence='high'), FieldBasis(field='mitigation_strategies_for_risks.0.specific_technique', reasoning='The specific finegrained field value refers to a defensive technique that constrains where the model retrieves information, i.e., Domain Whitelisting or Restricted Retrieval Sources. The most directly supportive content states to \"Restrict retrieval sources to approved, privacy-screened datasets\" and to apply relevant safeguards when routing queries to external sources, which aligns exactly with the concept of domain whitelisting and restricting retrieval origins to trusted sources. Additional excerpts discuss the broader context of retrieval-based systems (RAG) and grounding responses in external knowledge bases, which, while not explicitly naming the technique, provide context that restricted or vetted sources influence the quality and safety of retrieved information. Other excerpts touch on related privacy controls and data handling (e.g., logging policies, post-processing to redact sensitive information) that are part of a privacy-conscious retrieval framework but are less directly tied to the explicit mechanism of restricting origins of retrieved documents. Taken together, the combination of an explicit instruction to limit sources to approved datasets and the surrounding discussion of external knowledge grounding supports the interpretation of the targeted technique, while surrounding privacy and logging considerations provide corroborative but indirect context.', citations=[Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['al or third-party\\n\\nknowledge bases, user\\n\\nqueries may be logged or\\n\\nmonitored without\\n\\nconsent. \\uf0a7\\n\\nUse robust API security\\n\\nmeasures, including access\\n\\ncontrols, authentication,\\n\\nand rate limiting. \\uf0a7\\n\\nSanitize user input to\\n\\nprevent injection attacks. \\uf0a7\\n\\nMinimize API logging or\\n\\nensure logs are\\n\\nanonymized and protected\\n\\nby access controls. \\uf0a7\\n\\nRestrict retrieval sources to\\n\\napproved, privacy-screened\\n\\ndatasets (e.g., filtered CRM\\n\\ndata). \\uf0a7\\n\\nImplement relevance filters\\n\\nor scoring mechanisms to\\n\\nensure only appropriate\\n\\ncontent is passed to the\\n\\nLLM. \\uf0a7\\n\\nApply post-\\n\\nprocessing/output filters to\\n\\nremove or redact sensitive\\n\\ninformation from\\n\\nresponses. \\uf0a7\\n\\nUse internal retrieval\\n\\nsystems when possible; if\\n\\nthird-party search APIs are\\n\\nused, anonymize or', 'nstead of\\n\\nembedding domain-specific knowledge into the model itself, RAG connects the model to an external\\n\\nknowledge base and retrieves relevant documents at runtime to ground its responses', 'Retrieved content may\\n\\ncontain sensitive or\\n\\noutdated information,\\n\\nwhich could be exposed\\n\\nin generated outp', 'Logs might inadvertently\\n\\nstore sensitive user data'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)'), Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['Experiments conducted on 14 representative RAG components demonstrate that RAG exhibits significant vulnerability to all attack tasks and even the most apparent attack task can easily bypass existing retrievers, filters, or advanced LLMs, resulting in the degradation of RAG service quality.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='specific_rag_techniques.4.technique_name', reasoning='The field value specifies a multimodal RAG technique name, including examples such as SAM-RAG and OmniSearch. The excerpt explicitly describes a shift to multimodal RAG beyond traditional text-only RAG and directly names SAM-RAG and OmniSearch as concrete instances. This directly corroborates the existence and naming of multimodal RAG techniques, matching the requested field value. The context about combining text and image evidence further reinforces that the field value pertains to multimodal variants rather than purely text-based RAG approaches.', citations=[Citation(url='https://arxiv.org/html/2507.18910v1', excerpts=['Multimodal RAG breaks out: Where earlier RAG research was text-only, 2024 saw a surge in multimodal extensions. SAM-RAG and OmniSearch both combine text and image evidence'], title='A Systematic Review of Key Retrieval-Augmented ...')], confidence='high'), FieldBasis(field='specific_rag_techniques.4.core_concept', reasoning='The field value states that RAG is extended beyond text to handle multimodal data (images, audio, video) and cites systems like SAM-RAG that dynamically filter documents and verify evidence in multimodal contexts, as well as OmniSearch planning multi-hop retrieval chains for complex visual-question-answering. The excerpt explicitly describes multimodal RAG breaking out and notes that SAM-RAG and OmniSearch combine text and image evidence and pursue multimodal capabilities, thereby directly supporting the described core concept and the named systems. This shows alignment between the field value and the content of the excerpt. The excerpt thus provides direct evidence for the multimodal extension of RAG and the involvement of the cited systems.', citations=[Citation(url='https://arxiv.org/html/2507.18910v1', excerpts=['Multimodal RAG breaks out: Where earlier RAG research was text-only, 2024 saw a surge in multimodal extensions. SAM-RAG and OmniSearch both combine text and image evidence'], title='A Systematic Review of Key Retrieval-Augmented ...')], confidence='high'), FieldBasis(field='representative_agentic_systems.5.year', reasoning='The field value represents a year component (2025.0) within a system describing representative_agentic_systems. The most directly relevant content is that which discusses an agentic retrieval-augmented framework where a system dynamically triggers searches to fill knowledge gaps, and processes retrieved content to distill useful information, which directly supports the idea of a time-framed, advanced web-search capability for LLMs in 2025. The second relevant piece highlights that function calling expands LLM capabilities to access real-time information and external systems, reinforcing the notion of contemporary, time-aware search and integration capabilities that would be characteristic of 2025-era research. Additionally, a citation element within one excerpt explicitly references a 2025 year marker in the bibliographic context, aligning with the 2025 timeframe of the field value. Taken together, these excerpts support the notion that representative_agentic_systems operate within a 2025-era research landscape focused on real-time, search-enhanced LLMs, even though none of the excerpts state the exact numeric value of 2025.0 for the field. The evidence collectively suggests a high-level alignment with a 2025 timeframe but does not provide an unambiguous numeric confirmation for the precise field value, which is why the confidence is cautious.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='mitigation_strategies_for_risks.0.description', reasoning='The most relevant content directly echoes the described mitigation strategy: it calls for restricting retrieval sources to approved, privacy-screened datasets, implementing domain whitelists, and prioritizing internal retrieval systems. It also notes anonymizing or masking third-party search API queries, which aligns with the privacy-preserving aspect of the proposed approach. Supporting material discusses grounding RAG with an external knowledge base rather than embedding domain knowledge inside the model, which reinforces the retrieval-based mitigation strategy in principle. Additional notes about logs containing sensitive data and potential outdated information provide context on privacy risks but are not specific prescriptions for the exact mitigation steps. Together, these excerpts corroborate the emphasis on controlled sources, internal retrieval, and privacy-preserving practices as central to the described mitigation strategy.', citations=[Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['al or third-party\\n\\nknowledge bases, user\\n\\nqueries may be logged or\\n\\nmonitored without\\n\\nconsent. \\uf0a7\\n\\nUse robust API security\\n\\nmeasures, including access\\n\\ncontrols, authentication,\\n\\nand rate limiting. \\uf0a7\\n\\nSanitize user input to\\n\\nprevent injection attacks. \\uf0a7\\n\\nMinimize API logging or\\n\\nensure logs are\\n\\nanonymized and protected\\n\\nby access controls. \\uf0a7\\n\\nRestrict retrieval sources to\\n\\napproved, privacy-screened\\n\\ndatasets (e.g., filtered CRM\\n\\ndata). \\uf0a7\\n\\nImplement relevance filters\\n\\nor scoring mechanisms to\\n\\nensure only appropriate\\n\\ncontent is passed to the\\n\\nLLM. \\uf0a7\\n\\nApply post-\\n\\nprocessing/output filters to\\n\\nremove or redact sensitive\\n\\ninformation from\\n\\nresponses. \\uf0a7\\n\\nUse internal retrieval\\n\\nsystems when possible; if\\n\\nthird-party search APIs are\\n\\nused, anonymize or', 'nstead of\\n\\nembedding domain-specific knowledge into the model itself, RAG connects the model to an external\\n\\nknowledge base and retrieves relevant documents at runtime to ground its responses', 'Logs might inadvertently\\n\\nstore sensitive user data', 'Retrieved content may\\n\\ncontain sensitive or\\n\\noutdated information,\\n\\nwhich could be exposed\\n\\nin generated outp'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)'), Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['Experiments conducted on 14 representative RAG components demonstrate that RAG exhibits significant vulnerability to all attack tasks and even the most apparent attack task can easily bypass existing retrievers, filters, or advanced LLMs, resulting in the degradation of RAG service quality.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...')], confidence='high'), FieldBasis(field='specific_rag_techniques.1.key_paper_or_source', reasoning='The fine-grained field value identifies a specific source/paper: Corrective Retrieval Augmented Generation (Jan 2024). Excerpts that define Corrective Retrieval-Augmented Generation (CRAG) establish CRAG as a framework for improving robustness when dealing with inaccuracies in retrieved data, making those excerpts highly relevant to the core concept of the requested source. Excerpts that discuss the advantages of CRAG further support the importance and application of this approach, strengthening relevance to the CRAG paper/source. Excerpts that describe adaptive retrieval actions and decomposition/recomposition provide contextual information about related mechanisms in retrieval-augmented generation but do not directly pin CRAG as the central source, making them slightly less directly relevant to the exact field value. Importantly, none of the excerpts provide or confirm the precise date (January 2024) for the CRAG paper, so the date aspect remains unverified within the given text. Overall, the most direct support comes from the explicit CRAG definition, followed by its advantages and contextual usage, with date verification absent from the excerpts.', citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '#### **Advantages of CRAG**\\n\\n**Improved Accuracy** :\\n\\nBy evaluating and correcting retrieved data, CRAG ensures more reliable and factually accurate outputs.', '1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='medium'), FieldBasis(field='representative_agentic_systems.6.year', reasoning='The target field is the year component of a representative agentic system, which should reflect the time context of the work. The most relevant excerpt references a 2025 arXiv version (2025a) and discusses how the Search-o1 framework enhances large language models with an Agentic RAG mechanism and a Reason-in-Documents module. This directly ties the discussed work to the year 2025 in its formal citation/version, supporting the notion that the year value for a representative 2025 entry would be 2025.0. Other excerpts describe agentic RAG concepts and late-2023 self-critique mentions, which corroborate the domain but do not provide explicit 2025 dating, hence they are less supportive of the exact 2025.0 value.\\n', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='specific_rag_techniques.4.year_introduced', reasoning=\"The selected excerpt notes that 2024 saw a surge in multimodal RAG research, explicitly naming approaches like SAM-RAG and OmniSearch that integrate text and image evidence. This aligns with the target finegrained field value (2024.0) as the year associated with the introduction or notable emergence of multimodal RAG techniques, which is the specific focus of the field path. While the excerpt does not state an exact 'introduced in 2024' declaration, the direct association of year 2024 with these developments provides direct, relevant support for the year value being 2024.0.\", citations=[Citation(url='https://arxiv.org/html/2507.18910v1', excerpts=['Multimodal RAG breaks out: Where earlier RAG research was text-only, 2024 saw a surge in multimodal extensions. SAM-RAG and OmniSearch both combine text and image evidence'], title='A Systematic Review of Key Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='specific_rag_techniques.4.key_benefit', reasoning='The field value describes a benefit of grounding in and reasoning over multiple data types to support complex queries with text and visual evidence. The excerpt discusses multimodal retrieval-augmented generation and highlights approaches (SAM-RAG and OmniSearch) that combine text and image evidence, indicating a clear move toward multimodal grounding. This directly supports the notion of enabling grounding across multiple data types and richer analysis by integrating textual and visual information for comprehensive answering.', citations=[Citation(url='https://arxiv.org/html/2507.18910v1', excerpts=['Multimodal RAG breaks out: Where earlier RAG research was text-only, 2024 saw a surge in multimodal extensions. SAM-RAG and OmniSearch both combine text and image evidence'], title='A Systematic Review of Key Retrieval-Augmented ...')], confidence='high'), FieldBasis(field='representative_agentic_systems.2.associated_paper', reasoning='The most relevant excerpts directly address agentic capabilities and architectures relevant to agentic LLMs. Excerpt describing the Search-o1 framework outlines an agentic RAG mechanism that triggers searches based on knowledge gaps and processes retrieved content to distill relevant information, which aligns with March 2025 discussions of agentic LLMs and their ability to plan and execute retrievals. The following excerpt emphasizes how function calling broadens LLM capabilities to access real-time information and execute API/database interactions, which underpins the practical realization of agentic behavior. Additional excerpts describe the evolution of RAG toward agentic reasoning, including planning, tool use, and collaboration among sub-agents, which directly support the idea of agentic LLMs highlighted in 2025 research. Mentions of Self-RAG and self-critique frameworks describe introspective capabilities within LLMs that are characteristic of agentic systems and align with the reported focus of March 2025 studies. Excerpts on modular RAG illustrate flexible, component-based architectures that facilitate agentic workflows, further supporting the relevance to agentic LLM research in 2025. Although some excerpts discuss broader trajectory and governance concerns, they still contribute to the context of agentic LLM research that would be cited in March 2025 literature.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='high'), FieldBasis(field='specific_rag_techniques.1.core_concept', reasoning='The fine-grained field value describes a retrieval evaluation mechanism that flags retrieved documents as incorrect or ambiguous and triggers corrective actions, including large-scale web searches, to find better information, and it states the use of a Decompose-then-Recompose algorithm to filter and synthesize knowledge. One excerpt directly mentions the Generation with Decompose-then-Recompose Algorithm, explaining that retrieved documents are broken into smaller components to focus on key insights and then recombined into a concise dataset, which aligns with the field value‚Äôs emphasis on filtering and synthesis. Other excerpts discuss corrective retrieval frameworks (CRAG) that are designed to improve robustness when inaccuracies in retrieved data are detected, including triggering additional retrieval actions and improving overall accuracy, which supports the idea of corrective actions and improved data quality. Additionally, there is mention of adaptive knowledge retrieval that uses correct data for responses and triggers further retrieval actions when data is incorrect or ambiguous, which corroborates the mechanism of triggering corrective web searches. Collectively, these excerpts support the existence of a corrective retrieval workflow that includes evaluation of retrieved data, triggering additional searches, and a decomposition/recomposition approach to refine information, which maps to the described fine-grained field value.', citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['1. **Generation with Decompose-then-Recompose Algorithm** :\\n\\nRetrieved documents are broken down into smaller components to focus on key insights while filtering out irrelevant or redundant details. The filtered information is recombined into a cohesive and concise dataset, optimizing the quality of data input for generation.', '#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '#### **Advantages of CRAG**\\n\\n**Improved Accuracy** :\\n\\nBy evaluating and correcting retrieved data, CRAG ensures more reliable and factually accurate outputs.', '1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='medium'), FieldBasis(field='representative_agentic_systems.8.key_contribution', reasoning='The fine-grained field value describes a design goal where reliance on live web APIs during training is reduced, enabling a smooth transition to online inference. Excerpts that emphasize function calling and tool use show that LLMs can interact with external systems and APIs, which is central to how such systems operate during inference. Statements about Agentic RAG enabling an agent to plan steps, read and re-query information, and autonomously use tools indicate a move toward self-directed retrieval and reasoning, which can reduce fragility tied to external live APIs by embedding more robust, planned workflows. The discussion of Agentic RAG representing a shift from static retrieval to autonomous, self-directed processes further supports the idea that systems are designed to become more self-reliant and transferable to online inference. Additionally, the emphasis on planning, reflection, and tool use such as calculators or databases underlines components that can be leveraged to minimize dependency on unstable live endpoints, contributing to a more reliable inference phase. Collectively, these excerpts consistently describe architectures and capabilities (planning, self-correction, external tool usage) that align with reducing reliance on constant live API calls and promoting smoother transfer to online inference.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='specific_rag_techniques.4.key_paper_or_source', reasoning='The field value identifies two specific multimodal RAG approaches as key papers or sources: SAM-RAG attributed to Zhai (2024) and OmniSearch attributed to Li (2024). The only excerpt available discusses the expansion of retrieval-augmented generation to multimodal modalities in 2024 and explicitly names both SAM-RAG and OmniSearch as examples that combine text and image evidence. This excerpt directly supports the presence of the two papers/sources in the field value, by providing the exact names and the multimodal context in which they appear. The phrasing indicates these are prominent examples within the multimodal RAG trend, which matches the requested identification of key papers or sources. Therefore, this excerpt directly substantiates the field value with clear, relevant content about the same papers and their multimodal nature.', citations=[Citation(url='https://arxiv.org/html/2507.18910v1', excerpts=['Multimodal RAG breaks out: Where earlier RAG research was text-only, 2024 saw a surge in multimodal extensions. SAM-RAG and OmniSearch both combine text and image evidence'], title='A Systematic Review of Key Retrieval-Augmented ...')], confidence='high'), FieldBasis(field='representative_agentic_systems.6.key_contribution', reasoning='The most relevant passages explicitly discuss agentic RAG and collaboration across components. One excerpt describes Agentic RAG as an architecture where an Agent plans a sequence of actions, includes planning, tool use, and collaboration by coordinating specialized sub-agents for different tasks. This directly supports the idea of multiple agents handling distinct research parts. Another excerpt emphasizes that collaboration involves coordinating sub-agents for different tasks or knowledge domains, reinforcing the collaborative, multi-agent aspect. Additional excerpts describe how an Agentic RAG mechanism dynamically triggers searches and processes retrieved content to distill relevant information, which also aligns with a multi-component approach to research tasks. Related mentions of modular RAG, where distinct components can be upgraded or swapped, further support the concept of separate parts handling the research workflow. While some excerpts focus on broader shifts or related concepts (e.g., self-critique in Self-RAG or the capabilities of function calling), they still provide contextual support for the general notion of a system composed of interacting agents or modules that partition responsibilities. Taken together, the strongest and most direct support comes from the passages that explicitly describe planning, coordinating sub-agents, and collaborative workflows across different modules or agents; additional context from modular architectures and agentic mechanisms strengthens the interpretation that a collaborative, multi-agent setup is being described.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n'], title='Evolution of RAG from Static Knowledge to Agentic ...'), Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity', 'Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='representative_agentic_systems.6.core_methodology', reasoning='The field value describes a multi-agent system that coordinates specialized sub-agents to perform querying and summarization tasks, with the system autonomously driving reflection. The most directly relevant excerpt states that an Agentic RAG architecture includes an ‚ÄúAgent‚Äù that plans a sequence of actions and can query, read, re-query, and use tools, and explicitly notes ‚ÄúCollaboration: Coordinating specialized sub-agents for different tasks or knowledge domains.‚Äù It also mentions ‚ÄúReflection: Using Chain-of-Thought to critique intermediate results and refine the approach,‚Äù which aligns with autonomous reflection driving the process. A secondary excerpt describes a framework where the LLM dynamically triggers search queries and processes retrieved content to distill relevant information, which supports the idea of active querying and structured processing by components, though it does not emphasize explicit multi-agent coordination and reflection to the same extent. Together, these excerpts support the field value that the system is multi-agent, coordinates sub-agents for querying/summarization, and uses autonomous reflective reasoning in the process.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)'], title='Evolution of RAG from Static Knowledge to Agentic ...'), Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='high'), FieldBasis(field='specific_rag_techniques.8.technique_name', reasoning='The target field value is the technique name used for benchmarking security in retrieval-augmented generation. Each excerpt contains explicit mentions of SafeRAG, either as the paper title or in descriptive sentences about SafeRAG being a benchmark designed to evaluate RAG security or about its components and applicability. For example, the excerpts describe SafeRAG as a benchmark for evaluating RAG security, note its relevance to LLMs, and even provide a code repository, all of which directly support SafeRAG as the technique name in question. The snippets collectively establish that SafeRAG is a defined technique/benchmark within this research context, aligning with the specified field value.', citations=[Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.', 'In this paper, we introduce a benchmark named SafeRAG designed to evaluate the RAG security.', 'The indexing-retrieval-generation paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs).', 'Experiments conducted on 14 representative RAG components demonstrate that RAG exhibits significant vulnerability to all attack tasks and even the most apparent attack task can easily bypass existing retrievers, filters, or advanced LLMs, resulting in the degradation of RAG service quality.', 'Code is available at: https://github.com/IAAR-Shanghai/SafeRAG.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.', 'The _indexing-retrieval-generation_ paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs). However, the incorporation of external and unverified knowledge increases the vulnerability of LLMs because attackers can perform attack tasks by manipulating knowledge.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...')], confidence='high'), FieldBasis(field='specific_rag_techniques.8.key_benefit', reasoning='The finegrained field value describes a framework for systematically testing and improving the security and robustness of RAG systems against adversarial attacks. The most directly relevant information comes from excerpts that introduce SafeRAG as a benchmark designed to evaluate the security of retrieval-augmented generation, which aligns with providing a testing framework for RAG security. Supporting evidence also highlights that RAG is vulnerable to various attack tasks and that existing components can be bypassed, underscoring the need for systematic testing and improvements. Additional context about the attacking modalities (e.g., silver noise, inter-context conflict, soft ads, and DoS) illustrates the types of adversarial threats such a framework would address. References to the paradigm of retrieval-augmented generation and its success, as well as notes that code implementing related benchmarks is available, further contextualize the practical ecosystem for testing and hardening RAG systems. Taken together, these excerpts cohere around the notion of a structured benchmark/framework to assess and enhance RAG security and robustness against adversarial inputs.', citations=[Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['In this paper, we introduce a benchmark named SafeRAG designed to evaluate the RAG security.', 'Experiments conducted on 14 representative RAG components demonstrate that RAG exhibits significant vulnerability to all attack tasks and even the most apparent attack task can easily bypass existing retrievers, filters, or advanced LLMs, resulting in the degradation of RAG service quality.', 'First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.', 'The indexing-retrieval-generation paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs).', 'Code is available at: https://github.com/IAAR-Shanghai/SafeRAG.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['The _indexing-retrieval-generation_ paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs). However, the incorporation of external and unverified knowledge increases the vulnerability of LLMs because attackers can perform attack tasks by manipulating knowledge.', 'First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='representative_agentic_systems.2.year', reasoning='The finegrained field represents a year for a specific agentic system entry. Excerpts that describe agentic RAG capabilities‚Äîsuch as dynamically triggering searches based on knowledge gaps, processing retrieved content to distill relevant information, planning sub-goals, tool use, and self-reflection‚Äîprovide direct context about the maturity and evolution of agentic systems. This contextual content supports understanding why a contemporary year value (e.g., 2025.0) would be appropriate for a field documenting current or recent developments in representative_agentic_systems. Per the excerpts: the description of an Agentic RAG mechanism and a Reason-in-Documents module clarifies how information is retrieved and refined; statements about Self-RAG and self-critique indicate advanced, iterative capabilities; and discussions of Modular RAG describe adaptable, modern architectures. While none of the excerpts explicitly state the year 2025.0, they collectively establish that the field encompasses up-to-date, advanced agentic systems, which is compatible with assigning a recent year value. Therefore, the most relevant content is the material describing the agentic capabilities and architectural evolution, with less direct relevance to the specific year but still supportive of the overall context. The exact year value is not verifiable from the excerpts alone, reducing confidence about the claim being explicitly evidenced.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['Function calling significantly expands the capabilities of LLMs beyond text generation, enabling them to access real-time, dynamic information, interact with external systems and databases, automate tasks, and reliably convert natural language requests into structured API calls or database queries.', 'The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['4\\n\\n* Agentic RAG is an advanced architectural paradigm where an ‚ÄúAgent‚Äù plans a sequence of actions. It can query, read, re-query, use tools (Calculator, SQL, ‚Ä¶), and self-correct until the task is done. * This is enabled by integrating agentic capabilities into the LLM‚Äôs flow:\\n  \\n    + Reflection: Using Chain-of-Thought to critique intermediate results and refine the approach. + Planning: Breaking down complex queries into sequential sub-goals and retrieval steps. + Tool Use: Autonomously selecting and utilizing external resources, such as search engines, calculators, or APIs. + Collaboration: Coordinating specialized sub-agents for different tasks or knowledge domains. * Ultimately, Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. * Introduction by: Popularized by LangGraph / LlamaIndex. (Evolved from ReAct, 2022)', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', ' Modular RAG is an architectural paradigm that treats the Retrieval-Augmented Generation (RAG) system as a toolkit composed of distinct, interchangeable components. Rather than a fixed pipeline, Modular RAG enables developers to select and combine different modules to create highly optimized, use-case-specific workflows. * This architecture is widely adopted in domain-specific research environments and complex production AI applications requiring flexible performance tuning. * Introduction by: Gao et al. * Pros:\\n  \\n    + Highly flexible; you can upgrade one part without breaking the whole system. + Allows for specialized flows for different departments. * Cons:\\n  \\n    + Complex engineering overhead to orchestrate modules. + Debugging Difficulty: Tracing errors or performance bottlenecks can be challenging across multiple, separate component'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='low'), FieldBasis(field='specific_rag_techniques.0.core_concept', reasoning='The finegrained field value asserts that an LLM generates special reflection tokens to enable on-demand retrieval and self-critique, with adaptive retrieval and evaluation of retrieved passages prior to responding. The most direct support comes from descriptions of Self-RAG as an advanced framework where the model is trained to perform self-critique during the retrieval and generation process, which aligns with on-demand retrieval and evaluation of sources. Additional context from the evolution of RAG discussions reinforces that Self-RAG involves reflective and adaptive mechanisms during retrieval. These elements together corroborate the described core concept and its adaptive evaluation step, while the earlier evolution reference provides broader framing of the Self-RAG concept.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='high'), FieldBasis(field='specific_rag_techniques.0.year_introduced', reasoning='The targeted field asks for the year introduced for the first technique in the specific_rag_techniques list. The most directly supportive information is a statement that Self-RAG is associated with Late 2023, which aligns with the 2023.0 value. The other excerpts describe Self-RAG as a framework concept without giving a specific year, so while they provide context, they do not directly confirm the exact year for the first technique and are thus less informative for the requested field. Therefore, the strongest support comes from the excerpt that explicitly mentions 2023 (Late 2023).', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='high'), FieldBasis(field='specific_rag_techniques.6.key_benefit', reasoning='The most directly relevant excerpt discusses benchmarking retrieval-augmented generation systems, which aligns with creating standardized evaluation for RAG pipelines and addressing evaluation challenges. Excerpts that address evaluation criteria and benchmarking in the context of web search or generative AI also support the notion of standardized evaluation and grounding improvements, even if they aren‚Äôt explicitly framed as a unified evaluation standard. Additional excerpts cover broad explanations of RAG and related paradigms, which provide necessary context about how RAG systems operate and why evaluation is an important area of focus. Taken together, these excerpts collectively substantiate the idea of standardized evaluation and grounding improvements in RAG pipelines, with the strongest support from the benchmarking-focused piece and supportive context from the evaluation-oriented discussions in related works.', citations=[Citation(url='https://arxiv.org/html/2504.14891v1', excerpts=[' Mtrag: A multi-turn conversational benchmark for evaluating retrieval-augmented generation systems. arXiv preprint arXiv:2501.03468, 2025\\n'], title='Retrieval Augmented Generation Evaluation in the Era of ...'), Citation(url='https://arxiv.org/html/2510.11560v1', excerpts=['lts also highlight the need for revisiting evaluation criteria for web search in the age of Generative AI.'], title='Characterizing Web Search in The Age of Generative AI'), Citation(url='https://arxiv.org/abs/2312.10997', excerpts=['This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the ...'], title='Retrieval-Augmented Generation for Large Language Models - arXiv'), Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://aws.amazon.com/what-is/retrieval-augmented-generation/', excerpts=['RAG is the process of optimizing the output of a large language model, so it references an authoritative knowledge base outside of its training data sources ...'], title='What is RAG? - Retrieval-Augmented Generation AI Explained - AWS')], confidence='medium'), FieldBasis(field='specific_rag_techniques.8.year_introduced', reasoning='The most directly supportive excerpt states that SafeRAG is a benchmark designed to evaluate RAG security, which aligns with introducing a formal 2025 effort in this space. This establishes SafeRAG as a defined technique/benchmark within the 2025 timeframe and supports a year-based introduction claim. Additional excerpts describe SafeRAG‚Äôs labeling as a security benchmark and its presence in 2025 publications, reinforcing the 2025 introduction context. Excerpts that discuss the paradigm of indexing-retrieval-generation and the vulnerability findings in 2025 further corroborate that the technique and its evaluation framework belong to the 2025 era, bolstering the temporal claim. Other excerpts note code availability and general outcomes of 2025-era experiments, which provide supportive but ancillary evidence about the same 2025 introduction and its ongoing validation. Collectively, these excerpts form a coherent set of 2025-era statements about SafeRAG and related RAG security research, supporting the field value that the technique was introduced in 2025.', citations=[Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['In this paper, we introduce a benchmark named SafeRAG designed to evaluate the RAG security.', 'The indexing-retrieval-generation paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs).', 'Experiments conducted on 14 representative RAG components demonstrate that RAG exhibits significant vulnerability to all attack tasks and even the most apparent attack task can easily bypass existing retrievers, filters, or advanced LLMs, resulting in the degradation of RAG service quality.', 'First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.', 'Code is available at: https://github.com/IAAR-Shanghai/SafeRAG.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.', 'The _indexing-retrieval-generation_ paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs). However, the incorporation of external and unverified knowledge increases the vulnerability of LLMs because attackers can perform attack tasks by manipulating knowledge.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='specific_rag_techniques.0.technique_name', reasoning='The fine-grained field value corresponds to the technique name SELF-RAG. The most relevant evidence explicitly defines Self-RAG as an advanced framework in which the LLM engages in self-critique during the retrieval and generation process. This directly supports the notion that the technique is SELF-RAG and clarifies its core operational characteristic. Additional excerpts confirm the exact terminology used (Self-RAG) and situate it in a context (late 2023) that corroborates its discussion as a distinct RAG technique. The repeated appearance of the SELF-RAG term across multiple excerpts strengthens the link between the field value and the referenced descriptions, indicating consistent usage and definition of the technique without introducing conflicting information.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='high'), FieldBasis(field='specific_rag_techniques.5.technique_name', reasoning=\"The finegrained field value RECOMP refers to a 'Recompose' or recomposition step in retrieval-augmented generation techniques. The most directly relevant excerpt explicitly mentions a 'Decompose-then-Recompose Algorithm,' describing breaking down retrieved documents into components and then recombining them into a concise dataset for improved input quality. This aligns with the RECOMP notion of recomposing or reconstructing information after decomposition. The other excerpts discuss corrective mechanisms (CRAG) and adaptive retrieval strategies but do not specifically mention a recomposition technique under a name that matches RECOMP, nor do they describe a recomposition-oriented algorithm in the same explicit terms.\", citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['1. **Generation with Decompose-then-Recompose Algorithm** :\\n\\nRetrieved documents are broken down into smaller components to focus on key insights while filtering out irrelevant or redundant details. The filtered information is recombined into a cohesive and concise dataset, optimizing the quality of data input for generation.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='high'), FieldBasis(field='representative_agentic_systems.6.associated_paper', reasoning='The target field value asserts that there is an Agentic-Based Approach mentioned as an example in 2025. Among the excerpts, the one discussing the arXiv preprint on Reasoning Agentic Retrieval-Augmented (which includes a citation node labeled [2025a]) directly ties an agentic retrieval framework to a 2025 context, implying it serves as a concrete 2025 example of an Agentic-Based Approach. Other excerpts discuss agentic concepts (e.g., agentic retrieval, self-critique, tool use) but do not clearly anchor any example to the year 2025, making them less direct supports for the specific 2025 example claim. Therefore, the most relevant excerpt is the one that explicitly embeds a 2025 citation footprint, while the others provide contextual background on agentic RAG concepts without a clear 2025-timeframe anchor.', citations=[Citation(url='https://arxiv.org/html/2506.10408v1', excerpts=['The Search-o1 framework Li et al.\\n( [2025a](https://arxiv.org/html/2506.10408v1.bib17) ) is specifically designed to enhance LRMs by tackling knowledge insufficiency during long, step-by-step reasoning chains. It integrates two core components: an Agentic RAG Mechanism where the LRM dynamically triggers search queries based on self-assessed knowledge gaps, and a Reason-in-Documents Module that processes retrieved content to dist ill relevant information into a refined format, thereby minimizing noise and maintaining the LRM‚Äôs reasoning integrity'], title='A Survey on Reasoning Agentic Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='specific_rag_techniques.0.key_benefit', reasoning='The fine-grained field value describes benefits (improved factuality, reduced hallucinations, and enhanced transparency via citations) achieved by making the retrieval process adaptive and self-correcting. The most relevant excerpts explicitly define Self-RAG as an advanced framework where the LLM is trained to perform self-critique during the retrieval and generation process, which directly underpins self-correction and transparency. This supports the idea that adaptive, self-checking retrieval can reduce errors and improve traceability through citations. The other excerpts reinforce the evolution of RAG toward self-reflective and agentic approaches, providing contextual support that such self-monitoring mechanisms are part of the maturation of retrieval-augmented methods. Taken together, these excerpts coherently connect to the field value by illustrating how self-critique and adaptive retrieval are mechanisms that can yield higher factual accuracy, fewer hallucinations, and clearer citation trails.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='specific_rag_techniques.5.core_concept', reasoning='The most relevant excerpt explicitly describes a decomposition of retrieved documents into smaller components and recombination into a cohesive, concise dataset to optimize data input for generation, which aligns with the notion of compressing information into concise textual summaries before feeding into an LLM. Excerpts discussing adaptive knowledge retrieval and corrective retrieval suggest mechanisms for ensuring data quality and completeness but do not describe a compression step. Excerpts highlighting CRAG advantages emphasize accuracy improvements after correction rather than summarization, making them less directly aligned with the compression-focused field value. Therefore, the first excerpt provides direct support for the compression idea, while the second and third excerpts offer contextual relevance about retrieval and correction processes, and the fourth offers outcome benefits that are not about compression per se.', citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['1. **Generation with Decompose-then-Recompose Algorithm** :\\n\\nRetrieved documents are broken down into smaller components to focus on key insights while filtering out irrelevant or redundant details. The filtered information is recombined into a cohesive and concise dataset, optimizing the quality of data input for generation.', '1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.', '#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '#### **Advantages of CRAG**\\n\\n**Improved Accuracy** :\\n\\nBy evaluating and correcting retrieved data, CRAG ensures more reliable and factually accurate outputs.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='high'), FieldBasis(field='specific_rag_techniques.6.core_concept', reasoning='The field value refers to a framework of reference-free metrics for automated evaluation of RAG systems and specifies evaluation dimensions like faithfulness, context precision, context recall, and answer relevance. The most directly relevant excerpt describes a concrete evaluation resource for RAG systems: a multi-turn conversational benchmark designed to evaluate retrieval-augmented generation systems, which aligns with the notion of structured evaluation for RAG outputs. A second relevant source discusses evaluation criteria in the broader context of web search within Generative AI, highlighting the importance of evaluating relevance and related criteria in AI-assisted information retrieval, which supports the idea of a multi-faceted evaluation framework. A third source offers a comprehensive overview of RAG paradigms and their evolution, which provides necessary context for understanding what a robust evaluation framework would cover, including system capabilities and comparison baselines. A fourth source, while focused on the concept of RAG itself, reinforces that RAG optimization involves leveraging external knowledge sources, an aspect that an evaluation framework for RAG would need to address. A fifth source touches on security in retrieval-augmented systems, which, although not a primary focus of evaluation metrics, can influence the design of a holistic evaluation framework by highlighting potential risk dimensions that metrics might need to capture. Taken together, these excerpts support the existence and need for an automated, reference-free evaluation framework for RAG that would assess aspects like faithfulness and contextual understanding, even if they do not explicitly spell out the exact terminology used in the field value.', citations=[Citation(url='https://arxiv.org/html/2504.14891v1', excerpts=[' Mtrag: A multi-turn conversational benchmark for evaluating retrieval-augmented generation systems. arXiv preprint arXiv:2501.03468, 2025\\n'], title='Retrieval Augmented Generation Evaluation in the Era of ...'), Citation(url='https://arxiv.org/html/2510.11560v1', excerpts=['lts also highlight the need for revisiting evaluation criteria for web search in the age of Generative AI.'], title='Characterizing Web Search in The Age of Generative AI'), Citation(url='https://arxiv.org/abs/2312.10997', excerpts=['This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the ...'], title='Retrieval-Augmented Generation for Large Language Models - arXiv'), Citation(url='https://aws.amazon.com/what-is/retrieval-augmented-generation/', excerpts=['RAG is the process of optimizing the output of a large language model, so it references an authoritative knowledge base outside of its training data sources ...'], title='What is RAG? - Retrieval-Augmented Generation AI Explained - AWS'), Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='specific_rag_techniques.8.key_paper_or_source', reasoning=\"The most directly relevant excerpts clearly identify SafeRAG as a benchmark for evaluating security in retrieval-augmented generation, which aligns with the requested paper title and scope. Phrasings like 'we introduce a benchmark named SafeRAG designed to evaluate the RAG security' directly support the existence and purpose of SafeRAG as a security benchmark for RAG. Excerpts that mention the same work under the SafeRAG umbrella, including notes about the benchmarking focus and its application to RAG‚Äôs security, further corroborate the alignment with the requested field value. Additional excerpts that reference the SafeRAG title and its associated repository or related evaluation context reinforce the connection but are slightly less direct if they emphasize broader context (e.g., the RAG paradigm or security vulnerabilities) rather than the benchmark‚Äôs explicit title. Collectively, these excerpts substantiate that SafeRAG functions as a security benchmark for RAG, with particular emphasis on evaluating vulnerabilities and security considerations in RAG systems. The strongest support comes from explicit statements that SafeRAG is a benchmark for RAG security, followed by mentions of its evaluation outcomes and availability, which are consistent with the topic of a security benchmark paper by Liang et al. (2025).\", citations=[Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['In this paper, we introduce a benchmark named SafeRAG designed to evaluate the RAG security.', 'Experiments conducted on 14 representative RAG components demonstrate that RAG exhibits significant vulnerability to all attack tasks and even the most apparent attack task can easily bypass existing retrievers, filters, or advanced LLMs, resulting in the degradation of RAG service quality.', 'First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.', 'The indexing-retrieval-generation paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs).', 'Code is available at: https://github.com/IAAR-Shanghai/SafeRAG.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.', 'The _indexing-retrieval-generation_ paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs). However, the incorporation of external and unverified knowledge increases the vulnerability of LLMs because attackers can perform attack tasks by manipulating knowledge.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...')], confidence='high'), FieldBasis(field='specific_rag_techniques.7.technique_name', reasoning='The strongest ties to a multi-stage or iterative RAG concept come from excerpts describing Self-Reflective RAG, which implies a multi-step or iterative introspection process within the RAG framework. Next, the excerpt mentioning a Decompose-then-Recompose algorithm maps to a staged processing flow, where retrieved data is broken down and then recombined, aligning with a multi-stage or structured pipeline. The reference to Adaptive Knowledge Retrieval describes triggering additional retrieval actions when data is incorrect or ambiguous, which embodies an iterative retrieval stance. Other excerpts discuss broader RAG frameworks (CRAG) and general progressions of RAG paradigms in reviews; while informative, they do not explicitly articulate a multi-stage or MS-RAG approach. Consequently, the most relevant materials describe either self-reflection in RAG, stepwise decomposition/recombination, or iterative retrieval triggers, with decreasing relevance for broader CRAG discussions and generic RAG reviews. Based on this, the interpretation is that MS-RAG as a named technique is not directly evidenced, but related multi-stage or iterative themes are present in adjacent concepts within these excerpts.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n'], title='Evolution of RAG from Static Knowledge to Agentic ...'), Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['1. **Generation with Decompose-then-Recompose Algorithm** :\\n\\nRetrieved documents are broken down into smaller components to focus on key insights while filtering out irrelevant or redundant details. The filtered information is recombined into a cohesive and concise dataset, optimizing the quality of data input for generation.', '1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.', '#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '#### **Advantages of CRAG**\\n\\n**Improved Accuracy** :\\n\\nBy evaluating and correcting retrieved data, CRAG ensures more reliable and factually accurate outputs.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)'), Citation(url='https://arxiv.org/abs/2312.10997', excerpts=['This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the ...'], title='Retrieval-Augmented Generation for Large Language Models - arXiv')], confidence='medium'), FieldBasis(field='mitigation_strategies_for_risks.2.strategy_category', reasoning='The target field value Data Handling is best supported by excerpts that explicitly discuss how data is managed during interaction with LLMs and retrieval systems. The most relevant excerpt emphasizes minimizing and anonymizing logs, sanitizing user input, restricting retrieval sources to privacy-screened datasets, and applying post-processing/filters to remove sensitive information. These points map directly to core data handling practices: controlling what data is stored, who can access it, how inputs are treated, and what data sources are used. A closely related excerpt notes that logs can store sensitive user data, reinforcing the importance of careful data handling and protective measures. Another excerpt discusses how retrieval-augmented approaches ground responses by connecting to external knowledge bases and retrieving documents at runtime, which highlights data flow and handling decisions in a RAG setup, albeit in a more architectural sense. Taken together, these excerpts collectively support the Data Handling aspect of mitigation strategies for risks associated with LLMs and RAG systems, with the first excerpt providing the strongest, most direct evidence, the second confirming data sensitivity concerns, and the third offering contextual data flow considerations.', citations=[Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['al or third-party\\n\\nknowledge bases, user\\n\\nqueries may be logged or\\n\\nmonitored without\\n\\nconsent. \\uf0a7\\n\\nUse robust API security\\n\\nmeasures, including access\\n\\ncontrols, authentication,\\n\\nand rate limiting. \\uf0a7\\n\\nSanitize user input to\\n\\nprevent injection attacks. \\uf0a7\\n\\nMinimize API logging or\\n\\nensure logs are\\n\\nanonymized and protected\\n\\nby access controls. \\uf0a7\\n\\nRestrict retrieval sources to\\n\\napproved, privacy-screened\\n\\ndatasets (e.g., filtered CRM\\n\\ndata). \\uf0a7\\n\\nImplement relevance filters\\n\\nor scoring mechanisms to\\n\\nensure only appropriate\\n\\ncontent is passed to the\\n\\nLLM. \\uf0a7\\n\\nApply post-\\n\\nprocessing/output filters to\\n\\nremove or redact sensitive\\n\\ninformation from\\n\\nresponses. \\uf0a7\\n\\nUse internal retrieval\\n\\nsystems when possible; if\\n\\nthird-party search APIs are\\n\\nused, anonymize or', 'Logs might inadvertently\\n\\nstore sensitive user data', 'nstead of\\n\\nembedding domain-specific knowledge into the model itself, RAG connects the model to an external\\n\\nknowledge base and retrieves relevant documents at runtime to ground its responses'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)')], confidence='high'), FieldBasis(field='specific_rag_techniques.5.key_benefit', reasoning='The finegrained field value describes reducing computational load and context window needs by providing a condensed version of retrieved information. The most relevant excerpt states that retrieved documents are broken into smaller components and recombined into a concise dataset, which explicitly aims to optimize the quality of data input for generation. This directly aligns with the idea of condensing information to ease processing for the LLM. Additional excerpts discuss robustness and corrective mechanisms (CRAG) and adaptive retrieval that enhance accuracy or trigger extra retrievals, which provide useful context about RAG techniques but do not explicitly claim reductions in computation or context size. Taken together, the primary excerpt directly supports the notion of condensation leading to efficiency gains, while the others offer supplementary background on RAG improvements.', citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['1. **Generation with Decompose-then-Recompose Algorithm** :\\n\\nRetrieved documents are broken down into smaller components to focus on key insights while filtering out irrelevant or redundant details. The filtered information is recombined into a cohesive and concise dataset, optimizing the quality of data input for generation.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='medium'), FieldBasis(field='mitigation_strategies_for_risks.3.strategy_category', reasoning='The most directly relevant excerpt explains a fundamental architectural choice in RAG systems: connecting the model to an external knowledge base and retrieving documents at runtime to ground responses, which is a core system-architecture decision. This aligns with the finegrained field value System Architecture by identifying how the system is structured to mitigate risks through architectural design. The accompanying excerpt discusses preferring internal retrieval systems when possible and applying post-processing/output filters to manage information, which also centers on the overall system design and architecture for risk mitigation. Those elements explicitly address how the system should be built or configured to manage privacy, security, and correctness at the architectural level. Other excerpts primarily address privacy risks, governance, or general security considerations without detailing concrete architectural choices, making them less directly supportive of the System Architecture field value.', citations=[Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['nstead of\\n\\nembedding domain-specific knowledge into the model itself, RAG connects the model to an external\\n\\nknowledge base and retrieves relevant documents at runtime to ground its responses', 'al or third-party\\n\\nknowledge bases, user\\n\\nqueries may be logged or\\n\\nmonitored without\\n\\nconsent. \\uf0a7\\n\\nUse robust API security\\n\\nmeasures, including access\\n\\ncontrols, authentication,\\n\\nand rate limiting. \\uf0a7\\n\\nSanitize user input to\\n\\nprevent injection attacks. \\uf0a7\\n\\nMinimize API logging or\\n\\nensure logs are\\n\\nanonymized and protected\\n\\nby access controls. \\uf0a7\\n\\nRestrict retrieval sources to\\n\\napproved, privacy-screened\\n\\ndatasets (e.g., filtered CRM\\n\\ndata). \\uf0a7\\n\\nImplement relevance filters\\n\\nor scoring mechanisms to\\n\\nensure only appropriate\\n\\ncontent is passed to the\\n\\nLLM. \\uf0a7\\n\\nApply post-\\n\\nprocessing/output filters to\\n\\nremove or redact sensitive\\n\\ninformation from\\n\\nresponses. \\uf0a7\\n\\nUse internal retrieval\\n\\nsystems when possible; if\\n\\nthird-party search APIs are\\n\\nused, anonymize or'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)')], confidence='high'), FieldBasis(field='mitigation_strategies_for_risks.1.strategy_category', reasoning='The target field value is Content Sanitization, which corresponds to methods that remove or redact sensitive information and sanitize inputs/outputs to prevent leakage or misuse. The excerpt explicitly states to \"Sanitize user input to prevent injection attacks\" and to \"Apply post-processing/output filters to remove or redact sensitive information from responses.\" These phrases directly align with content sanitization as a mitigation strategy for privacy and security risks in LLM usage. Other lines emphasize secure handling of data and restricted sources, which support the broader context but are not as directly tied to sanitization actions as the explicit sanitization steps described above. Therefore, the excerpt provides strong, direct support for the field value, with additional context reinforcing the role of content sanitization in risk mitigation.', citations=[Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['al or third-party\\n\\nknowledge bases, user\\n\\nqueries may be logged or\\n\\nmonitored without\\n\\nconsent. \\uf0a7\\n\\nUse robust API security\\n\\nmeasures, including access\\n\\ncontrols, authentication,\\n\\nand rate limiting. \\uf0a7\\n\\nSanitize user input to\\n\\nprevent injection attacks. \\uf0a7\\n\\nMinimize API logging or\\n\\nensure logs are\\n\\nanonymized and protected\\n\\nby access controls. \\uf0a7\\n\\nRestrict retrieval sources to\\n\\napproved, privacy-screened\\n\\ndatasets (e.g., filtered CRM\\n\\ndata). \\uf0a7\\n\\nImplement relevance filters\\n\\nor scoring mechanisms to\\n\\nensure only appropriate\\n\\ncontent is passed to the\\n\\nLLM. \\uf0a7\\n\\nApply post-\\n\\nprocessing/output filters to\\n\\nremove or redact sensitive\\n\\ninformation from\\n\\nresponses. \\uf0a7\\n\\nUse internal retrieval\\n\\nsystems when possible; if\\n\\nthird-party search APIs are\\n\\nused, anonymize or'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)')], confidence='high'), FieldBasis(field='specific_rag_techniques.0.key_paper_or_source', reasoning='The target field value names a specific paper focused on Self-RAG, a framework described as learning to retrieve, generate, and critique via self-reflection. Excerpts that explicitly reference Self-RAG and describe its core mechanism‚Äîwhere the LLM engages in self-critique during retrieval and generation‚Äîdirectly support the idea that this paper (or closely related work) is a primary source for this topic. The excerpt stating that Self-RAG is an advanced framework where the LLM is trained to perform self-critique during retrieval and generation provides a direct link to the concept embedded in the field value. A closely related excerpt mentions Self-RAG (Self-Reflective RAG) and situates it within a late-2023 context, aligning with the timeframe of related work and reinforcing the relevance to the stated paper. Although none of the excerpts reproduce the exact title, the combination of explicit Self-RAG terminology and the described self-critique/reflective retrieval loop strongly supports that these excerpts pertain to the referenced paper‚Äôs domain and claims. Therefore, the most relevant materials are those that explicitly discuss Self-RAG and its self-critique mechanism, followed by the excerpt that identifies Self-RAG with a timing marker, and finally the broader title context of the evolution of RAG if needed for supplementary context.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='specific_rag_techniques.7.key_benefit', reasoning='The most relevant content explicitly states that a corrective RAG framework improves accuracy by evaluating and correcting retrieved data, ensuring more reliable outputs. This directly supports the component of the field value that highlights improved factual consistency. Related content about CRAG (Corrective Retrieval-Augmented Generation) emphasizes robustness when dealing with inaccuracies in retrieved data and the use of corrective retrieval actions to augment data, which aligns with the notion of increased precision and reduced misinformation. Additional material describing adaptive knowledge retrieval, which uses correct data for generation and triggers further retrieval when data is incorrect or ambiguous, further supports the idea of better precision and reliability in retrieval. Broader reviews of RAG architectures that trace the evolution and improvements in RAG paradigms provide context that such improvements are part of ongoing efforts to reduce hallucinations and improve data quality, though they do not make explicit claims about token efficiency or inference-time reductions. A specific mention of decomposition/recombination of documents focuses on data quality and succinctness which touches on efficient data handling, while general evolution discussions (Self-RAG) provide context but are less directly tied to the precise benefits in the field value. Overall, the strongest signals come from explicit claims of improved accuracy and corrective retrieval strategies, with supporting context on robustness and adaptive retrieval strategies; direct evidence about reduced token usage and inference time is not clearly stated in the excerpts. ', citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['#### **Advantages of CRAG**\\n\\n**Improved Accuracy** :\\n\\nBy evaluating and correcting retrieved data, CRAG ensures more reliable and factually accurate outputs.', '1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.', '#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '1. **Generation with Decompose-then-Recompose Algorithm** :\\n\\nRetrieved documents are broken down into smaller components to focus on key insights while filtering out irrelevant or redundant details. The filtered information is recombined into a cohesive and concise dataset, optimizing the quality of data input for generation.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)'), Citation(url='https://arxiv.org/abs/2312.10997', excerpts=['This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the ...'], title='Retrieval-Augmented Generation for Large Language Models - arXiv'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='mitigation_strategies_for_risks.1.specific_technique', reasoning='The target field value is about input sanitization and HTML stripping. The excerpt explicitly advises to \"Sanitize user input to prevent injection attacks,\" which directly supports sanitization as a mitigation technique. Additionally, it recommends \"Apply post-processing/output filters to remove or redact sensitive information from responses,\" which aligns with cleaning outputs and removing unsafe HTML or content when necessary. Although HTML stripping is not named, sanitization and output filtering are the core concepts that encompass HTML stripping as a practical technique. Therefore, this excerpt provides direct and actionable support for the mentioned finegrained field value.', citations=[Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['al or third-party\\n\\nknowledge bases, user\\n\\nqueries may be logged or\\n\\nmonitored without\\n\\nconsent. \\uf0a7\\n\\nUse robust API security\\n\\nmeasures, including access\\n\\ncontrols, authentication,\\n\\nand rate limiting. \\uf0a7\\n\\nSanitize user input to\\n\\nprevent injection attacks. \\uf0a7\\n\\nMinimize API logging or\\n\\nensure logs are\\n\\nanonymized and protected\\n\\nby access controls. \\uf0a7\\n\\nRestrict retrieval sources to\\n\\napproved, privacy-screened\\n\\ndatasets (e.g., filtered CRM\\n\\ndata). \\uf0a7\\n\\nImplement relevance filters\\n\\nor scoring mechanisms to\\n\\nensure only appropriate\\n\\ncontent is passed to the\\n\\nLLM. \\uf0a7\\n\\nApply post-\\n\\nprocessing/output filters to\\n\\nremove or redact sensitive\\n\\ninformation from\\n\\nresponses. \\uf0a7\\n\\nUse internal retrieval\\n\\nsystems when possible; if\\n\\nthird-party search APIs are\\n\\nused, anonymize or'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)')], confidence='medium'), FieldBasis(field='mitigation_strategies_for_risks.1.description', reasoning=\"The finegrained field value describes a mitigation involving cleaning and preprocessing data before it is passed to the LLM, including input sanitization to detect and neutralize malicious prompts (preventing prompt injection) and HTML stripping to remove harmful scripts or irrelevant formatting from retrieved content. The relevant excerpt explicitly states: 'Sanitize user input to prevent injection attacks.' and 'Apply post-processing/output filters to remove or redact sensitive information from responses.' It also discusses restricting retrieval sources to approved, privacy-screened datasets and using internal retrieval systems with anonymization when third-party APIs are used. Taken together, these points directly support the notion of preprocessing and sanitization as a mitigation strategy to reduce risks in LLM web-search contexts, aligning with the described finegrained field value.\", citations=[Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['al or third-party\\n\\nknowledge bases, user\\n\\nqueries may be logged or\\n\\nmonitored without\\n\\nconsent. \\uf0a7\\n\\nUse robust API security\\n\\nmeasures, including access\\n\\ncontrols, authentication,\\n\\nand rate limiting. \\uf0a7\\n\\nSanitize user input to\\n\\nprevent injection attacks. \\uf0a7\\n\\nMinimize API logging or\\n\\nensure logs are\\n\\nanonymized and protected\\n\\nby access controls. \\uf0a7\\n\\nRestrict retrieval sources to\\n\\napproved, privacy-screened\\n\\ndatasets (e.g., filtered CRM\\n\\ndata). \\uf0a7\\n\\nImplement relevance filters\\n\\nor scoring mechanisms to\\n\\nensure only appropriate\\n\\ncontent is passed to the\\n\\nLLM. \\uf0a7\\n\\nApply post-\\n\\nprocessing/output filters to\\n\\nremove or redact sensitive\\n\\ninformation from\\n\\nresponses. \\uf0a7\\n\\nUse internal retrieval\\n\\nsystems when possible; if\\n\\nthird-party search APIs are\\n\\nused, anonymize or'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)')], confidence='high'), FieldBasis(field='mitigation_strategies_for_risks.1.tradeoff', reasoning='The fine-grained field value asserts that adding multiple defense layers, such as content sanitization and filtering, increases processing time and can cause latency that affects real-time performance. The excerpt discusses several mitigation strategies: sanitizing user input to prevent injection attacks, minimizing API logging and anonymizing logs, implementing relevance filters to ensure appropriate content is passed to the LLM, and applying post-processing/output filters to redact sensitive information. Each of these steps requires additional processing (e.g., extra parsing, evaluation, and filtering) beyond a baseline pipeline, which aligns with the claim that multiple defense layers can slow down processing and impact real-time user experience. While the excerpt does not quantify latency, it explicitly describes the mechanisms (sanitization, filtering, post-processing) that would contribute to increased processing time, supporting the connection to the field value.', citations=[Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['al or third-party\\n\\nknowledge bases, user\\n\\nqueries may be logged or\\n\\nmonitored without\\n\\nconsent. \\uf0a7\\n\\nUse robust API security\\n\\nmeasures, including access\\n\\ncontrols, authentication,\\n\\nand rate limiting. \\uf0a7\\n\\nSanitize user input to\\n\\nprevent injection attacks. \\uf0a7\\n\\nMinimize API logging or\\n\\nensure logs are\\n\\nanonymized and protected\\n\\nby access controls. \\uf0a7\\n\\nRestrict retrieval sources to\\n\\napproved, privacy-screened\\n\\ndatasets (e.g., filtered CRM\\n\\ndata). \\uf0a7\\n\\nImplement relevance filters\\n\\nor scoring mechanisms to\\n\\nensure only appropriate\\n\\ncontent is passed to the\\n\\nLLM. \\uf0a7\\n\\nApply post-\\n\\nprocessing/output filters to\\n\\nremove or redact sensitive\\n\\ninformation from\\n\\nresponses. \\uf0a7\\n\\nUse internal retrieval\\n\\nsystems when possible; if\\n\\nthird-party search APIs are\\n\\nused, anonymize or'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)')], confidence='medium'), FieldBasis(field='mitigation_strategies_for_risks.2.specific_technique', reasoning='The fine-grained field value specifies a particular technique, Differential Privacy, as the method for mitigating privacy risks. Among the excerpts, the ones most directly relevant to privacy-preserving mitigation discuss concrete practices such as restricting retrieval sources to privacy-screened datasets, minimizing API logging and anonymizing logs, sanitizing input, and applying post-processing/output filters to redact sensitive information. These items show concern for privacy protections in LLM systems but do not state Differential Privacy explicitly. Excerpts that frame privacy in terms of general data handling, anonymization, and access controls are tangentially relevant as they relate to how privacy risk is mitigated, yet they do not confirm the use of DP as a technique. The remaining excerpts touch on broader security, logging practices, or RAG/act regulatory considerations, which provide context about privacy-aware methodology but do not directly support the specific field value. Therefore, the most relevant material supports the general privacy-preserving approach rather than evidencing the explicit implementation or discussion of Differential Privacy as a technique.', citations=[Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['al or third-party\\n\\nknowledge bases, user\\n\\nqueries may be logged or\\n\\nmonitored without\\n\\nconsent. \\uf0a7\\n\\nUse robust API security\\n\\nmeasures, including access\\n\\ncontrols, authentication,\\n\\nand rate limiting. \\uf0a7\\n\\nSanitize user input to\\n\\nprevent injection attacks. \\uf0a7\\n\\nMinimize API logging or\\n\\nensure logs are\\n\\nanonymized and protected\\n\\nby access controls. \\uf0a7\\n\\nRestrict retrieval sources to\\n\\napproved, privacy-screened\\n\\ndatasets (e.g., filtered CRM\\n\\ndata). \\uf0a7\\n\\nImplement relevance filters\\n\\nor scoring mechanisms to\\n\\nensure only appropriate\\n\\ncontent is passed to the\\n\\nLLM. \\uf0a7\\n\\nApply post-\\n\\nprocessing/output filters to\\n\\nremove or redact sensitive\\n\\ninformation from\\n\\nresponses. \\uf0a7\\n\\nUse internal retrieval\\n\\nsystems when possible; if\\n\\nthird-party search APIs are\\n\\nused, anonymize or', 'nstead of\\n\\nembedding domain-specific knowledge into the model itself, RAG connects the model to an external\\n\\nknowledge base and retrieves relevant documents at runtime to ground its responses', 'Logs might inadvertently\\n\\nstore sensitive user data', 'Retrieved content may\\n\\ncontain sensitive or\\n\\noutdated information,\\n\\nwhich could be exposed\\n\\nin generated outp', 'According to Article 25 of the AI Act, a deployer of a high risk AI system becomes a provider when they substantially modify an existing AI\\n\\nsystem, including by fine-tuning or adapting a pre-trained model for new applications'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)'), Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['Experiments conducted on 14 representative RAG components demonstrate that RAG exhibits significant vulnerability to all attack tasks and even the most apparent attack task can easily bypass existing retrievers, filters, or advanced LLMs, resulting in the degradation of RAG service quality.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['We construct a comprehensive question-contexts safety evaluation dataset specifically tailored to the Chinese news domain, aiming to address the complex issues likely to arise in real-world applications.', 'Our main contributions are:'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2510.05310v1', excerpts=['In contrast, our work centered on evaluating guardrail models in the RAG settings. ## 3 Problem Setup and Robustness Metric'], title='RAG Makes Guardrails Unsafe? Investigating Robustness ...'), Citation(url='https://pmc.ncbi.nlm.nih.gov/articles/PMC12306375/', excerpts=['by AH AlSammarraie ¬∑ 2025 ¬∑ Cited by 2 ‚Äî To develop and evaluate an agentic retrieval augmented generation (ARAG) framework using open-source large language models (LLMs) for generating\\xa0...'], title='Development and evaluation of an agentic LLM based ...')], confidence='low'), FieldBasis(field='specific_rag_techniques.8.core_concept', reasoning='The target field value asserts that there is a first security benchmark for RAG pipelines and that it catalogs four classes of attacks: silver noise, context conflict, soft-ad, and DoS. Excerpts that explicitly name these four attack classes directly validate the claimed taxonomy (silver noise, inter-context conflict/ context conflict, soft ad/soft-ad, and DoS/DoS). Excerpts that state there is a benchmark named SafeRAG for evaluating RAG security corroborate the existence and purpose of the benchmark. Excerpts that mention the benchmark in general terms, or state vulnerability of RAG to attack tasks, support the claim that the benchmark exists to evaluate security and robustness, even if they do not enumerate all class names in every sentence. By prioritizing excerpts that both name the four classes and reference the benchmark, we align with the finegrained value describing the specific security benchmark and its four-ca\\u200bttagorization. The top supporting evidence comes from explicit class enumeration, followed by explicit benchmark naming, and then general security evaluation statements that reinforce the context of a benchmark for RAG security.', citations=[Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.', 'Experiments conducted on 14 representative RAG components demonstrate that RAG exhibits significant vulnerability to all attack tasks and even the most apparent attack task can easily bypass existing retrievers, filters, or advanced LLMs, resulting in the degradation of RAG service quality.', 'In this paper, we introduce a benchmark named SafeRAG designed to evaluate the RAG security.', 'The indexing-retrieval-generation paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs).', 'Code is available at: https://github.com/IAAR-Shanghai/SafeRAG.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service.', 'The _indexing-retrieval-generation_ paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs). However, the incorporation of external and unverified knowledge increases the vulnerability of LLMs because attackers can perform attack tasks by manipulating knowledge.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...')], confidence='high'), FieldBasis(field='specific_rag_techniques.3.core_concept', reasoning=\"The most relevant content explicitly references a 'knowledge hypergraph' and a hypergraph-based RAG framework, which directly embodies integrating knowledge graphs with text retrieval and leveraging graph structure for retrieval tasks. The next most relevant content describes a hypergraph-based RAG system that includes construction, retrieval, and generation, indicating the use of graph-based representations to manage relational information for retrieval, aligning with the idea of leveraging structured graph knowledge. The least relevant content provides a broad overview of RAG progress without focusing on graph-structured knowledge representations, offering only contextual support rather than direct confirmation of the finegrained field value.\", citations=[Citation(url='https://arxiv.org/abs/2503.21322', excerpts=[' HyperGraphRAG, a novel hypergraph-based RAG method that represents n-ary relational facts via hyperedges, and consists of knowledge hypergraph construction, retrieval, and generation. ', 'Experiments across medicine, agriculture, computer science, and law demonstrate that HyperGraphRAG outperforms both standard RAG and previous graph-based RAG methods in answer accuracy, retrieval efficiency, and generation quality.'], title='HyperGraphRAG: Retrieval-Augmented Generation via Hypergraph ...'), Citation(url='https://arxiv.org/abs/2312.10997', excerpts=['This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the ...'], title='Retrieval-Augmented Generation for Large Language Models - arXiv')], confidence='high'), FieldBasis(field='timeline_of_milestones.0.category', reasoning='The field value ‚ÄòBenchmark‚Äô corresponds to a milestone category that focuses on how models are evaluated against standards and references. Excerpts that explicitly discuss benchmarking frameworks and evaluation metrics directly support the idea of benchmarking in RAG/LLM contexts, showing what aspects are measured (e.g., answer relevancy, faithfulness, context precision/recall). Content that describes related evaluation criteria (such as how well responses align with references or how relevant an answer is to a query) provides supporting context for benchmarking practice, even if it does not use the exact word ‚Äòbenchmark‚Äô in every case. Therefore, the most directly relevant portions are those that center on benchmarking frameworks and evaluation metrics; slightly less direct, but still pertinent, are excerpts detailing specific evaluation criteria used to judge model outputs. These connections collectively map to a ‚ÄòBenchmark‚Äô milestone category in the timeline.', citations=[Citation(url='https://www.giskard.ai/knowledge/rag-benchmarking-for-ai-evaluation', excerpts=['RAGAS (Retrieval-Augmented Generation Assessment System) is an evaluation framework offering various metrics to measure the quality of a RAG model‚Äôs responses. Below is an explanation of these metrics along with usage examples:', ' **Answer Relevancy  \\n   ** Answer relevancy evaluates whether the model‚Äôs response is relevant to the question, even if it is not entirely accurate or detail', '*Faithfulness  \\n   ** Faithfulness assesses the extent to which the model‚Äôs response is supported by information in the reference document. The response must align with the source or reference document without introducing unsupported information'], title='RAG Benchmarking: Comparing RAGAS, BERTScore, and ...'), Citation(url='https://dkaarthick.medium.com/ragas-for-rag-in-llms-a-comprehensive-guide-to-evaluation-metrics-3aca142d6e38', excerpts=['RAGAS introduces several metrics that provide a more holistic evaluation of RAG models, focusing on aspects like faithfulness, answer relevancy, context precision, and context recall.', 'Answer Relevancy** evaluates how relevant the generated response is to the original query. **Formu', 'aithfulness** measures the factual accuracy of the generated response based on the retrieved documents. **Formul'], title='RAGAS for RAG in LLMs: A Comprehensive Guide to ...')], confidence='high'), FieldBasis(field='mitigation_strategies_for_risks.2.description', reasoning='The most directly relevant content discusses privacy risks and mitigations in the context of large language models and retrieval-based systems. Passages that outline privacy considerations, such as log minimization, anonymization, and restricting retrieval sources to privacy-screened datasets, directly map to the general goal of protecting user data in retrieval-based workflows. The statement that RAG connects the model to an external knowledge base and retrieves relevant documents at runtime to ground responses is highly relevant because it establishes the retrieval mechanism that differential privacy would seek to protect and harden. Security-focused evaluations of retrieval-augmented systems and guardrail robustness are also relevant, as they provide context on where privacy-preserving techniques would be applied and what kinds of attacks these systems face. References to ARAG (agentic retrieval augmented generation) and SafeRAG-style risk assessments further support understanding of how retrieval processes can be secured and evaluated for privacy implications. While none of the excerpts explicitly describe retriever-level differential privacy or explicit noise-injection in retrieval, they collectively describe the privacy risks, RAG grounding, and security considerations that underpin the need for privacy-preserving retrieval techniques described in the requested field value. These excerpts collectively support the notion that privacy-preserving, DP-like approaches would be a relevant direction for safeguarding retrievals and mitigating information leakage in RAG systems.', citations=[Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['al or third-party\\n\\nknowledge bases, user\\n\\nqueries may be logged or\\n\\nmonitored without\\n\\nconsent. \\uf0a7\\n\\nUse robust API security\\n\\nmeasures, including access\\n\\ncontrols, authentication,\\n\\nand rate limiting. \\uf0a7\\n\\nSanitize user input to\\n\\nprevent injection attacks. \\uf0a7\\n\\nMinimize API logging or\\n\\nensure logs are\\n\\nanonymized and protected\\n\\nby access controls. \\uf0a7\\n\\nRestrict retrieval sources to\\n\\napproved, privacy-screened\\n\\ndatasets (e.g., filtered CRM\\n\\ndata). \\uf0a7\\n\\nImplement relevance filters\\n\\nor scoring mechanisms to\\n\\nensure only appropriate\\n\\ncontent is passed to the\\n\\nLLM. \\uf0a7\\n\\nApply post-\\n\\nprocessing/output filters to\\n\\nremove or redact sensitive\\n\\ninformation from\\n\\nresponses. \\uf0a7\\n\\nUse internal retrieval\\n\\nsystems when possible; if\\n\\nthird-party search APIs are\\n\\nused, anonymize or', 'nstead of\\n\\nembedding domain-specific knowledge into the model itself, RAG connects the model to an external\\n\\nknowledge base and retrieves relevant documents at runtime to ground its responses', 'According to Article 25 of the AI Act, a deployer of a high risk AI system becomes a provider when they substantially modify an existing AI\\n\\nsystem, including by fine-tuning or adapting a pre-trained model for new applications', 'Logs might inadvertently\\n\\nstore sensitive user data', 'Retrieved content may\\n\\ncontain sensitive or\\n\\noutdated information,\\n\\nwhich could be exposed\\n\\nin generated outp'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)'), Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['Experiments conducted on 14 representative RAG components demonstrate that RAG exhibits significant vulnerability to all attack tasks and even the most apparent attack task can easily bypass existing retrievers, filters, or advanced LLMs, resulting in the degradation of RAG service quality.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://pmc.ncbi.nlm.nih.gov/articles/PMC12306375/', excerpts=['by AH AlSammarraie ¬∑ 2025 ¬∑ Cited by 2 ‚Äî To develop and evaluate an agentic retrieval augmented generation (ARAG) framework using open-source large language models (LLMs) for generating\\xa0...'], title='Development and evaluation of an agentic LLM based ...'), Citation(url='https://arxiv.org/html/2501.18636v1', excerpts=['We construct a comprehensive question-contexts safety evaluation dataset specifically tailored to the Chinese news domain, aiming to address the complex issues likely to arise in real-world applications.', 'Our main contributions are:'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...'), Citation(url='https://arxiv.org/html/2510.05310v1', excerpts=['In contrast, our work centered on evaluating guardrail models in the RAG settings. ## 3 Problem Setup and Robustness Metric'], title='RAG Makes Guardrails Unsafe? Investigating Robustness ...')], confidence='medium'), FieldBasis(field='specific_rag_techniques.3.year_introduced', reasoning='The finegrained field value seeks the year a specific RAG technique (the third entry in a list under specific_rag_techniques) was introduced, specifically the year 2024. None of the provided excerpts explicitly state that a year of introduction (e.g., 2024) is associated with any RAG technique. The two HyperGraphRAG-related excerpts discuss the method, its hypergraph-based representation, and reported performance improvements, but do not mention a year of introduction. The third excerpt provides a high-level survey of Retrieval-Augmented Generation paradigms without specifying introduction years for particular techniques. Because there is no explicit citation of a 2024 introduction year for the technique in the targeted field path, there is no direct evidence to confirm the value 2024.0. Consequently, the evidence is insufficient to validate the finegrained field value, though the excerpts are still relevant for the broader topic of RAG techniques and their developments.', citations=[Citation(url='https://arxiv.org/abs/2503.21322', excerpts=['Experiments across medicine, agriculture, computer science, and law demonstrate that HyperGraphRAG outperforms both standard RAG and previous graph-based RAG methods in answer accuracy, retrieval efficiency, and generation quality.', ' HyperGraphRAG, a novel hypergraph-based RAG method that represents n-ary relational facts via hyperedges, and consists of knowledge hypergraph construction, retrieval, and generation. '], title='HyperGraphRAG: Retrieval-Augmented Generation via Hypergraph ...'), Citation(url='https://arxiv.org/abs/2312.10997', excerpts=['This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the ...'], title='Retrieval-Augmented Generation for Large Language Models - arXiv')], confidence='low'), FieldBasis(field='timeline_of_milestones.0.milestone_description', reasoning='The milestone describes a reference-free suite of metrics for automated evaluation of RAG system quality across multiple dimensions, including faithfulness and answer relevance. Excerpts describe an evaluation framework (RAGAS) that introduces metrics to measure RAG model quality, including aspects like faithfulness and answer relevancy. The discussion of answer relevancy explains whether generated responses are relevant to the question, which directly supports the dimension of answer relevance in the milestone. The faithfulness content explains alignment with source documents, which supports the faithfulness dimension. Additional excerpts emphasize holistic evaluation metrics and coverage of broader evaluation criteria, matching the description of a multi-dimensional, reference-free metric suite for RAG systems.', citations=[Citation(url='https://www.giskard.ai/knowledge/rag-benchmarking-for-ai-evaluation', excerpts=['RAGAS (Retrieval-Augmented Generation Assessment System) is an evaluation framework offering various metrics to measure the quality of a RAG model‚Äôs responses. Below is an explanation of these metrics along with usage examples:', ' **Answer Relevancy  \\n   ** Answer relevancy evaluates whether the model‚Äôs response is relevant to the question, even if it is not entirely accurate or detail', '*Faithfulness  \\n   ** Faithfulness assesses the extent to which the model‚Äôs response is supported by information in the reference document. The response must align with the source or reference document without introducing unsupported information'], title='RAG Benchmarking: Comparing RAGAS, BERTScore, and ...'), Citation(url='https://dkaarthick.medium.com/ragas-for-rag-in-llms-a-comprehensive-guide-to-evaluation-metrics-3aca142d6e38', excerpts=['RAGAS introduces several metrics that provide a more holistic evaluation of RAG models, focusing on aspects like faithfulness, answer relevancy, context precision, and context recall.', 'Answer Relevancy** evaluates how relevant the generated response is to the original query. **Formu', 'aithfulness** measures the factual accuracy of the generated response based on the retrieved documents. **Formul'], title='RAGAS for RAG in LLMs: A Comprehensive Guide to ...')], confidence='high'), FieldBasis(field='specific_rag_techniques.3.key_paper_or_source', reasoning='The finegrained field value specifies GraphRAG (2024) as a key paper or source, along with HyperGraphRAG in 2025. The excerpts clearly discuss HyperGraphRAG, including its definition as a hypergraph-based RAG method and its reported performance advantages, which directly supports the HyperGraphRAG (2025) portion of the field value. The exact year 2025 is implied by the arXiv identifier in the sources and by the phrasing that presents HyperGraphRAG as a contemporary advancement, which aligns with the field value‚Äôs claim about HyperGraphRAG in 2025. However, none of the excerpts mention GraphRAG (2024) specifically. Therefore, the excerpts collectively provide solid support for the HyperGraphRAG (2025) component but offer no evidence for GraphRAG (2024), making the overall support partial rather than complete for the field value.', citations=[Citation(url='https://arxiv.org/abs/2503.21322', excerpts=['Experiments across medicine, agriculture, computer science, and law demonstrate that HyperGraphRAG outperforms both standard RAG and previous graph-based RAG methods in answer accuracy, retrieval efficiency, and generation quality.', ' HyperGraphRAG, a novel hypergraph-based RAG method that represents n-ary relational facts via hyperedges, and consists of knowledge hypergraph construction, retrieval, and generation. '], title='HyperGraphRAG: Retrieval-Augmented Generation via Hypergraph ...'), Citation(url='https://arxiv.org/abs/2312.10997', excerpts=['This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the ...'], title='Retrieval-Augmented Generation for Large Language Models - arXiv')], confidence='medium'), FieldBasis(field='major_industry_implementations.2.technical_integration_pattern', reasoning='The target fine-grained value centers on OpenAI-like capabilities: browsing-enabled interaction to access real-time web information, and advanced agentic systems (for multi-step research tasks) with patterns that enable dynamic external knowledge access. Excerpts that emphasize grounding responses with current web data, and explain web-query workflow within an automated agent or Copilot-like system, directly support this concept. For example, passages describing how web search is used to ground Copilot‚Äôs answers and close knowledge gaps demonstrate the core mechanism of real-time information retrieval powering an agent. Descriptions of layered protections and enterprise-oriented web search illustrate the architectural context in which such agentic systems operate, further aligning with how such capabilities would be implemented in practice. Excerpts that mention agentic RAG, or refer to agent-based workflows and multi-step research tasks, provide conceptual alignment with the proposed OpenAI-style frameworks. While some excerpts focus on Microsoft 365 Copilot specifics, they still depict the same overarching pattern: prompts are parsed, web information is fetched when needed, and responses are grounded in live data. Collectively, the most relevant parts coalesce around a pattern of prompts triggering web queries, external grounding of responses, and agent-like orchestration of information retrieval for complex tasks, which is consistent with the described OpenAI‚Äëoriented framework of hands-on, web-enabled reasoning for LRMs.', citations=[Citation(url='https://techcommunity.microsoft.com/blog/microsoft365copilotblog/microsoft-365-copilot-web-search-delivering-multiple-layers-of-protection-and-co/4458224', excerpts=['A Copilot interaction has three parts: your prompt, a web query (if needed), and the response.', 'That‚Äôs why Copilot can ground its answers with current information from the web, closing knowledge gaps that every large language model (LLM) inevitably has based on its training data cutoff.', 'Traditional web search engines are optimized for broad consumer scenarios. Copilot‚Äôs web search is enterprise oriented and layered with controls that consumer search does not provide.'], title='Microsoft 365 Copilot Web Search: Delivering Multiple ...'), Citation(url='https://learn.microsoft.com/en-us/copilot/microsoft-365/manage-public-web-access', excerpts=['osoft 365 **Copilot Search** is an additional, universal search experience that allows users with a Microsoft 365 Copilot license to search across all their Microsoft 365 and third-party data sources.', 'When web search is enabled, Microsoft 365 Copilot and Microsoft 365 Copilot Chat parse the user‚Äôs prompt and identifies terms where information from the web would improve the quality of the response.', 'When web search is enabled, Microsoft 365 Copilot and Microsoft 365 Copilot Chat may fetch information from the Bing search service when information from the web helps to provide a better, more grounded response.', 'generated search queries sent to the Bing search service to ground responses in web data. The way Microsoft handles these queries is identical in both services. Gen', 'ontrols and a user-level **Web content** toggle (only for Microsoft 365 Copilot) are available to [manage whether web search is enabled]() in your environment'], title='Data, privacy, and security for web search in Microsoft 365 ...'), Citation(url='https://www.linkedin.com/posts/rakeshgohel01_ai-agent-trends-have-drastically-changed-activity-7383841580014723072-PxZp', excerpts=[\"CUA and Agentic RAG aren't just cool demos anymore. They're solving real operational gaps, fast. This list nails the shift from experimentation to execution.\"], title='AI Agent Trends for 2025: New Innovations and Products'), Citation(url='https://learn.microsoft.com/en-us/copilot/overview', excerpts=['Nov 11, 2025 ‚Äî Copilot Chat is AI chat grounded in data from the web and powered by the latest large language models (LLMs). Copilot Chat lets users access agents and create\\xa0...'], title='Overview of Microsoft 365 Copilot Chat')], confidence='medium'), FieldBasis(field='mitigation_strategies_for_risks.2.tradeoff', reasoning='The most directly relevant content describes concrete privacy-preserving mitigations applied to LLM retrieval systems, such as sanitizing input, limiting and anonymizing logs, restricting data sources to privacy-screened datasets, applying relevance filters, and post-processing to remove or redact sensitive information. These measures are designed to protect user privacy, but they can affect the usefulness of results if overly aggressive filtering or redaction reduces signal quality or factual content. Supporting this, one excerpt notes that post-processing and output filtering are used to remove or redact sensitive information, which directly ties to potential reductions in utility. Another excerpt highlights that retrieval-augmented generation service quality can degrade when defenses or adversarial conditions affect components, illustrating how privacy-focused or security-focused mitigations may come at the cost of performance or accuracy. A separate excerpt discusses how RAG systems connect to external knowledge bases to ground responses, a design choice that interacts with privacy and data handling practices, influencing both privacy protections and the utility of retrieved information.', citations=[Citation(url='https://www.edpb.europa.eu/system/files/2025-04/ai-privacy-risks-and-mitigations-in-llms.pdf', excerpts=['al or third-party\\n\\nknowledge bases, user\\n\\nqueries may be logged or\\n\\nmonitored without\\n\\nconsent. \\uf0a7\\n\\nUse robust API security\\n\\nmeasures, including access\\n\\ncontrols, authentication,\\n\\nand rate limiting. \\uf0a7\\n\\nSanitize user input to\\n\\nprevent injection attacks. \\uf0a7\\n\\nMinimize API logging or\\n\\nensure logs are\\n\\nanonymized and protected\\n\\nby access controls. \\uf0a7\\n\\nRestrict retrieval sources to\\n\\napproved, privacy-screened\\n\\ndatasets (e.g., filtered CRM\\n\\ndata). \\uf0a7\\n\\nImplement relevance filters\\n\\nor scoring mechanisms to\\n\\nensure only appropriate\\n\\ncontent is passed to the\\n\\nLLM. \\uf0a7\\n\\nApply post-\\n\\nprocessing/output filters to\\n\\nremove or redact sensitive\\n\\ninformation from\\n\\nresponses. \\uf0a7\\n\\nUse internal retrieval\\n\\nsystems when possible; if\\n\\nthird-party search APIs are\\n\\nused, anonymize or', 'nstead of\\n\\nembedding domain-specific knowledge into the model itself, RAG connects the model to an external\\n\\nknowledge base and retrieves relevant documents at runtime to ground its responses'], title='AI Privacy Risks & Mitigations ‚Äì Large Language Models (LLMs)'), Citation(url='https://aclanthology.org/2025.acl-long.230/', excerpts=['Experiments conducted on 14 representative RAG components demonstrate that RAG exhibits significant vulnerability to all attack tasks and even the most apparent attack task can easily bypass existing retrievers, filters, or advanced LLMs, resulting in the degradation of RAG service quality.'], title='SafeRAG: Benchmarking Security in Retrieval-Augmented ...')], confidence='medium'), FieldBasis(field='timeline_of_milestones.0.associated_work', reasoning='The target field value is RAGAS as the associated work for a milestone. Several excerpts explicitly name RAGAS and describe it as an evaluation framework with metrics such as faithfulness, answer relevancy, context precision, and context recall. These direct mentions establish that RAGAS is the work associated with milestones in the RAG/evaluation domain, which matches the finegrained field path‚Äôs focus on associated_work. The excerpts that discuss RAGAS in the context of RAG evaluation, benchmarking, and metric-focused descriptions provide strong, direct support for RAGAS being the associated work. One excerpt that repeats the benchmarking context (RAG Benchmarking) but still names RAGAS in the pairing confirms the linkage between RAGAS and evaluation/benchmarking activities. Collectively, these excerpts substantiate that RAGAS is the associated work for the specified milestone path, with the strongest support coming from explicit naming and framing of RAGAS as an evaluation framework and benchmarking component.\\n', citations=[Citation(url='https://www.giskard.ai/knowledge/rag-benchmarking-for-ai-evaluation', excerpts=['RAGAS (Retrieval-Augmented Generation Assessment System) is an evaluation framework offering various metrics to measure the quality of a RAG model‚Äôs responses. Below is an explanation of these metrics along with usage examples:', ' **Answer Relevancy  \\n   ** Answer relevancy evaluates whether the model‚Äôs response is relevant to the question, even if it is not entirely accurate or detail'], title='RAG Benchmarking: Comparing RAGAS, BERTScore, and ...'), Citation(url='https://dkaarthick.medium.com/ragas-for-rag-in-llms-a-comprehensive-guide-to-evaluation-metrics-3aca142d6e38', excerpts=['RAGAS introduces several metrics that provide a more holistic evaluation of RAG models, focusing on aspects like faithfulness, answer relevancy, context precision, and context recall.', 'Answer Relevancy** evaluates how relevant the generated response is to the original query. **Formu', 'aithfulness** measures the factual accuracy of the generated response based on the retrieved documents. **Formul'], title='RAGAS for RAG in LLMs: A Comprehensive Guide to ...')], confidence='high'), FieldBasis(field='timeline_of_milestones.6.category', reasoning='The field value corresponds to a benchmarking or evaluation category within a timeline of milestones. Excerpt content describes an evaluation framework (RAGAS) with metrics to measure the quality of a retrieval-augmented generation model‚Äôs responses, which directly aligns with benchmarking activities. It also explains aspects like answer relevancy and faithfulness, which are core components of benchmarking evaluations, clarifying how to gauge whether responses are relevant and supported by sources. Another excerpt explicitly discusses answer relevancy and its role in assessing model performance, which reinforces benchmarking context. A third excerpt introduces faithfulness as a metric that measures alignment with source documents, further anchoring the benchmarking narrative by detailing what can be evaluated and how. Collectively, these excerpts provide concrete benchmarking concepts, metrics, and evaluation criteria that map to the requested field value, showing that the timeline milestone category likely centers on benchmarking within RAG/LLM evaluation discourse.', citations=[Citation(url='https://www.giskard.ai/knowledge/rag-benchmarking-for-ai-evaluation', excerpts=['RAGAS (Retrieval-Augmented Generation Assessment System) is an evaluation framework offering various metrics to measure the quality of a RAG model‚Äôs responses. Below is an explanation of these metrics along with usage examples:', ' **Answer Relevancy  \\n   ** Answer relevancy evaluates whether the model‚Äôs response is relevant to the question, even if it is not entirely accurate or detail', '*Faithfulness  \\n   ** Faithfulness assesses the extent to which the model‚Äôs response is supported by information in the reference document. The response must align with the source or reference document without introducing unsupported information'], title='RAG Benchmarking: Comparing RAGAS, BERTScore, and ...')], confidence='high'), FieldBasis(field='timeline_of_milestones.9.year', reasoning=\"The target field is a year value (timeline_of_milestones.9.year) expected to be 2025.0. Excerpts that explicitly reference the year 2025 or describe 2025-focused guides/topics are directly relevant for supporting the notion of a milestone in 2025. Among the provided excerpts, the ones describing 'The 2025 Guide to Retrieval-Augmented Generation (RAG)' and related 2025-focused CRAG discussions clearly align with a 2025 milestone context. These excerpts discuss 2025 as a setting or focus for guides and frameworks in retrieval-augmented generation, which directly supports interpreting the timeline year as 2025.0. Other excerpts that discuss RAG evaluation metrics or general RAG concepts without a 2025 temporal anchor are less directly supportive for the specific year field but provide contextual backdrop for the broader research area.\\n\\nTherefore, the most relevant content comes from the 2025-focused guides (and related CRAG discussions), which directly corroborate a 2025 milestone. The subsequent relevance comes from contextual mentions of 2025 in adjacent discussions about RAG/CRAG, which still tie back to the same year context but with less direct alignment to the exact timeline field.\", citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.', '**Dynamic Adaptability** :\\n\\nThe integration of large-scale web searches allows CRAG to expand beyond static knowledge bases, providing up-to-date and diverse information.', '**Better Robustness** :\\n\\nCRAG mitigates the risk of generating incorrect knowledge by dynamically addressing errors in the retrieval process.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='medium'), FieldBasis(field='specific_rag_techniques.3.key_benefit', reasoning='The field value describes benefits that arise when combining structured graph knowledge with unstructured text to improve reasoning and retrieval of complex, multi-entity relations. Excerpt describing a hypergraph-based RAG method explicitly states that relations are represented as hyperedges and that the approach comprises knowledge graph construction, retrieval, and generation, which directly aligns with integrating structured (graph) knowledge with unstructured (text) data to enhance retrieval of n-ary relational facts. The excerpt also notes that this method outperforms standard RAG and earlier graph-based RAG approaches in accuracy, retrieval efficiency, and generation quality, supporting claims about improved retrieval and reasoning quality. A broader review of Retrieval-Augmented Generation elaborates on the evolution of RAG paradigms, providing contextual support that RAG methods progressively enhance retrieval and integration capabilities. Collectively, these passages substantiate the idea that leveraging a structured graph representation within RAG frameworks can boost reasoning and retrieval performance for complex, multi-relational knowledge, especially where n-ary relations are involved. The combination of explicit n-ary relation modeling (via hyperedges) and demonstrated performance gains underpins the high-confidence link between the field value and the excerpts.', citations=[Citation(url='https://arxiv.org/abs/2503.21322', excerpts=[' HyperGraphRAG, a novel hypergraph-based RAG method that represents n-ary relational facts via hyperedges, and consists of knowledge hypergraph construction, retrieval, and generation. ', 'Experiments across medicine, agriculture, computer science, and law demonstrate that HyperGraphRAG outperforms both standard RAG and previous graph-based RAG methods in answer accuracy, retrieval efficiency, and generation quality.'], title='HyperGraphRAG: Retrieval-Augmented Generation via Hypergraph ...'), Citation(url='https://arxiv.org/abs/2312.10997', excerpts=['This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the ...'], title='Retrieval-Augmented Generation for Large Language Models - arXiv')], confidence='high'), FieldBasis(field='timeline_of_milestones.10.associated_work', reasoning=\"The excerpt discusses 'Agentic RAG' as a significant shift in the field of retrieval-augmented generation, characterizing it as autonomous, self-directed retrieval and reasoning. This directly aligns with the finegrained field value 'Agentic RAG' and provides explicit context that the term denotes a move toward agentic capabilities in RAG systems, including the accompanying challenges of reliability, evaluation, and governance. Therefore, this excerpt directly supports the presence and interpretation of the target field value within the specified timeline location.\", citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. '], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='high'), FieldBasis(field='timeline_of_milestones.10.milestone_description', reasoning='The field value states that there is a notable shift in the research discourse from traditional RAG to Agentic RAG, characterized by autonomous agents that plan and execute complex retrieval and reasoning workflows. The excerpt describes Agentic RAG as a key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, which directly paraphrases and supports the claim about the evolving discourse toward Agentic RAG and its emphasis on autonomous planning and execution. This alignment confirms that the excerpt provides direct, relevant evidence about the described shift in the field. Mention of addressing new challenges in reliability, evaluation, and ethical governance also provides contextual support for why this shift is noteworthy in research discussions. ', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. '], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='high'), FieldBasis(field='timeline_of_milestones.10.category', reasoning=\"The finegrained field value denotes a general pattern or movement in the research area. The excerpt describes a key industry shift toward autonomous, self-directed retrieval and reasoning within RAG, which clearly exemplifies a current research trend rather than a specific milestone, method, or static capability. This directly supports labeling the timeline category as a 'Research Trend' by highlighting the directional change and evolving focus in the field. The content also notes accompanying challenges in reliability, evaluation, and ethics, which further reinforces the sense of an ongoing, broad trend rather than a one-off achievement.\", citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. '], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='high'), FieldBasis(field='timeline_of_milestones.3.associated_work', reasoning='The target field value is the explicit concept of Corrective Retrieval Augmented Generation (CRAG). Excerpts that directly introduce or define CRAG provide the strongest support for its presence in the timeline: a statement describing CRAG as a framework for Retrieval-Augmented Generation designed to improve robustness when dealing with inaccuracies in retrieved data, and a section highlighting advantages such as improved accuracy through evaluating and correcting retrieved data. Supporting excerpts elaborate on CRAG‚Äôs core mechanisms and improvements: adaptive knowledge retrieval that triggers additional retrieval actions to augment the original dataset with reliable information; dynamic adaptability by incorporating web-scale searches to stay up-to-date; and robustness enhancements that mitigate the risk of generating incorrect knowledge by addressing retrieval errors. Additional excerpts discuss the data processing workflow underpinning CRAG, such as decomposing documents into smaller components to focus on key insights and then recomposing them into a concise dataset, which aligns with the CRAG approach of improving input quality for generation. Collectively, these excerpts establish both the definition and the operational components that would be associated with a CRAG milestone in a timeline of advancements for web search-enabled LLMs.', citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '#### **Advantages of CRAG**\\n\\n**Improved Accuracy** :\\n\\nBy evaluating and correcting retrieved data, CRAG ensures more reliable and factually accurate outputs.', '1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.', '**Better Robustness** :\\n\\nCRAG mitigates the risk of generating incorrect knowledge by dynamically addressing errors in the retrieval process.', '**Dynamic Adaptability** :\\n\\nThe integration of large-scale web searches allows CRAG to expand beyond static knowledge bases, providing up-to-date and diverse information.', '**Efficient Data Utilization** :\\n\\nThe decompose-then-recompose algorithm reduces noise and focuses on critical insights, ensuring the generated responses are both concise and relevant.', '1. **Generation with Decompose-then-Recompose Algorithm** :\\n\\nRetrieved documents are broken down into smaller components to focus on key insights while filtering out irrelevant or redundant details. The filtered information is recombined into a cohesive and concise dataset, optimizing the quality of data input for generation.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='high'), FieldBasis(field='timeline_of_milestones.8.year', reasoning=\"The field value identifies a milestone year (2025.0) within a timeline. Excerpts that explicitly reference a 2025 guide to Retrieval-Augmented Generation provide direct alignment with that year, supporting the notion of a 2025 milestone in the RAG domain. Specifically, the excerpt titled 'The 2025 Guide to Retrieval-Augmented Generation (RAG)' directly anchors the year 2025 in the RAG context, and the accompanying discussion about dynamic adaptability and up-to-date information further reinforces that 2025 is treated as a current or upcoming year for advancements in CRAG/RAG frameworks. These passages collectively map onto the target field value by confirming that significant RAG-related content is centered on or around 2025. Other excerpts discuss RAG concepts, metrics, or evaluation but do not explicitly anchor a 2025 milestone, so they provide contextual support without directly confirming the year-specific field value.\", citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '**Dynamic Adaptability** :\\n\\nThe integration of large-scale web searches allows CRAG to expand beyond static knowledge bases, providing up-to-date and diverse information.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='high'), FieldBasis(field='timeline_of_milestones.11.year', reasoning='The most relevant excerpt directly refers to a guide focused on Retrieval-Augmented Generation in 2025, establishing a clear linkage to the year 2025 within the RAG timeline. The other excerpts also describe 2025-focused content or milestones related to RAG (such as 2025 guides or advancements like CRAG and dynamic adaptability enabled by up-to-date information), which supports the notion of a 2025 milestone in the timeline. The remaining excerpts do not explicitly reference the year 2025 and thus provide only peripheral context, making them less directly supportive of the specific field value. In summary, the year 2025 is supported by multiple sources discussing 2025 guides and related advancements in RAG, aligning with the target milestone year in the timeline.\\n', citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '**Better Robustness** :\\n\\nCRAG mitigates the risk of generating incorrect knowledge by dynamically addressing errors in the retrieval process.', '**Dynamic Adaptability** :\\n\\nThe integration of large-scale web searches allows CRAG to expand beyond static knowledge bases, providing up-to-date and diverse information.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)'), Citation(url='https://dkaarthick.medium.com/ragas-for-rag-in-llms-a-comprehensive-guide-to-evaluation-metrics-3aca142d6e38', excerpts=['RAGAS introduces several metrics that provide a more holistic evaluation of RAG models, focusing on aspects like faithfulness, answer relevancy, context precision, and context recall.'], title='RAGAS for RAG in LLMs: A Comprehensive Guide to ...')], confidence='high'), FieldBasis(field='timeline_of_milestones.3.milestone_description', reasoning='The central claim describes a paper proposing a RAG approach with a self-correcting retriever that evaluates retrieved data quality and triggers web searches to self-correct. Several excerpts directly reflect this: one discusses corrective Retrieval-Augmented Generation (CRAG) as a framework designed to improve robustness when retrieved data is inaccurate, which aligns with the notion of a self-correcting retriever. Another excerpt explicitly states adaptive knowledge retrieval, where correct data is used for response generation and incorrect or ambiguous data triggers additional retrieval actions, often web searches, to augment the dataset. A third excerpt highlights dynamic adaptability by integrating large-scale web searches to keep information up-to-date and diverse, which supports the idea of triggering external searches as part of self-correction. Additional excerpts enumerate the advantages of CRAG, including improved accuracy, which resonates with the goal of robust, self-correcting retrieval. Supporting context about robustness mechanisms and data utilization further corroborates the overall concept, while a separate note on a decomposition-then-recompose algorithm illustrates how data can be organized to improve generation quality but is less central to the self-correcting retriever mechanism itself. Taken together, these excerpts collectively support the presence of a RAG method focused on self-assessment of retrieval quality and triggering web searches for self-correction, which matches the described fine-grained field value.\\n', citations=[Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.', '#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '**Dynamic Adaptability** :\\n\\nThe integration of large-scale web searches allows CRAG to expand beyond static knowledge bases, providing up-to-date and diverse information.', '#### **Advantages of CRAG**\\n\\n**Improved Accuracy** :\\n\\nBy evaluating and correcting retrieved data, CRAG ensures more reliable and factually accurate outputs.', '**Better Robustness** :\\n\\nCRAG mitigates the risk of generating incorrect knowledge by dynamically addressing errors in the retrieval process.', '**Efficient Data Utilization** :\\n\\nThe decompose-then-recompose algorithm reduces noise and focuses on critical insights, ensuring the generated responses are both concise and relevant.', '1. **Generation with Decompose-then-Recompose Algorithm** :\\n\\nRetrieved documents are broken down into smaller components to focus on key insights while filtering out irrelevant or redundant details. The filtered information is recombined into a cohesive and concise dataset, optimizing the quality of data input for generation.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='medium'), FieldBasis(field='timeline_of_milestones.9.category', reasoning='The most directly relevant evidence is a passage that explicitly introduces benchmarking of RAG systems by comparing RAGAS, BERTScore, and other metrics, which aligns with evaluating and ranking RAG-based approaches. Supporting this, another excerpt enumerates key metrics used in evaluating RAG performance (context relevance, context sufficiency, answer relevance, answer correctness, and answer hallucination), which underpins what a benchmark would measure. Additional excerpts discuss holistic evaluation metrics (coverage of faithfulness, answer relevancy, and context precision/recall) and a guide to corrective and adaptive strategies that influence how benchmarks might be designed or interpreted in practice. Together, these excerpts map directly to benchmarking activities and the kinds of metrics used to assess a RAG system‚Äôs performance, while others provide contextual background on robustness and adaptive retrieval that may influence benchmark design but are secondary to the core benchmarking focus. The combination of explicit benchmarking discussion and explicit metrics for evaluation provides coherent support for the finegrained field value ‚ÄúBenchmark.‚Äù', citations=[Citation(url='https://www.giskard.ai/knowledge/rag-benchmarking-for-ai-evaluation', excerpts=['RAGAS (Retrieval-Augmented Generation Assessment System) is an evaluation framework offering various metrics to measure the quality of a RAG model‚Äôs responses. Below is an explanation of these metrics along with usage examples:'], title='RAG Benchmarking: Comparing RAGAS, BERTScore, and ...'), Citation(url='https://www.patronus.ai/llm-testing/rag-evaluation-metrics', excerpts=['Five key metrics are used to evaluate RAG performance: context relevance, context sufficiency, answer relevance, answer correctness and answer hallucination.'], title='Best Practices for Evaluating RAG Systems'), Citation(url='https://dkaarthick.medium.com/ragas-for-rag-in-llms-a-comprehensive-guide-to-evaluation-metrics-3aca142d6e38', excerpts=['RAGAS introduces several metrics that provide a more holistic evaluation of RAG models, focusing on aspects like faithfulness, answer relevancy, context precision, and context recall.', 'aithfulness** measures the factual accuracy of the generated response based on the retrieved documents. **Formul', 'Answer Relevancy** evaluates how relevant the generated response is to the original query. **Formu'], title='RAGAS for RAG in LLMs: A Comprehensive Guide to ...'), Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.', '**Dynamic Adaptability** :\\n\\nThe integration of large-scale web searches allows CRAG to expand beyond static knowledge bases, providing up-to-date and diverse information.', '**Better Robustness** :\\n\\nCRAG mitigates the risk of generating incorrect knowledge by dynamically addressing errors in the retrieval process.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='high'), FieldBasis(field='timeline_of_milestones.1.milestone_description', reasoning='The fine-grained field value points to a seminal framework where the LLM learns to retrieve on-demand and critique its own generations to improve quality and factuality, thereby reducing hallucinations. The most directly relevant information is that Self-RAG is an advanced framework where the LLM is trained to perform self-critique during the retrieval and generation process, directly describing retrieval-on-demand and internal critique mechanisms. Additional context notes that Self-RAG (Self-Reflective RAG) emerged in late 2023, and that Agentic RAG marks a shift toward autonomous, self-directed retrieval and reasoning, which corroborates the idea of on-demand retrieval and internal assessment to enhance reliability. Collectively, these excerpts support the existence and characteristics of a seminal framework emphasizing retrieval-on-demand and self-critique to improve LLM outputs and reduce hallucinations.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. '], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='high'), FieldBasis(field='timeline_of_milestones.11.milestone_description', reasoning=\"The field value suggests a forum of scholarly concern regarding the depth and originality of LLM-generated summaries when they are tied to web sources. Related discussions in the excerpts touch on faithfulness, which measures how well a model's output aligns with source documents, and on robustness against incorrect data, both of which can influence whether summaries are shallow or surface-level versus deep and original. Excerpt describing faithfulness explicitly defines how responses should align with the source, which is a proxy for evaluating depth of understanding. Excerpts addressing robustness and corrective retrieval frameworks indicate ongoing efforts to mitigate inaccuracies that could otherwise degrade the perceived originality or depth of synthesis. While none of the excerpts state the exact concern verbatim, the most relevant pieces discuss foundational quality controls (faithfulness) and data integrity (robustness of retrieval) that underlie the risk of shallower summaries. Supporting context about how RAG evaluation emphasizes context relevance and answer relevancy further clarifies the standards by which summaries might be judged for depth and originality.\", citations=[Citation(url='https://www.giskard.ai/knowledge/rag-benchmarking-for-ai-evaluation', excerpts=['*Faithfulness  \\n   ** Faithfulness assesses the extent to which the model‚Äôs response is supported by information in the reference document. The response must align with the source or reference document without introducing unsupported information', ' **Answer Relevancy  \\n   ** Answer relevancy evaluates whether the model‚Äôs response is relevant to the question, even if it is not entirely accurate or detail'], title='RAG Benchmarking: Comparing RAGAS, BERTScore, and ...'), Citation(url='https://dkaarthick.medium.com/ragas-for-rag-in-llms-a-comprehensive-guide-to-evaluation-metrics-3aca142d6e38', excerpts=['RAGAS introduces several metrics that provide a more holistic evaluation of RAG models, focusing on aspects like faithfulness, answer relevancy, context precision, and context recall.'], title='RAGAS for RAG in LLMs: A Comprehensive Guide to ...'), Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '**Dynamic Adaptability** :\\n\\nThe integration of large-scale web searches allows CRAG to expand beyond static knowledge bases, providing up-to-date and diverse information.', '**Better Robustness** :\\n\\nCRAG mitigates the risk of generating incorrect knowledge by dynamically addressing errors in the retrieval process.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)'), Citation(url='https://www.patronus.ai/llm-testing/rag-evaluation-metrics', excerpts=['Five key metrics are used to evaluate RAG performance: context relevance, context sufficiency, answer relevance, answer correctness and answer hallucination.'], title='Best Practices for Evaluating RAG Systems'), Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. ', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n'], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='timeline_of_milestones.1.year', reasoning='The target field value specifies a milestone year of 2023 within the timeline. The most relevant excerpt explicitly anchors the timeframe to late 2023, directly supporting the 2023.0 year value for the milestone. The remaining excerpts discuss the broader evolution of retrieval-augmented approaches (Self-RAG and Agentic RAG) and imply a recent, post-static knowledge shift that aligns with a 2023 timeframe, providing supporting context for a 2023 milestone without contradicting it. Collectively, these excerpts establish that around late 2023 there were notable developments in self-critique during retrieval (Self-RAG) and a move toward autonomous, self-directed retrieval and reasoning, which is consistent with a 2023 milestone in the timeline. Therefore, they are relevant to validating the year field value.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=[' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. '], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='medium'), FieldBasis(field='timeline_of_milestones.9.milestone_description', reasoning='Several excerpts describe comprehensive evaluation frameworks, metrics, and practices for RAG and related retrieval-augmented systems, which are closely aligned with the concept of an evaluation suite for deep-research tasks. For example, one excerpt discusses best practices for evaluating RAG systems and outlines key metrics such as context relevance, context sufficiency, answer relevance, answer correctness, and hallucination mitigation, which directly map to assessing an agent‚Äôs ability to locate, assess, and integrate information from sources. Another excerpt offers an overview of RAGAS-type metrics, detailing how to measure answer relevancy and faithfulness, which are critical components of a robust evaluation suite that governs how well an agent retrieves and uses source material. Additional excerpts describe benchmarking RAG models and comparing various evaluation metrics (e.g., RAGAS, BERTScore), which further illustrate structured, multi-faceted assessment approaches for retrieval-augmented systems. There are also discussions of adaptive retrieval frameworks and corrective or dynamic RAG concepts, which underscore the need for evaluation schemes that account for correctness, up-to-dateness, and the ability to revise retrieved data, all of which are essential features of a ‚Äúdeep research‚Äù task evaluation suite. While none of the excerpts explicitly states a milestone labeled as a comprehensive evaluation suite for deep research tasks, the content collectively supports the components and design considerations such a suite would encompass (relevance, faithfulness, context handling, up-to-dateness, and iterative verification and integration of evidence). In sum, the excerpts provide substantial, thematically aligned evidence about how a comprehensive evaluation framework for deep, web-backed research tasks would be structured and what metrics would be used, even though they do not confirm the exact milestone described in the field value.', citations=[Citation(url='https://www.patronus.ai/llm-testing/rag-evaluation-metrics', excerpts=['Five key metrics are used to evaluate RAG performance: context relevance, context sufficiency, answer relevance, answer correctness and answer hallucination.'], title='Best Practices for Evaluating RAG Systems'), Citation(url='https://www.giskard.ai/knowledge/rag-benchmarking-for-ai-evaluation', excerpts=['RAGAS (Retrieval-Augmented Generation Assessment System) is an evaluation framework offering various metrics to measure the quality of a RAG model‚Äôs responses. Below is an explanation of these metrics along with usage examples:'], title='RAG Benchmarking: Comparing RAGAS, BERTScore, and ...'), Citation(url='https://dkaarthick.medium.com/ragas-for-rag-in-llms-a-comprehensive-guide-to-evaluation-metrics-3aca142d6e38', excerpts=['RAGAS introduces several metrics that provide a more holistic evaluation of RAG models, focusing on aspects like faithfulness, answer relevancy, context precision, and context recall.', 'Answer Relevancy** evaluates how relevant the generated response is to the original query. **Formu', 'aithfulness** measures the factual accuracy of the generated response based on the retrieved documents. **Formul'], title='RAGAS for RAG in LLMs: A Comprehensive Guide to ...'), Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['1. **Adaptive Knowledge Retrieval** :\\n\\nCorrect data is directly used for response generation. For Incorrect or Ambiguous Data, ittriggers additional retrieval actions, often web searches, to augment the original dataset with more reliable or diverse information.', '**Dynamic Adaptability** :\\n\\nThe integration of large-scale web searches allows CRAG to expand beyond static knowledge bases, providing up-to-date and diverse information.', '**Better Robustness** :\\n\\nCRAG mitigates the risk of generating incorrect knowledge by dynamically addressing errors in the retrieval process.', '#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='medium'), FieldBasis(field='timeline_of_milestones.8.category', reasoning='The strongest support for a Timeline category labeled as Benchmark comes from an excerpt explicitly titled with benchmarking and comparison among evaluation methods in RAG systems. It discusses benchmarking RAGs against alternatives such as RAGAS and BERTScore, which directly aligns with a ‚ÄòBenchmark‚Äô category in a milestones timeline. Additional support comes from excerpts that outline evaluation metrics and benchmarking-like assessments for RAG systems, including lists of metrics and how they measure faithfulness, context relevance, and answer relevance. These pieces collectively reinforce the idea that benchmarking is a key milestone theme, even if they do not spell out the exact timeline field value. The remaining excerpts contribute context about retrieval-augmented generation, robustness, and metrics (e.g., faithfulness, answer relevancy, context precision/recall) that underpin benchmarking work, though they are less directly tied to the explicit concept of a benchmark in a timeline. In summary, the strongest alignment is with explicit benchmarking discussions; supportive alignment comes from broader evaluation-metric discussions; peripheral alignment comes from surrounding RAG/CRAG content that informs benchmarking context.', citations=[Citation(url='https://www.giskard.ai/knowledge/rag-benchmarking-for-ai-evaluation', excerpts=['*Faithfulness  \\n   ** Faithfulness assesses the extent to which the model‚Äôs response is supported by information in the reference document. The response must align with the source or reference document without introducing unsupported information'], title='RAG Benchmarking: Comparing RAGAS, BERTScore, and ...'), Citation(url='https://www.patronus.ai/llm-testing/rag-evaluation-metrics', excerpts=['Five key metrics are used to evaluate RAG performance: context relevance, context sufficiency, answer relevance, answer correctness and answer hallucination.'], title='Best Practices for Evaluating RAG Systems'), Citation(url='https://dkaarthick.medium.com/ragas-for-rag-in-llms-a-comprehensive-guide-to-evaluation-metrics-3aca142d6e38', excerpts=['RAGAS introduces several metrics that provide a more holistic evaluation of RAG models, focusing on aspects like faithfulness, answer relevancy, context precision, and context recall.', 'Answer Relevancy** evaluates how relevant the generated response is to the original query. **Formu'], title='RAGAS for RAG in LLMs: A Comprehensive Guide to ...'), Citation(url='https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag', excerpts=['#### **What is Corrective RAG (CRAG)?\\n**\\n\\nCorrective Retrieval-Augmented Generation (CRAG) is a framework for Retrieval-Augmented Generation (RAG) designed to improve robustness when dealing with inaccuracies in retrieved data', '**Dynamic Adaptability** :\\n\\nThe integration of large-scale web searches allows CRAG to expand beyond static knowledge bases, providing up-to-date and diverse information.', '**Better Robustness** :\\n\\nCRAG mitigates the risk of generating incorrect knowledge by dynamically addressing errors in the retrieval process.'], title='The 2025 Guide to Retrieval-Augmented Generation (RAG)')], confidence='high'), FieldBasis(field='timeline_of_milestones.1.associated_work', reasoning='The target field value is Self-RAG, which corresponds to the Self-Reflective RAG concept within the evolution of retrieval augmentation for LLMs. The most directly relevant excerpts explicitly describe Self-RAG as an advanced framework where the LLM performs self-critique during retrieval and generation, and outline Self-RAG as part of the evolution toward more autonomous retrieval and reasoning processes. These passages directly mention the term Self-RAG and define its role, providing concrete support for the field value. Additional excerpts mention Self-RAG in a contextual sense (e.g., noting Self-RAG in late 2023 or describing related self-reflective capabilities). While these still support the relevance of Self-RAG to the timeline of advancements, they are slightly less direct than the explicit definitions and descriptions, hence their placement after the most directly supportive excerpts. The excerpt discussing Agentic RAG offers context about a broader shift but does not center on the exact term Self-RAG, making it the least direct support among the provided excerpts.', citations=[Citation(url='https://blog.nashtechglobal.com/evolution-of-rag-from-static-knowledge-to-agentic-reasoning/', excerpts=['* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', '* Self-RAG is an advanced framework where the Large Language Model (LLM) is trained to perform self-critique during the retrieval and generation process.', ' Self-RAG (Self-Reflective RAG) ‚Äì Late 2023\\n\\n', ' Agentic RAG signifies the key industry shift from relatively static retrieval augmentation to autonomous, self-directed retrieval and reasoning, though it necessitates addressing new challenges in reliability, evaluation, and ethical governance. '], title='Evolution of RAG from Static Knowledge to Agentic ...')], confidence='high'), FieldBasis(field='timeline_of_milestones.6.milestone_description', reasoning='The target field value describes a benchmark explicitly designed to measure how accurately LLMs ground their responses in provided source documents and avoid hallucinations. Excerpts that introduce holistic evaluation metrics for RAG systems‚Äîsuch as faithfulness, which assesses whether the response is supported by retrieved documents, and answer relevancy, which gauges alignment with the query‚Äîdirectly support this concept. Furthermore, best-practice discussions of evaluation metrics (context relevance, context sufficiency, answer relevance, answer correctness, and hallucination) map closely to the notion of a benchmark focused on grounding and hallucination avoidance. Text describing RAGAS‚Äôs emphasis on faithfulness, answer relevancy, and context-related metrics, as well as CRAG‚Äôs approach to mitigating incorrect data through corrective retrieval and improved robustness, provide concrete mechanisms by which such a benchmark could operate and be evaluated. Although there is no explicit statement naming Google DeepMind or Kaggle as release parties for the benchmark, the cited material collectively substantiates the existence and design of benchmarking frameworks that assess grounding fidelity and hallucination resistance, which aligns with the requested field value.', citations=[Citation(url='https://dkaarthick.medium.com/ragas-for-rag-in-llms-a-comprehensive-guide-to-evaluation-metrics-3aca142d6e38', excerpts=['RAGAS introduces several metrics that provide a more holistic evaluation of RAG models, focusing on aspects like faithfulness, answer relevancy, context precision, and context recall.', 'Answer Relevancy** evaluates how relevant the generated response is to the original query. **Formu', 'aithfulness** measures the factual accuracy of the generated response based on the retrieved documents. **Formul'], title='RAGAS for RAG in LLMs: A Comprehensive Guide to ...'), Citation(url='https://www.patronus.ai/llm-testing/rag-evaluation-metrics', excerpts=['Five key metrics are used to evaluate RAG performance: context relevance, context sufficiency, answer relevance, answer correctness and answer hallucination.'], title='Best Practices for Evaluating RAG Systems'), Citation(url='https://www.giskard.ai/knowledge/rag-benchmarking-for-ai-evaluation', excerpts=['*Faithfulness  \\n   ** Faithfulness assesses the extent to which the model‚Äôs response is supported by information in the reference document. The response must align with the source or reference document without introducing unsupported information', 'RAGAS (Retrieval-Augmented Generation Assessment System) is an evaluation framework offering various metrics to measure the quality of a RAG model‚Äôs responses. Below is an explanation of these metrics along with usage examples:', ' **Answer Relevancy  \\n   ** Answer relevancy evaluates whether the model‚Äôs response is relevant to the question, even if it is not entirely accurate or detail'], title='RAG Benchmarking: Comparing RAGAS, BERTScore, and ...')], confidence='medium')], content={'report_summary': \"Academic research in web search for Large Language Models (LLMs) from late 2023 to late 2025 has been characterized by rapid evolution and the convergence of three core areas: Retrieval-Augmented Generation (RAG), LLM-powered search engines, and autonomous LLM agents. This period saw a paradigm shift from static information retrieval to dynamic, agentic reasoning. RAG architectures evolved from basic retrieval to advanced, self-correcting, and adaptive systems like Self-RAG and CRAG, which learn to critique and refine retrieved information. The introduction of GraphRAG and multimodal RAG (e.g., OmniSearch) further expanded capabilities to handle structured and non-textual data. Concurrently, 2025 was widely recognized as the 'year of agents,' marked by a surge in research using Reinforcement Learning (RL) to train LLMs to autonomously plan, use tools (including web search), and synthesize information (e.g., R1-Searcher, Search-R1). Major industry players like Google (AI Overviews) and Microsoft (Copilot) integrated LLMs into their search products, leading to a 'zero-click' future and significant impacts on the publisher ecosystem. This progress was paralleled by the development of sophisticated benchmarks to address critical challenges like factuality (FACTS Grounding), long-document reasoning (SummHay, LiveResearchBench), and security (SafeRAG), revealing both the advanced capabilities and persistent weaknesses of state-of-the-art models. Architectural trends toward longer context windows, multimodality, and more efficient models (e.g., Mixture-of-Experts) have provided the foundation for these advancements, though open problems related to evaluation, security, bias, and the cognitive impact on users remain active areas of investigation.\", 'clarification_of_scope': \"For the purpose of this report, the term 'web search for LLMs' is interpreted as a broad and evolving field encompassing three interconnected pillars. This interpretation is based on the consensus in recent academic literature and market trends, which see these areas converging. The three pillars are: 1. **Retrieval-Augmented Generation (RAG):** This refers to the family of techniques where LLMs are connected to external knowledge sources, including web content, to ground their responses in factual, up-to-date information. This is a foundational method for mitigating hallucinations, enhancing accuracy, and providing answers based on proprietary or real-time data. The scope includes the evolution from basic RAG to advanced, modular, and agentic RAG systems. 2. **LLM-powered Search Engines:** This pillar covers the integration of LLMs into the core functionality of search engines. It represents a shift from traditional keyword-based ranked lists to conversational, generative search experiences where the LLM synthesizes information from multiple web sources to provide a single, coherent answer, often with citations. Examples include Google's AI Overviews and Microsoft Copilot's web grounding. 3. **LLM Browsing Agents/Tools:** This refers to LLMs that act as autonomous or semi-autonomous agents capable of interacting with the web. These agents can perform multi-step tasks, navigate websites, use various tools (e.g., search APIs, calculators), and extract and synthesize information to fulfill complex user requests. Research in this area focuses on planning, tool-use protocols, and training agents with methods like Reinforcement Learning. The research indicates a significant blurring of lines, where advanced RAG systems become agentic and LLM-powered search engines incorporate agent-like capabilities.\", 'timeline_of_milestones': [{'year': 2023.0, 'period': 'Q3-Q4', 'milestone_description': 'Introduction of a reference-free suite of metrics for the automated evaluation of RAG system quality across multiple dimensions, including faithfulness and answer relevance.', 'category': 'Benchmark', 'associated_work': 'RAGAS'}, {'year': 2023.0, 'period': 'October', 'milestone_description': 'A seminal paper introducing a framework where an LLM learns to retrieve on-demand and critique its own generations to enhance quality and factuality, reducing hallucinations.', 'category': 'Paper', 'associated_work': 'Self-RAG'}, {'year': 2023.0, 'period': 'December', 'milestone_description': \"Launch of Google's next-generation multimodal model, which would become the core technology for its AI-powered search features.\", 'category': 'Model Release', 'associated_work': 'Google Gemini'}, {'year': 2024.0, 'period': 'January', 'milestone_description': 'A paper proposing a RAG method that enhances robustness with a self-correcting retriever that assesses retrieval quality and triggers web searches for self-correction.', 'category': 'Paper', 'associated_work': 'Corrective Retrieval Augmented Generation (CRAG)'}, {'year': 2024.0, 'period': 'May', 'milestone_description': 'Meta introduces a challenging benchmark for General AI Assistants, featuring complex, multi-step problems requiring tool use, including web browsing.', 'category': 'Benchmark', 'associated_work': 'GAIA Benchmark'}, {'year': 2024.0, 'period': 'May', 'milestone_description': 'Google begins rolling out its generative search experience, powered by the Gemini model, to all users in the U.S., marking a major shift in consumer search.', 'category': 'Industry Launch', 'associated_work': 'Google AI Overviews'}, {'year': 2024.0, 'period': 'December', 'milestone_description': 'Google DeepMind and Kaggle release a benchmark to evaluate how accurately LLMs ground their responses in provided source documents and avoid hallucinations.', 'category': 'Benchmark', 'associated_work': 'FACTS Grounding Benchmark'}, {'year': 2025.0, 'period': 'Q1', 'milestone_description': 'A series of papers are released focusing on using Reinforcement Learning (RL) to train LLMs to effectively leverage search engines and reason with search results.', 'category': 'Paper', 'associated_work': 'R1-Searcher, Search-R1, ReSearch'}, {'year': 2025.0, 'period': 'Q1', 'milestone_description': 'Introduction of the first security-focused benchmark for RAG pipelines, cataloging attack classes and evaluating the vulnerability of existing systems.', 'category': 'Benchmark', 'associated_work': 'SafeRAG'}, {'year': 2025.0, 'period': 'Q2', 'milestone_description': \"Launch of a comprehensive evaluation suite for 'deep research' tasks, assessing agents on their ability to iteratively seek, validate, and integrate evidence from the web.\", 'category': 'Benchmark', 'associated_work': 'LiveResearchBench and DeepEval'}, {'year': 2025.0, 'period': 'Mid', 'milestone_description': \"The discourse in the research community notably shifts from traditional RAG towards 'Agentic RAG,' where autonomous agents plan and execute complex retrieval and reasoning workflows.\", 'category': 'Research Trend', 'associated_work': 'Agentic RAG'}, {'year': 2025.0, 'period': 'September', 'milestone_description': 'An academic study raises concerns that LLM-generated summaries, despite being linked to web sources, may lead to shallower knowledge and less original thought compared to traditional search.', 'category': 'Paper', 'associated_work': 'Study on Learning Depth'}], 'rag_advancements_analysis': \"The evolution of Retrieval-Augmented Generation (RAG) from late 2023 to late 2025 marks a significant progression from a simple retrieval-and-generation pipeline to highly sophisticated, modular, and agentic systems. This evolution reflects a deeper integration of reasoning, self-correction, and autonomous decision-making into the retrieval process, fundamentally transforming how Large Language Models (LLMs) interact with external knowledge.\\n\\n1.  **Basic RAG (Pre-2023):** The foundational RAG architecture, as introduced by Lewis et al. in 2020, involves a straightforward three-step process: indexing a knowledge base, retrieving relevant documents based on a user query, and feeding these documents as context to an LLM for answer generation. This approach was widely adopted by 2023 to mitigate hallucinations and update the factual knowledge of LLMs. While easy and cheap to implement with low latency, Basic RAG suffered from several limitations, including low precision due to irrelevant retrieved chunks, the 'lost-in-the-middle' problem where information in the middle of a long context is ignored, and difficulty in answering questions that require synthesizing information from multiple sources.\\n\\n2.  **Advanced and Modular RAG (Late 2023 - 2024):** The period saw a shift towards more sophisticated RAG architectures. A 2024 taxonomy distinguished between Naive RAG, Advanced RAG (with pre-retrieval and post-retrieval enhancements like reranking), and Modular RAG. Modular RAG, as conceptualized by Gao et al. in late 2023, treats the RAG pipeline as a flexible toolkit of interchangeable components. This allows for highly optimized, use-case-specific workflows by incorporating modules for query transformation, routing, and advanced retrieval strategies. This phase also saw the rise of retriever-centric (e.g., optimizing chunking, reranking) and generator-centric (e.g., iterative reasoning) designs. While offering greater flexibility and performance, Modular RAG introduced significant engineering complexity and debugging challenges.\\n\\n3.  **Self-Correcting and Active RAG (Late 2023 - 2024):** This stage introduced more intelligence into the retrieval process. Techniques like **SELF-RAG** (late 2023) empowered the LLM to perform self-critique during both retrieval and generation. It learns to generate 'reflection tokens' that trigger on-demand retrieval and assess the relevance of retrieved passages, making the process adaptive. Similarly, **Corrective RAG (CRAG)** (Jan 2024) introduced a lightweight retrieval evaluator to assess the quality of retrieved documents and trigger corrective actions, such as web searches, if the information is deemed incorrect or ambiguous. These approaches significantly enhanced the factuality and robustness of RAG systems by actively mitigating the impact of irrelevant or misleading context.\\n\\n4.  **Agentic RAG (Late 2024 - 2025):** This represents the latest paradigm shift, where the RAG process is driven by an autonomous 'Agent'. An Agentic RAG system can plan a sequence of actions, including iterative querying, reading documents, using external tools (like calculators or code interpreters), and performing self-correction. This architecture integrates reflection, planning, and tool use, moving from a static retrieval pipeline to a dynamic, self-directed reasoning process. LlamaIndex identified this as a major trend for 2025, noting that it blurs the lines between RAG and agent platforms. Agentic RAG excels at solving complex, multi-step problems that require intelligent decision-making but comes at the cost of higher latency and token consumption due to the sequential nature of tool calls and the LLM's need to 'think' through its steps. This evolution is also tied to the concept of 'Context Engineering' or 'RAG 2.0', which focuses on strategically filling the context window with the most relevant information at each step of an agent's trajectory.\", 'specific_rag_techniques': [{'technique_name': 'SELF-RAG', 'year_introduced': 2023.0, 'core_concept': \"An LLM is trained to generate special 'reflection' tokens that enable it to perform on-demand retrieval and self-critique. It adaptively decides when to retrieve information and evaluates the quality and relevance of retrieved passages before generating a response.\", 'key_benefit': 'Improves factuality, reduces hallucinations, and enhances transparency through citations by making the retrieval process adaptive and self-correcting.', 'key_paper_or_source': 'Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection (Asai et al., 2023 / ICLR 2024)'}, {'technique_name': 'Corrective Retrieval Augmented Generation (CRAG)', 'year_introduced': 2024.0, 'core_concept': \"Employs a lightweight retrieval evaluator to assess the quality of retrieved documents. If documents are deemed incorrect or ambiguous, it triggers corrective actions, including large-scale web searches, to find better information. It uses a 'Decompose-then-Recompose' algorithm to filter and synthesize knowledge.\", 'key_benefit': 'Enhances the robustness of RAG against inaccurate or low-quality retrieved information, improving overall factuality and reliability.', 'key_paper_or_source': 'Corrective Retrieval Augmented Generation (Jan 2024)'}, {'technique_name': 'FLARE (Forward-Looking Active Retrieval)', 'year_introduced': 2023.0, 'core_concept': 'An active retrieval method that iteratively uses a prediction of the upcoming sentence as a query to retrieve relevant documents. It dynamically decides when to retrieve information to balance computational cost and effectiveness.', 'key_benefit': 'Improves efficiency and performance by optimizing the timing and relevance of retrieval actions, reducing computational costs by 30-50% without compromising performance.', 'key_paper_or_source': 'Active Retrieval Augmented Generation (May 2023)'}, {'technique_name': 'GraphRAG', 'year_introduced': 2024.0, 'core_concept': 'Integrates knowledge graphs with text retrieval. It leverages the structured nature of graphs to represent and retrieve information, helping to bridge the semantic gap between user queries and documents.', 'key_benefit': 'Enhances reasoning, addresses query diversity, and improves retrieval of n-ary relational facts by combining structured graph knowledge with unstructured text.', 'key_paper_or_source': 'GraphRAG (2024), with surveys and advancements like HyperGraphRAG in 2025.'}, {'technique_name': 'Multimodal RAG (e.g., SAM-RAG, OmniSearch)', 'year_introduced': 2024.0, 'core_concept': 'Extends RAG beyond text to handle multimodal data, including images, audio, and video. Systems like SAM-RAG dynamically filter documents and verify evidence in multimodal contexts, while OmniSearch plans multi-hop retrieval chains for complex visual-question-answering.', 'key_benefit': 'Enables grounding in and reasoning over multiple data types, allowing for more comprehensive analysis and answering of complex queries involving both text and visual evidence.', 'key_paper_or_source': 'SAM-RAG (Zhai 2024), OmniSearch (Li 2024)'}, {'technique_name': 'RECOMP', 'year_introduced': 2023.0, 'core_concept': 'A compression technique that compresses retrieved documents into concise textual summaries before they are passed to the LLM.', 'key_benefit': 'Reduces the computational load and context window requirements for the LLM by providing a condensed version of the retrieved information.', 'key_paper_or_source': 'RECOMP (Oct 2023)'}, {'technique_name': 'RAGAS (Retrieval-Augmented Generation Assessment)', 'year_introduced': 2023.0, 'core_concept': 'A framework and suite of reference-free metrics designed for the automated evaluation of RAG systems. It assesses dimensions like faithfulness, context precision, context recall, and answer relevance.', 'key_benefit': 'Provides a standardized, automated way to evaluate and benchmark the performance of RAG pipelines, helping to identify and penalize hallucinations and improve grounding.', 'key_paper_or_source': 'RAGAS: Automated Evaluation of Retrieval Augmented Generation (Es et al., Sep 2023)'}, {'technique_name': 'MS-RAG (Multi-Stage RAG)', 'year_introduced': 2025.0, 'core_concept': 'A framework that enhances retrieval precision by integrating dense (neural) and sparse (BM25) retrieval with reinforcement learning optimization in a hybrid, multi-stage pipeline.', 'key_benefit': 'Improves retrieval precision, factual consistency, and reduces hallucinations while also decreasing token usage and inference time compared to standard RAG.', 'key_paper_or_source': 'MS-RAG (2025)'}, {'technique_name': 'SafeRAG', 'year_introduced': 2025.0, 'core_concept': 'The first security benchmark for RAG pipelines, cataloging four classes of attacks (silver noise, context conflict, soft-ad, DoS) to evaluate the security and robustness of RAG systems against manipulation.', 'key_benefit': 'Provides a framework for systematically testing and improving the security and robustness of RAG systems against adversarial attacks.', 'key_paper_or_source': 'SafeRAG: A Security Benchmark for Retrieval-Augmented Generation (Liang et al., 2025)'}], 'agentic_llm_evolution': \"The evolution of agentic Large Language Models (LLMs) for web search between late 2023 and late 2025 represents a fundamental paradigm shift from passive information retrieval to active, autonomous problem-solving. This progression, often termed 'Agentic Deep Research' or 'Agentic Reinforcement Learning' (Agentic RL), has been driven by advancements in reinforcement learning, the formalization of tool-use protocols, and the development of sophisticated multi-step reasoning capabilities, effectively blurring the lines between search engines and autonomous agents.\\n\\nThe core of this evolution lies in moving beyond supervised fine-tuning (SFT) to training methods that enable agents to perceive, reason, plan, and adapt in dynamic web environments. Reinforcement Learning (RL) has been the key enabler. Instead of just predicting the next token, agents are trained to take actions (like issuing a search query or clicking a link) to maximize a reward. These rewards are increasingly sophisticated:\\n\\n1.  **Reinforcement Learning on Search Outcomes:** Early methods used simple rewards, but by 2025, systems began using complex, outcome-based rewards. For example, agents are rewarded based on the final accuracy or completeness of their answer, incentivizing them to learn effective, multi-step search strategies. Proximal Policy Optimization (PPO) variants became a common strategy, used in systems like R1-Searcher to first learn *when* to search and then *how* to use the results. Other approaches like Direct Preference Optimization (DPO) are used to align agent behavior with human feedback, as seen in WebThinker, which tackles complex report generation.\\n\\n2.  **Simulated Feedback and Self-Play:** A significant challenge in training with live web search is the high cost of API calls and the instability caused by noisy, real-world data. To mitigate this, researchers developed methods using simulated environments. Systems like ZeroSearch and SSRL (Self-Supervised RL) employ offline 'self-search' during training, where the agent interacts with a pseudo search engine distilled from other LLMs. This enhances training efficiency, stability, and controllability while reducing reliance on costly real-time APIs.\\n\\n3.  **Tool-Use Protocols and Multi-Step Reasoning:** The ability of agents to use tools is central to their evolution. The ReAct (Reason + Act) architecture, which involves a loop of thought, action, and observation, became a foundational protocol for enabling agents to iteratively solve tasks. This allows agents to perform complex, multi-step research processes that involve planning, issuing multiple search queries, consulting documents, and even collaborating with other specialized agents. Agents learn to reformulate queries based on initial findings, demonstrating a dynamic understanding of the information-seeking process. Protocols like the Model Context Protocol (MCP) have also been proposed to improve quality by separating web search functionalities from the LLM's core reasoning 'brain', allowing for more specialized and reliable tool use.\\n\\nThis evolution has created autonomous search agents capable of in-depth analysis, synthesizing insights, and drafting comprehensive reports. However, it also introduces new challenges, including 'action hallucinations' (fabricating tool call information), getting stuck in repetitive loops, and the critical need for robust safety guardrails and human oversight to manage the risks of live, autonomous web browsing.\", 'representative_agentic_systems': [{'system_name': 'R1-Searcher', 'year': 2025.0, 'core_methodology': 'Reinforcement Learning using a two-stage, cold-start Proximal Policy Optimization (PPO) strategy.', 'key_contribution': 'Incentivizes and trains LLMs to first learn *when* to invoke a web search and then *how* to effectively utilize the retrieved information.', 'associated_paper': 'R1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning (arXiv:2503.05592)'}, {'system_name': 'Search-R1', 'year': 2025.0, 'core_methodology': 'Reinforcement Learning with retrieved-token masking and outcome-based rewards, training the agent to interact with live web search APIs.', 'key_contribution': 'Trains LLMs to learn sophisticated strategies for tool interaction and fosters emergent cognitive behaviors for complex, deep research tasks.', 'associated_paper': 'Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning (arXiv:2503.09516)'}, {'system_name': 'ReSearch', 'year': 2025.0, 'core_methodology': 'Fully end-to-end Reinforcement Learning with Proximal Policy Optimization (PPO) that does not rely on pre-existing supervised tool-use trajectories.', 'key_contribution': 'Demonstrates a purely RL-based approach to training search agents without the need for initial supervised data.', 'associated_paper': 'Mentioned in research on agentic LLMs in March 2025.'}, {'system_name': 'WebDancer', 'year': 2025.0, 'core_methodology': 'Combines supervision from human browsing trajectories with Reinforcement Learning (RL) fine-tuning.', 'key_contribution': 'Produces autonomous ReAct-style agents that learn effective web navigation and interaction strategies from expert human behavior.', 'associated_paper': 'Mentioned as a system that excels on GAIA and WebWalkerQA benchmarks in 2025.'}, {'system_name': 'WebThinker', 'year': 2025.0, 'core_methodology': \"Embeds a 'Deep Web Explorer' into a think-search-draft loop, with behavior aligned via Direct Preference Optimization (DPO) using human feedback.\", 'key_contribution': 'Aligns agent behavior with human preferences to tackle complex report generation tasks, ensuring outputs are more useful and aligned.', 'associated_paper': 'Mentioned in research on agentic LLMs in 2025.'}, {'system_name': 'Search-o1', 'year': 2025.0, 'core_methodology': 'An agentic RAG mechanism integrated with Large Reasoning Models (LRMs) for dynamic, inference-time retrieval based on identified knowledge gaps.', 'key_contribution': \"Enhances the reasoning capabilities of powerful models like OpenAI's o1 by allowing them to dynamically search for and process external knowledge as needed.\", 'associated_paper': 'Search-o1: An Agentic RAG Mechanism for Large Reasoning Models (Li et al., 2025)'}, {'system_name': 'DeepResearch', 'year': 2025.0, 'core_methodology': 'A multi-agent system that coordinates specialized sub-agents for querying and summarization, using models to autonomously drive reflection.', 'key_contribution': 'Demonstrates a collaborative agent approach where different agents handle distinct parts of the research process.', 'associated_paper': 'Mentioned as an example of an Agentic-Based Approach in 2025.'}, {'system_name': 'ASearcher', 'year': 2025.0, 'core_methodology': 'Utilizes large-scale asynchronous Reinforcement Learning (RL) with synthesized Question-Answering (QA) data.', 'key_contribution': 'Enables agents to handle long-horizon search tasks that may require 40 or more sequential tool calls, outperforming prior open-source methods.', 'associated_paper': 'Mentioned in research on agentic LLMs in 2025.'}, {'system_name': 'SSRL (Self-Supervised RL)', 'year': 2025.0, 'core_methodology': \"Performs entirely offline 'self-search' during training by interacting with a pseudo search engine distilled from LLMs.\", 'key_contribution': 'Reduces reliance on costly and unstable live web APIs during training, allowing for seamless transfer to online inference.', 'associated_paper': 'Mentioned in research on agentic LLMs in 2025.'}], 'llm_powered_search_engine_integration': \"The integration of Large Language Models (LLMs) into the core functionality of search engines has given rise to a new paradigm known as 'generative search'. This represents a fundamental shift from the traditional web search model, which presents users with a ranked list of independent web pages. In contrast, generative search engines like Google's AI Overviews, Microsoft Copilot, and ChatGPT Search leverage LLMs to retrieve information from a wide array of web pages and then synthesize this data into a single, coherent, conversational text response. This approach aims to provide direct, synthesized answers, often with citations, thereby reducing the user's need to click through multiple links. This trend is leading towards a 'zero-click' future, which has significant implications for publishers and the SEO ecosystem, as it can drastically reduce referral traffic. Academic research from 2025 characterizes this evolution, noting that while early 2023 versions were often plagued by hallucinations, by 2025, major platforms have become genuinely useful and more reliable. Beyond just generating answers, LLMs are also being employed for more nuanced search tasks, including advanced query understanding, re-ranking search results, and proactively generating clarifying questions to better understand user intent. This deeper integration is transforming search into a more interactive, intelligent, and conversational experience, fundamentally altering how users seek and consume information on the web.\", 'major_industry_implementations': [{'company': 'Google', 'product_name': 'AI Overviews', 'underlying_llm': 'Custom Gemini model (including Gemini 1.5 Pro with a 2 million token context window)', 'technical_integration_pattern': \"AI Overviews are deeply integrated with Google's existing Search systems and vast web index. The system is powered by a custom Gemini model that leverages multi-step reasoning, planning, and multimodality to synthesize information from various web sources into a single summary. The underlying Gemini 1.5 Pro model's massive 2 million token context window allows it to process extensive amounts of data for generating comprehensive responses. The goal is to provide quick, synthesized answers, with a full-screen, conversational 'AI Mode' also being tested in Search Labs.\", 'quality_control_mechanism': \"Google implements algorithmic and manual guardrails to prevent policy violations. However, the initial public rollout in May 2024 faced significant criticism, with independent analysis showing that 40-60% of initial AI-generated previews contained factually incorrect or misleading information. While Gemini's general hallucination rate is cited as low (2.6%), it has shown a very high rate (76.7%) in specific high-stakes domains like financial referencing. For attribution, Google claims that links within AI Overviews receive more clicks than traditional web listings and that the feature encourages visits to a greater diversity of websites, implying a citation mechanism is in place.\"}, {'company': 'Microsoft', 'product_name': 'Copilot (including Microsoft 365 Copilot and Copilot Chat)', 'underlying_llm': 'GPT-4 and other models from its partnership with OpenAI', 'technical_integration_pattern': \"Microsoft Copilot's integration is heavily enterprise-focused, emphasizing security and data privacy. It uses a process called 'grounding' to preprocess prompts, accessing real-time web information via the Bing Index and internal organizational data via the Microsoft Graph. A 'Semantic Index' enhances the Microsoft Graph by embedding semantic understanding, improving Copilot's ability to find relevant internal content. Copilot Agents can automate tasks by connecting to data sources via APIs. For web searches, only essential keywords are sent to Bing, with user and tenant identifiers removed, and all data remains within the Microsoft 365 service boundary.\", 'quality_control_mechanism': \"Copilot employs multiple layers of quality and safety controls. It enforces Responsible AI (RAI) protections to automatically reject risky terms. Source citations are provided directly in the UI for user verification. The system's real-time web grounding is designed to mitigate hallucinations and ensure information is current. For governance, Microsoft is rolling out features like the 'Content Governance Agent' (Preview Nov 2025) and 'Microsoft Purview AI Observability' (Preview Dec 2025) to help administrators manage risk and enforce policies. Contractual commitments ensure that enterprise query data is not used to train AI models or for advertising.\"}, {'company': 'OpenAI', 'product_name': 'ChatGPT (Browsing/Agent Modes), Deep Research Agent, o1 model', 'underlying_llm': 'GPT-4, GPT-4o, o1 (a large reasoning model)', 'technical_integration_pattern': \"OpenAI's ChatGPT integrates web search via its browsing mode, allowing the model to access and process real-time information from the internet to answer queries. Beyond simple browsing, OpenAI is developing more advanced agentic systems. The 'OpenAI Deep Research Agent' is a prime example, designed for complex, multi-step research tasks. The 'o1' model is specifically focused on chain-of-thought reasoning for agents. Frameworks like 'Search-o1' are being developed to enhance these Large Reasoning Models (LRMs) with an 'agentic RAG' mechanism, enabling them to dynamically search for external knowledge when they identify gaps in their own understanding.\", 'quality_control_mechanism': 'Quality control is assessed through rigorous benchmarking. The OpenAI Deep Research Agent demonstrates high performance on difficult benchmarks like BrowseComp (51.5%) and HLE (26.6%), significantly outperforming standard LLMs. Hallucination rates are actively measured for models like GPT-4 Turbo (0.019). The focus of development is on improving the reliability of tool use and the robustness of multi-step reasoning to ensure agents can perform complex tasks accurately and safely.'}, {'company': 'Anthropic', 'product_name': 'Claude 3.5 Agent, Contextual Retrieval', 'underlying_llm': 'Claude 3 family (including Claude 3.5 Sonnet)', 'technical_integration_pattern': \"Anthropic is a leader in developing agentic AI, focusing on training models to iteratively improve responses and use a variety of tools (search, calculators, etc.). The 'Claude 3.5 Agent' (released 2025) is designed for enterprise assistance and features multimodal input capabilities. A key technical innovation is 'Contextual Retrieval' (Sept 2024), which significantly enhances RAG performance. Anthropic is also pioneering protocols like the Model Context Protocol (MCP) to better integrate tools like web search, allowing for more specialized and reliable agent behavior.\", 'quality_control_mechanism': \"Anthropic's models are top performers on various industry benchmarks. For instance, Claude 3.5 Sonnet scores highly on MixEval-Hard, and the company actively tracks metrics like hallucination rates (e.g., 0.014 for a Claude 3.7 Sonnet model). The company's research emphasizes creating reliable and steerable AI, with a focus on enterprise-grade applications where accuracy and safety are paramount. Their approach involves training models for self-correction and robust tool integration to ensure high-quality outputs.\"}], 'influential_architectural_and_model_trends': {'trend_name': 'Agentic RAG and AI Agent Systems', 'description': \"Agentic RAG represents a significant architectural evolution from earlier RAG models, marking a paradigm shift towards autonomous, intelligent systems. This trend, which gained major traction from late 2024 into 2025, involves an 'Agent'‚Äîan LLM-powered system‚Äîthat can perceive its environment, reason, create complex plans, and execute a sequence of actions to achieve a goal. Instead of a static, one-shot retrieval process, an Agentic RAG system can dynamically query data sources, use external tools (like calculators, code interpreters, or SQL databases), read and synthesize results, re-query based on new information, and self-correct its approach. This approach integrates core agentic capabilities such as reflection, planning, tool use, and even collaboration with other agents, blurring the lines between RAG and autonomous agent platforms. A key concept within this trend is 'Context Engineering,' which focuses on strategically filling the model's context window with the most relevant information at each step of the agent's task.\", 'impact_on_web_search': 'This trend fundamentally transforms LLM web search from a simple information retrieval task into a complex problem-solving process. For RAG, it moves beyond just grounding answers in facts to enabling multi-hop reasoning, where the agent can synthesize information from multiple web searches and documents to answer complex questions that require several steps. For agentic browsing, it allows the LLM to not just find information but to act on it, performing tasks like booking flights, analyzing market data from multiple financial sites, or conducting deep research by autonomously navigating the web. This enables the resolution of complex, multi-step problems and facilitates more intelligent and nuanced decision-making, far surpassing the capabilities of basic RAG or simple web browsing modes.', 'cost_and_latency_implications': \"The advanced capabilities of Agentic RAG come with significant tradeoffs in cost and latency. Unlike basic RAG which has low latency, agentic systems are inherently slower. The need for the LLM to 'think'‚Äîto plan, execute sequential tool calls, and process the results of each step‚Äîintroduces considerable latency. Each step in the agent's reasoning process often requires a separate call to the LLM, leading to a substantial increase in total token consumption and, consequently, higher computational costs. This makes Agentic RAG more expensive and less suitable for applications requiring instantaneous responses, positioning it more for deep, complex analysis rather than quick Q&A.\", 'representative_models_or_systems': \"The Agentic RAG trend is embodied by a variety of frameworks and models. The 'ReAct' (Reason + Act) prompting paradigm is a foundational framework that enables this behavior. More advanced systems include 'Search-o1', a framework designed to enhance Large Reasoning Models (LRMs) like OpenAI's 'o1' with agentic retrieval. Reinforcement Learning-based approaches like 'Search-R1' train agents to interact with live web search APIs. Experimental open-source projects like 'AutoGPT' demonstrated the potential for multi-step planning and web querying. Industry players like Microsoft are also heavily investing in integrating agentic capabilities into their platforms, such as Azure, MS Office, and Copilot.\"}, 'evaluation_benchmarks_and_metrics': [{'benchmark_name': 'FACTS Grounding', 'year': 2024.0, 'purpose': 'To evaluate the ability of LLMs to generate responses that are factually accurate with respect to provided source material (up to 32k tokens) and sufficiently detailed, thereby preventing hallucinations.', 'key_metrics': 'A two-phased evaluation using an ensemble of LLM judges (Gemini 1.5 Pro, GPT-4o, Claude 3.5 Sonnet): 1) Eligibility (does the response address the request?) and 2) Factual Accuracy (is the response fully grounded in the document?).', 'main_finding_or_use_case': 'Used to drive industry-wide advancements in factuality and grounding. An active leaderboard is maintained on Kaggle. Initial results show high factuality scores for models like Gemini 1.5 Pro and Gemini 1.5 Flash.'}, {'benchmark_name': 'RAGAS (Retrieval-Augmented Generation Assessment System)', 'year': 2023.0, 'purpose': 'To evaluate the factuality and overall quality of Retrieval-Augmented Generation (RAG) pipelines by assessing the alignment between generated content and retrieved documents.', 'key_metrics': 'Reference-free metrics including Faithfulness, Context Precision, Context Recall, and Answer Relevance. A combined factuality score can be computed from these.', 'main_finding_or_use_case': 'Used to identify and penalize hallucinations in RAG systems. A faithfulness score below 0.8 typically indicates the model is introducing unsupported claims. It is often implemented as a composable evaluation node within LangChain pipelines.'}, {'benchmark_name': 'SafeRAG', 'year': 2025.0, 'purpose': 'The first security benchmark specifically designed for RAG pipelines, cataloging and evaluating system robustness against various attack classes.', 'key_metrics': 'Classifies attack tasks into four categories: Silver Noise (partially correct evidence), Inter-context Conflict (tampered texts), Soft Ad Attack (implicit toxicity), and White DoS (false safety warnings).', 'main_finding_or_use_case': 'Demonstrated that 14 representative RAG systems were vulnerable to simple manipulations, which sparked research interest in provenance tracking and adversarially trained retrievers to improve RAG security.'}, {'benchmark_name': 'LiveResearchBench', 'year': 2025.0, 'purpose': \"A user-centric benchmark for deep research, designed to evaluate an LLM's ability to iteratively seek, validate, and integrate evidence for complex tasks requiring up-to-date information.\", 'key_metrics': 'Evaluated using the DeepEval suite, which includes report-level metrics (presentation, consistency) and fine-grained dimensions (depth, checklist-based coverage, citation association, rubric-tree accuracy).', 'main_finding_or_use_case': 'Revealed that even state-of-the-art systems struggle with citation reliability and analytical depth, often functioning more as information collectors than sophisticated writers of evidence-grounded reports.'}, {'benchmark_name': 'CURIE', 'year': 2025.0, 'purpose': 'To evaluate the reasoning capabilities of LLMs across long scientific documents.', 'key_metrics': 'The specific metrics are not detailed in the provided context.', 'main_finding_or_use_case': 'Revealed that even leading models like Claude 3 and Gemini 2.0 Flash struggle with reasoning across long scientific documents, highlighting a key area for improvement.'}, {'benchmark_name': 'SummHay', 'year': 2025.0, 'purpose': \"To evaluate long-context understanding in LLMs and RAG systems by challenging them to generate summaries that capture key insights deliberately repeated across a 'haystack' of documents.\", 'key_metrics': 'Coverage (capturing repeated key insights) and Citation (accurately citing source documents), which are combined into a joint score.', 'main_finding_or_use_case': 'Found that current LLM and RAG systems lag human performance by over 10 points on the joint score, indicating significant room for improvement in long-context summarization and citation.'}, {'benchmark_name': 'RARE (Retrieval-Aware Robustness Evaluation)', 'year': 2025.0, 'purpose': 'A comprehensive framework for evaluating the robustness of RAG systems against noisy or imperfect inputs, particularly for domain-specific, technical queries.', 'key_metrics': 'The framework includes RARE-Get (a dynamic synthesis pipeline for time-sensitive data) and RARE-Set (a large-scale benchmark with over 48,000 queries across finance, economics, and policy).', 'main_finding_or_use_case': 'Used to assess how RAG systems perform with perturbed queries or when provided with partially relevant or contradictory retrieved documents, pushing for more robust system design.'}, {'benchmark_name': 'CRAG (Comprehensive RAG benchmark)', 'year': 2024.0, 'purpose': 'A benchmark for evaluating RAG systems, with a particular focus on those utilizing search engines.', 'key_metrics': 'The benchmark contains 4,409 entries. The associated CRAG *method* uses a retrieval evaluator to assign a confidence score (Correct, Incorrect, Ambiguous) to documents.', 'main_finding_or_use_case': 'Provides a standardized dataset for evaluating and comparing the performance of different RAG systems. The CRAG method enhances robustness by triggering corrective actions like web searches for low-confidence retrievals.'}, {'benchmark_name': 'MTEB (Massive Text Embedding Benchmark)', 'year': 2022.0, 'purpose': 'To comprehensively evaluate text embedding models, which are a critical component of the retrieval stage in RAG systems.', 'key_metrics': 'Evaluates models across a wide range of tasks including retrieval, reranking, classification, clustering, and summarization, over 58 datasets and 112 languages.', 'main_finding_or_use_case': 'Serves as an essential tool for selecting and improving the retriever component of RAG systems. For example, Contextualized Embeddings (2024) achieved state-of-the-art retrieval performance on this benchmark.'}, {'benchmark_name': 'Deep Research Bench', 'year': 2025.0, 'purpose': 'To evaluate agentic LLMs on deep research tasks within a controlled, offline environment called RetroSearch.', 'key_metrics': 'Success rates, grounded accuracy, latency, tool-call reliability, citation/grounding rates, and action budgets (e.g., 50 actions per task).', 'main_finding_or_use_case': 'Used to evaluate advanced agents like the OpenAI Deep Research Agent, which significantly outperformed standard LLMs on complex tasks requiring synthesis from obscure sources.'}], 'security_and_robustness_challenges': {'challenge_area': 'Security', 'specific_threat': 'Data Poisoning', 'description': 'Data poisoning is a significant threat to the integrity and security of LLMs, particularly in Retrieval-Augmented Generation (RAG) systems. Adversaries can compromise the integrity of the external knowledge base by poisoning indices, implanting backdoors, or crafting retrieval-optimized injections. This manipulation leads to the retrieval of false, misleading, or malicious information, which is then used by the LLM to generate its response. This can be used to manipulate the model towards unsafe behaviors. Research from 2024-2025, including works by Zou et al. and Xue et al., has specifically investigated these vulnerabilities, demonstrating that the integration of external knowledge corpora in RAG creates unique attack vectors not present in traditional LLMs.', 'affected_systems': 'Retrieval-Augmented Generation (RAG) and Agentic Browsing'}, 'mitigation_strategies_for_risks': [{'strategy_category': 'Retrieval Hardening', 'specific_technique': 'Domain Whitelisting / Restricted Retrieval Sources', 'description': \"This strategy involves restricting the RAG system's retrieval process to a pre-approved set of trusted and privacy-screened data sources. By implementing domain whitelisting and prioritizing internal retrieval systems, it prevents the model from accessing and ingesting information from potentially malicious or unreliable websites. This directly mitigates risks from adversarial web content, data poisoning, and the retrieval of misleading information. When third-party search APIs must be used, queries can be anonymized or masked to enhance privacy.\", 'tradeoff': 'The primary tradeoff is between coverage and safety. Restricting retrieval sources enhances security but may significantly reduce the breadth of information available to the LLM, potentially limiting the comprehensiveness and currency of its responses.'}, {'strategy_category': 'Content Sanitization', 'specific_technique': 'Input Sanitization and HTML Stripping', 'description': 'This mitigation involves cleaning and preprocessing data before it is passed to the LLM. Input sanitization is used to detect and neutralize malicious instructions embedded in user prompts, thereby preventing prompt injection attacks. Similarly, HTML stripping removes potentially harmful scripts, irrelevant formatting, or hidden instructions from retrieved web content, ensuring that the LLM processes clean, relevant text. This helps to fortify the system against attacks embedded within the retrieved content itself.', 'tradeoff': 'Adding multiple layers of defense, including content sanitization and filtering, invariably increases processing time. This can introduce noticeable latency, which may impact the real-time performance and user experience of the LLM web search system.'}, {'strategy_category': 'Data Handling', 'specific_technique': 'Differential Privacy', 'description': \"Retriever-level differential privacy is a promising technique for building privacy-preserving RAG systems. It works by adding a mathematically calibrated amount of noise to the retrieval process or the data itself. This makes it difficult for an attacker to determine whether a specific document was part of the retrieval set or to reconstruct sensitive information from the model's output, thus protecting against document-level membership inference and reconstruction attacks. Research from 2024 has explored its application to guard against information leakage.\", 'tradeoff': \"The main tradeoff is between utility and privacy. While effective for privacy, the introduction of noise can sometimes reduce the accuracy and utility of the retrieved information, potentially affecting the quality and factual correctness of the LLM's final output.\"}, {'strategy_category': 'System Architecture', 'specific_technique': 'Sandboxed Browsing', 'description': \"Specifically for agentic AI systems that can perform actions like browsing the web, sandboxing provides a critical layer of security. The agent's actions are executed within an isolated, controlled environment. This containment prevents a compromised or malicious agent from performing unsafe tool actions, accessing unauthorized system resources, or causing harm to the underlying infrastructure, effectively limiting the blast radius of a security incident.\", 'tradeoff': \"Implementing and managing a sandboxed environment adds complexity to the system architecture. Furthermore, if the sandbox is overly restrictive, it might limit the agent's legitimate capabilities and overall utility.\"}, {'strategy_category': 'Bias Mitigation', 'specific_technique': 'Bias-Controlled Embedding and Query Rewriting', 'description': \"This strategy aims to address and mitigate fairness issues and demographic biases that can be amplified by RAG systems. It involves several components: curating more inclusive and diverse datasets for retrieval, prompting the LLM to generate balanced responses, and implementing query rewriting techniques to neutralize biases present in the user's initial query before it is sent to the retriever. This multi-pronged approach helps to ensure the system produces more equitable and fair outputs.\", 'tradeoff': \"Implementing bias controls adds layers of processing, which can increase latency. There is also a risk of over-correction, where the attempt to mitigate bias might inadvertently skew results or reduce the relevance of the retrieved information for the user's original intent.\"}], 'market_and_publisher_ecosystem_impact': \"The integration of Large Language Models (LLMs) into web search, particularly through features like Google's AI Overviews, has triggered significant and disruptive impacts on the digital market and publisher ecosystem between late 2023 and 2025. The most profound effect is the acceleration of the 'zero-click' phenomenon. By providing synthesized, direct answers at the top of the search results page, these systems reduce the user's need to click through to source websites. This has led to substantial traffic displacement for publishers who rely on search referral traffic for revenue and audience engagement. \\n\\nEmpirical data from the initial rollout of Google's AI Overviews in 2024 highlighted the severity of this impact, with publishers reporting a significant '40-60% drop in click-through rates from AI summaries'. This has raised existential concerns for the content ecosystem, as it directly affects advertising revenue and the viability of many online publications. The economic model of the ad-funded internet is further challenged by the rise of agentic search, which, as of November 2025, is noted to be 'generating massive web traffic without ad revenue'. While this shift benefits users with quick answers and search engine providers with increased engagement, it threatens the symbiotic relationship between search engines and content creators. Interestingly, Google has countered these concerns, claiming that links within AI Overviews actually receive more clicks than traditional web listings for the same queries and that the feature encourages visits to a 'greater diversity of websites', especially for complex questions. The financial upside for search providers is substantial; Morgan Stanley projects that for every 10% of search queries handled by AI, Google could see an additional $1.2 billion in annual revenue, potentially reaching $12 billion if 50% of queries are AI-processed.\\n\\nIn response to this new paradigm, a necessary and rapid shift in Search Engine Optimization (SEO) and content strategies is underway. To remain visible and relevant to LLM-powered search crawlers and synthesizers, brands and publishers are advised to adapt their strategies. This includes a greater emphasis on structured data through 'schema markup', providing 'real-time updates', creating comprehensive 'FAQs', and incorporating rich 'multimedia content'. The goal is to create content that is easily digestible and valuable for AI synthesis, thereby increasing the chances of being featured and cited in AI-generated answers. The impact, however, is not uniform. Enterprise-focused systems like Microsoft Copilot, which use web grounding primarily for internal business intelligence within a secure and private framework, have a less pronounced direct impact on the public SEO ecosystem compared to broad, consumer-facing systems like Google's AI Overviews.\", 'user_experience_and_cognitive_impacts': \"The rise of generative search, powered by LLMs, has fundamentally altered the user experience (UX) of information retrieval and raises significant questions about its long-term cognitive impacts. The primary UX shift is from the traditional paradigm of a ranked list of blue links, which requires users to click, evaluate, and synthesize information from multiple sources, to a more direct, conversational model that provides a single, synthesized answer. Systems like Google's AI Overviews and ChatGPT Search, which by early 2025 were considered 'genuinely useful' after overcoming earlier hallucination issues, exemplify this change.\\n\\nFrom a user experience perspective, this shift has been largely positive. Research indicates that for Google's AI Overviews, 'users reported increased satisfaction and more frequent use of Search'. The feature is particularly valued for its ability to handle complex questions that would have traditionally required multiple searches, effectively 'streamlining the information retrieval process' and reducing user effort. The user experience is set to become even more personalized, with planned features for Google's Search Labs allowing users to 'adjust the overview's language for simplicity or greater detail'. Furthermore, Google is testing a full-screen 'AI Mode' powered by Gemini, which offers a fully conversational search experience that prioritizes detailed responses over link lists, representing a deeper commitment to this new paradigm. In the enterprise space, systems like Microsoft Copilot enhance productivity by providing contextually relevant answers, while also giving users control, such as the ability to toggle web grounding on or off.\\n\\nHowever, this streamlined consumption of pre-synthesized information has prompted serious concerns about the cognitive impacts on users. An academic study from September 2025 suggests that LLM summaries, by their very nature, 'might lead to shallower knowledge and less original thought compared to traditional web search'. The cognitive effort of seeking out, comparing, and synthesizing information from various sources, while more laborious, is integral to deep learning and critical thinking. By offloading this process to an AI, there is a risk that users may engage less critically with information, potentially hindering their ability to form nuanced perspectives and develop their own insights. This raises profound questions about the long-term effects of generative search on information literacy, learning depth, and the development of critical thinking skills in the general population, representing a critical tradeoff between convenience and cognitive engagement.\", 'open_problems_and_future_research_directions': \"The rapid advancements in LLM-powered web search from late 2023 to 2025 have surfaced a multitude of complex open problems and defined clear future research directions that will shape the next generation of information access.\\n\\n**1. Evaluation of Complex Reasoning and Generative Search:**\\nA primary challenge is the inadequacy of existing evaluation metrics. Traditional Information Retrieval (IR) benchmarks are designed for ranked lists of documents, not for the single, synthesized, long-form answers produced by generative search. Future research must develop new evaluation criteria and benchmarks that can assess the quality, coherence, factuality, and attribution of these generative outputs. Furthermore, current benchmarks like CURIE, SummHay, and LiveResearchBench reveal that even state-of-the-art models struggle with reasoning across long scientific documents, complex multi-hop queries, and deep research tasks. Overcoming weaknesses in current evaluation frameworks, such as data contamination, LLM evaluator bias, and high latency, is also a critical research direction.\\n\\n**2. Security, Robustness, and Privacy:**\\nThe integration of external web content via RAG and agentic browsing introduces significant security vulnerabilities. A key area for future research is defending against a new class of threats. The SafeRAG benchmark (2025) revealed that RAG systems are vulnerable to attacks like 'silver noise' (partially correct evidence), 'inter-context conflict', and 'soft ad attacks' that can bypass existing guardrails. Open problems include:\\n*   **Privacy-Preserving RAG:** Developing robust techniques like retriever-level differential privacy, encrypted search indices, and federated retrieval to prevent the leakage of sensitive information from retrieval databases or user queries.\\n*   **Retrieval and Data Poisoning:** Creating methods to harden retrievers against poisoned indices and adversarial web content designed to manipulate model behavior.\\n*   **Agentic Security:** Securing autonomous agents from prompt injections, unsafe tool actions, and other exploits that could lead to unauthorized data access or harmful outcomes. This includes developing secure sandboxed browsing environments.\\n\\n**3. Factuality, Hallucination, and Bias:**\\nDespite improvements, ensuring factual accuracy remains a paramount challenge. Even advanced models like Google's Gemini have shown high hallucination rates (e.g., 76.7% in high-stakes financial referencing tasks) in practice. Agentic systems introduce new failure modes like 'Action Hallucinations' (fabricating information in tool calls). Future research must focus on:\\n*   **Robust Grounding and Citation:** Improving the reliability of citations and ensuring that generated claims are strictly supported by retrieved evidence.\\n*   **Mitigating Bias:** Developing methods to control for and mitigate demographic and other biases present in both the LLM's training data and the retrieved web content. This includes research into bias-controlled embeddings and query rewriting techniques.\\n*   **Handling Noisy and Misleading Context:** Enhancing the ability of RAG systems to identify and discard irrelevant, outdated, or intentionally misleading information retrieved from the web.\\n\\n**4. Performance, Cost, and Scalability:**\\nThe computational cost and latency of advanced RAG and agentic systems are significant barriers to widespread, real-time deployment. Open problems include:\\n*   **Efficient Long-Context Handling:** Addressing the 'lost-in-the-middle' problem where models overlook key details in long context windows and reducing the high computational cost associated with them.\\n*   **Optimized Architectures:** Research into methods like KV-cache reuse and sparse attention to reduce inference costs, and improving their effectiveness for RAG on lengthy documents.\\n*   **Scalable Systems:** Designing architectures and accessible tooling that allow for the efficient deployment, maintenance, and scaling of RAG and agentic search systems.\\n\\n**5. Long-Term Societal and Cognitive Impact:**\\nPerhaps the most profound open questions relate to the broader societal impact of this technology. A critical area for academic inquiry is the long-term effect on user cognition. As identified in a 2025 study, the shift to pre-synthesized answers may lead to 'shallower knowledge and less original thought'. Research is urgently needed to understand and potentially mitigate these impacts on learning, critical thinking, and information literacy. Additionally, the economic disruption to the publisher ecosystem and the ad-funded internet model requires further study to understand its long-term consequences and explore sustainable alternatives.\\n\\n**6. Multimodal and Advanced Reasoning Capabilities:**\\nFuture research will continue to push the boundaries of what LLM search can do. Key directions include:\\n*   **Multimodal RAG:** Solving open challenges in multimodal RAG, such as effective cross-modal alignment and vision-aware reranking, to enable retrieval and reasoning over text, images, audio, and video.\\n*   **Graph-Enhanced RAG (GraphRAG):** Integrating LLMs with auto-updating knowledge graphs to enhance context-aware, multi-hop reasoning and provide more structured, reliable knowledge.\"}, type='json', beta_fields=None, output_schema={'type': 'object', 'properties': {'report_summary': {'type': 'string', 'description': 'A concise, high-level executive summary of the most significant academic research advancements in web search for LLMs between late 2023 and late 2025.'}, 'clarification_of_scope': {'type': 'string', 'description': \"An explanation of how the term 'web search for LLMs' is interpreted for this report, covering the three main pillars: Retrieval-Augmented Generation (RAG), LLM-powered search engines, and LLM browsing agents/tools.\"}, 'timeline_of_milestones': {'type': 'array', 'items': {'type': 'object', 'properties': {'year': {'type': 'number', 'description': 'The year the milestone occurred.'}, 'period': {'type': 'string', 'description': 'The specific time within the year (e.g., Late, Q3, May).'}, 'milestone_description': {'type': 'string', 'description': 'A description of the milestone, such as a paper release, benchmark introduction, or industry launch.'}, 'category': {'type': 'string', 'description': 'The type of milestone (e.g., Paper, Benchmark, Model Release, Industry Launch).'}, 'associated_work': {'type': 'string', 'description': 'The name of the associated paper, model, or system (e.g., Self-RAG, GAIA Benchmark).'}}, 'required': ['year', 'period', 'milestone_description', 'category', 'associated_work'], 'additionalProperties': False}, 'description': 'A chronological list of key milestones, seminal papers, model releases, and benchmark introductions from late 2023 to late 2025 that have shaped the field of LLM web search.'}, 'rag_advancements_analysis': {'type': 'string', 'description': 'A detailed analysis of the evolution of Retrieval-Augmented Generation (RAG), covering the progression from basic RAG to advanced, modular, and agentic RAG architectures.'}, 'specific_rag_techniques': {'type': 'array', 'items': {'type': 'object', 'properties': {'technique_name': {'type': 'string', 'description': 'The name of the RAG technique (e.g., SELF-RAG, CRAG, GraphRAG).'}, 'year_introduced': {'type': 'number', 'description': 'The year the technique was introduced or gained prominence.'}, 'core_concept': {'type': 'string', 'description': \"A brief explanation of the technique's core methodology.\"}, 'key_benefit': {'type': 'string', 'description': 'The primary improvement offered by the technique (e.g., improved factuality, robustness, efficiency).'}, 'key_paper_or_source': {'type': 'string', 'description': 'The seminal paper or source that introduced the technique.'}}, 'required': ['technique_name', 'year_introduced', 'core_concept', 'key_benefit', 'key_paper_or_source'], 'additionalProperties': False}, 'description': 'A list of specific and influential RAG techniques developed or refined during this period. For each technique, include its purpose, methodology, and impact on factuality, efficiency, or robustness. Examples include CRAG, Self-RAG, FLARE, GraphRAG, and Multimodal RAG.'}, 'agentic_llm_evolution': {'type': 'string', 'description': 'An analysis of the evolution of agentic LLMs for web search, including the role of reinforcement learning (RL), tool-use protocols, and multi-step reasoning in creating autonomous search agents.'}, 'representative_agentic_systems': {'type': 'array', 'items': {'type': 'object', 'properties': {'system_name': {'type': 'string', 'description': 'The name of the agentic system or framework (e.g., R1-Searcher, WebDancer).'}, 'year': {'type': 'number', 'description': 'The year the system was introduced.'}, 'core_methodology': {'type': 'string', 'description': 'The main training approach or architecture (e.g., Reinforcement Learning with PPO, Human Trajectory Supervision).'}, 'key_contribution': {'type': 'string', 'description': 'The primary contribution or innovation of the system.'}, 'associated_paper': {'type': 'string', 'description': 'The research paper associated with the system.'}}, 'required': ['system_name', 'year', 'core_methodology', 'key_contribution', 'associated_paper'], 'additionalProperties': False}, 'description': 'A list of representative agentic search systems and frameworks. For each, describe its core methods, training signals (e.g., RL on search outcomes), and key contributions. Examples include R1-Searcher, Search-R1, ReSearch, and protocols like MCP.'}, 'llm_powered_search_engine_integration': {'type': 'string', 'description': \"An overview of how LLMs are being integrated into the core functionality of search engines, leading to the rise of 'generative search' and a shift from ranked lists to synthesized conversational answers.\"}, 'major_industry_implementations': {'type': 'array', 'items': {'type': 'object', 'properties': {'company': {'type': 'string', 'description': 'The name of the company (e.g., Google, Microsoft, Anthropic).'}, 'product_name': {'type': 'string', 'description': 'The name of the product or feature (e.g., AI Overviews, Copilot).'}, 'underlying_llm': {'type': 'string', 'description': 'The Large Language Model powering the implementation (e.g., Gemini, GPT-4).'}, 'technical_integration_pattern': {'type': 'string', 'description': 'Details on how the LLM is integrated, including retrieval stacks and real-time validation methods.'}, 'quality_control_mechanism': {'type': 'string', 'description': 'Mechanisms used for quality control, such as citation policies, guardrails, and hallucination mitigation.'}}, 'required': ['company', 'product_name', 'underlying_llm', 'technical_integration_pattern', 'quality_control_mechanism'], 'additionalProperties': False}, 'description': \"Case studies of how major industry players are implementing LLM-integrated search. For each company (e.g., Google's AI Overviews, Microsoft Copilot, OpenAI's ChatGPT browsing), detail their technical integration patterns, adoption metrics, and quality control mechanisms.\"}, 'influential_architectural_and_model_trends': {'type': 'object', 'properties': {'trend_name': {'type': 'string', 'description': 'The name of the architectural or model trend (e.g., Agentic RAG, Multimodality, Mixture-of-Experts).'}, 'description': {'type': 'string', 'description': 'A summary of what the trend entails.'}, 'impact_on_web_search': {'type': 'string', 'description': 'How this trend specifically improves RAG or agentic search capabilities.'}, 'cost_and_latency_implications': {'type': 'string', 'description': 'The effects of this trend on compute, cost, and latency.'}, 'representative_models_or_systems': {'type': 'string', 'description': 'Examples of models or systems that embody this trend (e.g., Mixtral 8x7B, Search-o1).'}}, 'required': ['trend_name', 'description', 'impact_on_web_search', 'cost_and_latency_implications', 'representative_models_or_systems'], 'additionalProperties': False}, 'evaluation_benchmarks_and_metrics': {'type': 'array', 'items': {'type': 'object', 'properties': {'benchmark_name': {'type': 'string', 'description': 'The name of the benchmark or evaluation framework (e.g., FACTS Grounding, RAGAS, SafeRAG).'}, 'year': {'type': 'number', 'description': 'The year the benchmark was introduced or significantly updated.'}, 'purpose': {'type': 'string', 'description': 'The primary goal of the benchmark (e.g., evaluating factuality, security, long-document reasoning).'}, 'key_metrics': {'type': 'string', 'description': 'The core metrics used for evaluation (e.g., Faithfulness, Context Precision, nugget recall).'}, 'main_finding_or_use_case': {'type': 'string', 'description': \"A key finding from the benchmark's application or its primary use case.\"}}, 'required': ['benchmark_name', 'year', 'purpose', 'key_metrics', 'main_finding_or_use_case'], 'additionalProperties': False}, 'description': 'A detailed overview of the key benchmarks and evaluation frameworks developed to assess grounding, factuality, retrieval quality, and long-document reasoning in LLM search systems. For each benchmark (e.g., RAGAS, FACTS Grounding, CURIE, LiveResearchBench, SafeRAG), describe its purpose, metrics, and key findings on model performance.'}, 'security_and_robustness_challenges': {'type': 'object', 'properties': {'challenge_area': {'type': 'string', 'description': 'The broad category of the challenge (e.g., Security, Privacy, Robustness, Bias).'}, 'specific_threat': {'type': 'string', 'description': 'The specific threat model or vulnerability (e.g., Prompt Injection, Data Poisoning, PII Leakage).'}, 'description': {'type': 'string', 'description': 'A detailed explanation of the threat and how it manifests.'}, 'affected_systems': {'type': 'string', 'description': 'The types of systems most affected by this challenge (e.g., RAG, Agentic Browsing).'}}, 'required': ['challenge_area', 'specific_threat', 'description', 'affected_systems'], 'additionalProperties': False}, 'mitigation_strategies_for_risks': {'type': 'array', 'items': {'type': 'object', 'properties': {'strategy_category': {'type': 'string', 'description': 'The general category of the mitigation strategy (e.g., Data Handling, Retrieval Hardening, Content Sanitization).'}, 'specific_technique': {'type': 'string', 'description': 'The specific technique used for mitigation (e.g., Differential Privacy, Domain Whitelisting, Sandboxed Browsing).'}, 'description': {'type': 'string', 'description': 'How the mitigation technique works to address a specific risk.'}, 'tradeoff': {'type': 'string', 'description': 'The potential tradeoffs associated with implementing this strategy (e.g., increased latency, reduced coverage).'}}, 'required': ['strategy_category', 'specific_technique', 'description', 'tradeoff'], 'additionalProperties': False}, 'description': 'A list of promising mitigation strategies to address the identified security and bias challenges. Include techniques like retriever hardening, content sanitization, sandboxed browsing, and bias-controlled embedding.'}, 'market_and_publisher_ecosystem_impact': {'type': 'string', 'description': \"An analysis of the market and ecosystem impacts of LLM-integrated search, focusing on the 'zero-click' phenomenon, traffic displacement for publishers, and subsequent shifts in SEO and content strategies.\"}, 'user_experience_and_cognitive_impacts': {'type': 'string', 'description': 'An examination of the effects of generative search on user experience and cognitive outcomes, including discussions on changes in learning depth, information consumption habits, and critical thinking compared to traditional search.'}, 'open_problems_and_future_research_directions': {'type': 'string', 'description': 'A summary of the identified gaps, open problems, and potential future directions for academic research in LLM web search, such as the evaluation of complex reasoning, privacy-preserving RAG, and the long-term societal impact.'}}, 'required': ['report_summary', 'clarification_of_scope', 'timeline_of_milestones', 'rag_advancements_analysis', 'specific_rag_techniques', 'agentic_llm_evolution', 'representative_agentic_systems', 'llm_powered_search_engine_integration', 'major_industry_implementations', 'influential_architectural_and_model_trends', 'evaluation_benchmarks_and_metrics', 'security_and_robustness_challenges', 'mitigation_strategies_for_risks', 'market_and_publisher_ecosystem_impact', 'user_experience_and_cognitive_impacts', 'open_problems_and_future_research_directions'], 'additionalProperties': False})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from parallel import Parallel\n",
    "\n",
    "client = Parallel(api_key=os.environ[\"PARALLEL_API_KEY\"])\n",
    "\n",
    "query = \"What is the most recent academic research advancements in web search for LLMs?\"\n",
    "\n",
    "task_run = client.task_run.create(\n",
    "    input=query,\n",
    "    processor=\"ultra\"\n",
    ")\n",
    "print(f\"Task Created. Run ID: {task_run.run_id}\")\n",
    "\n",
    "run_result = client.task_run.result(task_run.run_id, api_timeout=3600)\n",
    "print(run_result.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b031dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['basis', 'content', 'type', 'beta_fields', 'output_schema'])\n"
     ]
    }
   ],
   "source": [
    "print(run_result.output.__dict__.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d68f8a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['report_summary', 'clarification_of_scope', 'timeline_of_milestones', 'rag_advancements_analysis', 'specific_rag_techniques', 'agentic_llm_evolution', 'representative_agentic_systems', 'llm_powered_search_engine_integration', 'major_industry_implementations', 'influential_architectural_and_model_trends', 'evaluation_benchmarks_and_metrics', 'security_and_robustness_challenges', 'mitigation_strategies_for_risks', 'market_and_publisher_ecosystem_impact', 'user_experience_and_cognitive_impacts', 'open_problems_and_future_research_directions'])\n"
     ]
    }
   ],
   "source": [
    "print(run_result.output.content.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c20cddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report_summary:\n",
      "Academic research in web search for Large Language Models (LLMs) from late 2023 to late 2025 has been characterized by rapid evolution and the convergence of three core areas: Retrieval-Augmented Generation (RAG), LLM-powered search engines, and autonomous LLM agents. This period saw a paradigm shift from static information retrieval to dynamic, agentic reasoning. RAG architectures evolved from basic retrieval to advanced, self-correcting, and adaptive systems like Self-RAG and CRAG, which learn to critique and refine retrieved information. The introduction of GraphRAG and multimodal RAG (e.g., OmniSearch) further expanded capabilities to handle structured and non-textual data. Concurrently, 2025 was widely recognized as the 'year of agents,' marked by a surge in research using Reinforcement Learning (RL) to train LLMs to autonomously plan, use tools (including web search), and synthesize information (e.g., R1-Searcher, Search-R1). Major industry players like Google (AI Overviews) and Microsoft (Copilot) integrated LLMs into their search products, leading to a 'zero-click' future and significant impacts on the publisher ecosystem. This progress was paralleled by the development of sophisticated benchmarks to address critical challenges like factuality (FACTS Grounding), long-document reasoning (SummHay, LiveResearchBench), and security (SafeRAG), revealing both the advanced capabilities and persistent weaknesses of state-of-the-art models. Architectural trends toward longer context windows, multimodality, and more efficient models (e.g., Mixture-of-Experts) have provided the foundation for these advancements, though open problems related to evaluation, security, bias, and the cognitive impact on users remain active areas of investigation.\n",
      "\n",
      "clarification_of_scope:\n",
      "For the purpose of this report, the term 'web search for LLMs' is interpreted as a broad and evolving field encompassing three interconnected pillars. This interpretation is based on the consensus in recent academic literature and market trends, which see these areas converging. The three pillars are: 1. **Retrieval-Augmented Generation (RAG):** This refers to the family of techniques where LLMs are connected to external knowledge sources, including web content, to ground their responses in factual, up-to-date information. This is a foundational method for mitigating hallucinations, enhancing accuracy, and providing answers based on proprietary or real-time data. The scope includes the evolution from basic RAG to advanced, modular, and agentic RAG systems. 2. **LLM-powered Search Engines:** This pillar covers the integration of LLMs into the core functionality of search engines. It represents a shift from traditional keyword-based ranked lists to conversational, generative search experiences where the LLM synthesizes information from multiple web sources to provide a single, coherent answer, often with citations. Examples include Google's AI Overviews and Microsoft Copilot's web grounding. 3. **LLM Browsing Agents/Tools:** This refers to LLMs that act as autonomous or semi-autonomous agents capable of interacting with the web. These agents can perform multi-step tasks, navigate websites, use various tools (e.g., search APIs, calculators), and extract and synthesize information to fulfill complex user requests. Research in this area focuses on planning, tool-use protocols, and training agents with methods like Reinforcement Learning. The research indicates a significant blurring of lines, where advanced RAG systems become agentic and LLM-powered search engines incorporate agent-like capabilities.\n",
      "\n",
      "timeline_of_milestones:\n",
      "[{'year': 2023.0, 'period': 'Q3-Q4', 'milestone_description': 'Introduction of a reference-free suite of metrics for the automated evaluation of RAG system quality across multiple dimensions, including faithfulness and answer relevance.', 'category': 'Benchmark', 'associated_work': 'RAGAS'}, {'year': 2023.0, 'period': 'October', 'milestone_description': 'A seminal paper introducing a framework where an LLM learns to retrieve on-demand and critique its own generations to enhance quality and factuality, reducing hallucinations.', 'category': 'Paper', 'associated_work': 'Self-RAG'}, {'year': 2023.0, 'period': 'December', 'milestone_description': \"Launch of Google's next-generation multimodal model, which would become the core technology for its AI-powered search features.\", 'category': 'Model Release', 'associated_work': 'Google Gemini'}, {'year': 2024.0, 'period': 'January', 'milestone_description': 'A paper proposing a RAG method that enhances robustness with a self-correcting retriever that assesses retrieval quality and triggers web searches for self-correction.', 'category': 'Paper', 'associated_work': 'Corrective Retrieval Augmented Generation (CRAG)'}, {'year': 2024.0, 'period': 'May', 'milestone_description': 'Meta introduces a challenging benchmark for General AI Assistants, featuring complex, multi-step problems requiring tool use, including web browsing.', 'category': 'Benchmark', 'associated_work': 'GAIA Benchmark'}, {'year': 2024.0, 'period': 'May', 'milestone_description': 'Google begins rolling out its generative search experience, powered by the Gemini model, to all users in the U.S., marking a major shift in consumer search.', 'category': 'Industry Launch', 'associated_work': 'Google AI Overviews'}, {'year': 2024.0, 'period': 'December', 'milestone_description': 'Google DeepMind and Kaggle release a benchmark to evaluate how accurately LLMs ground their responses in provided source documents and avoid hallucinations.', 'category': 'Benchmark', 'associated_work': 'FACTS Grounding Benchmark'}, {'year': 2025.0, 'period': 'Q1', 'milestone_description': 'A series of papers are released focusing on using Reinforcement Learning (RL) to train LLMs to effectively leverage search engines and reason with search results.', 'category': 'Paper', 'associated_work': 'R1-Searcher, Search-R1, ReSearch'}, {'year': 2025.0, 'period': 'Q1', 'milestone_description': 'Introduction of the first security-focused benchmark for RAG pipelines, cataloging attack classes and evaluating the vulnerability of existing systems.', 'category': 'Benchmark', 'associated_work': 'SafeRAG'}, {'year': 2025.0, 'period': 'Q2', 'milestone_description': \"Launch of a comprehensive evaluation suite for 'deep research' tasks, assessing agents on their ability to iteratively seek, validate, and integrate evidence from the web.\", 'category': 'Benchmark', 'associated_work': 'LiveResearchBench and DeepEval'}, {'year': 2025.0, 'period': 'Mid', 'milestone_description': \"The discourse in the research community notably shifts from traditional RAG towards 'Agentic RAG,' where autonomous agents plan and execute complex retrieval and reasoning workflows.\", 'category': 'Research Trend', 'associated_work': 'Agentic RAG'}, {'year': 2025.0, 'period': 'September', 'milestone_description': 'An academic study raises concerns that LLM-generated summaries, despite being linked to web sources, may lead to shallower knowledge and less original thought compared to traditional search.', 'category': 'Paper', 'associated_work': 'Study on Learning Depth'}]\n",
      "\n",
      "rag_advancements_analysis:\n",
      "The evolution of Retrieval-Augmented Generation (RAG) from late 2023 to late 2025 marks a significant progression from a simple retrieval-and-generation pipeline to highly sophisticated, modular, and agentic systems. This evolution reflects a deeper integration of reasoning, self-correction, and autonomous decision-making into the retrieval process, fundamentally transforming how Large Language Models (LLMs) interact with external knowledge.\n",
      "\n",
      "1.  **Basic RAG (Pre-2023):** The foundational RAG architecture, as introduced by Lewis et al. in 2020, involves a straightforward three-step process: indexing a knowledge base, retrieving relevant documents based on a user query, and feeding these documents as context to an LLM for answer generation. This approach was widely adopted by 2023 to mitigate hallucinations and update the factual knowledge of LLMs. While easy and cheap to implement with low latency, Basic RAG suffered from several limitations, including low precision due to irrelevant retrieved chunks, the 'lost-in-the-middle' problem where information in the middle of a long context is ignored, and difficulty in answering questions that require synthesizing information from multiple sources.\n",
      "\n",
      "2.  **Advanced and Modular RAG (Late 2023 - 2024):** The period saw a shift towards more sophisticated RAG architectures. A 2024 taxonomy distinguished between Naive RAG, Advanced RAG (with pre-retrieval and post-retrieval enhancements like reranking), and Modular RAG. Modular RAG, as conceptualized by Gao et al. in late 2023, treats the RAG pipeline as a flexible toolkit of interchangeable components. This allows for highly optimized, use-case-specific workflows by incorporating modules for query transformation, routing, and advanced retrieval strategies. This phase also saw the rise of retriever-centric (e.g., optimizing chunking, reranking) and generator-centric (e.g., iterative reasoning) designs. While offering greater flexibility and performance, Modular RAG introduced significant engineering complexity and debugging challenges.\n",
      "\n",
      "3.  **Self-Correcting and Active RAG (Late 2023 - 2024):** This stage introduced more intelligence into the retrieval process. Techniques like **SELF-RAG** (late 2023) empowered the LLM to perform self-critique during both retrieval and generation. It learns to generate 'reflection tokens' that trigger on-demand retrieval and assess the relevance of retrieved passages, making the process adaptive. Similarly, **Corrective RAG (CRAG)** (Jan 2024) introduced a lightweight retrieval evaluator to assess the quality of retrieved documents and trigger corrective actions, such as web searches, if the information is deemed incorrect or ambiguous. These approaches significantly enhanced the factuality and robustness of RAG systems by actively mitigating the impact of irrelevant or misleading context.\n",
      "\n",
      "4.  **Agentic RAG (Late 2024 - 2025):** This represents the latest paradigm shift, where the RAG process is driven by an autonomous 'Agent'. An Agentic RAG system can plan a sequence of actions, including iterative querying, reading documents, using external tools (like calculators or code interpreters), and performing self-correction. This architecture integrates reflection, planning, and tool use, moving from a static retrieval pipeline to a dynamic, self-directed reasoning process. LlamaIndex identified this as a major trend for 2025, noting that it blurs the lines between RAG and agent platforms. Agentic RAG excels at solving complex, multi-step problems that require intelligent decision-making but comes at the cost of higher latency and token consumption due to the sequential nature of tool calls and the LLM's need to 'think' through its steps. This evolution is also tied to the concept of 'Context Engineering' or 'RAG 2.0', which focuses on strategically filling the context window with the most relevant information at each step of an agent's trajectory.\n",
      "\n",
      "specific_rag_techniques:\n",
      "[{'technique_name': 'SELF-RAG', 'year_introduced': 2023.0, 'core_concept': \"An LLM is trained to generate special 'reflection' tokens that enable it to perform on-demand retrieval and self-critique. It adaptively decides when to retrieve information and evaluates the quality and relevance of retrieved passages before generating a response.\", 'key_benefit': 'Improves factuality, reduces hallucinations, and enhances transparency through citations by making the retrieval process adaptive and self-correcting.', 'key_paper_or_source': 'Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection (Asai et al., 2023 / ICLR 2024)'}, {'technique_name': 'Corrective Retrieval Augmented Generation (CRAG)', 'year_introduced': 2024.0, 'core_concept': \"Employs a lightweight retrieval evaluator to assess the quality of retrieved documents. If documents are deemed incorrect or ambiguous, it triggers corrective actions, including large-scale web searches, to find better information. It uses a 'Decompose-then-Recompose' algorithm to filter and synthesize knowledge.\", 'key_benefit': 'Enhances the robustness of RAG against inaccurate or low-quality retrieved information, improving overall factuality and reliability.', 'key_paper_or_source': 'Corrective Retrieval Augmented Generation (Jan 2024)'}, {'technique_name': 'FLARE (Forward-Looking Active Retrieval)', 'year_introduced': 2023.0, 'core_concept': 'An active retrieval method that iteratively uses a prediction of the upcoming sentence as a query to retrieve relevant documents. It dynamically decides when to retrieve information to balance computational cost and effectiveness.', 'key_benefit': 'Improves efficiency and performance by optimizing the timing and relevance of retrieval actions, reducing computational costs by 30-50% without compromising performance.', 'key_paper_or_source': 'Active Retrieval Augmented Generation (May 2023)'}, {'technique_name': 'GraphRAG', 'year_introduced': 2024.0, 'core_concept': 'Integrates knowledge graphs with text retrieval. It leverages the structured nature of graphs to represent and retrieve information, helping to bridge the semantic gap between user queries and documents.', 'key_benefit': 'Enhances reasoning, addresses query diversity, and improves retrieval of n-ary relational facts by combining structured graph knowledge with unstructured text.', 'key_paper_or_source': 'GraphRAG (2024), with surveys and advancements like HyperGraphRAG in 2025.'}, {'technique_name': 'Multimodal RAG (e.g., SAM-RAG, OmniSearch)', 'year_introduced': 2024.0, 'core_concept': 'Extends RAG beyond text to handle multimodal data, including images, audio, and video. Systems like SAM-RAG dynamically filter documents and verify evidence in multimodal contexts, while OmniSearch plans multi-hop retrieval chains for complex visual-question-answering.', 'key_benefit': 'Enables grounding in and reasoning over multiple data types, allowing for more comprehensive analysis and answering of complex queries involving both text and visual evidence.', 'key_paper_or_source': 'SAM-RAG (Zhai 2024), OmniSearch (Li 2024)'}, {'technique_name': 'RECOMP', 'year_introduced': 2023.0, 'core_concept': 'A compression technique that compresses retrieved documents into concise textual summaries before they are passed to the LLM.', 'key_benefit': 'Reduces the computational load and context window requirements for the LLM by providing a condensed version of the retrieved information.', 'key_paper_or_source': 'RECOMP (Oct 2023)'}, {'technique_name': 'RAGAS (Retrieval-Augmented Generation Assessment)', 'year_introduced': 2023.0, 'core_concept': 'A framework and suite of reference-free metrics designed for the automated evaluation of RAG systems. It assesses dimensions like faithfulness, context precision, context recall, and answer relevance.', 'key_benefit': 'Provides a standardized, automated way to evaluate and benchmark the performance of RAG pipelines, helping to identify and penalize hallucinations and improve grounding.', 'key_paper_or_source': 'RAGAS: Automated Evaluation of Retrieval Augmented Generation (Es et al., Sep 2023)'}, {'technique_name': 'MS-RAG (Multi-Stage RAG)', 'year_introduced': 2025.0, 'core_concept': 'A framework that enhances retrieval precision by integrating dense (neural) and sparse (BM25) retrieval with reinforcement learning optimization in a hybrid, multi-stage pipeline.', 'key_benefit': 'Improves retrieval precision, factual consistency, and reduces hallucinations while also decreasing token usage and inference time compared to standard RAG.', 'key_paper_or_source': 'MS-RAG (2025)'}, {'technique_name': 'SafeRAG', 'year_introduced': 2025.0, 'core_concept': 'The first security benchmark for RAG pipelines, cataloging four classes of attacks (silver noise, context conflict, soft-ad, DoS) to evaluate the security and robustness of RAG systems against manipulation.', 'key_benefit': 'Provides a framework for systematically testing and improving the security and robustness of RAG systems against adversarial attacks.', 'key_paper_or_source': 'SafeRAG: A Security Benchmark for Retrieval-Augmented Generation (Liang et al., 2025)'}]\n",
      "\n",
      "agentic_llm_evolution:\n",
      "The evolution of agentic Large Language Models (LLMs) for web search between late 2023 and late 2025 represents a fundamental paradigm shift from passive information retrieval to active, autonomous problem-solving. This progression, often termed 'Agentic Deep Research' or 'Agentic Reinforcement Learning' (Agentic RL), has been driven by advancements in reinforcement learning, the formalization of tool-use protocols, and the development of sophisticated multi-step reasoning capabilities, effectively blurring the lines between search engines and autonomous agents.\n",
      "\n",
      "The core of this evolution lies in moving beyond supervised fine-tuning (SFT) to training methods that enable agents to perceive, reason, plan, and adapt in dynamic web environments. Reinforcement Learning (RL) has been the key enabler. Instead of just predicting the next token, agents are trained to take actions (like issuing a search query or clicking a link) to maximize a reward. These rewards are increasingly sophisticated:\n",
      "\n",
      "1.  **Reinforcement Learning on Search Outcomes:** Early methods used simple rewards, but by 2025, systems began using complex, outcome-based rewards. For example, agents are rewarded based on the final accuracy or completeness of their answer, incentivizing them to learn effective, multi-step search strategies. Proximal Policy Optimization (PPO) variants became a common strategy, used in systems like R1-Searcher to first learn *when* to search and then *how* to use the results. Other approaches like Direct Preference Optimization (DPO) are used to align agent behavior with human feedback, as seen in WebThinker, which tackles complex report generation.\n",
      "\n",
      "2.  **Simulated Feedback and Self-Play:** A significant challenge in training with live web search is the high cost of API calls and the instability caused by noisy, real-world data. To mitigate this, researchers developed methods using simulated environments. Systems like ZeroSearch and SSRL (Self-Supervised RL) employ offline 'self-search' during training, where the agent interacts with a pseudo search engine distilled from other LLMs. This enhances training efficiency, stability, and controllability while reducing reliance on costly real-time APIs.\n",
      "\n",
      "3.  **Tool-Use Protocols and Multi-Step Reasoning:** The ability of agents to use tools is central to their evolution. The ReAct (Reason + Act) architecture, which involves a loop of thought, action, and observation, became a foundational protocol for enabling agents to iteratively solve tasks. This allows agents to perform complex, multi-step research processes that involve planning, issuing multiple search queries, consulting documents, and even collaborating with other specialized agents. Agents learn to reformulate queries based on initial findings, demonstrating a dynamic understanding of the information-seeking process. Protocols like the Model Context Protocol (MCP) have also been proposed to improve quality by separating web search functionalities from the LLM's core reasoning 'brain', allowing for more specialized and reliable tool use.\n",
      "\n",
      "This evolution has created autonomous search agents capable of in-depth analysis, synthesizing insights, and drafting comprehensive reports. However, it also introduces new challenges, including 'action hallucinations' (fabricating tool call information), getting stuck in repetitive loops, and the critical need for robust safety guardrails and human oversight to manage the risks of live, autonomous web browsing.\n",
      "\n",
      "representative_agentic_systems:\n",
      "[{'system_name': 'R1-Searcher', 'year': 2025.0, 'core_methodology': 'Reinforcement Learning using a two-stage, cold-start Proximal Policy Optimization (PPO) strategy.', 'key_contribution': 'Incentivizes and trains LLMs to first learn *when* to invoke a web search and then *how* to effectively utilize the retrieved information.', 'associated_paper': 'R1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning (arXiv:2503.05592)'}, {'system_name': 'Search-R1', 'year': 2025.0, 'core_methodology': 'Reinforcement Learning with retrieved-token masking and outcome-based rewards, training the agent to interact with live web search APIs.', 'key_contribution': 'Trains LLMs to learn sophisticated strategies for tool interaction and fosters emergent cognitive behaviors for complex, deep research tasks.', 'associated_paper': 'Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning (arXiv:2503.09516)'}, {'system_name': 'ReSearch', 'year': 2025.0, 'core_methodology': 'Fully end-to-end Reinforcement Learning with Proximal Policy Optimization (PPO) that does not rely on pre-existing supervised tool-use trajectories.', 'key_contribution': 'Demonstrates a purely RL-based approach to training search agents without the need for initial supervised data.', 'associated_paper': 'Mentioned in research on agentic LLMs in March 2025.'}, {'system_name': 'WebDancer', 'year': 2025.0, 'core_methodology': 'Combines supervision from human browsing trajectories with Reinforcement Learning (RL) fine-tuning.', 'key_contribution': 'Produces autonomous ReAct-style agents that learn effective web navigation and interaction strategies from expert human behavior.', 'associated_paper': 'Mentioned as a system that excels on GAIA and WebWalkerQA benchmarks in 2025.'}, {'system_name': 'WebThinker', 'year': 2025.0, 'core_methodology': \"Embeds a 'Deep Web Explorer' into a think-search-draft loop, with behavior aligned via Direct Preference Optimization (DPO) using human feedback.\", 'key_contribution': 'Aligns agent behavior with human preferences to tackle complex report generation tasks, ensuring outputs are more useful and aligned.', 'associated_paper': 'Mentioned in research on agentic LLMs in 2025.'}, {'system_name': 'Search-o1', 'year': 2025.0, 'core_methodology': 'An agentic RAG mechanism integrated with Large Reasoning Models (LRMs) for dynamic, inference-time retrieval based on identified knowledge gaps.', 'key_contribution': \"Enhances the reasoning capabilities of powerful models like OpenAI's o1 by allowing them to dynamically search for and process external knowledge as needed.\", 'associated_paper': 'Search-o1: An Agentic RAG Mechanism for Large Reasoning Models (Li et al., 2025)'}, {'system_name': 'DeepResearch', 'year': 2025.0, 'core_methodology': 'A multi-agent system that coordinates specialized sub-agents for querying and summarization, using models to autonomously drive reflection.', 'key_contribution': 'Demonstrates a collaborative agent approach where different agents handle distinct parts of the research process.', 'associated_paper': 'Mentioned as an example of an Agentic-Based Approach in 2025.'}, {'system_name': 'ASearcher', 'year': 2025.0, 'core_methodology': 'Utilizes large-scale asynchronous Reinforcement Learning (RL) with synthesized Question-Answering (QA) data.', 'key_contribution': 'Enables agents to handle long-horizon search tasks that may require 40 or more sequential tool calls, outperforming prior open-source methods.', 'associated_paper': 'Mentioned in research on agentic LLMs in 2025.'}, {'system_name': 'SSRL (Self-Supervised RL)', 'year': 2025.0, 'core_methodology': \"Performs entirely offline 'self-search' during training by interacting with a pseudo search engine distilled from LLMs.\", 'key_contribution': 'Reduces reliance on costly and unstable live web APIs during training, allowing for seamless transfer to online inference.', 'associated_paper': 'Mentioned in research on agentic LLMs in 2025.'}]\n",
      "\n",
      "llm_powered_search_engine_integration:\n",
      "The integration of Large Language Models (LLMs) into the core functionality of search engines has given rise to a new paradigm known as 'generative search'. This represents a fundamental shift from the traditional web search model, which presents users with a ranked list of independent web pages. In contrast, generative search engines like Google's AI Overviews, Microsoft Copilot, and ChatGPT Search leverage LLMs to retrieve information from a wide array of web pages and then synthesize this data into a single, coherent, conversational text response. This approach aims to provide direct, synthesized answers, often with citations, thereby reducing the user's need to click through multiple links. This trend is leading towards a 'zero-click' future, which has significant implications for publishers and the SEO ecosystem, as it can drastically reduce referral traffic. Academic research from 2025 characterizes this evolution, noting that while early 2023 versions were often plagued by hallucinations, by 2025, major platforms have become genuinely useful and more reliable. Beyond just generating answers, LLMs are also being employed for more nuanced search tasks, including advanced query understanding, re-ranking search results, and proactively generating clarifying questions to better understand user intent. This deeper integration is transforming search into a more interactive, intelligent, and conversational experience, fundamentally altering how users seek and consume information on the web.\n",
      "\n",
      "major_industry_implementations:\n",
      "[{'company': 'Google', 'product_name': 'AI Overviews', 'underlying_llm': 'Custom Gemini model (including Gemini 1.5 Pro with a 2 million token context window)', 'technical_integration_pattern': \"AI Overviews are deeply integrated with Google's existing Search systems and vast web index. The system is powered by a custom Gemini model that leverages multi-step reasoning, planning, and multimodality to synthesize information from various web sources into a single summary. The underlying Gemini 1.5 Pro model's massive 2 million token context window allows it to process extensive amounts of data for generating comprehensive responses. The goal is to provide quick, synthesized answers, with a full-screen, conversational 'AI Mode' also being tested in Search Labs.\", 'quality_control_mechanism': \"Google implements algorithmic and manual guardrails to prevent policy violations. However, the initial public rollout in May 2024 faced significant criticism, with independent analysis showing that 40-60% of initial AI-generated previews contained factually incorrect or misleading information. While Gemini's general hallucination rate is cited as low (2.6%), it has shown a very high rate (76.7%) in specific high-stakes domains like financial referencing. For attribution, Google claims that links within AI Overviews receive more clicks than traditional web listings and that the feature encourages visits to a greater diversity of websites, implying a citation mechanism is in place.\"}, {'company': 'Microsoft', 'product_name': 'Copilot (including Microsoft 365 Copilot and Copilot Chat)', 'underlying_llm': 'GPT-4 and other models from its partnership with OpenAI', 'technical_integration_pattern': \"Microsoft Copilot's integration is heavily enterprise-focused, emphasizing security and data privacy. It uses a process called 'grounding' to preprocess prompts, accessing real-time web information via the Bing Index and internal organizational data via the Microsoft Graph. A 'Semantic Index' enhances the Microsoft Graph by embedding semantic understanding, improving Copilot's ability to find relevant internal content. Copilot Agents can automate tasks by connecting to data sources via APIs. For web searches, only essential keywords are sent to Bing, with user and tenant identifiers removed, and all data remains within the Microsoft 365 service boundary.\", 'quality_control_mechanism': \"Copilot employs multiple layers of quality and safety controls. It enforces Responsible AI (RAI) protections to automatically reject risky terms. Source citations are provided directly in the UI for user verification. The system's real-time web grounding is designed to mitigate hallucinations and ensure information is current. For governance, Microsoft is rolling out features like the 'Content Governance Agent' (Preview Nov 2025) and 'Microsoft Purview AI Observability' (Preview Dec 2025) to help administrators manage risk and enforce policies. Contractual commitments ensure that enterprise query data is not used to train AI models or for advertising.\"}, {'company': 'OpenAI', 'product_name': 'ChatGPT (Browsing/Agent Modes), Deep Research Agent, o1 model', 'underlying_llm': 'GPT-4, GPT-4o, o1 (a large reasoning model)', 'technical_integration_pattern': \"OpenAI's ChatGPT integrates web search via its browsing mode, allowing the model to access and process real-time information from the internet to answer queries. Beyond simple browsing, OpenAI is developing more advanced agentic systems. The 'OpenAI Deep Research Agent' is a prime example, designed for complex, multi-step research tasks. The 'o1' model is specifically focused on chain-of-thought reasoning for agents. Frameworks like 'Search-o1' are being developed to enhance these Large Reasoning Models (LRMs) with an 'agentic RAG' mechanism, enabling them to dynamically search for external knowledge when they identify gaps in their own understanding.\", 'quality_control_mechanism': 'Quality control is assessed through rigorous benchmarking. The OpenAI Deep Research Agent demonstrates high performance on difficult benchmarks like BrowseComp (51.5%) and HLE (26.6%), significantly outperforming standard LLMs. Hallucination rates are actively measured for models like GPT-4 Turbo (0.019). The focus of development is on improving the reliability of tool use and the robustness of multi-step reasoning to ensure agents can perform complex tasks accurately and safely.'}, {'company': 'Anthropic', 'product_name': 'Claude 3.5 Agent, Contextual Retrieval', 'underlying_llm': 'Claude 3 family (including Claude 3.5 Sonnet)', 'technical_integration_pattern': \"Anthropic is a leader in developing agentic AI, focusing on training models to iteratively improve responses and use a variety of tools (search, calculators, etc.). The 'Claude 3.5 Agent' (released 2025) is designed for enterprise assistance and features multimodal input capabilities. A key technical innovation is 'Contextual Retrieval' (Sept 2024), which significantly enhances RAG performance. Anthropic is also pioneering protocols like the Model Context Protocol (MCP) to better integrate tools like web search, allowing for more specialized and reliable agent behavior.\", 'quality_control_mechanism': \"Anthropic's models are top performers on various industry benchmarks. For instance, Claude 3.5 Sonnet scores highly on MixEval-Hard, and the company actively tracks metrics like hallucination rates (e.g., 0.014 for a Claude 3.7 Sonnet model). The company's research emphasizes creating reliable and steerable AI, with a focus on enterprise-grade applications where accuracy and safety are paramount. Their approach involves training models for self-correction and robust tool integration to ensure high-quality outputs.\"}]\n",
      "\n",
      "influential_architectural_and_model_trends:\n",
      "{'trend_name': 'Agentic RAG and AI Agent Systems', 'description': \"Agentic RAG represents a significant architectural evolution from earlier RAG models, marking a paradigm shift towards autonomous, intelligent systems. This trend, which gained major traction from late 2024 into 2025, involves an 'Agent'‚Äîan LLM-powered system‚Äîthat can perceive its environment, reason, create complex plans, and execute a sequence of actions to achieve a goal. Instead of a static, one-shot retrieval process, an Agentic RAG system can dynamically query data sources, use external tools (like calculators, code interpreters, or SQL databases), read and synthesize results, re-query based on new information, and self-correct its approach. This approach integrates core agentic capabilities such as reflection, planning, tool use, and even collaboration with other agents, blurring the lines between RAG and autonomous agent platforms. A key concept within this trend is 'Context Engineering,' which focuses on strategically filling the model's context window with the most relevant information at each step of the agent's task.\", 'impact_on_web_search': 'This trend fundamentally transforms LLM web search from a simple information retrieval task into a complex problem-solving process. For RAG, it moves beyond just grounding answers in facts to enabling multi-hop reasoning, where the agent can synthesize information from multiple web searches and documents to answer complex questions that require several steps. For agentic browsing, it allows the LLM to not just find information but to act on it, performing tasks like booking flights, analyzing market data from multiple financial sites, or conducting deep research by autonomously navigating the web. This enables the resolution of complex, multi-step problems and facilitates more intelligent and nuanced decision-making, far surpassing the capabilities of basic RAG or simple web browsing modes.', 'cost_and_latency_implications': \"The advanced capabilities of Agentic RAG come with significant tradeoffs in cost and latency. Unlike basic RAG which has low latency, agentic systems are inherently slower. The need for the LLM to 'think'‚Äîto plan, execute sequential tool calls, and process the results of each step‚Äîintroduces considerable latency. Each step in the agent's reasoning process often requires a separate call to the LLM, leading to a substantial increase in total token consumption and, consequently, higher computational costs. This makes Agentic RAG more expensive and less suitable for applications requiring instantaneous responses, positioning it more for deep, complex analysis rather than quick Q&A.\", 'representative_models_or_systems': \"The Agentic RAG trend is embodied by a variety of frameworks and models. The 'ReAct' (Reason + Act) prompting paradigm is a foundational framework that enables this behavior. More advanced systems include 'Search-o1', a framework designed to enhance Large Reasoning Models (LRMs) like OpenAI's 'o1' with agentic retrieval. Reinforcement Learning-based approaches like 'Search-R1' train agents to interact with live web search APIs. Experimental open-source projects like 'AutoGPT' demonstrated the potential for multi-step planning and web querying. Industry players like Microsoft are also heavily investing in integrating agentic capabilities into their platforms, such as Azure, MS Office, and Copilot.\"}\n",
      "\n",
      "evaluation_benchmarks_and_metrics:\n",
      "[{'benchmark_name': 'FACTS Grounding', 'year': 2024.0, 'purpose': 'To evaluate the ability of LLMs to generate responses that are factually accurate with respect to provided source material (up to 32k tokens) and sufficiently detailed, thereby preventing hallucinations.', 'key_metrics': 'A two-phased evaluation using an ensemble of LLM judges (Gemini 1.5 Pro, GPT-4o, Claude 3.5 Sonnet): 1) Eligibility (does the response address the request?) and 2) Factual Accuracy (is the response fully grounded in the document?).', 'main_finding_or_use_case': 'Used to drive industry-wide advancements in factuality and grounding. An active leaderboard is maintained on Kaggle. Initial results show high factuality scores for models like Gemini 1.5 Pro and Gemini 1.5 Flash.'}, {'benchmark_name': 'RAGAS (Retrieval-Augmented Generation Assessment System)', 'year': 2023.0, 'purpose': 'To evaluate the factuality and overall quality of Retrieval-Augmented Generation (RAG) pipelines by assessing the alignment between generated content and retrieved documents.', 'key_metrics': 'Reference-free metrics including Faithfulness, Context Precision, Context Recall, and Answer Relevance. A combined factuality score can be computed from these.', 'main_finding_or_use_case': 'Used to identify and penalize hallucinations in RAG systems. A faithfulness score below 0.8 typically indicates the model is introducing unsupported claims. It is often implemented as a composable evaluation node within LangChain pipelines.'}, {'benchmark_name': 'SafeRAG', 'year': 2025.0, 'purpose': 'The first security benchmark specifically designed for RAG pipelines, cataloging and evaluating system robustness against various attack classes.', 'key_metrics': 'Classifies attack tasks into four categories: Silver Noise (partially correct evidence), Inter-context Conflict (tampered texts), Soft Ad Attack (implicit toxicity), and White DoS (false safety warnings).', 'main_finding_or_use_case': 'Demonstrated that 14 representative RAG systems were vulnerable to simple manipulations, which sparked research interest in provenance tracking and adversarially trained retrievers to improve RAG security.'}, {'benchmark_name': 'LiveResearchBench', 'year': 2025.0, 'purpose': \"A user-centric benchmark for deep research, designed to evaluate an LLM's ability to iteratively seek, validate, and integrate evidence for complex tasks requiring up-to-date information.\", 'key_metrics': 'Evaluated using the DeepEval suite, which includes report-level metrics (presentation, consistency) and fine-grained dimensions (depth, checklist-based coverage, citation association, rubric-tree accuracy).', 'main_finding_or_use_case': 'Revealed that even state-of-the-art systems struggle with citation reliability and analytical depth, often functioning more as information collectors than sophisticated writers of evidence-grounded reports.'}, {'benchmark_name': 'CURIE', 'year': 2025.0, 'purpose': 'To evaluate the reasoning capabilities of LLMs across long scientific documents.', 'key_metrics': 'The specific metrics are not detailed in the provided context.', 'main_finding_or_use_case': 'Revealed that even leading models like Claude 3 and Gemini 2.0 Flash struggle with reasoning across long scientific documents, highlighting a key area for improvement.'}, {'benchmark_name': 'SummHay', 'year': 2025.0, 'purpose': \"To evaluate long-context understanding in LLMs and RAG systems by challenging them to generate summaries that capture key insights deliberately repeated across a 'haystack' of documents.\", 'key_metrics': 'Coverage (capturing repeated key insights) and Citation (accurately citing source documents), which are combined into a joint score.', 'main_finding_or_use_case': 'Found that current LLM and RAG systems lag human performance by over 10 points on the joint score, indicating significant room for improvement in long-context summarization and citation.'}, {'benchmark_name': 'RARE (Retrieval-Aware Robustness Evaluation)', 'year': 2025.0, 'purpose': 'A comprehensive framework for evaluating the robustness of RAG systems against noisy or imperfect inputs, particularly for domain-specific, technical queries.', 'key_metrics': 'The framework includes RARE-Get (a dynamic synthesis pipeline for time-sensitive data) and RARE-Set (a large-scale benchmark with over 48,000 queries across finance, economics, and policy).', 'main_finding_or_use_case': 'Used to assess how RAG systems perform with perturbed queries or when provided with partially relevant or contradictory retrieved documents, pushing for more robust system design.'}, {'benchmark_name': 'CRAG (Comprehensive RAG benchmark)', 'year': 2024.0, 'purpose': 'A benchmark for evaluating RAG systems, with a particular focus on those utilizing search engines.', 'key_metrics': 'The benchmark contains 4,409 entries. The associated CRAG *method* uses a retrieval evaluator to assign a confidence score (Correct, Incorrect, Ambiguous) to documents.', 'main_finding_or_use_case': 'Provides a standardized dataset for evaluating and comparing the performance of different RAG systems. The CRAG method enhances robustness by triggering corrective actions like web searches for low-confidence retrievals.'}, {'benchmark_name': 'MTEB (Massive Text Embedding Benchmark)', 'year': 2022.0, 'purpose': 'To comprehensively evaluate text embedding models, which are a critical component of the retrieval stage in RAG systems.', 'key_metrics': 'Evaluates models across a wide range of tasks including retrieval, reranking, classification, clustering, and summarization, over 58 datasets and 112 languages.', 'main_finding_or_use_case': 'Serves as an essential tool for selecting and improving the retriever component of RAG systems. For example, Contextualized Embeddings (2024) achieved state-of-the-art retrieval performance on this benchmark.'}, {'benchmark_name': 'Deep Research Bench', 'year': 2025.0, 'purpose': 'To evaluate agentic LLMs on deep research tasks within a controlled, offline environment called RetroSearch.', 'key_metrics': 'Success rates, grounded accuracy, latency, tool-call reliability, citation/grounding rates, and action budgets (e.g., 50 actions per task).', 'main_finding_or_use_case': 'Used to evaluate advanced agents like the OpenAI Deep Research Agent, which significantly outperformed standard LLMs on complex tasks requiring synthesis from obscure sources.'}]\n",
      "\n",
      "security_and_robustness_challenges:\n",
      "{'challenge_area': 'Security', 'specific_threat': 'Data Poisoning', 'description': 'Data poisoning is a significant threat to the integrity and security of LLMs, particularly in Retrieval-Augmented Generation (RAG) systems. Adversaries can compromise the integrity of the external knowledge base by poisoning indices, implanting backdoors, or crafting retrieval-optimized injections. This manipulation leads to the retrieval of false, misleading, or malicious information, which is then used by the LLM to generate its response. This can be used to manipulate the model towards unsafe behaviors. Research from 2024-2025, including works by Zou et al. and Xue et al., has specifically investigated these vulnerabilities, demonstrating that the integration of external knowledge corpora in RAG creates unique attack vectors not present in traditional LLMs.', 'affected_systems': 'Retrieval-Augmented Generation (RAG) and Agentic Browsing'}\n",
      "\n",
      "mitigation_strategies_for_risks:\n",
      "[{'strategy_category': 'Retrieval Hardening', 'specific_technique': 'Domain Whitelisting / Restricted Retrieval Sources', 'description': \"This strategy involves restricting the RAG system's retrieval process to a pre-approved set of trusted and privacy-screened data sources. By implementing domain whitelisting and prioritizing internal retrieval systems, it prevents the model from accessing and ingesting information from potentially malicious or unreliable websites. This directly mitigates risks from adversarial web content, data poisoning, and the retrieval of misleading information. When third-party search APIs must be used, queries can be anonymized or masked to enhance privacy.\", 'tradeoff': 'The primary tradeoff is between coverage and safety. Restricting retrieval sources enhances security but may significantly reduce the breadth of information available to the LLM, potentially limiting the comprehensiveness and currency of its responses.'}, {'strategy_category': 'Content Sanitization', 'specific_technique': 'Input Sanitization and HTML Stripping', 'description': 'This mitigation involves cleaning and preprocessing data before it is passed to the LLM. Input sanitization is used to detect and neutralize malicious instructions embedded in user prompts, thereby preventing prompt injection attacks. Similarly, HTML stripping removes potentially harmful scripts, irrelevant formatting, or hidden instructions from retrieved web content, ensuring that the LLM processes clean, relevant text. This helps to fortify the system against attacks embedded within the retrieved content itself.', 'tradeoff': 'Adding multiple layers of defense, including content sanitization and filtering, invariably increases processing time. This can introduce noticeable latency, which may impact the real-time performance and user experience of the LLM web search system.'}, {'strategy_category': 'Data Handling', 'specific_technique': 'Differential Privacy', 'description': \"Retriever-level differential privacy is a promising technique for building privacy-preserving RAG systems. It works by adding a mathematically calibrated amount of noise to the retrieval process or the data itself. This makes it difficult for an attacker to determine whether a specific document was part of the retrieval set or to reconstruct sensitive information from the model's output, thus protecting against document-level membership inference and reconstruction attacks. Research from 2024 has explored its application to guard against information leakage.\", 'tradeoff': \"The main tradeoff is between utility and privacy. While effective for privacy, the introduction of noise can sometimes reduce the accuracy and utility of the retrieved information, potentially affecting the quality and factual correctness of the LLM's final output.\"}, {'strategy_category': 'System Architecture', 'specific_technique': 'Sandboxed Browsing', 'description': \"Specifically for agentic AI systems that can perform actions like browsing the web, sandboxing provides a critical layer of security. The agent's actions are executed within an isolated, controlled environment. This containment prevents a compromised or malicious agent from performing unsafe tool actions, accessing unauthorized system resources, or causing harm to the underlying infrastructure, effectively limiting the blast radius of a security incident.\", 'tradeoff': \"Implementing and managing a sandboxed environment adds complexity to the system architecture. Furthermore, if the sandbox is overly restrictive, it might limit the agent's legitimate capabilities and overall utility.\"}, {'strategy_category': 'Bias Mitigation', 'specific_technique': 'Bias-Controlled Embedding and Query Rewriting', 'description': \"This strategy aims to address and mitigate fairness issues and demographic biases that can be amplified by RAG systems. It involves several components: curating more inclusive and diverse datasets for retrieval, prompting the LLM to generate balanced responses, and implementing query rewriting techniques to neutralize biases present in the user's initial query before it is sent to the retriever. This multi-pronged approach helps to ensure the system produces more equitable and fair outputs.\", 'tradeoff': \"Implementing bias controls adds layers of processing, which can increase latency. There is also a risk of over-correction, where the attempt to mitigate bias might inadvertently skew results or reduce the relevance of the retrieved information for the user's original intent.\"}]\n",
      "\n",
      "market_and_publisher_ecosystem_impact:\n",
      "The integration of Large Language Models (LLMs) into web search, particularly through features like Google's AI Overviews, has triggered significant and disruptive impacts on the digital market and publisher ecosystem between late 2023 and 2025. The most profound effect is the acceleration of the 'zero-click' phenomenon. By providing synthesized, direct answers at the top of the search results page, these systems reduce the user's need to click through to source websites. This has led to substantial traffic displacement for publishers who rely on search referral traffic for revenue and audience engagement. \n",
      "\n",
      "Empirical data from the initial rollout of Google's AI Overviews in 2024 highlighted the severity of this impact, with publishers reporting a significant '40-60% drop in click-through rates from AI summaries'. This has raised existential concerns for the content ecosystem, as it directly affects advertising revenue and the viability of many online publications. The economic model of the ad-funded internet is further challenged by the rise of agentic search, which, as of November 2025, is noted to be 'generating massive web traffic without ad revenue'. While this shift benefits users with quick answers and search engine providers with increased engagement, it threatens the symbiotic relationship between search engines and content creators. Interestingly, Google has countered these concerns, claiming that links within AI Overviews actually receive more clicks than traditional web listings for the same queries and that the feature encourages visits to a 'greater diversity of websites', especially for complex questions. The financial upside for search providers is substantial; Morgan Stanley projects that for every 10% of search queries handled by AI, Google could see an additional $1.2 billion in annual revenue, potentially reaching $12 billion if 50% of queries are AI-processed.\n",
      "\n",
      "In response to this new paradigm, a necessary and rapid shift in Search Engine Optimization (SEO) and content strategies is underway. To remain visible and relevant to LLM-powered search crawlers and synthesizers, brands and publishers are advised to adapt their strategies. This includes a greater emphasis on structured data through 'schema markup', providing 'real-time updates', creating comprehensive 'FAQs', and incorporating rich 'multimedia content'. The goal is to create content that is easily digestible and valuable for AI synthesis, thereby increasing the chances of being featured and cited in AI-generated answers. The impact, however, is not uniform. Enterprise-focused systems like Microsoft Copilot, which use web grounding primarily for internal business intelligence within a secure and private framework, have a less pronounced direct impact on the public SEO ecosystem compared to broad, consumer-facing systems like Google's AI Overviews.\n",
      "\n",
      "user_experience_and_cognitive_impacts:\n",
      "The rise of generative search, powered by LLMs, has fundamentally altered the user experience (UX) of information retrieval and raises significant questions about its long-term cognitive impacts. The primary UX shift is from the traditional paradigm of a ranked list of blue links, which requires users to click, evaluate, and synthesize information from multiple sources, to a more direct, conversational model that provides a single, synthesized answer. Systems like Google's AI Overviews and ChatGPT Search, which by early 2025 were considered 'genuinely useful' after overcoming earlier hallucination issues, exemplify this change.\n",
      "\n",
      "From a user experience perspective, this shift has been largely positive. Research indicates that for Google's AI Overviews, 'users reported increased satisfaction and more frequent use of Search'. The feature is particularly valued for its ability to handle complex questions that would have traditionally required multiple searches, effectively 'streamlining the information retrieval process' and reducing user effort. The user experience is set to become even more personalized, with planned features for Google's Search Labs allowing users to 'adjust the overview's language for simplicity or greater detail'. Furthermore, Google is testing a full-screen 'AI Mode' powered by Gemini, which offers a fully conversational search experience that prioritizes detailed responses over link lists, representing a deeper commitment to this new paradigm. In the enterprise space, systems like Microsoft Copilot enhance productivity by providing contextually relevant answers, while also giving users control, such as the ability to toggle web grounding on or off.\n",
      "\n",
      "However, this streamlined consumption of pre-synthesized information has prompted serious concerns about the cognitive impacts on users. An academic study from September 2025 suggests that LLM summaries, by their very nature, 'might lead to shallower knowledge and less original thought compared to traditional web search'. The cognitive effort of seeking out, comparing, and synthesizing information from various sources, while more laborious, is integral to deep learning and critical thinking. By offloading this process to an AI, there is a risk that users may engage less critically with information, potentially hindering their ability to form nuanced perspectives and develop their own insights. This raises profound questions about the long-term effects of generative search on information literacy, learning depth, and the development of critical thinking skills in the general population, representing a critical tradeoff between convenience and cognitive engagement.\n",
      "\n",
      "open_problems_and_future_research_directions:\n",
      "The rapid advancements in LLM-powered web search from late 2023 to 2025 have surfaced a multitude of complex open problems and defined clear future research directions that will shape the next generation of information access.\n",
      "\n",
      "**1. Evaluation of Complex Reasoning and Generative Search:**\n",
      "A primary challenge is the inadequacy of existing evaluation metrics. Traditional Information Retrieval (IR) benchmarks are designed for ranked lists of documents, not for the single, synthesized, long-form answers produced by generative search. Future research must develop new evaluation criteria and benchmarks that can assess the quality, coherence, factuality, and attribution of these generative outputs. Furthermore, current benchmarks like CURIE, SummHay, and LiveResearchBench reveal that even state-of-the-art models struggle with reasoning across long scientific documents, complex multi-hop queries, and deep research tasks. Overcoming weaknesses in current evaluation frameworks, such as data contamination, LLM evaluator bias, and high latency, is also a critical research direction.\n",
      "\n",
      "**2. Security, Robustness, and Privacy:**\n",
      "The integration of external web content via RAG and agentic browsing introduces significant security vulnerabilities. A key area for future research is defending against a new class of threats. The SafeRAG benchmark (2025) revealed that RAG systems are vulnerable to attacks like 'silver noise' (partially correct evidence), 'inter-context conflict', and 'soft ad attacks' that can bypass existing guardrails. Open problems include:\n",
      "*   **Privacy-Preserving RAG:** Developing robust techniques like retriever-level differential privacy, encrypted search indices, and federated retrieval to prevent the leakage of sensitive information from retrieval databases or user queries.\n",
      "*   **Retrieval and Data Poisoning:** Creating methods to harden retrievers against poisoned indices and adversarial web content designed to manipulate model behavior.\n",
      "*   **Agentic Security:** Securing autonomous agents from prompt injections, unsafe tool actions, and other exploits that could lead to unauthorized data access or harmful outcomes. This includes developing secure sandboxed browsing environments.\n",
      "\n",
      "**3. Factuality, Hallucination, and Bias:**\n",
      "Despite improvements, ensuring factual accuracy remains a paramount challenge. Even advanced models like Google's Gemini have shown high hallucination rates (e.g., 76.7% in high-stakes financial referencing tasks) in practice. Agentic systems introduce new failure modes like 'Action Hallucinations' (fabricating information in tool calls). Future research must focus on:\n",
      "*   **Robust Grounding and Citation:** Improving the reliability of citations and ensuring that generated claims are strictly supported by retrieved evidence.\n",
      "*   **Mitigating Bias:** Developing methods to control for and mitigate demographic and other biases present in both the LLM's training data and the retrieved web content. This includes research into bias-controlled embeddings and query rewriting techniques.\n",
      "*   **Handling Noisy and Misleading Context:** Enhancing the ability of RAG systems to identify and discard irrelevant, outdated, or intentionally misleading information retrieved from the web.\n",
      "\n",
      "**4. Performance, Cost, and Scalability:**\n",
      "The computational cost and latency of advanced RAG and agentic systems are significant barriers to widespread, real-time deployment. Open problems include:\n",
      "*   **Efficient Long-Context Handling:** Addressing the 'lost-in-the-middle' problem where models overlook key details in long context windows and reducing the high computational cost associated with them.\n",
      "*   **Optimized Architectures:** Research into methods like KV-cache reuse and sparse attention to reduce inference costs, and improving their effectiveness for RAG on lengthy documents.\n",
      "*   **Scalable Systems:** Designing architectures and accessible tooling that allow for the efficient deployment, maintenance, and scaling of RAG and agentic search systems.\n",
      "\n",
      "**5. Long-Term Societal and Cognitive Impact:**\n",
      "Perhaps the most profound open questions relate to the broader societal impact of this technology. A critical area for academic inquiry is the long-term effect on user cognition. As identified in a 2025 study, the shift to pre-synthesized answers may lead to 'shallower knowledge and less original thought'. Research is urgently needed to understand and potentially mitigate these impacts on learning, critical thinking, and information literacy. Additionally, the economic disruption to the publisher ecosystem and the ad-funded internet model requires further study to understand its long-term consequences and explore sustainable alternatives.\n",
      "\n",
      "**6. Multimodal and Advanced Reasoning Capabilities:**\n",
      "Future research will continue to push the boundaries of what LLM search can do. Key directions include:\n",
      "*   **Multimodal RAG:** Solving open challenges in multimodal RAG, such as effective cross-modal alignment and vision-aware reranking, to enable retrieval and reasoning over text, images, audio, and video.\n",
      "*   **Graph-Enhanced RAG (GraphRAG):** Integrating LLMs with auto-updating knowledge graphs to enhance context-aware, multi-hop reasoning and provide more structured, reliable knowledge.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join the dict keys with newline, each followed by its content (stringified)\n",
    "joined_keys_and_content = \"\\n\".join(\n",
    "    f\"{key}:\\n{run_result.output.content[key]}\\n\" for key in run_result.output.content.keys()\n",
    ")\n",
    "print(joined_keys_and_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56e973d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in run_result.output: 11776\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Count the number of tokens in run_result.output using tiktoken's default GPT-3.5 encoder\n",
    "encoder = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "num_tokens = len(encoder.encode(joined_keys_and_content))\n",
    "print(f\"Number of tokens in run_result.output: {num_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e1e5915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/weaviate/warnings.py:302: ResourceWarning: Con004: The connection to Weaviate was not closed properly. This can lead to memory leaks.\n",
      "            Please make sure to close the connection using `client.close()`.\n",
      "  warnings.warn(\n",
      "/var/folders/41/8dp_379x15d8zz4ppsjthdw40000gn/T/ipykernel_80899/1590768392.py:5: ResourceWarning: unclosed <ssl.SSLSocket fd=88, family=2, type=1, proto=0, laddr=('10.0.0.233', 63725), raddr=('35.201.124.182', 443)>\n",
      "  weaviate_client = weaviate.connect_to_weaviate_cloud(\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "from weaviate.classes.config import Configure, Property, DataType\n",
    "\n",
    "weaviate_client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=os.getenv(\"WEAVIATE_URL\"),\n",
    "    auth_credentials=Auth.api_key(os.getenv(\"WEAVIATE_API_KEY\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38e84b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_research_reports = weaviate_client.collections.create(\n",
    "    name=\"WebResearchReports\",\n",
    "    description=\"Web research reports on LLMs\",\n",
    "    vector_config=Configure.Vectors.text2vec_weaviate(),\n",
    "    properties=[\n",
    "        Property(name=\"content\", data_type=DataType.TEXT),\n",
    "        Property(name=\"query\", data_type=DataType.TEXT),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48810180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('d55bb4f7-990d-45eb-88f5-316cac32ce6a')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_research_reports.data.insert(\n",
    "    properties={\n",
    "        \"query\": query,\n",
    "        \"content\": joined_keys_and_content,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e3f8ba",
   "metadata": {},
   "source": [
    "# Chat with Query Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6755732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent advances in Information Retrieval (IR) applied to Web Search, especially in the context of Large Language Models (LLMs) from late 2023 to 2025, reveal a transformative shift from traditional static retrieval toward dynamic, agentic reasoning and integration of generative AI techniques. The overlap of cutting-edge IR and Web Search is characterized by several key converging areas:\n",
      "\n",
      "1. **Retrieval-Augmented Generation (RAG) Evolution:**  \n",
      "   RAG systems combine LLMs with external knowledge sources, particularly web content, to ground responses in real-time, factual data. There has been a progression from basic retrieval models to modular, self-correcting, and agentic RAG systems. Key innovations include:  \n",
      "   - **Self-RAG:** LLMs learn to trigger on-demand retrieval and critique their own generations to improve factuality and reduce hallucinations.  \n",
      "   - **Corrective RAG (CRAG):** Incorporates retrieval quality evaluators that prompt corrective web searches when necessary.  \n",
      "   - **Agentic RAG:** Autonomous agents plan multi-step workflows, dynamically query data sources, use external tools, and self-correct iteratively, transcending static retrieval pipelines.  \n",
      "   - **GraphRAG and Multimodal RAG:** Integration of structured knowledge graphs and support for multi-modal data (images, video) enrich retrieval capabilities.\n",
      "\n",
      "2. **LLM-Powered Search Engines:**  \n",
      "   Search engines like Google AI Overviews, Microsoft Copilot, and OpenAI ChatGPT integrate LLMs deeply to synthesize diverse web results into single, conversational answers. This generative search model moves away from ranked lists toward zero-click search experiences, providing users with synthesized summaries often with citations. This shift improves user satisfaction but disrupts traditional publisher traffic models.\n",
      "\n",
      "3. **Agentic LLMs and Autonomous Search Agents:**  \n",
      "   Reinforcement learning (RL) and techniques like Proximal Policy Optimization train LLMs to autonomously plan, issue queries, interpret retrieved information, and execute multi-step reasoning tasks. This ability transforms web search into an interactive, tool-using agent process capable of complex research and dynamic knowledge synthesis.\n",
      "\n",
      "4. **Architectural Innovations and Benchmarks:**  \n",
      "   Advances include longer context windows (up to millions of tokens), more efficient models (like Mixture-of-Experts), and the creation of evaluation benchmarks (RAGAS, FACTS Grounding, LiveResearchBench, SafeRAG) that measure factuality, robustness, and security in retrieval-augmented systems. These benchmarks highlight both progress and persistent challenges such as hallucinations, citation reliability, robustness against attacks, and cognitive impact on users.\n",
      "\n",
      "5. **Security and Robustness:**  \n",
      "   The introduction of external web knowledge exposes new attack surfaces like data poisoning, prompting development of mitigation strategies such as domain whitelisting, content sanitization, sandboxed browsing for agents, and retriever-level differential privacy.\n",
      "\n",
      "6. **User Experience and Societal Impacts:**  \n",
      "   Generative search improves immediate usability and reduces user effort but may lead to shallower knowledge acquisition and reduced critical engagement by presenting pre-synthesized answers instead of diverse source exploration.\n",
      "\n",
      "In summary, the current cutting-edge in IR applied to web search centers on seamlessly blending advanced retrieval models with LLMs to enable interactive, accurate, and context-aware search experiences. These systems autonomously manage retrieval, reasoning, and multi-step tool use, while ongoing research focuses on enhancing factual accuracy, security, efficiency, and the holistic user impact of this paradigm shift.\n"
     ]
    }
   ],
   "source": [
    "from weaviate.agents.query import QueryAgent\n",
    "\n",
    "query_agent = QueryAgent(\n",
    "    client=weaviate_client,\n",
    "    collections=[\"WebResearchReports\", \"IRPapersText_Default\"]\n",
    ")\n",
    "\n",
    "response = query_agent.ask(\n",
    "    \"What is the overlap of recent advances in Information Retrieval applied to Web Search?\"\n",
    ")\n",
    "\n",
    "print(response.final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
