{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local RAG with Ollama and Weaviate\n",
    "## Using Weaviate integration\n",
    "\n",
    "This example shows how to use the text2vec-ollama as well the generative-ollama "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "1. Download and install Ollama for your operating system: https://ollama.com/download\n",
    "2. `pip` install the Python library to generate vector embeddings from the model  with `pip install ollama`. (REST API or JavaScript library also available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U weaviate-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Pull relevant LLM and [embedding model](https://ollama.com/blog/embedding-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ollama pull llama3\n",
    "#!ollama pull all-minilm # mxbai-embed-large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Optional: Test if the vectorizer works (`ollama run llama2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"embedding\":[-0.37209033966064453,0.41945910453796387,-0.42962121963500977,0.301665335893631,-0.47567272186279297,-0.006124582141637802,-0.18393747508525848,-0.4657520353794098,0.024121297523379326,0.41036325693130493,0.2584318220615387,-0.3501233458518982,0.3749215006828308,-0.17598895728588104,0.0711904764175415,0.07458031177520752,-0.01956084743142128,0.0819740742444992,-0.11168335378170013,-0.09002675116062164,-0.14640718698501587,-0.003168143332004547,0.3027119040489197,0.036542121320962906,-0.38922950625419617,0.6812086701393127,0.022584855556488037,-0.14138051867485046,0.007853759452700615,0.056560762226581573,-0.3321329951286316,-0.17216357588768005,0.3234858512878418,-0.07221385836601257,-0.25651711225509644,0.26626133918762207,0.2913508415222168,0.4247307777404785,0.531809389591217,0.2818898856639862,0.3869876265525818,0.10163667798042297,0.44477325677871704,-0.4057876169681549,0.18915584683418274,-0.46048250794410706,-0.1599886119365692,0.4838547110557556,0.37467050552368164,0.5489786863327026,0.03950950503349304,-0.47058647871017456,0.023886648938059807,-0.08725707232952118,0.1774318814277649,-0.2026488184928894,-0.45874083042144775,-0.30728280544281006,-0.0655234158039093,0.10643117129802704,0.40838348865509033,0.13274240493774414,0.023195555433630943,0.2408665418624878,-0.10203438252210617,-0.04191429913043976,0.07857876271009445,-0.20157694816589355,-0.018373876810073853,-0.45229092240333557,-0.11794888228178024,-0.048641983419656754,-0.16064128279685974,0.4971936047077179,-0.8507972955703735,0.3952779769897461,0.3996374011039734,-0.19274328649044037,-0.3220020532608032,0.23038017749786377,-0.34131869673728943,-0.07201544940471649,-0.05530153214931488,0.18839450180530548,-0.01031940896064043,0.41932588815689087,0.048731137067079544,-0.048124805092811584,-0.2311696857213974,-0.04325147718191147,-0.10154056549072266,-0.3987206816673279,0.39738303422927856,-0.16688580811023712,0.09610196948051453,-0.1740434318780899,0.24585872888565063,0.3052745759487152,-0.5116039514541626,0.2130918651819229,-0.073385089635849,-0.4634999632835388,0.1535351723432541,0.05950577184557915,-0.1531306356191635,0.06365344673395157,-0.4396103024482727,0.05053701251745224,-0.04075149819254875,-0.25876685976982117,-0.6404903531074524,0.10672592371702194,-0.5257860422134399,0.3974034786224365,-0.08858504146337509,-0.05106503143906593,0.029038021340966225,-0.0720849558711052,-0.45400524139404297,-0.2558499574661255,-0.019033368676900864,-0.09344528615474701,0.375601202249527,-0.043496254831552505,0.5519961714744568,-0.010452371090650558,-0.23284952342510223,-1.393872695467061e-32,0.13052667677402496,-0.31139400601387024,0.17242053151130676,-0.06438953429460526,0.02074982225894928,-0.1283559799194336,-0.37698808312416077,0.26793986558914185,-0.3396163880825043,-0.16427284479141235,-0.5153746008872986,0.18173933029174805,0.3735239803791046,-0.18889868259429932,0.2136746644973755,0.08191340416669846,-0.20752465724945068,-0.21216821670532227,0.16151365637779236,-0.6101203560829163,-0.38703441619873047,0.5350027680397034,0.28569716215133667,-0.13036179542541504,-0.2860144376754761,0.18782968819141388,0.5696808695793152,-0.5237735509872437,-0.5575640201568604,0.1863565742969513,0.056216612458229065,-0.0055171772837638855,-0.38307106494903564,-0.010429512709379196,-0.410847008228302,0.20786389708518982,-0.19443587958812714,-0.27672287821769714,-0.33873021602630615,-0.03521300107240677,-0.12021312117576599,-0.16079704463481903,-0.02580297738313675,0.1872997283935547,-0.21164003014564514,-0.15188182890415192,0.017056845128536224,-0.3072252869606018,0.10919933021068573,0.3950623869895935,-0.18403446674346924,0.36776474118232727,0.193450465798378,0.26436513662338257,-0.24407421052455902,-0.11202553659677505,0.23397284746170044,0.2149268090724945,-0.10513941943645477,0.2545173168182373,0.28994855284690857,-0.12789547443389893,-0.005550257861614227,-0.09852835536003113,-0.02616177499294281,0.16143718361854553,0.04082256555557251,0.07622797787189484,0.6219577193260193,0.06422118842601776,0.4534900188446045,0.0761273205280304,0.24534140527248383,0.3397858440876007,0.15807770192623138,-0.02060851827263832,0.1291147768497467,0.3414180278778076,-0.1551847755908966,0.1298799216747284,0.25647664070129395,0.2953099012374878,0.499838650226593,0.009898758493363857,-0.25320762395858765,0.18592053651809692,0.13019394874572754,0.23021668195724487,-0.457153856754303,-0.453892320394516,0.14225246012210846,0.5112994909286499,-0.3583093285560608,-0.38234347105026245,0.35166412591934204,-1.961471750768317e-33,-0.012965701520442963,-0.17010711133480072,-0.12123184651136398,-0.35493677854537964,-0.27631503343582153,-0.43949824571609497,0.3679261803627014,0.27992314100265503,-0.3097590208053589,0.09422089159488678,-0.020984165370464325,0.06871011108160019,-0.04599980264902115,-0.311811625957489,0.13170649111270905,-0.3077235817909241,-0.09357818216085434,-0.1508655846118927,0.2299269586801529,-0.6516737937927246,0.001304134726524353,0.16466380655765533,0.2712422013282776,-0.4356854259967804,0.21923813223838806,-0.30168062448501587,-0.15682804584503174,0.07861083000898361,-0.2610197365283966,-0.03343929350376129,-0.1896410882472992,0.36612144112586975,-0.02603141963481903,-0.1798054575920105,0.06024153158068657,-0.14110594987869263,-0.5858433842658997,0.24278391897678375,-0.02997596189379692,-0.17848439514636993,-0.05301710590720177,0.32303866744041443,-0.0632171481847763,0.10957224667072296,0.44106268882751465,0.3788635730743408,-0.13664820790290833,0.1267879605293274,-0.17723381519317627,-0.05754293501377106,0.36879223585128784,0.2253907024860382,0.4214901626110077,0.13192689418792725,0.9874517321586609,0.0189534779638052,-0.25634896755218506,-0.19266784191131592,0.15025414526462555,-0.10584060847759247,0.08010183274745941,-0.11066581308841705,0.02172360196709633,-0.023356176912784576,0.30773836374282837,-0.07578292489051819,-0.08771444112062454,-0.19032829999923706,0.4195217788219452,0.14262042939662933,0.31274518370628357,-0.47900617122650146,-0.25897133350372314,-0.19332155585289001,0.314441442489624,-0.01662939041852951,-0.5543906688690186,-0.04148702323436737,0.16160999238491058,-0.012709449976682663,-0.25939369201660156,-0.09126201272010803,0.2506054937839508,0.25572311878204346,0.07650640606880188,-0.30574145913124084,0.603861391544342,0.35968664288520813,0.08213572204113007,0.3328155279159546,-0.01913725771009922,-0.20091168582439423,0.18375512957572937,-0.014483239501714706,-0.0025200359523296356,-9.868210781860398e-8,-0.09623037278652191,0.09487982094287872,0.10423922538757324,0.24417413771152496,0.17205572128295898,0.5242272615432739,-0.6974058151245117,0.26162025332450867,0.24764740467071533,0.07649681717157364,0.3931533694267273,0.00048540160059928894,0.1821220964193344,0.33594685792922974,-0.14935608208179474,-0.10455330461263657,0.20635674893856049,-0.03135408088564873,0.03213052079081535,0.014914823696017265,-0.43815404176712036,-0.07119771838188171,-0.20042815804481506,-0.13498422503471375,0.05023503303527832,-0.1443944275379181,-0.1743946522474289,-0.19978810846805573,0.08767610043287277,0.10155776888132095,-0.6871986389160156,-0.2343878149986267,-0.030755287036299706,-0.514163613319397,-0.03656774014234543,0.18806356191635132,-0.14379580318927765,0.07245340943336487,0.3606613278388977,-0.03439561650156975,-0.15575245022773743,-0.4734754264354706,0.1786009967327118,0.29324036836624146,0.19475480914115906,0.12240459024906158,0.05384033918380737,0.1816522479057312,-0.6758416891098022,-0.432510107755661,0.113388292491436,-0.15828272700309753,0.06823204457759857,-0.24538937211036682,-0.3672160506248474,-0.4527789056301117,-0.15739595890045166,-0.36564353108406067,0.12703663110733032,0.221724733710289,0.3191145658493042,0.2028302550315857,0.2269177883863449,0.16832202672958374]}"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:11434/api/embeddings -d '{\"model\": \"all-minilm\",\"prompt\": \"Llamas are members of the camelid family\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Optional: Test if the llm/generative model is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model\":\"llama3\",\"created_at\":\"2024-05-30T23:18:23.059448Z\",\"response\":\"A vector database, also known as a vector store or vector index, is a type of database that specializes in storing and querying high-dimensional vectors. These vectors are typically dense numerical arrays used to represent objects, such as images, documents, or audio files.\\n\\nVector databases are designed to efficiently store and retrieve large numbers of vectors, often with millions or billions of dimensions (features). They provide fast query capabilities, such as:\\n\\n1. **Nearest Neighbor Search**: Find the most similar vector(s) to a given query vector.\\n2. **Similarity Search**: Retrieve all vectors that have a similarity score above a certain threshold.\\n3. **Range Search**: Return all vectors within a certain distance or range from a query vector.\\n\\nVector databases are commonly used in various applications, such as:\\n\\n1. **Computer Vision**: Object recognition, image search, and facial recognition.\\n2. **Natural Language Processing (NLP)**: Text classification, sentiment analysis, and information retrieval.\\n3. **Audio Analysis**: Music recommendation, speech recognition, and audio indexing.\\n\\nSome popular vector database technologies include:\\n\\n1. **FAISS** (Facebook AI Similarity Search): A library for efficient similarity search in high-dimensional spaces.\\n2. **Annoy** (Approximate Nearest Neighbors Oh Yeah!): A C++ library for efficient nearest neighbor search.\\n3. **Hnswlib** (Hierarchical Navigable Small World Library): A Python library for efficient nearest neighbor search.\\n\\nVector databases are particularly useful when dealing with large-scale data and complex queries that involve similarity searches or clustering. They can provide significant performance improvements compared to traditional database systems, which are often optimized for structured data and simple query patterns.\\n\\nIf you're interested in learning more about vector databases, I'd be happy to provide more information on the underlying algorithms and techniques used in these technologies!\",\"done\":true,\"done_reason\":\"stop\",\"context\":[128006,882,128007,271,3923,374,264,4724,4729,30,128009,128006,78191,128007,271,32,4724,4729,11,1101,3967,439,264,4724,3637,477,4724,1963,11,374,264,955,315,4729,430,46672,304,28672,323,82198,1579,33520,23728,13,4314,23728,527,11383,29050,35876,18893,1511,311,4097,6302,11,1778,439,5448,11,9477,11,477,7855,3626,382,3866,32906,527,6319,311,30820,3637,323,17622,3544,5219,315,23728,11,3629,449,11990,477,33151,315,15696,320,20922,570,2435,3493,5043,3319,17357,11,1778,439,1473,16,13,3146,8989,15795,98263,7694,96618,7531,279,1455,4528,4724,1161,8,311,264,2728,3319,4724,627,17,13,3146,35502,488,7694,96618,32662,682,23728,430,617,264,38723,5573,3485,264,3738,12447,627,18,13,3146,6174,7694,96618,3494,682,23728,2949,264,3738,6138,477,2134,505,264,3319,4724,382,3866,32906,527,17037,1511,304,5370,8522,11,1778,439,1473,16,13,3146,38432,31541,96618,3075,18324,11,2217,2778,11,323,28900,18324,627,17,13,3146,55381,11688,29225,320,45,12852,33395,25,2991,24790,11,27065,6492,11,323,2038,57470,627,18,13,3146,15097,18825,96618,10948,28782,11,8982,18324,11,323,7855,53080,382,8538,5526,4724,4729,14645,2997,1473,16,13,3146,3711,31949,334,320,21124,15592,22196,488,7694,1680,362,6875,369,11297,38723,2778,304,1579,33520,12908,627,17,13,3146,2127,2201,88,334,320,70620,3509,4275,15795,4275,25068,8840,22335,0,1680,362,356,1044,6875,369,11297,24379,9760,2778,627,18,13,3146,39,77,2332,2808,334,320,76009,46334,452,3030,481,15344,4435,11896,1680,362,13325,6875,369,11297,24379,9760,2778,382,3866,32906,527,8104,5505,994,14892,449,3544,13230,828,323,6485,20126,430,21736,38723,27573,477,59454,13,2435,649,3493,5199,5178,18637,7863,311,8776,4729,6067,11,902,527,3629,34440,369,34030,828,323,4382,3319,12912,382,2746,499,2351,8173,304,6975,810,922,4724,32906,11,358,4265,387,6380,311,3493,810,2038,389,279,16940,26249,323,12823,1511,304,1521,14645,0,128009],\"total_duration\":13055860500,\"load_duration\":1407006458,\"prompt_eval_count\":15,\"prompt_eval_duration\":209480000,\"eval_count\":372,\"eval_duration\":11437718000}"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:11434/api/generate -d '{\"model\": \"llama3\",\"prompt\":\"What is a vector database?\", \"stream\": false }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started /Users/dudanogueira/.cache/weaviate-embedded: process ID 37293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-05-30T20:18:25-03:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-05-30T20:18:25-03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-05-30T20:18:25-03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"open cluster service\",\"servers\":{\"Embedded_at_8079\":52783},\"time\":\"2024-05-30T20:18:25-03:00\"}\n",
      "{\"address\":\"192.168.28.99:52784\",\"level\":\"info\",\"msg\":\"starting cloud rpc server ...\",\"time\":\"2024-05-30T20:18:25-03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"starting raft sub-system ...\",\"time\":\"2024-05-30T20:18:25-03:00\"}\n",
      "{\"address\":\"192.168.28.99:52783\",\"level\":\"info\",\"msg\":\"tcp transport\",\"tcpMaxPool\":3,\"tcpTimeout\":10000000000,\"time\":\"2024-05-30T20:18:25-03:00\"}\n",
      "{\"level\":\"info\",\"metadata_only_voters\":false,\"msg\":\"construct a new raft node\",\"name\":\"Embedded_at_8079\",\"time\":\"2024-05-30T20:18:25-03:00\"}\n",
      "{\"id\":\"2-3-1716906483472\",\"last-index\":3,\"last-term\":2,\"level\":\"info\",\"msg\":\"starting restore from snapshot\",\"size-in-bytes\":20109,\"time\":\"2024-05-30T20:18:25-03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"restoring schema from snapshot\",\"time\":\"2024-05-30T20:18:25-03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"successfully restored schema from snapshot\",\"time\":\"2024-05-30T20:18:25-03:00\"}\n",
      "{\"last_applied_index\":0,\"last_snapshot_index\":3,\"last_store_log_applied_index\":37,\"level\":\"info\",\"msg\":\"load local db from snapshot\",\"time\":\"2024-05-30T20:18:25-03:00\"}\n",
      "{\"action\":\"\",\"id\":\"2-3-1716906483472\",\"last-index\":3,\"last-term\":2,\"level\":\"info\",\"msg\":\"snapshot restore progress\",\"percent-complete\":\"[100.00]%\",\"read-bytes\":20109,\"size-in-bytes\":20109,\"time\":\"2024-05-30T20:18:25-03:00\"}\n",
      "{\"id\":\"2-3-1716906483472\",\"last-index\":3,\"last-term\":2,\"level\":\"info\",\"msg\":\"restored from snapshot\",\"size-in-bytes\":20109,\"time\":\"2024-05-30T20:18:25-03:00\"}\n",
      "{\"action\":\"raft\",\"index\":18,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.28.99:51558}]]\",\"time\":\"2024-05-30T20:18:25-03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"loading local db\",\"time\":\"2024-05-30T20:18:25-03:00\"}\n",
      "{\"action\":\"raft\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2024-05-30T20:18:25-03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"database has been successfully loaded\",\"n\":1,\"time\":\"2024-05-30T20:18:25-03:00\"}\n",
      "{\"last_snapshot_index\":3,\"last_store_applied_index\":3,\"last_store_log_applied_index\":37,\"level\":\"info\",\"msg\":\"raft node constructed\",\"raft_applied_index\":3,\"raft_last_index\":37,\"time\":\"2024-05-30T20:18:25-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Question\",\"index\":\"question\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/question/aYwENgfZb4Zq/lsm/objects/segment-1717111010149579000\",\"shard\":\"aYwENgfZb4Zq\",\"time\":\"2024-05-30T20:18:26-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Question\",\"index\":\"question\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/question/aYwENgfZb4Zq/lsm/property_question/segment-1717111010151692000\",\"shard\":\"aYwENgfZb4Zq\",\"time\":\"2024-05-30T20:18:26-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Question\",\"index\":\"question\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/question/aYwENgfZb4Zq/lsm/property_question_searchable/segment-1717111010151934000\",\"shard\":\"aYwENgfZb4Zq\",\"time\":\"2024-05-30T20:18:26-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Question\",\"index\":\"question\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/question/aYwENgfZb4Zq/lsm/property_answer/segment-1717111010152158000\",\"shard\":\"aYwENgfZb4Zq\",\"time\":\"2024-05-30T20:18:26-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Question\",\"index\":\"question\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/question/aYwENgfZb4Zq/lsm/property_answer_searchable/segment-1717111010152340000\",\"shard\":\"aYwENgfZb4Zq\",\"time\":\"2024-05-30T20:18:26-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Question\",\"index\":\"question\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/question/aYwENgfZb4Zq/lsm/property__id/segment-1717111010152627000\",\"shard\":\"aYwENgfZb4Zq\",\"time\":\"2024-05-30T20:18:26-03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard question_aYwENgfZb4Zq in 2.836333ms\",\"time\":\"2024-05-30T20:18:26-03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-05-30T20:18:26-03:00\",\"took\":72000}\n",
      "{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [192.168.28.99:52783]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"192.168.28.99:52783\"],\"time\":\"2024-05-30T20:18:27-03:00\",\"voter\":true}\n",
      "{\"action\":\"bootstrap\",\"candidates\":[{\"Suffrage\":0,\"ID\":\"Embedded_at_8079\",\"Address\":\"192.168.28.99:52783\"}],\"level\":\"info\",\"msg\":\"starting cluster bootstrapping\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"action\":\"bootstrap\",\"error\":\"bootstrap only works on new clusters\",\"level\":\"error\",\"msg\":\"could not bootstrapping cluster\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"notified peers this node is ready to join as voter\",\"servers\":[\"192.168.28.99:52783\"],\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"action\":\"raft\",\"last-leader-addr\":\"\",\"last-leader-id\":\"\",\"level\":\"warning\",\"msg\":\"raft heartbeat timeout reached, starting election\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":9,\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft election won\",\"tally\":1,\"term\":9,\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"action\":\"raft\",\"leader\":{},\"level\":\"info\",\"msg\":\"raft entering leader state\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"reload local db: update schema ...\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"index\":\"Question\",\"level\":\"info\",\"msg\":\"restore local index\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Question\",\"index\":\"question\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/question/Lq9BSQPRjz8n/lsm/objects/segment-1717111010359386000\",\"shard\":\"Lq9BSQPRjz8n\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Question\",\"index\":\"question\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/question/Lq9BSQPRjz8n/lsm/property_question/segment-1717111010360951000\",\"shard\":\"Lq9BSQPRjz8n\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Question\",\"index\":\"question\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/question/Lq9BSQPRjz8n/lsm/property_question_searchable/segment-1717111010361539000\",\"shard\":\"Lq9BSQPRjz8n\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Question\",\"index\":\"question\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/question/Lq9BSQPRjz8n/lsm/property_answer/segment-1717111010361944000\",\"shard\":\"Lq9BSQPRjz8n\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Question\",\"index\":\"question\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/question/Lq9BSQPRjz8n/lsm/property_answer_searchable/segment-1717111010362297000\",\"shard\":\"Lq9BSQPRjz8n\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Question\",\"index\":\"question\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/question/Lq9BSQPRjz8n/lsm/property__id/segment-1717111010362663000\",\"shard\":\"Lq9BSQPRjz8n\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard question_Lq9BSQPRjz8n in 4.187292ms\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"index\":\"OllamaCollection\",\"level\":\"info\",\"msg\":\"restore local index\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-05-30T20:18:27-03:00\",\"took\":9405875}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"OllamaCollection\",\"index\":\"ollamacollection\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/ollamacollection/vqsrAbO7lQvQ/lsm/objects/segment-1717111028174188000\",\"shard\":\"vqsrAbO7lQvQ\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"OllamaCollection\",\"index\":\"ollamacollection\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/ollamacollection/vqsrAbO7lQvQ/lsm/property__id/segment-1717111028174844000\",\"shard\":\"vqsrAbO7lQvQ\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard ollamacollection_vqsrAbO7lQvQ in 1.548333ms\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-05-30T20:18:27-03:00\",\"took\":93959}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50050\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"address\":\"192.168.28.99:52783\",\"level\":\"info\",\"msg\":\"current Leader\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-05-30T20:18:27-03:00\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"node reporting ready, node has probably recovered cluster from raft config. Exiting bootstrap process\",\"time\":\"2024-05-30T20:18:28-03:00\"}\n",
      "{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:db56bdb3-f923-4dc6-ad66-9cfb547dd405 Type:INIT Version:1.25.1 Modules:generative-ollama,text2vec-ollama NumObjects:0 OS:darwin Arch:arm64}\",\"time\":\"2024-05-30T20:18:28-03:00\"}\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "client = weaviate.connect_to_embedded(\n",
    "    environment_variables={\"ENABLE_MODULES\": \"text2vec-ollama,generative-ollama\"},\n",
    "    version=\"1.25.1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can check the meta information for our Embedded instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hostname': 'http://127.0.0.1:8079',\n",
       " 'modules': {'generative-ollama': {'documentationHref': 'https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-completion',\n",
       "   'name': 'Generative Search - Ollama'},\n",
       "  'text2vec-ollama': {'documentationHref': 'https://github.com/ollama/ollama/blob/main/docs/api.md#generate-embeddings',\n",
       "   'name': 'Ollama Module'}},\n",
       " 'version': '1.25.1'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "Above we use http://localhost:11434 for calling ollama models.\n",
    "\n",
    "As we are using **Weaviate Embedded instead of Docker**, and we assume here your ollama instalation is on the host, we should call ollama, from Weaviate, at `http://localhost:11434`\n",
    "\n",
    "If your are **running Weaviate as a docker** container, the api_endpoint must be `http://host.docker.internal:11434`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"level\":\"info\",\"msg\":\"Created shard ollamacollection_wLgUWG5NS3P7 in 1.306083ms\",\"time\":\"2024-05-30T20:18:34-03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-05-30T20:18:34-03:00\",\"took\":54333}\n"
     ]
    }
   ],
   "source": [
    "from weaviate import classes as wvc\n",
    "client.collections.delete(\"OllamaCollection\")\n",
    "# lets create the collection, specifing our base url accordingling\n",
    "collection = client.collections.create(\n",
    "    \"OllamaCollection\",\n",
    "    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_ollama(\n",
    "        api_endpoint=\"http://localhost:11434\",\n",
    "        model=\"all-minilm\"\n",
    "    ),\n",
    "    generative_config=wvc.config.Configure.Generative.ollama(\n",
    "        api_endpoint=\"http://localhost:11434\",\n",
    "        model=\"llama3\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_VectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_OLLAMA: 'text2vec-ollama'>, model={'apiEndpoint': 'http://localhost:11434', 'model': 'all-minilm'}, vectorize_collection_name=True)\n",
      "_GenerativeConfig(generative=<GenerativeSearches.OLLAMA: 'generative-ollama'>, model={'apiEndpoint': 'http://localhost:11434', 'model': 'llama3'})\n"
     ]
    }
   ],
   "source": [
    "# Let's check our collection\n",
    "print(collection.config.get().vectorizer_config)\n",
    "print(collection.config.get().generative_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Add data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "  \"Llamas are members of the camelid family meaning they're pretty closely related to vicu単as and camels\",\n",
    "  \"Llamas were first domesticated and used as pack animals 4,000 to 5,000 years ago in the Peruvian highlands\",\n",
    "  \"Llamas can grow as much as 6 feet tall though the average llama between 5 feet 6 inches and 5 feet 9 inches tall\",\n",
    "  \"Llamas weigh between 280 and 450 pounds and can carry 25 to 30 percent of their body weight\",\n",
    "  \"Llamas are vegetarians and have very efficient digestive systems\",\n",
    "  \"Llamas live to be about 20 years old, though some only live for 15 years and others live to be 30 years old\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store each document in a vector embedding database\n",
    "with collection.batch.dynamic() as batch:\n",
    "  for i, d in enumerate(documents):\n",
    "    batch.add_object(\n",
    "        properties = {\"text\" : d},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Llamas can grow as much as 6 feet tall though the average llama between 5 feet 6 inches and 5 feet 9 inches tall'}\n",
      "{'text': 'Llamas were first domesticated and used as pack animals 4,000 to 5,000 years ago in the Peruvian highlands'}\n",
      "{'text': 'Llamas weigh between 280 and 450 pounds and can carry 25 to 30 percent of their body weight'}\n",
      "{'text': 'Llamas are vegetarians and have very efficient digestive systems'}\n",
      "{'text': 'Llamas live to be about 20 years old, though some only live for 15 years and others live to be 30 years old'}\n",
      "{'text': \"Llamas are members of the camelid family meaning they're pretty closely related to vicu単as and camels\"}\n"
     ]
    }
   ],
   "source": [
    "result = collection.generate.fetch_objects()\n",
    "for object in result.objects:\n",
    "    print(object.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Retrieve\n",
    "Next, add the code to retrieve the most relevant document given an example prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Llamas are members of the camelid family meaning they're pretty closely related to vicu単as and camels\"}\n"
     ]
    }
   ],
   "source": [
    "# Now we retrieve our data\n",
    "results = collection.query.near_text(\n",
    "    query=\"What animals are llamas related to?\",\n",
    "    limit=1\n",
    ")\n",
    "print(results.objects[0].properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate\n",
    "Lastly, use the prompt and the document retrieved in the previous step to generate an answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the text, llamas are related to vicu単as and camels, as they are members of the camelid family.\n"
     ]
    }
   ],
   "source": [
    "results = collection.generate.near_text(\n",
    "    query=\"What animals are llamas related to?\",\n",
    "    limit=5,\n",
    "    grouped_task=\"Answer the question: What animals are llamas related to?\"\n",
    ")\n",
    "print(results.generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we are both passing the query as a python variable as well as {text} (double {{ to scape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given context, here are the answers:\n",
      "\n",
      "1. When Lamas were first domesticated: They were first domesticated and used as pack animals 4,000 to 5,000 years ago in the Peruvian highlands.\n",
      "2. How long do they live?: Llamas live to be about 20 years old, though some only live for 15 years and others live to be 30 years old.\n"
     ]
    }
   ],
   "source": [
    "query=\"When Lamas were first domesticated and how long do they live?\"\n",
    "results = collection.generate.near_text(\n",
    "    query=query,\n",
    "    limit=2,\n",
    "    grouped_task=f\"Answer the question: {query}? only using the given context in {{text}}\"\n",
    ")\n",
    "print(results.generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Llamas live to be about 20 years old, though some only live for 15 years and others live to be 30 years old'}\n",
      "{'text': 'Llamas were first domesticated and used as pack animals 4,000 to 5,000 years ago in the Peruvian highlands'}\n"
     ]
    }
   ],
   "source": [
    "for object in results.objects:\n",
    "    print(object.properties)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
