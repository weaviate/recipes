{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc78447",
   "metadata": {},
   "source": [
    "# Connect to Cohere Command-R+ LLM\n",
    "\n",
    "\"Command R+, like our recently launched Command R model, features a 128k-token context window and is designed to offer best-in-class:\n",
    "\n",
    "Advanced Retrieval Augmented Generation (RAG) with citation to reduce hallucinations\n",
    "Multilingual coverage in 10 key languages to support global business operations\n",
    "Tool Use to automate sophisticated business processes\". Source: [txt.cohere.com](\"https://txt.cohere.com/command-r-plus-microsoft-azure/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62a2ef2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yes, Binary Quantization (BQ) is available in Weaviate 1.24 and can be used in combination with HNSW indexes for improved compression and speed.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dspy\n",
    "command_r_plus = dspy.Cohere(model=\"command-r-plus\", max_tokens=4000, api_key=cohere_api_key)\n",
    "\n",
    "command_r_plus(\"\"\"Answer the question based on the following context:\n",
    "\n",
    "Features released in Weaviate 1.24\n",
    "<li>Named vectors. A single object can have multiple vectors. Create vectors for properties, use different vectorization models, and apply different metrics to fine tune interactions with your data.\n",
    "<li>HNSW and binary quantization (BQ) HNSW indexes and BQ combine for serious compression and blazing speed.\n",
    "<li>Simplified Docker configuration. A new Docker image that needs no configuration.\n",
    "<li>Backend improvements. Numerous improvements to make updates, imports, and deletions faster.\n",
    "<li>Python client update. General availability, support for all the latest features.\n",
    "\n",
    "question: Can I use Binary Quantization in Weaviate?\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfbc1ca",
   "metadata": {},
   "source": [
    "# Connect to Weaviate\n",
    "\n",
    "### Weaviate Blogs\n",
    "\n",
    "This weaviate instance contains the 80 blog posts from the Weaviate team, totaling 1,200 text chunks. This covers diverse information about Weaviate from release notes to case studies, research, and more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9dc74b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] ---\n",
      "title: What is Ref2Vec and why you need it for your recommendation system\n",
      "slug: ref2vec-centroid\n",
      "authors: [connor]\n",
      "date: 2022-11-23\n",
      "tags: ['integrations', 'concepts']\n",
      "image: ./img/hero.png\n",
      "description: \"Weaviate introduces Ref2Vec, a new module that utilises Cross-References for Recommendation!\"\n",
      "---\n",
      "![Ref2vec-centroid](./img/hero.png)\n",
      "\n",
      "<!-- truncate -->\n",
      "\n",
      "Weaviate 1.16 introduced the [Ref2Vec](/developers/weaviate/modules/retriever-vectorizer-modules/ref2vec-centroid) module. In this article, we give you an overview of what Ref2Vec is and some examples in which it can add value such as recommendations or representing long objects. ## What is Ref2Vec? The name Ref2Vec is short for reference-to-vector, and it offers the ability to vectorize a data object with its cross-references to other objects. The Ref2Vec module currently holds the name ref2vec-**centroid** because it uses the average, or centroid vector, of the cross-referenced vectors to represent the **referencing** object.\n",
      "[2] As you have seen above, we think Ref2Vec can add value for use cases such as recommendations, re-ranking, overcoming the cold start problem and representing long objects. We are also excited to see what you build with Ref2Vec, and excited to build on this module with its future iterations. Speaking of which, we have another blog post coming soon on the development directions of Ref2Vec for the future. We will discuss topics such as **collaborative filtering**, **multiple centroids**, **graph neural networks**, and more on **re-ranking** with Ref2Vec. Stay tuned!\n",
      "\n",
      "\n",
      "import WhatNext from '/_includes/what-next.mdx'\n",
      "\n",
      "<WhatNext />\n",
      "[3] In other words, the User vector is being updated in real-time here to take into account their preferences and actions, which helps to produce more relevant results at speed. Another benefit of Ref2Vec is that this calculation is not compute-heavy, leading to low overhead. With Ref2Vec, you can use Weaviate to provide Recommendation with \"user-as-query\". This is a very common and powerful way to build Home Feed style features in apps. This can be done by sending queries like this to Weaviate:\n",
      "\n",
      "```graphql\n",
      "{\n",
      "  Get {\n",
      "    Product (\n",
      "      nearObject: {\n",
      "        id: \"8abc5-4d5...\" # id for the User object with vector defined by ref2vec-centroid\n",
      "      }\n",
      "    ) {\n",
      "      product_name\n",
      "      price\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "This short query encapsulates the power of Ref2Vec.\n",
      "[4] The following image depicts how Ref2Vec aggregates the representations of 3 Product items to represent a User who has purchased a pair of boots, shorts, and Weaviate t-shirt!\n",
      "\n",
      "![Ref2Vec Image](./img/ref2vec.png)\n",
      "\n",
      "Such a representation of the User, by an aggregation of their cross-references, allows Weaviate to conveniently and immediately learn from each User's preferences and actions to provide improved and up-to-date characterizations. Ref2Vec can in other words capture each User's interests and tendencies across multiple axes, such as product categories or even fashion styles! And by doing so, the resulting recommendations can more closely match the User's product and style preferences. We envision Ref2Vec to have great potential in multiple application areas. Let's take a look at a few of them in more detail, starting with recommendation systems. ## Recommendation in Weaviate\n",
      "Many of you might primarily know Weaviate as a vector database and search engine, but Weaviate can also power high-quality, lightning-fast recommendations.\n",
      "[5] Although all the query does is provide the ID of the User object, Ref2Vec has done the hard work by inferring a centroid vector from the User's references to other vectors. And as the set of references continues to evolve, the Ref2Vec vectors will continue to evolve also, ensuring that the User vector remains up-to-date with their latest interests. Whether your goal is to construct a Home Feed interface for users or to pair with search queries, Ref2Vec provides a strong foundation to enable Recommendation with fairly low overhead. For example, it can achieve personalized re-ranking, also known as a session-based recommendation, without persisting user data over a long sequence of interactions. A new user could have personalization available after a few interactions on the app which will help them quickly settle in and feel at home, helping to overcome what is known as the cold-start problem.\n",
      "[6] Each query engine has its own strengths in the information retrieval process, let’s dive into a couple of them and how we might think about evaluation. <img\n",
      "  src={require('./img/sub-question.png').default}\n",
      "  alt=\"Sub Question Query Engine\"\n",
      "  style={{ maxWidth: \"60%\" }}\n",
      "/>\n",
      "\n",
      "Multi-hop query engines (otherwise known as [sub question query engine](https://gpt-index.readthedocs.io/en/latest/examples/query_engine/sub_question_query_engine.html)) are great at breaking down complex questions into sub-questions. In the visual above, we have the query “What is Ref2Vec in Weaviate?” To answer this question, you need to know what Ref2Vec and Weaviate are separately. Therefore, two calls will need to be made to your database to retrieve relevant context based on the two questions. The two answers are then combined to generate one output.\n",
      "[7] ![Cross-reference](./img/Weaviate-Ref2Vec_1.png)\n",
      "\n",
      "Ref2Vec gives Weaviate another way to vectorize a class, such as the User class, based on their relationships to other classes. This allows Weaviate to quickly create up-to-date representations of users based on their relationships such as recent interactions. If a user clicks on 3 shoe images on an e-commerce store, it is a safe bet that they want to see more shoes. Ref2Vec captures this intuition by calculating vectors that aggregate each User's interaction with another class. The below animation visualizes a real example of this in e-Commerce images.\n",
      "[8] Particularly from my conversation with Nils Reimers, I have become very interested in the continual learning nature of this. For example, when we released the `ref2vec` module and discussed it on the podcast, the `all-miniLM-L6-v2` model has never seen ref2vec before in its training set. Additionally, a model fine-tuned up to podcast #30 will have never seen ref2vec either!\n",
      "\n",
      "    I am also very interested in the fine-tuning of cross-encoder models, which you can learn more about [here](/blog/cross-encoders-as-reranker). 3. Custom Benchmarking\n",
      "\n",
      "\tI have also been working on the BEIR benchmarking in Weaviate (nearly finished!).\n",
      "[9] This allows us to combine the title of the Article with the vector search in the Paragraph vectors in Weaviate with the following query:\n",
      "\n",
      "```graphql\n",
      "{\n",
      "  Get {\n",
      "    Paragraph(\n",
      "      nearText: {\n",
      "        concepts: [\"What was Obama's legacy?\"],\n",
      "      }\n",
      "      where: {\n",
      "        operator: Equal,\n",
      "        path: [\"inArticle\", \"Article\", \"title\"]\n",
      "        valueText: \"Barack Obama\"\n",
      "      }\n",
      "    ) {\n",
      "      content\n",
      "      order\n",
      "      title\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "So Weaviate already has a strong solution to long documents in play. However, what if we are searching through Scientific Papers, Legal contracts, or Screenplays such that we need to make long-range references between the Paragraphs? In this case, Ref2Vec can be used to average the vectors that represent each **Paragraph** to form the representation of the referencing **Article Class**. In other words, each Article instance would refer to constituent Paragraph instances, and the Ref2Vec module would calculate the vector of the Article as the centroid of the Paragraph vectors. We can then search directly through these Articles with an aggregated vector representation from each Wikipedia Article, thus helping to identify full articles that best match the query.\n",
      "[10] This will take the candidates from hybrid search and apply the cross encoder to rank the final results. :::warning\n",
      "This feature is not implemented into Weaviate yet, so the below code is an example of what it will look like. :::\n",
      "\n",
      "```graphql\n",
      "{\n",
      "  Get {\n",
      "    PodClip(\n",
      "      hybrid: {\n",
      "        query: \"How can I use ref2vec to build a home feed?\"\n",
      "        alpha: 0.5\n",
      "      }\n",
      "    ){\n",
      "    content\n",
      "    _additional {\n",
      "      crossrank(\n",
      "        query: \"How can I use ref2vec to build a homefeed?\"\n",
      "        property: \"content\"\n",
      "      ){\n",
      "      score\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "Let’s see an example of this in action using the Weaviate Podcast Search dataset!\n",
      "\n",
      "**Query**: Are there any ways to benchmark the performance of self-ask prompting? | Ranker                | Output |\n",
      "|---------------------------|------------------------------------|\n",
      "| Cross Encoder                  | That's a great question. Honestly, you should invite Ofir to chat about that.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/41/8dp_379x15d8zz4ppsjthdw40000gn/T/ipykernel_31325/3014742529.py:4: ResourceWarning: unclosed <socket.socket fd=87, family=AddressFamily.AF_INET6, type=SocketKind.SOCK_STREAM, proto=6, laddr=('::1', 57287, 0, 0), raddr=('::1', 8080, 0, 0)>\n",
      "  retriever_model = WeaviateRM(\"WeaviateBlogChunk\", weaviate_client=weaviate_client, k=10)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "from dspy.retrieve.weaviate_rm import WeaviateRM\n",
    "weaviate_client = weaviate.connect_to_local()\n",
    "retriever_model = WeaviateRM(\"WeaviateBlogChunk\", weaviate_client=weaviate_client, k=10)\n",
    "\n",
    "data = [d[\"long_text\"] for d in retriever_model(\"What is ref2vec?\")]\n",
    "formatted_string = \"\\n\".join(f\"[{i+1}] {text}\" for i, text in enumerate(data))\n",
    "print(formatted_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a926d73",
   "metadata": {},
   "source": [
    "### Long Context RAG\n",
    "\n",
    "Because Command-R-Plus supports a 128K input window, we can test much higher values of `k` for retrieval than previous generation RAG systems.\n",
    "\n",
    "For example, the `k=10` search results above contain about `1,900 tokens`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b118f8e",
   "metadata": {},
   "source": [
    "# Set DSPy default LLM to Command R Plus and RM to Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdcb57e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(lm=command_r_plus, rm=retriever_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01240655",
   "metadata": {},
   "source": [
    "# Define RAG Progarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c003f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Assess the the context and answer the question.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"Helpful information for answering the question.\")\n",
    "    question = dspy.InputField()\n",
    "    detailed_answer = dspy.OutputField(desc=\"A detailed answer that is supported by the context. Only output the answer.\")\n",
    "    \n",
    "class RAG(dspy.Module):\n",
    "    def __init__(self, k=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.retrieve = dspy.Retrieve(k=k)\n",
    "        self.generate_answer = dspy.Predict(GenerateAnswer)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        pred = self.generate_answer(context=context, question=question).detailed_answer\n",
    "        return dspy.Prediction(context=context, answer=pred, question=question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb26fee",
   "metadata": {},
   "source": [
    "## Query Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94b88c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HNSW, or Hierarchical Navigable Small World graphs, is an ANN (Approximate Nearest Neighbor) algorithm that powers Weaviate, a vector database. HNSW organizes vector indexes so that closely related vectors are stored next to each other, enabling fast and efficient vector searches. By trading a small amount of accuracy for significant performance gains, HNSW can maintain high recall rates (>95%) while achieving high throughput and low latency, making it ideal for fast and reliable vector searches.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAG()(question=\"How does HNSW vector search work?\").answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
