{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/weaviate/recipes/blob/main/integrations/operations/comet/Opik-Tracing-and-Evals.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4lyGVV413Ry"
      },
      "source": [
        "# Example RAG with Opik Tracing and Evals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndkY7MxbsUYr"
      },
      "source": [
        "This simple example will get you started with using Opik, Weaviate, and the OpenAI API to build a RAG system.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQl7CHhX3XBF"
      },
      "source": [
        "# Set up your Environment\n",
        "\n",
        "[Comet](https://www.comet.com/) provides a hosted version of the Opik platform, simply [create a free account](https://www.comet.com/site/products/opik/) and grab you API Key from the UI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQdYMW091iz0"
      },
      "source": [
        "First, we need pip install the opik and openai libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "063DSqmmqKQM",
        "outputId": "e52990b3-c55f-43b1-f861-e31af0811989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.5/148.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.0/400.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.2/473.2 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -U opik openai --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D238f3uZ1mPG"
      },
      "source": [
        "Now, we'll configure Opik and OpenAI with our respective API keys."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7uYVtVMqNhs",
        "outputId": "dd935aef-971a-4aa7-b0f9-31e5a6110385"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "OPIK: Your Opik API key is available in your account settings, can be found at https://www.comet.com/api/my/settings/ for Opik cloud\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your Opik API key:··········\n",
            "Do you want to use \"statisticianinstilettos\" workspace? (Y/n)Y\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "OPIK: Configuration saved to file: /root/.opik.config\n"
          ]
        }
      ],
      "source": [
        "import opik\n",
        "\n",
        "opik.configure(use_local=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwlbJ_F4qPdd",
        "outputId": "ba098437-563d-4af3-d1ba-7ec3e901f866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuy9Dmg01s9H"
      },
      "source": [
        "Traces will now be automatically logged to the Opik UI where you can inspect the inputs, outputs, and configure evaluation metrics. After you run this cell, follow the link to the Comet UI to see you traces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCSQN2_x0-sQ"
      },
      "source": [
        "# Set up Weaviate Client\n",
        "\n",
        "Weaviate is a vector database which supports billion scale vector search with sub 50ms query times. We'll use Weaviate to query for books in this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGW4xKQDrTou",
        "outputId": "737c46ee-1eb9-458b-ce19-384623eaefe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/353.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/353.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.3/353.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.8/223.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -U weaviate-client --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_tbFISQ0-gr",
        "outputId": "6a10f2dd-7f6d-4e16-eff4-5d455f2bdd62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import weaviate\n",
        "from weaviate.classes.init import Auth\n",
        "from weaviate.classes.init import AdditionalConfig, Timeout\n",
        "\n",
        "\n",
        "WEAVIATE_CLUSTER_URL = os.getenv('WEAVIATE_CLUSTER_URL') or 'https://zxzyqcyksbw7ozpm5yowa.c0.us-west2.gcp.weaviate.cloud'\n",
        "WEAVIATE_API_KEY = os.getenv('WEAVIATE_API_KEY') or 'n6mdfI32xrXF3DH76i8Pwc2IajzLZop2igb6' # This is a read key\n",
        "\n",
        "weaviate_client = weaviate.connect_to_weaviate_cloud(\n",
        "    cluster_url=WEAVIATE_CLUSTER_URL,\n",
        "    auth_credentials=Auth.api_key(WEAVIATE_API_KEY),\n",
        "    headers={\"X-OpenAI-Api-Key\": os.environ[\"OPENAI_API_KEY\"]},\n",
        ")\n",
        "\n",
        "print(weaviate_client.is_connected())\n",
        "\n",
        "book_collection = weaviate_client.collections.get(name=\"Book\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POkdxVeQcOvQ"
      },
      "source": [
        "# Write a RAG app with OpenAI, Weaviate and Opik Traces\n",
        "\n",
        "Next, we will build a very simple LLM reasoning application and log the trace data to Opik where we can apply additional evaluation metrics and debug the LLM response.\n",
        "\n",
        "We will use Opik to collect traces to inspect the inputs and outputs of the reasoning tasks, and to create evaluation metrics for hallicinations and other common or custom issues you want to detect.\n",
        "\n",
        "Opik integrates with OpenAI to provide a simple way to log traces for all OpenAI LLM calls. This works for all OpenAI models, including if you are using the streaming API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciD73aK2qDXc"
      },
      "outputs": [],
      "source": [
        "from opik.integrations.openai import track_openai\n",
        "from openai import OpenAI\n",
        "\n",
        "os.environ[\"OPIK_PROJECT_NAME\"] = \"rag-project\" #name your project. This will appear as the project name in the Opik UI\n",
        "\n",
        "\n",
        "client = OpenAI()\n",
        "client = track_openai(client)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYUzfsnvY7JG"
      },
      "source": [
        "We are using the @opik.track decorator and the OpenAI logging integration to automatically log our traces and spans. Learn more here https://www.comet.com/docs/opik/tracing/log_traces#using-an-integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbxVyTwdYC4R"
      },
      "outputs": [],
      "source": [
        "@opik.track\n",
        "def retrieve_context(user_query):\n",
        "    # Semantic Search\n",
        "    response = book_collection.query.near_text(\n",
        "        query=user_query,\n",
        "        limit=3\n",
        "    )\n",
        "\n",
        "    recommended_books = []\n",
        "    for book in response.objects:\n",
        "        recommended_books.append(book.properties['title'])\n",
        "    return recommended_books"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4jYELuJ1Zjo"
      },
      "outputs": [],
      "source": [
        "@opik.track\n",
        "def generate_response(user_query, recommended_books):\n",
        "  prompt = f\"\"\"\n",
        "  You're a helpful assistant, reply to a chatbot message for someone inquiring for\n",
        "  book recommendations. The user query was {user_query}\n",
        "\n",
        "\n",
        "  These were the book that were extracted from the vector\n",
        "  search:\n",
        "\n",
        "  {recommended_books}\n",
        "  \"\"\"\n",
        "\n",
        "  response = client.chat.completions.create(\n",
        "      model=\"o3-mini\",\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt\n",
        "          }\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  return (response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LhqAN_y2xS-"
      },
      "outputs": [],
      "source": [
        "@opik.track(name=\"rag-example\")\n",
        "def llm_chain(user_query):\n",
        "    context = retrieve_context(user_query)\n",
        "    response = generate_response(user_query, context)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fozL4CdW6lO",
        "outputId": "2e527653-a134-4d3b-9593-767e7bdf779e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What types of books are you looking for? running\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "OPIK: Started logging traces to the \"rag-project\" project at https://www.comet.com/opik/statisticianinstilettos/redirect/projects?name=rag-project.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on your interest in running, here are three recommendations we found:\n",
            "\n",
            "• Running in the Family – Although known primarily as Michael Ondaatje’s vivid memoir about family history, this book uses running as a kind of metaphor for life’s journeys and the passage of time. Its lyrical style might resonate if you enjoy reflective, meandering narratives.\n",
            "\n",
            "• Winterdance – Also subtitled “The Fine Madness of Running the Iditarod,” this memoir by Gary Paulsen offers an exhilarating and personal account of the brutal, yet deeply captivating, world of dog sled racing. If you’re drawn to stories of endurance and adventure, this one delivers a firsthand glimpse into one of the most challenging races on Earth.\n",
            "\n",
            "• Drina Dances Again – While perhaps a less obvious connection to “running,” this title suggests a narrative filled with movement and energy. Often, such works blend historical or cultural insights with an underlying pulse of forward momentum. It might offer a unique literary journey if you’re open to exploring different angles on the theme.\n",
            "\n",
            "Each of these books provides a different perspective—whether it’s reflective, adrenaline-fueled, or culturally vibrant. Do any of these catch your eye, or would you like more details on a specific title?\n"
          ]
        }
      ],
      "source": [
        "# Use the LLM chain\n",
        "user_query = input(\"What types of books are you looking for? \")\n",
        "result = llm_chain(user_query)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vtOE4DDcmcx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
