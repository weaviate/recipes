{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/weaviate/recipes/blob/main/integrations/llm-agent-frameworks/function-calling/anthropic/weaviate-query-agent-tool.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weaviate Query Agent with Anthropic\n",
    "\n",
    "This notebook will show you how to define the Weaviate Query Agent as a tool through Anthropic.\n",
    "\n",
    "### Requirements\n",
    "1. Weaviate Cloud instance (WCD): The Weaviate Query Agent is only accessible through WCD at the moment. You can create a serverless cluster or a free 14-day sandbox [here](https://console.weaviate.cloud/).\n",
    "1. Install the Anthropic Python API with `pip install anthropic`. We're using version `0.49.0` at the time of creating this notebook.\n",
    "1. Install the Weaviate Agents package with `pip install weaviate-agents`\n",
    "1. You'll need a Weaviate cluster with data. If you don't have one, check out [this notebook](integrations/Weaviate-Import-Example.ipynb) to import the Weaviate Blogs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate_agents.query import QueryAgent\n",
    "import os\n",
    "import json\n",
    "\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WEAVIATE_URL\"] = \"\"\n",
    "os.environ[\"WEAVIATE_API_KEY\"] = \"\"\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Query Agent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_query_agent_request(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Send a query to the database and get the response.\n",
    "\n",
    "    Args:\n",
    "        query (str): The question or query to search for in the database. This can be any natural language question related to the content stored in the database.\n",
    "\n",
    "    Returns:\n",
    "        str: The response from the database containing relevant information.\n",
    "    \"\"\"\n",
    "\n",
    "    # connect to your Weaviate Cloud instance\n",
    "    weaviate_client = weaviate.connect_to_weaviate_cloud(\n",
    "        cluster_url=os.getenv(\"WEAVIATE_URL\"), \n",
    "        auth_credentials=weaviate.auth.AuthApiKey(os.getenv(\"WEAVIATE_API_KEY\")),\n",
    "        headers={ # add the API key to the model provider from your Weaviate collection, for example `headers={\"X-VoyageAI-Api-Key\": os.getenv(\"VOYAGE_API_KEY\")}` \n",
    "        }\n",
    "    )\n",
    "\n",
    "    # connect the query agent to your Weaviate collection(s)\n",
    "    query_agent = QueryAgent(\n",
    "        client=weaviate_client,\n",
    "        collections=[\"Blogs\"] \n",
    "    )\n",
    "    return query_agent.run(query).final_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Anthropic client and define Query Agent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_assistant(message, chat_history=None):\n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "\n",
    "    # Initialize Anthropic client\n",
    "    anthropic_client = anthropic.Anthropic(os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    )\n",
    "\n",
    "    # Print user message\n",
    "    print(f\"Question:\\n{message}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Initial message to Claude\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-3-7-sonnet-20250219\",\n",
    "        max_tokens=1024,\n",
    "        tools=[\n",
    "            {\n",
    "                \"name\": \"send_query_agent_request\",\n",
    "                \"description\": \"Send a query to a database filled with information about Weaviate and get the response\",\n",
    "                \"input_schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The question or query to search for in the database. This can be any natural language question related to the content stored in the database.\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"query\"],\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "        messages=[*chat_history, {\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "\n",
    "    while response.stop_reason == 'tool_use':\n",
    "        # Extract tool use blocks from the response\n",
    "        tool_blocks = [block for block in response.content if block.type == 'tool_use']\n",
    "        \n",
    "        if any(block.type == 'text' for block in response.content):\n",
    "            print(\"Tool plan:\")\n",
    "            print([block.text for block in response.content if block.type == 'text'][0], \"\\n\")\n",
    "            \n",
    "        print(\"Tool calls:\")\n",
    "        for tool_block in tool_blocks:\n",
    "            print(f\"Tool name: {tool_block.name} | Parameters: {tool_block.input}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Execute tool calls and collect results\n",
    "        tool_results = []\n",
    "        for tool_block in tool_blocks:\n",
    "            try:\n",
    "                tool_output = send_query_agent_request(**tool_block.input)\n",
    "                tool_results.append({\n",
    "                    \"type\": \"tool_result\",\n",
    "                    \"tool_use_id\": tool_block.id,\n",
    "                    \"content\": tool_output\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error executing tool {tool_block.name}: {str(e)}\")\n",
    "                tool_results.append({\n",
    "                    \"type\": \"tool_result\", \n",
    "                    \"tool_use_id\": tool_block.id,\n",
    "                    \"content\": f\"Error: {str(e)}\"\n",
    "                })\n",
    "\n",
    "        # Get next response from Claude with tool outputs\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=\"claude-3-7-sonnet-20250219\",\n",
    "            max_tokens=1024,\n",
    "            messages=[\n",
    "                *chat_history,\n",
    "                {\"role\": \"user\", \"content\": message},\n",
    "                {\"role\": \"assistant\", \"content\": response.content},\n",
    "                {\"role\": \"user\", \"content\": tool_results}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Print final response\n",
    "    print(\"Final response:\")\n",
    "    final_text = next((block.text for block in response.content if block.type == 'text'), None)\n",
    "    print(final_text)\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Update chat history with final exchange\n",
    "    chat_history.extend([\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "        {\"role\": \"assistant\", \"content\": response.content}\n",
    "    ])\n",
    "    \n",
    "    return chat_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "How do I run Weaviate with Docker?\n",
      "==================================================\n",
      "Tool plan:\n",
      "I'll help you find information about running Weaviate with Docker. Let me search for that information for you. \n",
      "\n",
      "Tool calls:\n",
      "Tool name: send_query_agent_request | Parameters: {'query': 'How to run Weaviate with Docker'}\n",
      "==================================================\n",
      "Final response:\n",
      "# Running Weaviate with Docker\n",
      "\n",
      "Here's how to run Weaviate using Docker:\n",
      "\n",
      "## Prerequisites\n",
      "- Docker and Docker Compose installed on your system\n",
      "- Basic familiarity with Docker commands\n",
      "\n",
      "## Step-by-Step Instructions\n",
      "\n",
      "1. **Install Docker and Docker Compose**\n",
      "   - For Windows/Mac: Install [Docker Desktop](https://www.docker.com/products/docker-desktop)\n",
      "   - For Linux: Install [Docker Engine](https://docs.docker.com/engine/install/) and [Docker Compose](https://docs.docker.com/compose/install/)\n",
      "\n",
      "2. **Get the Docker Compose Configuration**\n",
      "   - Option 1: Use the [Weaviate configuration tool](https://weaviate.io/developers/weaviate/installation/docker-compose) to generate a custom `docker-compose.yml`\n",
      "   - Option 2: Download a sample configuration from Weaviate's documentation\n",
      "\n",
      "3. **Start Weaviate**\n",
      "   ```bash\n",
      "   docker compose up -d\n",
      "   ```\n",
      "   The `-d` flag runs containers in detached mode (in the background)\n",
      "\n",
      "4. **Verify Weaviate is Running**\n",
      "   - Check if Weaviate is ready by accessing the readiness endpoint:\n",
      "   ```bash\n",
      "   curl http://localhost:8080/v1/.well-known/ready\n",
      "   ```\n",
      "   - You should receive a 2xx status code when Weaviate is operational\n",
      "\n",
      "## Notes\n",
      "- This Docker Compose setup is recommended for development and testing\n",
      "- For production environments, a Kubernetes deployment is recommended\n",
      "\n",
      "Would you like me to provide more specific information about configuring Weaviate modules or customizing your Docker setup?\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "chat_history = run_assistant(\"How do I run Weaviate with Docker?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
