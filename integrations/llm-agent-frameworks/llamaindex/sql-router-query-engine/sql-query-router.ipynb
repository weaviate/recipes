{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/weaviate/recipes/blob/main/integrations/llm-agent-frameworks/llamaindex/sql-router-query-engine/sql-query-router.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVo_25Tge76N"
   },
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBoH4EYA0oGq"
   },
   "outputs": [],
   "source": [
    "%pip install llama_index llama_hub weaviate_client urllib3 llama-cpp-python llama-hub-youtube-transcript llama-index-readers-youtube-transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dYmRkpOt1u7q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    SQLDatabase,\n",
    "    download_loader\n",
    ")\n",
    "from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
    "\n",
    "\n",
    "import weaviate\n",
    "from weaviate import classes as wvc\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "embed_model = OpenAIEmbedding(\n",
    "    embed_batch_size=10,\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "openai.api_key = os.environ[\"OPENAI_APIKEY\"]\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnsDxF4ifBmI"
   },
   "source": [
    "## Connect to Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hp1xmGEr2Z0E",
    "outputId": "7709f5a5-661f-4876-da68-d47597103aab"
   },
   "outputs": [],
   "source": [
    "client = weaviate.connect_to_embedded(\n",
    "    headers={\n",
    "        \"X-OpenAI-Api-Key\": os.environ[\"OPENAI_APIKEY\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDIHyiyPfL8I"
   },
   "source": [
    "### Create Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "upanknG02liC",
    "outputId": "a5f2a230-aadd-4358-d59f-a75fd3bec306"
   },
   "outputs": [],
   "source": [
    "client.collections.delete(\"Podcast\")\n",
    "collection = client.collections.create(\n",
    "    name=\"Podcast\",\n",
    "    description=\"Weaviate podcast\",\n",
    "    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(\n",
    "        model=\"text-embedding-3-small\"\n",
    "    ),\n",
    "    properties=[\n",
    "        wvc.config.Property(name=\"content\", data_type=wvc.config.DataType.TEXT, description=\"Content from the podcasts\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2P2WVok5fQvr"
   },
   "source": [
    "## Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "EEBHP6L-2sUD"
   },
   "outputs": [],
   "source": [
    "from llama_index.readers.youtube_transcript import YoutubeTranscriptReader\n",
    "\n",
    "loader = YoutubeTranscriptReader()\n",
    "\n",
    "podcasts = loader.load_data(ytlinks=['https://www.youtube.com/watch?v=xk28RMhRy1U', 'https://www.youtube.com/watch?v=Du6IphCcCec',\n",
    "'https://www.youtube.com/watch?v=Q7f2JeuMN7E', 'https://www.youtube.com/watch?v=nSCUk5pHXlo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "print(\"Documents\", len(podcasts))\n",
    "parser = SimpleNodeParser()\n",
    "nodes = parser.get_nodes_from_documents(podcasts)\n",
    "print(\"Number of nodes:\", len(nodes))\n",
    "print(nodes[1].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4kwMqZUftdy"
   },
   "source": [
    "## Build the Weaviate Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p6F1LPp53QF1",
    "outputId": "c440c298-c635-4c12-95bf-817a48f8792c"
   },
   "outputs": [],
   "source": [
    "vector_store = WeaviateVectorStore(weaviate_client=client, index_name=\"Podcast\")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingest data\n",
    "podcast_index = VectorStoreIndex.from_documents(podcasts, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can instantiate the index at anytime like this, without ingesting:\n",
    "podcast_index = WeaviateVectorStore(\n",
    "    weaviate_client=client, index_name=\"Podcast\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4RMRgE8g4bE"
   },
   "source": [
    "## Create SQL Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "ugdDS0DL3upy"
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    select,\n",
    "    column,\n",
    ")\n",
    "\n",
    "engine = create_engine(\"sqlite:///:memory:\", future=True)\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "a-5u5_WF3-2U"
   },
   "outputs": [],
   "source": [
    "table_name = \"podcast_stats\"\n",
    "podcast_stats_table = Table(\n",
    "    table_name,\n",
    "    metadata_obj,\n",
    "    Column(\"podcast_title\", String(16), primary_key=True),\n",
    "    Column(\"views\", Integer),\n",
    "    Column(\"duration\", Integer),\n",
    ")\n",
    "\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7zWmZ3nV4YaJ",
    "outputId": "8929dda9-f9e8-4513-f793-5de43fe86427"
   },
   "outputs": [],
   "source": [
    "metadata_obj.tables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "j-B-lF-T4Z2u"
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import insert\n",
    "\n",
    "rows = [\n",
    "    {\"podcast_title\": \"Weaviate 1.20\", \"views\": 328, \"duration\": 65},\n",
    "    {\"podcast_title\": \"Weaviate 1.19\", \"views\": 280, \"duration\": 27},\n",
    "    {\"podcast_title\": \"Weaviate 1.18\", \"views\": 428, \"duration\": 65},\n",
    "    {\"podcast_title\": \"Weaviate 1.17\", \"views\": 257, \"duration\": 43}\n",
    "]\n",
    "\n",
    "for row in rows:\n",
    "  stmt = insert(podcast_stats_table).values(**row)\n",
    "  with engine.connect() as connection:\n",
    "    cursor = connection.execute(stmt)\n",
    "    connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SQL Table in LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "tOp9RGLt5tJk"
   },
   "outputs": [],
   "source": [
    "sql_database = SQLDatabase(engine, include_tables=[\"podcast_stats\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "YtHjm93O5xvy"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.indices.struct_store.sql_query import NLSQLTableQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "eKK5nOj-50ve"
   },
   "outputs": [],
   "source": [
    "# set up text2SQL prompt\n",
    "sql_query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    tables=[\"podcast_stats\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_engine.query(\"Which release podcast had the most views?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "JkVOaovf54RP"
   },
   "outputs": [],
   "source": [
    "vector_query_engine = podcast_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_query_engine.query(\"Tell me about a cool feature in Weaviate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tell LlamaIndex about the Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "iszRogIX6LqJ"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.tools.query_engine import QueryEngineTool\n",
    "\n",
    "sql_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine = sql_query_engine,\n",
    "    description=(\n",
    "        \"Useful for translating a natural language query into a SQL query over a table containing: \"\n",
    "        \"podcast_stats, containing the views/duration of each podcast\"\n",
    "    ),\n",
    ")\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=\"Useful for answering semantic questions about Weaviate release podcasts\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "FtCm96Kf65om"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors.llm_selectors import LLMSingleSelector\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=([sql_tool] + [vector_tool]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nxNnuoDC7FtX",
    "outputId": "ce5b2b87-7ea3-4cea-9c1f-2fa0a10f0285"
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(\"Which release podcast had the most views?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2m8gkQM67MoV",
    "outputId": "ba88177b-4705-4716-8a33-00a537fcc25e"
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(\"Tell me about a new feature in Weaviate 1.18\")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
