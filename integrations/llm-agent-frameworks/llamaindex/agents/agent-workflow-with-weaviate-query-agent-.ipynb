{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weaviate Query Agent with LlamaIndex\n",
    "\n",
    "This notebook will show you how to define the Weaviate Query Agent as a tool through LlamaIndex.\n",
    "\n",
    "### Requirements\n",
    "1. Weaviate Cloud instance (WCD): The Weaviate Query Agent is only accessible through WCD at the moment. You can create a serverless cluster or a free 14-day sandbox [here](https://console.weaviate.cloud/).\n",
    "2. Install LlamaIndex with `pip install llama-index` (we used version `0.12.22` for this notebook)\n",
    "3. Install the Weaviate Agents package with `pip install weaviate-agents`\n",
    "4. You'll need a Weaviate cluster with data. If you don't have one, check out [this notebook](integrations/Weaviate-Import-Example.ipynb) to import the Weaviate Blogs.\n",
    "\n",
    "### Resources on the LlamaIndex Agent Workflow\n",
    "1. [Getting Started Guide](https://docs.llamaindex.ai/en/latest/getting_started/starter_example/)\n",
    "1. [Agent Tutorial](https://docs.llamaindex.ai/en/latest/understanding/agent/)\n",
    "1. [Key Features in the Agent Workflow](https://docs.llamaindex.ai/en/latest/examples/agent/agent_workflow_basic/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate_agents.query import QueryAgent\n",
    "import os\n",
    "import json\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.agent.workflow import AgentWorkflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WEAVIATE_URL\"] = \"\"\n",
    "os.environ[\"WEAVIATE_API_KEY\"] = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Query Agent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_agent_request(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Send a query to the database and get the response.\n",
    "\n",
    "    Args:\n",
    "        query (str): The question or query to search for in the database. This can be any natural language question related to the content stored in the database.\n",
    "\n",
    "    Returns:\n",
    "        str: The response from the database containing relevant information.\n",
    "    \"\"\"\n",
    "\n",
    "    # connect to your Weaviate Cloud instance\n",
    "    weaviate_client = weaviate.connect_to_weaviate_cloud(\n",
    "        cluster_url=os.getenv(\"WEAVIATE_URL\"), \n",
    "        auth_credentials=weaviate.auth.AuthApiKey(os.getenv(\"WEAVIATE_API_KEY\")),\n",
    "        headers={ \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_API_KEY\") \n",
    "        }\n",
    "    )\n",
    "\n",
    "    # connect the query agent to your Weaviate collection(s)\n",
    "    query_agent = QueryAgent(\n",
    "        client=weaviate_client,\n",
    "        collections=[\"Blogs\"] \n",
    "    )\n",
    "    return query_agent.run(query).final_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Agent Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = AgentWorkflow.from_tools_or_functions(\n",
    "    [query_agent_request],\n",
    "    llm=llm,\n",
    "    system_prompt=\"You are an agent that can search a database of Weaviate blog content and answer questions about it.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/weaviate/warnings.py:314: ResourceWarning: Con004: The connection to Weaviate was not closed properly. This can lead to memory leaks.\n",
      "            Please make sure to close the connection using `client.close()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To run Weaviate with Docker, follow these steps:\n",
      "\n",
      "1. **Install Docker and Docker Compose**: Ensure that you have Docker (version 17.09.0 or higher) and Docker Compose installed. You can find installation guides for various operating systems on the Docker documentation site.\n",
      "\n",
      "2. **Download a Weaviate Docker Image**: Use the command to pull the latest version of Weaviate:\n",
      "   ```bash\n",
      "   docker pull cr.weaviate.io/semitechnologies/weaviate:latest\n",
      "   ```\n",
      "\n",
      "3. **Run Weaviate**: Start a Weaviate instance using the following command:\n",
      "   ```bash\n",
      "   docker run -p 8080:8080 -p 50051:50051 cr.weaviate.io/semitechnologies/weaviate:latest\n",
      "   ```\n",
      "   This command will map the ports and start the Weaviate instance.\n",
      "\n",
      "4. **Using Docker Compose**: For a more manageable configuration, it's recommended to use Docker Compose. Create a `docker-compose.yml` file with the required setup. Hereâ€™s a simple example:\n",
      "   ```yaml\n",
      "   version: '3.8'\n",
      "   services:\n",
      "     weaviate:\n",
      "       image: cr.weaviate.io/semitechnologies/weaviate:latest\n",
      "       ports:\n",
      "         - \"8080:8080\"\n",
      "         - \"50051:50051\"\n",
      "       environment:\n",
      "         AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: \"true\"\n",
      "         PERSISTENCE_DATA_PATH: \"/var/lib/weaviate\"\n",
      "   ```\n",
      "   Place this file in a directory and run:\n",
      "   ```bash\n",
      "   docker-compose up -d\n",
      "   ```\n",
      "\n",
      "5. **Check the Status**: After starting, you can check if Weaviate is running by sending a request to its readiness endpoint:\n",
      "   ```bash\n",
      "   curl --fail -s localhost:8080/v1/.well-known/ready\n",
      "   ```\n",
      "   This command will confirm if Weaviate is up and ready for use.\n"
     ]
    }
   ],
   "source": [
    "response = await workflow.run(user_msg=\"How do I run Weaviate with Docker?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
