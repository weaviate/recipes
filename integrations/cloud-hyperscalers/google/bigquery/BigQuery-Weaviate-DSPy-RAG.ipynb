{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b871c0",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/weaviate/recipes/blob/main/integrations/cloud-hyperscalers/google/bigquery/BigQuery-Weaviate-DSPy-RAG.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da25e61a",
   "metadata": {},
   "source": [
    "# RAGwithContextFusion\n",
    "\n",
    "### How to build a RAG System with Weaviate, BigQuery, and DSPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff51ae6",
   "metadata": {},
   "source": [
    "Retrieval-Augmented Generation (RAG) systems combine the power of Large Language Models with knowledge sources, such as databases.\n",
    "\n",
    "This tutorial will show you how to use DSPy to combine multiple knowledge sources, using Weaviate for vector search on chunks from the Weaviate blog post and Google's BigQuery for structured information about the authors of the blogs, such as their names, what team they work on at Weaviate, how many blogs they have written, and whether they are an active member of the Weaviate team.\n",
    "\n",
    "We will use DSPy to create our RAGwithContextFusion agent to route queries, convert natural language queries into SQL commands to send to BigQuery, and use the acquired context to answer questions. DSPy uses the Gemini LLM under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e44ec5",
   "metadata": {},
   "source": [
    "![alt text](./bigquery-images/RAGwithContextFusion.png \"Title Text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe8575d",
   "metadata": {},
   "source": [
    "# Connect DSPy to the Gemini API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85d3920",
   "metadata": {},
   "source": [
    "![alt text](./bigquery-images/Gemini.png \"Title Text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25820d",
   "metadata": {},
   "source": [
    "Image source: https://gemini.google.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f51f19ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cshorten/Desktop/DSPy-local/cohere_fix/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hello!']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "gemini_pro = dspy.Google(model=\"gemini-pro\", api_key=GOOGLE_API_KEY)\n",
    "\n",
    "dspy.settings.configure(lm=gemini_pro)\n",
    "\n",
    "gemini_pro(\"say hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9b3c143d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"**Google BigQuery** is a fully managed, serverless data warehouse that enables fast and cost-effective analysis of large datasets. It is a cloud-based service that allows users to store, query, and analyze data at scale.\\n\\n**Key Features:**\\n\\n* **Massive Scalability:** BigQuery can handle datasets up to petabytes in size, making it suitable for large-scale data analysis.\\n* **Fast Query Performance:** BigQuery uses a distributed processing engine to execute queries quickly, even on massive datasets.\\n* **Serverless Architecture:** BigQuery is a fully managed service, eliminating the need for infrastructure management and maintenance.\\n* **Cost-Effective:** BigQuery charges only for the data stored and the queries executed, making it a cost-effective solution for data analysis.\\n* **Standard SQL Support:** BigQuery supports standard SQL, making it easy for users to write complex queries and perform advanced data analysis.\\n* **Integration with Google Cloud Platform:** BigQuery seamlessly integrates with other Google Cloud services, such as Cloud Storage, Cloud Dataflow, and Cloud Machine Learning.\\n* **Data Sharing and Collaboration:** BigQuery allows users to share datasets and collaborate with others, enabling data-driven decision-making across teams.\\n\\n**Use Cases:**\\n\\nBigQuery is used for a wide range of data analysis applications, including:\\n\\n* Business Intelligence and Reporting\\n* Data Exploration and Visualization\\n* Machine Learning and Data Science\\n* Log Analysis and Monitoring\\n* Data Warehousing and Data Lake Management\\n\\n**Benefits:**\\n\\n* **Reduced Time to Insight:** BigQuery's fast query performance enables users to quickly extract insights from large datasets.\\n* **Cost Optimization:** The serverless architecture and pay-as-you-go pricing model help organizations optimize their data analysis costs.\\n* **Improved Data Governance:** BigQuery provides data access controls and audit logs, ensuring data security and compliance.\\n* **Enhanced Collaboration:** Data sharing and collaboration features facilitate data-driven decision-making across teams.\\n* **Scalability and Flexibility:** BigQuery's massive scalability and flexible data ingestion options allow organizations to handle growing data volumes and evolving analysis needs.\"]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_pro(\"What is Google BigQuery?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095e7254",
   "metadata": {},
   "source": [
    "# Load Unstructured Text Data into Weaviate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a4f512",
   "metadata": {},
   "source": [
    "![alt text](./bigquery-images/weaviate-logo.png \"Title Text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3321948",
   "metadata": {},
   "source": [
    "# Load Unstructured Text Data into Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df6909f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "title: Combining LangChain and Weaviate\n",
      "slug: combining-langchain-and-weaviate\n",
      "authors: [erika]\n",
      "date: 2023-02-21\n",
      "tags: ['integrations']\n",
      "image: ./img/hero.png\n",
      "description: \"LangChain is one of the most exciting new tools in AI. It helps overcome many limitations of LLMs, such as hallucination and limited input lengths.\"\n",
      "---\n",
      "![Combining LangChain and Weaviate](./img/hero.png)\n",
      "\n",
      "Large Language Models (LLMs) have revolutionized the way we interact and communicate with computers. These machines can understand and generate human-like language on a massive scale. LLMs are a versatile tool that is seen in many applications like chatbots, content creation, and much more. Despite being a powerful tool, LLMs have the drawback of being too general.\n"
     ]
    }
   ],
   "source": [
    "# read markdowns from disk\n",
    "import os\n",
    "import re\n",
    "\n",
    "def chunk_list(lst, chunk_size):\n",
    "    \"\"\"Break a list into chunks of the specified size.\"\"\"\n",
    "    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    \"\"\"Split text into sentences using regular expressions.\"\"\"\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "    return [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "\n",
    "def read_and_chunk_index_files(main_folder_path):\n",
    "    \"\"\"Read index.md files from subfolders, split into sentences, and chunk every 5 sentences.\"\"\"\n",
    "    blog_chunks = []\n",
    "    for folder_name in os.listdir(main_folder_path):\n",
    "        subfolder_path = os.path.join(main_folder_path, folder_name)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            index_file_path = os.path.join(subfolder_path, 'index.mdx')\n",
    "            if os.path.isfile(index_file_path):\n",
    "                with open(index_file_path, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()\n",
    "                    sentences = split_into_sentences(content)\n",
    "                    sentence_chunks = chunk_list(sentences, 5)\n",
    "                    sentence_chunks = [' '.join(chunk) for chunk in sentence_chunks]\n",
    "                    blog_chunks.extend(sentence_chunks)\n",
    "    return blog_chunks\n",
    "\n",
    "# Example usage\n",
    "main_folder_path = '../../../llm-frameworks/data'\n",
    "blog_chunks = read_and_chunk_index_files(main_folder_path)\n",
    "print(blog_chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d14754a",
   "metadata": {},
   "source": [
    "# Create a Weaviate Schema and Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "14724170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import weaviate.classes.config as wvcc\n",
    "from weaviate.util import get_valid_uuid\n",
    "from uuid import uuid4\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "weaviate_blog_chunks = client.collections.create(\n",
    "    name = \"WeaviateBlogChunk\",\n",
    "    vectorizer_config=wvcc.Configure.Vectorizer.text2vec_cohere(\n",
    "        model=\"embed-english-v3.0\"\n",
    "    ),\n",
    "    properties=[\n",
    "        wvcc.Property(name=\"content\", data_type=wvcc.DataType.TEXT)\n",
    "    ]\n",
    ")\n",
    "\n",
    "for idx, blog_chunk in enumerate(blog_chunks):\n",
    "    upload = weaviate_blog_chunks.data.insert(\n",
    "        properties={\n",
    "            \"content\": blog_chunk\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034d3e43",
   "metadata": {},
   "source": [
    "# Query Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "97fe7979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': \"In a garbage-collected language, such as Go, C#, or Java, the programmer doesn't have to deallocate objects manually after using them. A GC cycle runs periodically to collect memory no longer needed and ensure it can be assigned again. Using a garbage-collected language is a trade-off between development complexity and execution time. Some CPU time has to be spent at runtime to run the GC cycles. Go's Garbage collector is highly concurrent and [quite efficient](https://tip.golang.org/doc/gc-guide#Understanding_costs).\"}\n"
     ]
    }
   ],
   "source": [
    "response = weaviate_blog_chunks.query.hybrid(\n",
    "    query=\"How does the Golang Garbage Collector work?\",\n",
    "    limit=1\n",
    ")\n",
    "\n",
    "for obj in response.objects:\n",
    "    print(obj.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c269b10",
   "metadata": {},
   "source": [
    "# Load Structured Data into BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c8aec3",
   "metadata": {},
   "source": [
    "From cloud.google.com/bigquery, \"BigQuery is a fully managed, AI-ready data analytics platform that helps you maximize value from your data and is designed to be multi-engine, multi-format, and multi-cloud\". For example, companies often store information about transactions or customer relationships in structured tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82944e3",
   "metadata": {},
   "source": [
    "![alt text](./bigquery-images/bigquery.png \"Title Text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16af66b",
   "metadata": {},
   "source": [
    "Image source: https://cloud.google.com/bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c90268",
   "metadata": {},
   "source": [
    "# Connect to BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e402d7f",
   "metadata": {},
   "source": [
    "Download the `google-cloud-bigquery` Python client with `pip`!\n",
    "\n",
    "This tutorial is written with google-cloud-bigquery==3.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3263311d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-bigquery > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "01ba888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import google.auth\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Replace with your Google Cloud credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    './google_auth.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c0041a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigquery_client = bigquery.Client(\n",
    "    project=\"bigquery-playground-422417\",\n",
    "    credentials=credentials\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef5f7d7",
   "metadata": {},
   "source": [
    "## Google Cloud Data Marketplace with BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b5cdd7",
   "metadata": {},
   "source": [
    "You can access many datasets in the Google Cloud Data Marketplace!\n",
    "\n",
    "Maybe your RAG application needs to know what the most commonly occuring names of residents in Texas are!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "2a2681a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(('Ruby', 314), {'name': 0, 'number': 1})\n",
      "Row(('Louise', 127), {'name': 0, 'number': 1})\n",
      "Row(('Carrie', 63), {'name': 0, 'number': 1})\n"
     ]
    }
   ],
   "source": [
    "QUERY = (\n",
    "    'SELECT name, number FROM `bigquery-public-data.usa_names.usa_1910_2013` '\n",
    "    'WHERE state = \"TX\" '\n",
    "    'LIMIT 100')\n",
    "query_job = bigquery_client.query(QUERY)\n",
    "rows = query_job.result()\n",
    "\n",
    "for idx, row in enumerate(rows):\n",
    "    if idx > 2:\n",
    "        break\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf86ce5",
   "metadata": {},
   "source": [
    "Learn more about the [Google Cloud Marketplace in the 95th Weaviate Podcast](https://www.youtube.com/watch?v=UdAtsuoEd38) with **Dai Vu**, Director of Google Cloud Marketplace and ISV GTM and **Bob van Luijt**, Weaviate Co-Founder and CEO!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa74debd",
   "metadata": {},
   "source": [
    "![alt text](./bigquery-images/gcp-pod.png \"Title Text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2caa23f",
   "metadata": {},
   "source": [
    "## Custom Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3e3b44",
   "metadata": {},
   "source": [
    "Schema created in the Google Cloud console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0de6df99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/41/8dp_379x15d8zz4ppsjthdw40000gn/T/ipykernel_8009/3365144275.py:1: PendingDeprecationWarning: Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.\n",
      "  table_ref = bigquery_client.dataset(\"WeaviateBlogs\").table(\"BlogInfo\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigquery-playground-422417.WeaviateBlogs.BlogInfo\n",
      "Rows inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "table_ref = bigquery_client.dataset(\"WeaviateBlogs\").table(\"BlogInfo\")\n",
    "\n",
    "print(bigquery_client.get_table(\"WeaviateBlogs.BlogInfo\"))\n",
    "\n",
    "# Define the schema fields\n",
    "schema_fields = [\n",
    "    bigquery.SchemaField(\"Name\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"Team\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"Blogs_Written\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"Active_Weaviate_Team_Member\", \"BOOLEAN\")\n",
    "]\n",
    "\n",
    "rows_to_insert = [\n",
    "    (\"Abdel Rodriguez\", \"Applied Research\", 5, True),\n",
    "    (\"Adam Chan\", \"Developer Growth\", 1, True),\n",
    "    (\"Ajit Mistry\", \"Developer Growth\", 1, True),\n",
    "    (\"Alea Abed\", \"Marketing\", 2, True),\n",
    "    (\"Amir Houieh\", \"Unbody\", 1, False),\n",
    "    (\"Asdine El Hrychy\", \"Applied Research\", 1, True),\n",
    "    (\"Bob van Luijt\", \"CEO Team\", 5, True),\n",
    "    (\"Charles Frye\", \"Modal\", 1, False),\n",
    "    (\"Connor Shorten\", \"Applied Research\", 14, True),\n",
    "    (\"Dan Dascalescu\", \"Developer Relations\", 6, True),\n",
    "    (\"Daniel Phiri\", \"Developer Relations\", 3, True),\n",
    "    (\"Dave Cuthbert\", \"Developer Relations\", 2, True),\n",
    "    (\"Dirk Kulawiak\", \"Core Engineering\", 5, True),\n",
    "    (\"Edward Schmuhl\", \"Developer Growth\", 2, True),\n",
    "    (\"Erika Cardenas\", \"Partnerships\", 20, True),\n",
    "    (\"Etienne Dilocker\", \"CTO Team\", 9, True),\n",
    "    (\"Femke Plantinga\", \"Developer Growth\", 1, True),\n",
    "    (\"Ieva Urbaite\", \"Marketing\", 2, True),\n",
    "    (\"Jerry Liu\", \"LlamaIndex\", 1, False),\n",
    "    (\"John Trengrove\", \"Applied Research\", 2, True),\n",
    "    (\"Jonathan Tuite\", \"Sales Engineering\", 2, True),\n",
    "    (\"Joon-Pil (JP) Hwang\", \"Developer Relations\", 18, True),\n",
    "    (\"Laura Ham\", \"Product\", 7, False),\n",
    "    (\"Leonie Monigatti\", \"Developer Growth\", 4, True),\n",
    "    (\"Marion Nehring\", \"Developer Relations\", 1, True),\n",
    "    (\"Mohd Shukri Hasan\", \"Sales Engineering\", 3, True),\n",
    "    (\"Peter Schramm\", \"Weaviate Cloud Services\", 1, False),\n",
    "    (\"Sam Stoelinga\", \"Substratus AI\", 1, False),\n",
    "    (\"Sebastian Witalec\", \"Developer Relations\", 7, True),\n",
    "    (\"Stefan Bogdan\", \"Customer Success\", 1, True),\n",
    "    (\"Tommy Smith\", \"Core Engineering\", 3, True),\n",
    "    (\"Victoria Slocum\", \"Developer Growth\", 1, True),\n",
    "    (\"Zain Hasan\", \"Developer Relations\", 20, True)\n",
    "]\n",
    "\n",
    "errors = bigquery_client.insert_rows(\n",
    "    table_ref,\n",
    "    rows_to_insert,\n",
    "    selected_fields=schema_fields\n",
    ")\n",
    "\n",
    "if errors == []:\n",
    "    print(\"Rows inserted successfully.\")\n",
    "else:\n",
    "    print(\"Errors occurred during insertion:\")\n",
    "    for error in errors:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "82d11414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(('Abdel Rodriguez', 'Applied Research', 5, True), {'Name': 0, 'Team': 1, 'Blogs_Written': 2, 'Active_Weaviate_Team_Member': 3})\n"
     ]
    }
   ],
   "source": [
    "QUERY = (\n",
    "    'SELECT * FROM bigquery-playground-422417.WeaviateBlogs.BlogInfo'\n",
    ")\n",
    "\n",
    "query_job = bigquery_client.query(QUERY)\n",
    "rows = query_job.result()\n",
    "\n",
    "for row in rows:\n",
    "    print(row)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3056e25",
   "metadata": {},
   "source": [
    "# Storing Monitoring Logs in Weaviate *and* BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "c5b240f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/41/8dp_379x15d8zz4ppsjthdw40000gn/T/ipykernel_8009/497179841.py:7: PendingDeprecationWarning: Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.\n",
      "  table_ref = bigquery_client.dataset(\"WeaviateBlogs\").table(\"RAGLogs\")\n"
     ]
    }
   ],
   "source": [
    "file_path = './WeaviateBlogRAG-0-0-0.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    dataset = json.load(file)\n",
    "\n",
    "# Get BigQuery Table\n",
    "table_ref = bigquery_client.dataset(\"WeaviateBlogs\").table(\"RAGLogs\")\n",
    "\n",
    "schema_fields = [\n",
    "    bigquery.SchemaField(\"query\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"answer\", \"STRING\"),\n",
    "\n",
    "]\n",
    "\n",
    "# Create Weaviate Collection\n",
    "rag_log_weaviate = client.collections.create(\n",
    "    name = \"RAGLog\",\n",
    "    # Embed with Cohere\n",
    "    vectorizer_config=wvcc.Configure.Vectorizer.text2vec_cohere(\n",
    "        model=\"embed-english-v3.0\"\n",
    "    ),\n",
    "    properties=[\n",
    "        wvcc.Property(name=\"query\", data_type=wvcc.DataType.TEXT),\n",
    "        wvcc.Property(name=\"answer\", data_type=wvcc.DataType.TEXT)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Import Data\n",
    "for row in dataset:\n",
    "    # Import to BigQuery\n",
    "    rows_to_insert = [(row[\"query\"], row[\"gold_answer\"])]\n",
    "    bigquery_client.insert_rows(\n",
    "        table_ref,\n",
    "        rows_to_insert,\n",
    "        selected_fields=schema_fields\n",
    "    )\n",
    "    # Import to Weaviate\n",
    "    upload = rag_log_weaviate.data.insert(\n",
    "        properties={\n",
    "            \"query\": row[\"query\"],\n",
    "            \"answer\": row[\"gold_answer\"]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2302eb",
   "metadata": {},
   "source": [
    "# RAGwithContextFusion Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2becdc95",
   "metadata": {},
   "source": [
    "![alt text](./bigquery-images/dspy.png \"Title Text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703c9548",
   "metadata": {},
   "source": [
    "Image source: https://dspy-docs.vercel.app/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74510dd6",
   "metadata": {},
   "source": [
    "Now we will turn to our RAGwithContextFusion program that uses the:\n",
    "\n",
    "- Blog chunks stored in Weaviate\n",
    "- Author metadata stored in BigQuery\n",
    "- RAG logs stored in Weaviate\n",
    "- RAG logs stored in BigQuery\n",
    "\n",
    "To answer questions, the program will route queries to the appropriate information sources, looping when multiple rounds of queries are needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffef12b",
   "metadata": {},
   "source": [
    "# DSPy Signatures and Route Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "eb58c1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from enum import Enum\n",
    "\n",
    "class Route(Enum):\n",
    "    Author_Info_BigQuery = \"Author_Info_BigQuery\"\n",
    "    RAG_Log_BigQuery = \"RAG_Log_BigQuery\"\n",
    "    RAG_Log_Weaviate = \"RAG_Log_Weaviate\"\n",
    "    Blogs_Weaviate = \"Blogs_Weaviate\"\n",
    "\n",
    "class TextToSQL(dspy.Signature):\n",
    "    \"\"\"Translate the natural language query into a valid SQL query for the given schema\"\"\"\n",
    "    \n",
    "    sql_schema_with_description: str = dspy.InputField()\n",
    "    natural_language_query: str = dspy.InputField()\n",
    "    sql_query: str = dspy.OutputField(desc=\"Only output the SQL query string without any newline characters.\")\n",
    "    \n",
    "class QueryRouter(dspy.Signature):\n",
    "    \"\"\"Given a query and a list of data sources, output the best data source for answering the query.\"\"\"\n",
    "    \n",
    "    query: str = dspy.InputField(desc=\"The query to answer with information from one of the data sources.\")\n",
    "    data_sources: str = dspy.InputField(desc=\"A description of each data source.\")\n",
    "    route: Route = dspy.OutputField()\n",
    "        \n",
    "class AgentLoopCondition(dspy.Signature):\n",
    "    \"\"\"Assess the context and search history and determine if enough context has been gathered to answer the question or if more context must be acquired from the information sources.\"\"\"\n",
    "    \n",
    "    query: str = dspy.InputField(desc=\"The query to answer with information from the context.\")\n",
    "    data_sources: str = dspy.InputField(desc=\"A description of each data source.\")\n",
    "    contexts: str = dspy.InputField(desc=\"The context acquired so far.\")\n",
    "    more_info_needed: bool = dspy.OutputField(desc=\"Whether or not the question can be answered based on the context provided.\")\n",
    "    \n",
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Asess the context and answer the question. \n",
    "Some context may be missing depending on the information sources the query router determined were needed to answer the question.\"\"\"\n",
    "    \n",
    "    question: str = dspy.InputField()\n",
    "    contexts: str = dspy.InputField(desc=\"Information acquired from searching multiple data sources.\")\n",
    "    data_sources: str = dspy.InputField(desc=\"A description of the data sources the contexts were acquired from.\")\n",
    "    answer: str = dspy.OutputField()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737a8a9f",
   "metadata": {},
   "source": [
    "# Database Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "8e52e890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class BigQuerySearcher():\n",
    "    def __init__(self, sql_schema_with_description: str, \n",
    "                 bigquery_client: google.cloud.bigquery.client.Client):\n",
    "        self.text_to_sql = dspy.TypedPredictor(TextToSQL)\n",
    "        self.sql_schema_with_description = sql_schema_with_description\n",
    "        self.bigquery_client = bigquery_client\n",
    "    \n",
    "    def sql_results_to_text(self,rows: bigquery.table.RowIterator) -> str:\n",
    "        results = []\n",
    "        for row in rows:\n",
    "            row_strings = [f\"{column}: {row[column]}\" for column in row.keys()]\n",
    "            result_string = \", \".join(row_strings)\n",
    "            results.append(result_string)\n",
    "    \n",
    "        return \"\\n\".join(results)\n",
    "    \n",
    "    def forward(self, query: str):\n",
    "        sql_query = self.text_to_sql(natural_language_query=query, \n",
    "                            sql_schema_with_description=self.sql_schema_with_description).sql_query\n",
    "        query_job = self.bigquery_client.query(sql_query)\n",
    "        sql_results = query_job.result()\n",
    "        text_sql_results = self.sql_results_to_text(sql_results)\n",
    "        return text_sql_results\n",
    "    \n",
    "class WeaviateSearcher():\n",
    "    def __init__(self, weaviate_client: weaviate.client.WeaviateClient,\n",
    "                 collection_name: str,\n",
    "                 view_properties: List[str]):\n",
    "        self.collection = weaviate_client.collections.get(collection_name)\n",
    "        self.view_properties = view_properties\n",
    "    \n",
    "    # ToDo, set `view_properties` as an Optional argument\n",
    "    def parse_weaviate_response(self, response: weaviate.collections.classes.internal.QueryReturn):\n",
    "        string_output = []\n",
    "        for index, obj in enumerate(response.objects, start=1):\n",
    "            result = {}\n",
    "            for prop in self.view_properties:\n",
    "                if prop in obj.properties:\n",
    "                    result[prop] = obj.properties[prop]\n",
    "            string_output.append(f\"[{index}] {result}\")\n",
    "        return \"\\n\".join(string_output)\n",
    "    \n",
    "    def forward(self, query: str):\n",
    "        response = self.collection.query.hybrid(\n",
    "            query=query,\n",
    "            limit=3\n",
    "        )\n",
    "        return self.parse_weaviate_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfe446e",
   "metadata": {},
   "source": [
    "# Structured Schema Info and Data Source Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "87e28cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_schema_with_description = \"\"\"\n",
    "Technical Schema Information:\n",
    "\n",
    "Table: bigquery-playground-422417.WeaviateBlogs.BlogInfo\n",
    "Attributes: \n",
    "`Name` STRING\n",
    "`Team` STRING\n",
    "`Blogs_Written` INTEGER\n",
    "`Active_Weaviate_Team_Member` BOOLEAN\n",
    "\n",
    "Description of the Table:\n",
    "\n",
    "The table contains information about Weaviate Blog post authors.\n",
    "The `Name` attribute is the name of the author.\n",
    "The `Team` attribute is the particular team the author works on at Weaviate.\n",
    "The `Blogs_Written` attribute is the number of blogs the author has written.\n",
    "The `Active_Weaviate_Team_Member` attribute denotes whether the author is currently a member of the Weaviate team.\n",
    "\"\"\"\n",
    "\n",
    "rag_log_schema_with_description = \"\"\"\n",
    "Technical Schema Information:\n",
    "\n",
    "Table: bigquery-playground-422417.WeaviateBlogs.RAGLog\n",
    "Attributes:\n",
    "`query` STRING\n",
    "`answer` STRING\n",
    "\n",
    "Description of the Table:\n",
    "\n",
    "The table contains questions submitted to a question answering system and the resulting response from the system.\n",
    "The `query` attribute is the query sent to the system.\n",
    "The `answer` attribute is the system's response to the query.\n",
    "\"\"\"\n",
    "\n",
    "route_config = {\n",
    "    \"data_sources\": {\n",
    "        \"Author_Info_BigQuery\": BigQuerySearcher(author_schema_with_description, bigquery_client),\n",
    "        \"RAG_Log_BigQuery\": BigQuerySearcher(rag_log_schema_with_description, bigquery_client),\n",
    "        \"RAG_Log_Weaviate\": WeaviateSearcher(weaviate_client, \"RAGLog\", [\"query\", \"answer\"]),\n",
    "        \"Blogs_Weaviate\": WeaviateSearcher(weaviate_client, \"WeaviateBlogChunk\", [\"content\"])\n",
    "    },\n",
    "    \"description\": \"\"\"\n",
    "        Author_Info_BigQuery: Structured SQL table in BigQuery that contains information about authors of Weaviate blog posts such as their `Name`, the `Team` they work on at Weaviate, the number of `Blogs_Written` from the author, and whether they are an `Active_Weaviate_Team_Member`.\n",
    "        RAG_Log_BigQuery: Structured SQL table in BigQuery that contains questions submitted to a question answering system and the system's response.\n",
    "        RAG_Log_Weaviate: A Vector Index that contains questions submitted to a question answering system and the system's response.\n",
    "        Blogs_Weaviate: A Vector Index that contains snippets from Weaviate's blog posts.\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f71a83",
   "metadata": {},
   "source": [
    "# RAGwithContextFusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "ff3366e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGwithContextFusion(dspy.Module):\n",
    "    def __init__(self, route_config):\n",
    "        self.route_config = route_config\n",
    "        self.query_router = dspy.TypedPredictor(QueryRouter)\n",
    "        self.agent_loop_condition = dspy.TypedPredictor(AgentLoopCondition)\n",
    "        self.generate_answer = dspy.TypedPredictor(GenerateAnswer)\n",
    "    \n",
    "    def forward(self, query):\n",
    "        enough_context = False\n",
    "        contexts, queries = [], []\n",
    "        while not enough_context:\n",
    "            query_route = self.query_router(query=query, data_sources=self.route_config[\"description\"]).route.name\n",
    "            context = self.route_config[\"data_sources\"][query_route].forward(query=query)\n",
    "            contexts.append(context)\n",
    "            queries.append(query)\n",
    "            query_history = \"\\n\".join(f\"query {i+1}: {query}\" for i, query in enumerate(queries))\n",
    "            contexts_str = \"\\n\".join(f\"context {i+1}: {item}\" for i, item in enumerate(contexts))\n",
    "            enough_context = self.agent_loop_condition(query=query,\n",
    "                                                       data_sources=self.route_config[\"description\"],\n",
    "                                                       contexts=contexts_str).more_info_needed\n",
    "        answer = self.generate_answer(question=query,\n",
    "                                      contexts=contexts_str, data_sources=self.route_config[\"description\"]).answer\n",
    "        return dspy.Prediction(answer=answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "5bf0e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_with_context_fusion = RAGwithContextFusion(route_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "1b9c0502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='Zain Hasan and Erika Cardenas are the most frequent authors of Weaviate blog posts, with 20 posts each.'\n",
       ")"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_with_context_fusion(query=\"Who are the most frequent authors of Weaviate blog posts?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "72caebc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='Ref2Vec infers a centroid vector from a user\\'s references to other vectors. This vector is updated in real-time to reflect the user\\'s preferences and actions. Ref2Vec integrates with Weaviate through the \"user-as-query\" method, where the user\\'s vector is used as a query to fetch relevant products.'\n",
       ")"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_with_context_fusion(query=\"How does ref2vec work?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
