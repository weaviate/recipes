{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41a31d7e",
   "metadata": {},
   "source": [
    "# Dialogue Classifier with OpenAI and DSPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "639eff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import dspy\n",
    "\n",
    "gpt4 = dspy.OpenAI(model = \"gpt-4\", max_tokens=4000)\n",
    "\n",
    "dspy.settings.configure(lm=gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de0b1088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello! How can I assist you today?']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4(\"say hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3c48975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_output(classification):\n",
    "    valid_inputs = [\"not relevant\", \"partial context\", \"full context\"]\n",
    "    return classification in valid_inputs\n",
    "\n",
    "class DialogueClassifier(dspy.Signature):\n",
    "    \"\"\"Classify dialogue snippets into the given categories.\n",
    "    \n",
    "    The categories are given as:\n",
    "    \n",
    "    'not relevant': Completely unrelated to the question the user might eventually ask.\n",
    "    'partial context': A question that gives only part of the required context, for example there are many different reports that could be relevant.\n",
    "    'full context': The dialogue has everything required to answer the question\n",
    "    \"\"\"\n",
    "    dialogue = dspy.InputField()\n",
    "    classification = dspy.OutputField(desc=\"ONLY OUTPUT one of 'not relevant', 'partial context', or 'full context' NOTHING ELSE! IMPORTANT!\")\n",
    "\n",
    "class OutputParser(dspy.Signature):\n",
    "    \"\"\"Parse a raw response from a system into one of the desired outputs.\n",
    "    \n",
    "    The desired outputs are:\n",
    "    \n",
    "    -not relevant\n",
    "    -partial context\n",
    "    -full context\n",
    "    \"\"\"\n",
    "    \n",
    "    raw_response = dspy.InputField(desc=\"A raw response from a system that needs to be parsed.\")\n",
    "    desired_outputs = dspy.OutputField(desc=\"\")\n",
    "\n",
    "class ClassifierProgram(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.dialogue_classifier = dspy.ChainOfThought(DialogueClassifier)\n",
    "        self.parser = dspy.Predict(OutputParser)\n",
    "    \n",
    "    def forward(self, dialogue):\n",
    "        classification = self.dialogue_classifier(dialogue=dialogue).classification\n",
    "        parser = self.parser(raw_response=classification).desired_outputs\n",
    "        #[WIP] dspy.Suggest(test_output(parser), \"One of 'not relevant', 'partial context', or 'full context'.\")\n",
    "        return dspy.Prediction(classification=parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b50b23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not relevant'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_program = ClassifierProgram()\n",
    "my_program(dialogue=\"Hi Joel, how was your holiday\").classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f560527e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Parse a raw response from a system into one of the desired outputs.\n",
      "    \n",
      "    The desired outputs are:\n",
      "    \n",
      "    -not relevant\n",
      "    -partial context\n",
      "    -full context\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Raw Response: A raw response from a system that needs to be parsed.\n",
      "Desired Outputs:\n",
      "\n",
      "---\n",
      "\n",
      "Raw Response: not relevant\n",
      "Desired Outputs:\u001b[32m not relevant\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt4.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f9c142f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'partial context'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_program(dialogue=\"I have a problem with my Reports\").classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d8c1cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Parse a raw response from a system into one of the desired outputs.\n",
      "    \n",
      "    The desired outputs are:\n",
      "    \n",
      "    -not relevant\n",
      "    -partial context\n",
      "    -full context\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Raw Response: A raw response from a system that needs to be parsed.\n",
      "Desired Outputs:\n",
      "\n",
      "---\n",
      "\n",
      "Raw Response: partial context\n",
      "Desired Outputs:\u001b[32m partial context\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt4.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a83fd1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'full context'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_program(dialogue=\"I have a issue creating the gardening report, can you help?\").classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a078267b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Parse a raw response from a system into one of the desired outputs.\n",
      "    \n",
      "    The desired outputs are:\n",
      "    \n",
      "    -not relevant\n",
      "    -partial context\n",
      "    -full context\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Raw Response: A raw response from a system that needs to be parsed.\n",
      "Desired Outputs:\n",
      "\n",
      "---\n",
      "\n",
      "Raw Response: full context\n",
      "Desired Outputs:\u001b[32m full context\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt4.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1317eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally connect the WeaviateRM to your DSPy programs with:\n",
    "'''\n",
    "from dspy.retrieve.weaviate_rm import WeaviateRM\n",
    "import weaviate\n",
    "weaviate_client = weaviate.Client(\"http://localhost:8080\")\n",
    "retriever_model = WeaviateRM(collection_name=\"WeaviateBlogChunk\", \n",
    "                            weaviate_collection_key=\"content\",\n",
    "                            weaviate_client=weaviate_client)\n",
    "dspy.settings.configure(lm=llm, rm=retriever_model)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
