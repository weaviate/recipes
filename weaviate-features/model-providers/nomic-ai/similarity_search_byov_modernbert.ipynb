{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag9kcX2B_atc"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/weaviate/recipes/blob/main/weaviate-features/bring-your-own-vectors-and-multi-lingual/modernBERT_embeddings/vector_search_modernbert.ipynb)\n",
        "\n",
        "![Cover image](vector_search_modernbert_cover_image.png)\n",
        "\n",
        "# Generating Embeddings for Vector Search with ModernBERT in Weaviate\n",
        "## A 100% open source recipe üßë‚Äçüç≥ üíö\n",
        "By Mary Newhauser, MLE @ Weaviate\n",
        "\n",
        "This is a code recipe that uses [Nomic AI](https://www.nomic.ai/)'s [modernbert-embed-base](https://huggingface.co/nomic-ai/modernbert-embed-base) model to generate text embeddings for machine learning papers, inserts them into [Weaviate](https://weaviate.io/) and performs similarity search over the documents.\n",
        "\n",
        "In this notebook, we accomplish the following:\n",
        "* Load and transform the [ML-ArXiv-Papers](https://huggingface.co/datasets/CShorten/ML-ArXiv-Papers) dataset\n",
        "* Generate text embeddings for a random sample of 100 articles using `sentence-transformers` and `modernbert-embed-base`\n",
        "* Perform a basic similarity search over the dataset\n",
        "\n",
        "## About ModernBERT\n",
        "[ModernBERT](https://arxiv.org/abs/2412.13663) is the biggest improvement in years to the [BERT](https://arxiv.org/abs/1810.04805) model. ModernBERT features:\n",
        "* 16x longer sequence length\n",
        "* Faster inference\n",
        "* SOTA performance across tasks like classification and retrieval\n",
        "\n",
        "For more information, check out Hugging Face's ModernBERT [blog post](https://huggingface.co/blog/modernbert).\n",
        "\n",
        "## Requirements\n",
        "To run this notebook, we used Python version `3.9.6` and Transformers `4.48.0`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "49AguLS_izgn"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install --q transformers==4.48.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "u076oUSF_YUG"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install sentence-transformers\n",
        "%pip install datasets\n",
        "%pip install -U weaviate-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q2F9RUmR8Wj"
      },
      "source": [
        "## Load and transform dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6lmOYEPm_-7"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"CShorten/ML-ArXiv-Papers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "T75_q7iunTOS"
      },
      "outputs": [],
      "source": [
        "# Keep only \"title\" and \"abstract\" columns in train set\n",
        "train_ds = ds[\"train\"].select_columns([\"title\", \"abstract\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CzfutYG0Qm1"
      },
      "source": [
        "The original dataset contains over ~100k titles and abstracts for ML papers from arXiv. For this demo, we'll just take a random sample of 100 papers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoKLdyYdoMu2",
        "outputId": "1927e16e-5283-4748-b846-6c261c2094cd"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Set seed\n",
        "random.seed(42)\n",
        "\n",
        "# Shuffle the dataset and select the first 100 rows\n",
        "subset_ds = train_ds.shuffle(seed=42).select(range(100))\n",
        "\n",
        "# Concatenate abstract and titles\n",
        "def combine_text(row):\n",
        "    row[\"text\"] = row[\"abstract\"] + \" \" + row[\"title\"]\n",
        "    return row\n",
        "\n",
        "# Apply function to entire dataset\n",
        "subset_ds = subset_ds.map(combine_text)\n",
        "\n",
        "# Print number of rows\n",
        "print(f\"Number of rows: {len(subset_ds)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHmxwEaK0cZR"
      },
      "source": [
        "## Generate embeddings with `modernbert-embed-base`\n",
        "We'll use the `sentence-transformers` library to load and embed the concatenated titles and abstracts with the `modernbert-embed-base` embedding model, adding them to their own column in the original dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hoxESKCpS6j"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load the SentenceTransformer model\n",
        "model = SentenceTransformer(\"nomic-ai/modernbert-embed-base\")\n",
        "\n",
        "# Function to generate embeddings for a single text\n",
        "def generate_embeddings(example):\n",
        "    example[\"embeddings\"] = model.encode(example[\"text\"], reference_compile=False)\n",
        "    return example\n",
        "\n",
        "# Apply the function to the dataset using map\n",
        "embeddings_ds = subset_ds.map(generate_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96ZIRpZF03fT"
      },
      "source": [
        "Next, we'll convert the dataset to a `pandas` `DataFrame` for insertion into Weaviate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CwjknzYMp8O4",
        "outputId": "e7625e8f-d891-4152-8aa1-e11c10a97cec"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert HF dataset to Pandas DF\n",
        "df = embeddings_ds.to_pandas()\n",
        "\n",
        "# Take a peek at the data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhLlCpQODaT3"
      },
      "source": [
        "## Insert the embeddings into Weaviate\n",
        "### Create and configure an embedded Weaviate collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho7xYQTZK5Wk"
      },
      "source": [
        "[Embedded Weaviate](https://weaviate.io/developers/weaviate/installation/embedded) allows you to spin up a Weaviate instance directly from your application code, without having to use a Docker container.\n",
        "\n",
        "If you're interested in other deployment methods, like using Docker-Compose or Kubernetes, check out this [page](https://weaviate.io/developers/weaviate/installation) in the Weaviate docs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFUBEZiJUMic",
        "outputId": "360e30e0-f10b-48f8-e2df-109a77b3cad7"
      },
      "outputs": [],
      "source": [
        "import weaviate\n",
        "\n",
        "# Connect to Weaviate\n",
        "client = weaviate.connect_to_embedded()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqqyQSFt1TWr"
      },
      "source": [
        "Next, we define the collection and its properties."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jEhxseguKf9"
      },
      "outputs": [],
      "source": [
        "import weaviate.classes as wvc\n",
        "import weaviate.classes.config as wc\n",
        "from weaviate.classes.config import Property, DataType\n",
        "\n",
        "# Define the collection name\n",
        "collection_name = \"ml_papers\"\n",
        "\n",
        "# Delete the collection if it already exists\n",
        "if (client.collections.exists(collection_name)):\n",
        "    client.collections.delete(collection_name)\n",
        "\n",
        "# Create the collection\n",
        "collection = client.collections.create(\n",
        "    collection_name,\n",
        "    vectorizer_config = wvc.config.Configure.Vectorizer.none(),\n",
        "\n",
        "    # Define properties of metadata\n",
        "    properties=[\n",
        "        wc.Property(\n",
        "            name=\"text\",\n",
        "            data_type=wc.DataType.TEXT\n",
        "        ),\n",
        "        wc.Property(\n",
        "            name=\"title\",\n",
        "            data_type=wc.DataType.TEXT,\n",
        "            skip_vectorization=True\n",
        "        ),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FKKoIx01awT"
      },
      "source": [
        "Finally, we insert the embeddings and metadata into our Weaviate collection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HhxnBF8h1fLu"
      },
      "outputs": [],
      "source": [
        "# Insert embeddings and metadata into collection\n",
        "objs = []\n",
        "for i, d in enumerate(df[\"text\"]):\n",
        "    objs.append(wvc.data.DataObject(\n",
        "            properties={\n",
        "                \"text\": df[\"text\"][i],\n",
        "                \"title\": df[\"title\"][i],\n",
        "            },\n",
        "            vector = df[\"embeddings\"][i].tolist()\n",
        "        )\n",
        "    )\n",
        "\n",
        "collection.data.insert_many(objs);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI01PxjuD_XR"
      },
      "source": [
        "## Query the data using similarity search\n",
        "\n",
        "Here, we perform a simple similarity search to return the most similar embedded chunks to our search query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qI3w-Lkdv8Vt"
      },
      "outputs": [],
      "source": [
        "# Define query and number of results\n",
        "query = \"Which papers apply ML to the medical domain?\"\n",
        "\n",
        "top_n = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbz6nWJc5CSj",
        "outputId": "9527cb40-2d83-4d7f-c7aa-c3f92c374f21"
      },
      "outputs": [],
      "source": [
        "from weaviate.classes.query import MetadataQuery\n",
        "\n",
        "query_embedding = model.encode(query)",
        "\n",
        "results = collection.query.near_vector(\n",
        "    near_vector = query_embedding,\n",
        "    limit=top_n\n",
        ")\n",
        "\n",
        "print(f\"Top {top_n} results:\\n\")\n",
        "for i, obj in enumerate(results.objects):\n",
        "    print(obj.properties['title'])\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tGz49nfUegG"
      },
      "source": [
        "‚òÅÔ∏è Want to scale this notebook? \n",
        "\n",
        "üòç Get 14 days of free access to Weaviate Cloud's Sandbox by creating an account [here](https://console.weaviate.cloud/). \n",
        "\n",
        "*No name, no credit card required.*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
