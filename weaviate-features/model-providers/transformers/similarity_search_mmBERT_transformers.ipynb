{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MklMC3etolzu"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/weaviate/recipes/blob/main/weaviate-features/model-providers/huggingface/similarity_search_mmBERT.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ7MqblkouF9"
      },
      "source": [
        "## Similarity search with Multilingual ModernBERT (mmBERT) via Hugging Face and Weaviate\n",
        "\n",
        "- Read more on the [blog](https://huggingface.co/blog/mmbert)\n",
        "- Check out the model: [`mmBERT-small`](https://huggingface.co/jhu-clsp/mmBERT-small)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJD9aP9eVcsT"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3IgZm3pYwWa8"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -q -U weaviate-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgL-mnMqVf0B"
      },
      "source": [
        "## Connect to Weaviate\n",
        "\n",
        "This Notebook uses the [`text2vec-transformers`](https://docs.weaviate.io/weaviate/model-providers/transformers/embeddings) module, which is **only** available through Weaviate open-source via [Docker](https://docs.weaviate.io/deploy/installation-guides/docker-installation) or [Kubernetes](https://docs.weaviate.io/deploy/installation-guides/k8s-installation). This integration is **not** available for Weaviate Cloud (WCD) serverless instances, as it requires spinning up a container with the Hugging Face model.\n",
        "\n",
        "This notebook uses a [pre-built transformers model container](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-transformers#pre-built-images). For this, create a `docker-compose.yml` file with the following contents:\n",
        "```\n",
        "---\n",
        "services:\n",
        "  weaviate:\n",
        "    command:\n",
        "    - --host\n",
        "    - 0.0.0.0\n",
        "    - --port\n",
        "    - '8080'\n",
        "    - --scheme\n",
        "    - http\n",
        "    image: cr.weaviate.io/semitechnologies/weaviate:1.32.2\n",
        "    ports:\n",
        "    - 8080:8080\n",
        "    - 50051:50051\n",
        "    restart: on-failure:0\n",
        "    environment:\n",
        "      TRANSFORMERS_INFERENCE_API: 'http://t2v-transformers:8080'\n",
        "      QUERY_DEFAULTS_LIMIT: 25\n",
        "      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n",
        "      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n",
        "      DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers'\n",
        "      ENABLE_MODULES: 'text2vec-transformers'\n",
        "      CLUSTER_HOSTNAME: 'weaviate-0'\n",
        "  t2v-transformers:\n",
        "    image: cr.weaviate.io/semitechnologies/transformers-inference:jhu-clsp-mmBERT-small\n",
        "    environment:\n",
        "      ENABLE_CUDA: '0'\n",
        "...\n",
        "``` \n",
        "and start up Docker container with\n",
        "```\n",
        "docker-compose up -d\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnByDFpEsDL-",
        "outputId": "325993c8-503e-4604-ed82-d6cafb7c7f2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import weaviate\n",
        "\n",
        "# Connect to your local Weaviate instance deployed with Docker\n",
        "client = weaviate.connect_to_local()\n",
        "\n",
        "print(client.is_ready())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a88jHUTCo9ep",
        "outputId": "dc4bf245-9d17-43a3-f3bb-38581ec6cddc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text2vec-transformers': {'model': {'_name_or_path': 'jhu-clsp/mmBERT-small',\n",
              "   'add_cross_attention': False,\n",
              "   'architectures': ['ModernBertForMaskedLM'],\n",
              "   'attention_bias': False,\n",
              "   'attention_dropout': 0,\n",
              "   'bad_words_ids': None,\n",
              "   'begin_suppress_tokens': None,\n",
              "   'bos_token_id': 2,\n",
              "   'chunk_size_feed_forward': 0,\n",
              "   'classifier_activation': 'gelu',\n",
              "   'classifier_bias': False,\n",
              "   'classifier_dropout': 0,\n",
              "   'classifier_pooling': 'mean',\n",
              "   'cls_token_id': 1,\n",
              "   'cross_attention_hidden_size': None,\n",
              "   'decoder_bias': True,\n",
              "   'decoder_start_token_id': None,\n",
              "   'deterministic_flash_attn': False,\n",
              "   'diversity_penalty': 0,\n",
              "   'do_sample': False,\n",
              "   'dtype': 'float32',\n",
              "   'early_stopping': False,\n",
              "   'embedding_dropout': 0,\n",
              "   'encoder_no_repeat_ngram_size': 0,\n",
              "   'eos_token_id': 1,\n",
              "   'exponential_decay_length_penalty': None,\n",
              "   'finetuning_task': None,\n",
              "   'forced_bos_token_id': None,\n",
              "   'forced_eos_token_id': None,\n",
              "   'global_attn_every_n_layers': 3,\n",
              "   'global_rope_theta': 160000,\n",
              "   'gradient_checkpointing': False,\n",
              "   'hidden_activation': 'gelu',\n",
              "   'hidden_size': 384,\n",
              "   'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'},\n",
              "   'initializer_cutoff_factor': 2,\n",
              "   'initializer_range': 0.02,\n",
              "   'intermediate_size': 1152,\n",
              "   'is_decoder': False,\n",
              "   'is_encoder_decoder': False,\n",
              "   'label2id': {'LABEL_0': 0, 'LABEL_1': 1},\n",
              "   'layer_norm_eps': 1e-05,\n",
              "   'length_penalty': 1,\n",
              "   'local_attention': 128,\n",
              "   'local_rope_theta': 160000,\n",
              "   'mask_token_id': 4,\n",
              "   'max_length': 20,\n",
              "   'max_position_embeddings': 8192,\n",
              "   'min_length': 0,\n",
              "   'mlp_bias': False,\n",
              "   'mlp_dropout': 0,\n",
              "   'model_type': 'modernbert',\n",
              "   'no_repeat_ngram_size': 0,\n",
              "   'norm_bias': False,\n",
              "   'norm_eps': 1e-05,\n",
              "   'num_attention_heads': 6,\n",
              "   'num_beam_groups': 1,\n",
              "   'num_beams': 1,\n",
              "   'num_hidden_layers': 22,\n",
              "   'num_return_sequences': 1,\n",
              "   'output_attentions': False,\n",
              "   'output_hidden_states': False,\n",
              "   'output_scores': False,\n",
              "   'pad_token_id': 0,\n",
              "   'position_embedding_type': 'sans_pos',\n",
              "   'prefix': None,\n",
              "   'problem_type': None,\n",
              "   'pruned_heads': {},\n",
              "   'remove_invalid_values': False,\n",
              "   'repad_logits_with_grad': False,\n",
              "   'repetition_penalty': 1,\n",
              "   'return_dict': True,\n",
              "   'return_dict_in_generate': False,\n",
              "   'sep_token_id': 1,\n",
              "   'sparse_pred_ignore_index': -100,\n",
              "   'sparse_prediction': False,\n",
              "   'suppress_tokens': None,\n",
              "   'task_specific_params': None,\n",
              "   'temperature': 1,\n",
              "   'tf_legacy_loss': False,\n",
              "   'tie_encoder_decoder': False,\n",
              "   'tie_word_embeddings': True,\n",
              "   'tokenizer_class': None,\n",
              "   'top_k': 50,\n",
              "   'top_p': 1,\n",
              "   'torchscript': False,\n",
              "   'transformers_version': '4.56.1',\n",
              "   'typical_p': 1,\n",
              "   'use_bfloat16': False,\n",
              "   'vocab_size': 256000},\n",
              "  'model_path': './models/model'}}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the cluster metadata to verify if the module is enabled\n",
        "client.get_meta()['modules']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze5J8E4MWC8g"
      },
      "source": [
        "## Create a collection\n",
        "> Collection stores your data and vector embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J32wdDCMWCgS",
        "outputId": "f6907bfc-01f2-479e-ed0d-f939650f83ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully created collection: MyCollection.\n"
          ]
        }
      ],
      "source": [
        "# Note: in practice, you shouldn't rerun this cell, as it deletes your data\n",
        "# in \"MyCollection\", and then you need to re-import it again.\n",
        "import weaviate.classes.config as wc\n",
        "\n",
        "# Delete the collection if it already exists\n",
        "if (client.collections.exists(\"MyCollection\")):\n",
        "    client.collections.delete(\"MyCollection\")\n",
        "\n",
        "# Create a collection\n",
        "collection = client.collections.create(\n",
        "    \"MyCollection\",\n",
        "    vector_config=wc.Configure.Vectors.text2vec_transformers(\n",
        "        # dimensions=384, # default: 384, possible options: 128, 256\n",
        "    ),\n",
        "    properties=[ # defining properties (data schema) is optional\n",
        "        wc.Property(name=\"Text\", data_type=wc.DataType.TEXT),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Successfully created collection: MyCollection.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjcuCEcCXlRK"
      },
      "source": [
        "## Import the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "paWgPOGsa_NV",
        "outputId": "aebde12d-90f1-4e30-b363-f656ae55712f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Insert complete.\n"
          ]
        }
      ],
      "source": [
        "# Set up our multi-lingual data\n",
        "multilingual_data = [\n",
        "    {\"text\": \"The quick brown fox jumps over the lazy dog.\"},\n",
        "    {\"text\": \"Der schnelle braune Fuchs springt über den faulen Hund.\"},\n",
        "\n",
        "    {\"text\": \"Artificial intelligence is transforming industries.\"},\n",
        "    {\"text\": \"Künstliche Intelligenz verändert Industrien.\"},\n",
        "\n",
        "    {\"text\": \"I love to read books in my free time.\"},\n",
        "    {\"text\": \"Ich lese gerne Bücher in meiner Freizeit.\"},\n",
        "\n",
        "    {\"text\": \"Beautiful weather today, perfect for a walk.\"},\n",
        "    {\"text\": \"Schönes Wetter heute, perfekt für einen Spaziergang.\"},\n",
        "\n",
        "    {\"text\": \"The capital of Germany is Berlin.\"},\n",
        "    {\"text\": \"Die Hauptstadt Deutschlands ist Berlin.\"}\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "# Insert data objects\n",
        "response = collection.data.insert_many(multilingual_data)\n",
        "\n",
        "# Note, the `data` array contains 10 objects, which is great to call insert_many with.\n",
        "# However, if you have a milion objects to insert, then you should spit them into smaller batches (i.e. 100-1000 per insert)\n",
        "\n",
        "if (response.has_errors):\n",
        "    print(response.errors)\n",
        "else:\n",
        "    print(\"Insert complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz-D8_4IpNue"
      },
      "source": [
        "Quick check to see if all objects are in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wkIUTMcEpRPL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(collection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NISdgAYebLyX"
      },
      "source": [
        "## Query Weaviate: Similarity Search (Text objects)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHSeuEgScFFS"
      },
      "source": [
        "Similarity search options for text objects in **Weaviate**:\n",
        "\n",
        "1. [near_text](https://weaviate.io/developers/weaviate/search/similarity#an-input-medium)\n",
        "\n",
        "2. [near_object](https://weaviate.io/developers/weaviate/search/similarity#an-object)\n",
        "\n",
        "3. [near_vector](https://weaviate.io/developers/weaviate/search/similarity#a-vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF-ln5Nsgp1C"
      },
      "source": [
        "### nearText Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yROGPv9huDe"
      },
      "source": [
        "Find a object in `MyCollection` closest to the query \"What's the capital of Germany?\". Limit it to only 4 responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bA9Hjy_Molzx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ID: 126432e1-23d2-4709-aac5-6ccd19552ab1\n",
            "Data: {\n",
            "  \"text\": \"The capital of Germany is Berlin.\"\n",
            "}\n",
            "Vector: [-0.002085368847474456, 0.01193431206047535, 0.0018889668863266706] ...\n",
            "Distance: 0.030832409858703613 \n",
            "\n",
            "ID: 127ed77a-9508-40c4-962c-04476d21143c\n",
            "Data: {\n",
            "  \"text\": \"Beautiful weather today, perfect for a walk.\"\n",
            "}\n",
            "Vector: [-0.0008074266952462494, -0.002204334130510688, 0.007476783357560635] ...\n",
            "Distance: 0.05185425281524658 \n",
            "\n",
            "ID: 74862999-97c9-434e-8df7-f2c241a41550\n",
            "Data: {\n",
            "  \"text\": \"I love to read books in my free time.\"\n",
            "}\n",
            "Vector: [0.00960230827331543, 0.005805480759590864, -0.0019345288164913654] ...\n",
            "Distance: 0.052883267402648926 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import weaviate.classes.query as wq\n",
        "import json\n",
        "\n",
        "# note, you can reuse the collection object from the previous cell.\n",
        "# Get a collection object for \"JeopardyQuestion\"\n",
        "collection = client.collections.get(\"MyCollection\")\n",
        "\n",
        "query = \"What's the capital of Germany?\"\n",
        "\n",
        "response = collection.query.near_text(\n",
        "    query=query,\n",
        "    include_vector=True,                             # return the vector embeddings\n",
        "    return_metadata=wq.MetadataQuery(distance=True), # return the distance\n",
        "    limit=3\n",
        ")\n",
        "\n",
        "for item in response.objects:\n",
        "    print(\"ID:\", item.uuid)\n",
        "    print(\"Data:\", json.dumps(item.properties, indent=2))\n",
        "    print(\"Vector:\", item.vector['default'][:3], '...')\n",
        "    print(\"Distance:\", item.metadata.distance, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UYMIsYwQpY8O"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "384\n"
          ]
        }
      ],
      "source": [
        "# Save last item's vector embedding and UUID for near_object and near_vector search\n",
        "vector = item.vector['default']\n",
        "uuid = item.uuid\n",
        "print(len(vector))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn-ELUA_iJVM"
      },
      "source": [
        "### nearObject Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI9GY5kOihM9"
      },
      "source": [
        "Search through the `JeopardyQuestion` class to find the top 4 objects closest to id (The id was taken from the query above)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NBk3tH7Holzy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "74862999-97c9-434e-8df7-f2c241a41550\n",
            "ID: 74862999-97c9-434e-8df7-f2c241a41550\n",
            "Data: {'text': 'I love to read books in my free time.'} \n",
            "\n",
            "ID: 127ed77a-9508-40c4-962c-04476d21143c\n",
            "Data: {'text': 'Beautiful weather today, perfect for a walk.'} \n",
            "\n",
            "ID: 1f6493c3-21fa-4893-8093-8101e8f7a616\n",
            "Data: {'text': 'The quick brown fox jumps over the lazy dog.'} \n",
            "\n",
            "ID: f0c7c042-e0ab-4ce3-b725-13a252ac2eda\n",
            "Data: {'text': 'Ich lese gerne Bücher in meiner Freizeit.'} \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(uuid)\n",
        "\n",
        "response = collection.query.near_object(\n",
        "    near_object=uuid, # replace with your id of interest\n",
        "    limit=4\n",
        ")\n",
        "\n",
        "for item in response.objects:\n",
        "    print(\"ID:\", item.uuid)\n",
        "    print(\"Data:\", item.properties, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzNmHZdijTKu"
      },
      "source": [
        "### nearVector Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVUXMzMcjXmC"
      },
      "source": [
        "Search through the `MyCollection` class to find the top 2 objects closest to the query vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZZARB1qUjUoq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.00960230827331543, 0.005805480759590864, -0.0019345288164913654, -0.007073240354657173, -0.018555009737610817]\n",
            "ID: 74862999-97c9-434e-8df7-f2c241a41550\n",
            "Data: {'text': 'I love to read books in my free time.'} \n",
            "\n",
            "ID: 127ed77a-9508-40c4-962c-04476d21143c\n",
            "Data: {'text': 'Beautiful weather today, perfect for a walk.'} \n",
            "\n",
            "ID: 1f6493c3-21fa-4893-8093-8101e8f7a616\n",
            "Data: {'text': 'The quick brown fox jumps over the lazy dog.'} \n",
            "\n",
            "ID: f0c7c042-e0ab-4ce3-b725-13a252ac2eda\n",
            "Data: {'text': 'Ich lese gerne Bücher in meiner Freizeit.'} \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(vector[:5])\n",
        "\n",
        "response = collection.query.near_vector(\n",
        "    near_vector=vector, # your vector object goes here\n",
        "    limit=4\n",
        ")\n",
        "\n",
        "for item in response.objects:\n",
        "    print(\"ID:\", item.uuid)\n",
        "    print(\"Data:\", item.properties, \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "rJD9aP9eVcsT",
        "rgL-mnMqVf0B",
        "Ze5J8E4MWC8g",
        "bjcuCEcCXlRK",
        "XF-ln5Nsgp1C",
        "Bn-ELUA_iJVM"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
