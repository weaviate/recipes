{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MklMC3etolzu"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/weaviate/recipes/blob/main/weaviate-features/model-providers/huggingface/similarity_search_all_MiniLM_L6_v2.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Similarity search with all_MiniLM_L6_v2 via Hugging Face and Weaviate"
      ],
      "metadata": {
        "id": "wJ7MqblkouF9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJD9aP9eVcsT"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3IgZm3pYwWa8"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -q -U weaviate-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgL-mnMqVf0B"
      },
      "source": [
        "## Connect to Weaviate\n",
        "\n",
        "Now, you will need to connect to a running Weaviate vector database cluster.\n",
        "\n",
        "You can choose one of the following options:\n",
        "\n",
        "1. **Option 1:** You can create a 14-day free sandbox on the managed service [Weaviate Cloud (WCD)](https://console.weaviate.cloud/)\n",
        "2. **Option 2:** [Embedded Weaviate](https://docs.weaviate.io/deploy/installation-guides/embedded)\n",
        "3. **Option 3:** [Local deployment](https://docs.weaviate.io/deploy/installation-guides/docker-installation)\n",
        "4. [Other options](https://docs.weaviate.io/deploy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "huggingface_key = os.environ[\"HF_TOKEN\"] # Replace with your HuggingFace key\n",
        "WCD_URL = os.environ[\"WEAVIATE_URL\"] # Replace with your Weaviate cluster URL\n",
        "WCD_AUTH_KEY = os.environ[\"WEAVIATE_API_KEY\"] # Replace with your cluster auth key\n",
        "\n",
        "# Uncomment if you are working in a Google Colab environment\n",
        "#from google.colab import userdata\n",
        "\n",
        "#huggingface_key = userdata.get('HF_TOKEN')\n",
        "#WCD_URL = userdata.get(\"WEAVIATE_URL\")\n",
        "#WCD_AUTH_KEY = userdata.get(\"WEAVIATE_API_KEY\")\n",
        "\n",
        "headers={\n",
        "    \"X-huggingface-Api-Key\": huggingface_key\n",
        "  }\n"
      ],
      "metadata": {
        "id": "_GLb9rQgp1EP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import weaviate\n",
        "\n",
        "# Option 1: Weaviate Cloud\n",
        "# Weaviate Cloud Deployment\n",
        "client = weaviate.connect_to_weaviate_cloud(\n",
        "    cluster_url=WCD_URL,\n",
        "    auth_credentials=weaviate.auth.AuthApiKey(WCD_AUTH_KEY),\n",
        "    headers=headers,\n",
        ")\n",
        "\n",
        "# Option 2: Embedded Weaviate instance\n",
        "# use if you want to explore Weaviate without any additional setup\n",
        "#client = weaviate.connect_to_embedded(\n",
        "#  headers=headers\n",
        "#)\n",
        "\n",
        "# Option 3: Locally hosted instance of Weaviate via Docker or Kubernetes\n",
        "#!docker run --detach -p 8080:8080 -p 50051:50051 cr.weaviate.io/semitechnologies/weaviate:1.29.0\n",
        "#client = weaviate.connect_to_local(\n",
        "#  headers=headers\n",
        "#)\n",
        "\n",
        "print(client.is_ready())"
      ],
      "metadata": {
        "id": "nnByDFpEsDL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the cluster metadata to verify if the module is enabled\n",
        "client.get_meta()['modules']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a88jHUTCo9ep",
        "outputId": "08a63490-ba36-4f74-b643-1b5da1c2d9b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'generative-openai': {'documentationHref': 'https://platform.openai.com/docs/api-reference/completions',\n",
              "  'name': 'Generative Search - OpenAI'},\n",
              " 'qna-openai': {'documentationHref': 'https://platform.openai.com/docs/api-reference/completions',\n",
              "  'name': 'OpenAI Question & Answering Module'},\n",
              " 'ref2vec-centroid': {},\n",
              " 'reranker-cohere': {'documentationHref': 'https://txt.cohere.com/rerank/',\n",
              "  'name': 'Reranker - Cohere'},\n",
              " 'text2vec-cohere': {'documentationHref': 'https://docs.cohere.ai/embedding-wiki/',\n",
              "  'name': 'Cohere Module'},\n",
              " 'text2vec-huggingface': {'documentationHref': 'https://huggingface.co/docs/api-inference/detailed_parameters#feature-extraction-task',\n",
              "  'name': 'Hugging Face Module'},\n",
              " 'text2vec-openai': {'documentationHref': 'https://platform.openai.com/docs/guides/embeddings/what-are-embeddings',\n",
              "  'name': 'OpenAI Module'}}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze5J8E4MWC8g"
      },
      "source": [
        "## Create a collection\n",
        "> Collection stores your data and vector embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "J32wdDCMWCgS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb0818fd-85e6-4f99-ad15-c3c9ff1fa227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created collection: MyCollection.\n"
          ]
        }
      ],
      "source": [
        "# Note: in practice, you shouldn't rerun this cell, as it deletes your data\n",
        "# in \"MyCollection\", and then you need to re-import it again.\n",
        "import weaviate.classes.config as wc\n",
        "\n",
        "# Delete the collection if it already exists\n",
        "if (client.collections.exists(\"MyCollection\")):\n",
        "    client.collections.delete(\"MyCollection\")\n",
        "\n",
        "# Create a collection\n",
        "collection = client.collections.create(\n",
        "    \"MyCollection\",\n",
        "    vector_config=wc.Configure.Vectors.text2vec_huggingface( # specify the vectorizer and model type you're using\n",
        "        model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "        wait_for_model=True,\n",
        "        use_gpu=True,\n",
        "        use_cache=True,\n",
        "       # dimensions=512,# default: 768, possible options: 128, 256, 512\n",
        "    ),\n",
        "    properties=[ # defining properties (data schema) is optional\n",
        "        wc.Property(name=\"Text\", data_type=wc.DataType.TEXT),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Successfully created collection: MyCollection.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjcuCEcCXlRK"
      },
      "source": [
        "## Import the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "paWgPOGsa_NV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f917f7f3-e955-48e5-f087-c0f73fd0a82a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert complete.\n"
          ]
        }
      ],
      "source": [
        "# Set up our multi-lingual data\n",
        "multilingual_data = [\n",
        "    {\"text\": \"The quick brown fox jumps over the lazy dog.\"},\n",
        "    {\"text\": \"Der schnelle braune Fuchs springt über den faulen Hund.\"},\n",
        "\n",
        "    {\"text\": \"Artificial intelligence is transforming industries.\"},\n",
        "    {\"text\": \"Künstliche Intelligenz verändert Industrien.\"},\n",
        "\n",
        "    {\"text\": \"I love to read books in my free time.\"},\n",
        "    {\"text\": \"Ich lese gerne Bücher in meiner Freizeit.\"},\n",
        "\n",
        "    {\"text\": \"Beautiful weather today, perfect for a walk.\"},\n",
        "    {\"text\": \"Schönes Wetter heute, perfekt für einen Spaziergang.\"},\n",
        "\n",
        "    {\"text\": \"The capital of Germany is Berlin.\"},\n",
        "    {\"text\": \"Die Hauptstadt Deutschlands ist Berlin.\"}\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "# Insert data objects\n",
        "response = collection.data.insert_many(multilingual_data)\n",
        "\n",
        "# Note, the `data` array contains 10 objects, which is great to call insert_many with.\n",
        "# However, if you have a milion objects to insert, then you should spit them into smaller batches (i.e. 100-1000 per insert)\n",
        "\n",
        "if (response.has_errors):\n",
        "    print(response.errors)\n",
        "else:\n",
        "    print(\"Insert complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quick check to see if all objects are in."
      ],
      "metadata": {
        "id": "Sz-D8_4IpNue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(collection)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkIUTMcEpRPL",
        "outputId": "29ad3ecf-cbf7-4ca6-9220-6545804f6d9a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NISdgAYebLyX"
      },
      "source": [
        "## Query Weaviate: Similarity Search (Text objects)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHSeuEgScFFS"
      },
      "source": [
        "Similarity search options for text objects in **Weaviate**:\n",
        "\n",
        "1. [near_text](https://weaviate.io/developers/weaviate/search/similarity#an-input-medium)\n",
        "\n",
        "2. [near_object](https://weaviate.io/developers/weaviate/search/similarity#an-object)\n",
        "\n",
        "3. [near_vector](https://weaviate.io/developers/weaviate/search/similarity#a-vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF-ln5Nsgp1C"
      },
      "source": [
        "### nearText Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yROGPv9huDe"
      },
      "source": [
        "Find a object in `MyCollection` closest to the query \"What's the capital of Germany?\". Limit it to only 4 responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA9Hjy_Molzx",
        "outputId": "ab0a8b39-ac13-4310-a59d-cbcd82670e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID: adcdd665-87ad-45f1-85c2-dd7d6beac702\n",
            "Data: {\n",
            "  \"text\": \"The capital of Germany is Berlin.\"\n",
            "}\n",
            "Vector: [0.04136650264263153, 0.08663720637559891, -0.007826615124940872] ...\n",
            "Distance: 0.39156365394592285 \n",
            "\n",
            "ID: 58a67982-224c-46eb-8f34-68c73d33d65d\n",
            "Data: {\n",
            "  \"text\": \"Die Hauptstadt Deutschlands ist Berlin.\"\n",
            "}\n",
            "Vector: [-0.018270188942551613, 0.10900147259235382, -0.06833386421203613] ...\n",
            "Distance: 0.5286470651626587 \n",
            "\n",
            "ID: 74a85b70-f6ca-457f-b40d-29206f852663\n",
            "Data: {\n",
            "  \"text\": \"Der schnelle braune Fuchs springt \\u00fcber den faulen Hund.\"\n",
            "}\n",
            "Vector: [-0.0851321667432785, 0.06763748824596405, -0.02962086722254753] ...\n",
            "Distance: 0.7293647527694702 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import weaviate.classes.query as wq\n",
        "import json\n",
        "\n",
        "# note, you can reuse the collection object from the previous cell.\n",
        "# Get a collection object for \"JeopardyQuestion\"\n",
        "collection = client.collections.get(\"MyCollection\")\n",
        "\n",
        "query = \"What's the capital of Germany?\"\n",
        "\n",
        "response = collection.query.near_text(\n",
        "    query=query,\n",
        "    include_vector=True,                             # return the vector embeddings\n",
        "    return_metadata=wq.MetadataQuery(distance=True), # return the distance\n",
        "    limit=3\n",
        ")\n",
        "\n",
        "for item in response.objects:\n",
        "    print(\"ID:\", item.uuid)\n",
        "    print(\"Data:\", json.dumps(item.properties, indent=2))\n",
        "    print(\"Vector:\", item.vector['default'][:3], '...')\n",
        "    print(\"Distance:\", item.metadata.distance, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save last item's vector embedding and UUID for near_object and near_vector search\n",
        "vector = item.vector['default']\n",
        "uuid = item.uuid"
      ],
      "metadata": {
        "id": "UYMIsYwQpY8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn-ELUA_iJVM"
      },
      "source": [
        "### nearObject Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI9GY5kOihM9"
      },
      "source": [
        "Search through the `JeopardyQuestion` class to find the top 4 objects closest to id (The id was taken from the query above)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBk3tH7Holzy"
      },
      "outputs": [],
      "source": [
        "print(uuid)\n",
        "\n",
        "response = collection.query.near_object(\n",
        "    near_object=uuid, # replace with your id of interest\n",
        "    limit=4\n",
        ")\n",
        "\n",
        "for item in response.objects:\n",
        "    print(\"ID:\", item.uuid)\n",
        "    print(\"Data:\", item.properties, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzNmHZdijTKu"
      },
      "source": [
        "### nearVector Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVUXMzMcjXmC"
      },
      "source": [
        "Search through the `MyCollection` class to find the top 2 objects closest to the query vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZARB1qUjUoq"
      },
      "outputs": [],
      "source": [
        "print(vector[:5])\n",
        "\n",
        "response = collection.query.near_vector(\n",
        "    near_vector=vector, # your vector object goes here\n",
        "    limit=4\n",
        ")\n",
        "\n",
        "for item in response.objects:\n",
        "    print(\"ID:\", item.uuid)\n",
        "    print(\"Data:\", item.properties, \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "rJD9aP9eVcsT",
        "rgL-mnMqVf0B",
        "Ze5J8E4MWC8g",
        "bjcuCEcCXlRK",
        "XF-ln5Nsgp1C",
        "Bn-ELUA_iJVM"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}