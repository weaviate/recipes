{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/weaviate/recipes/blob/main/weaviate-features/model-providers/huggingface/hybrid_search_all_MiniLM_L6_v2.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJD9aP9eVcsT"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IgZm3pYwWa8"
      },
      "outputs": [],
      "source": [
        "!pip install weaviate-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --pre -I \"weaviate-client==4.3.b2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgL-mnMqVf0B"
      },
      "source": [
        "## Connect to Weaviate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjjGCYRKd9tz"
      },
      "outputs": [],
      "source": [
        "import weaviate, os\n",
        "\n",
        "huggingface_key = os.environ[\"HF_API_KEY\"] # Replace with your HuggingFace key\n",
        "\n",
        "# Connect to your local Weaviate instance deployed with Docker\n",
        "client = weaviate.connect_to_local(\n",
        "  headers={\n",
        "    \"X-huggingface-Api-Key\": huggingface_key\n",
        "  }\n",
        ")\n",
        "\n",
        "# Option 2\n",
        "# Connect to your Weaviate Client Service cluster\n",
        "# client = weaviate.connect_to_wcs(\n",
        "#     cluster_id=\"WCS-CLUSTER-ID\", # Replace with your WCS cluster ID\n",
        "#     auth_credentials=weaviate.AuthApiKey(\n",
        "#       api_key=\"WCS-API-KEY\" # Replace with your WCS API KEY\n",
        "#     ),\n",
        "#     headers={\n",
        "#       \"X-huggingface-Api-Key\": huggingface_key\n",
        "#     }\n",
        "# )\n",
        "\n",
        "client.is_ready()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz7haOQRf9f2"
      },
      "source": [
        "### For more information on how to deploy your model as an endpoint using the Hugging Face inference endpoints, check out the [documentation](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-huggingface#additional-information)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze5J8E4MWC8g"
      },
      "source": [
        "## Create a collection\n",
        "> Collection stores your data and vector embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J32wdDCMWCgS"
      },
      "outputs": [],
      "source": [
        "# Note: in practice, you shouldn't rerun this cell, as it deletes your data\n",
        "# in \"JeopardyQuestion\", and then you need to re-import it again.\n",
        "import weaviate.classes.config as wc\n",
        "\n",
        "# Delete the collection if it already exists\n",
        "if (client.collections.exists(\"JeopardyQuestion\")):\n",
        "    client.collections.delete(\"JeopardyQuestion\")\n",
        "\n",
        "client.collections.create(\n",
        "    name=\"JeopardyQuestion\",\n",
        "\n",
        "    vectorizer_config=wc.Configure.Vectorizer.text2vec_huggingface( # specify the vectorizer and model type you're using\n",
        "        model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "        wait_for_model=True,\n",
        "        use_gpu=True,\n",
        "        use_cache=True,\n",
        "    ),\n",
        "\n",
        "    properties=[ # defining properties (data schema) is optional\n",
        "        wc.Property(name=\"Question\", data_type=wc.DataType.TEXT), \n",
        "        wc.Property(name=\"Answer\", data_type=wc.DataType.TEXT),\n",
        "        wc.Property(name=\"Category\", data_type=wc.DataType.TEXT, skip_vectorization=True), \n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Successfully created collection: JeopardyQuestion.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjcuCEcCXlRK"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paWgPOGsa_NV"
      },
      "outputs": [],
      "source": [
        "import requests, json\n",
        "url = 'https://raw.githubusercontent.com/weaviate/weaviate-examples/main/jeopardy_small_dataset/jeopardy_tiny.json'\n",
        "resp = requests.get(url)\n",
        "data = json.loads(resp.text)\n",
        "\n",
        "# Get a collection object for \"JeopardyQuestion\"\n",
        "jeopardy = client.collections.get(\"JeopardyQuestion\")\n",
        "\n",
        "# Insert data objects\n",
        "response = jeopardy.data.insert_many(data)\n",
        "\n",
        "# Note, the `data` array contains 10 objects, which is great to call insert_many with.\n",
        "# However, if you have a milion objects to insert, then you should spit them into smaller batches (i.e. 100-1000 per insert)\n",
        "\n",
        "if (response.has_errors):\n",
        "    print(response.errors)\n",
        "else:\n",
        "    print(\"Insert complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NISdgAYebLyX"
      },
      "source": [
        "## Hybrid Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svmbj8JC1y0g"
      },
      "source": [
        "The `alpha` parameter determines the weight given to the sparse and dense search methods. `alpha = 0` is pure sparse (bm25) search, whereas `alpha = 1` is pure dense (vector) search. \n",
        "\n",
        "Alpha is an optional parameter. The default is set to `0.75`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wsYL2vD5G_9"
      },
      "source": [
        "### Hybrid Search only\n",
        "\n",
        "The below query is finding Jeopardy questions about animals and is limiting the output to only two results. Notice `alpha` is set to `0.80`, which means it is weighing the vector search results more than bm25. If you were to set `alpha = 0.25`, you would get different results. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QI5P082I1yA-"
      },
      "outputs": [],
      "source": [
        "# note, you can reuse the collection object from the previous cell.\n",
        "# Get a collection object for \"JeopardyQuestion\"\n",
        "jeopardy = client.collections.get(\"JeopardyQuestion\")\n",
        "\n",
        "response = jeopardy.query.hybrid(\n",
        "    query=\"northern beast\",\n",
        "    alpha=0.8,\n",
        "    limit=3\n",
        ")\n",
        "\n",
        "for item in response.objects:\n",
        "    print(\"ID:\", item.uuid)\n",
        "    print(\"Data:\", json.dumps(item.properties, indent=2), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcmaLcry7De_"
      },
      "source": [
        "### Hybrid Search on a specific property\n",
        "\n",
        "The `properties` parameter allows you to list the properties that you want bm25 to search on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp3hhbNu6Lsv"
      },
      "outputs": [],
      "source": [
        "response = jeopardy.query.hybrid(\n",
        "    query=\"northern beast\",\n",
        "    query_properties=[\"question\"],\n",
        "    alpha=0.8,\n",
        "    limit=3\n",
        ")\n",
        "\n",
        "for item in response.objects:\n",
        "    print(\"ID:\", item.uuid)\n",
        "    print(\"Data:\", json.dumps(item.properties, indent=2), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkX9rn-25rHC"
      },
      "source": [
        "### Hybrid Search with a `where` filter\n",
        "\n",
        "Find Jeopardy questions about elephants, where the category is set to Animals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76CgsOd451PB"
      },
      "outputs": [],
      "source": [
        "import weaviate.classes.query as wq # wq is an alias to save us from typing weaviate.classes everywhere ;)\n",
        "\n",
        "response = jeopardy.query.hybrid(\n",
        "    query=\"northern beast\",\n",
        "    alpha=0.8,\n",
        "    filters=wq.Filter.by_property(\"category\").equal(\"Animals\"),\n",
        "    limit=3\n",
        ")\n",
        "\n",
        "for item in response.objects:\n",
        "    print(\"ID:\", item.uuid)\n",
        "    print(\"Data:\", json.dumps(item.properties, indent=2), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZeyVS6V73Rl"
      },
      "source": [
        "### Hybrid Search with a custom vector\n",
        "\n",
        "You can pass in your own vector as input into the hybrid query, by using the `vector` parameter. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_BPO75F76wa"
      },
      "outputs": [],
      "source": [
        "vector = [-0.0125526935, -0.021168863, ...]\n",
        "\n",
        "response = jeopardy.query.hybrid(\n",
        "    query=\"animal\",\n",
        "    vector=vector,\n",
        "    limit=2\n",
        ")\n",
        "\n",
        "for item in response.objects:\n",
        "    print(\"ID:\", item.uuid)\n",
        "    print(\"Data:\", json.dumps(item.properties, indent=2), \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "rJD9aP9eVcsT",
        "rgL-mnMqVf0B",
        "Ze5J8E4MWC8g",
        "_wsYL2vD5G_9",
        "JcmaLcry7De_",
        "kkX9rn-25rHC",
        "MZeyVS6V73Rl"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
