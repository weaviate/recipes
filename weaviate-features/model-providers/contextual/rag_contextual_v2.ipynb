{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e75878",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/weaviate/recipes/blob/main/integrations/data-platforms/aryn/weaviate_blog_post.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6068072",
   "metadata": {},
   "source": [
    "# Generative Search with Contextual AI\n",
    "\n",
    "This notebook demonstrates how to use ContextualAI's generative model (v2) with Weaviate for RAG, combining hybrid search (sparse + dense) with generative search to answer questions based on retrieved Jeopardy data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca28dae5",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "1. Weaviate Database == `>1.34.0`\n",
    "2. Weaviate Python Client == `4.18.2`\n",
    "3. Contextual API key - you can grab one from [the console](https://app.contextual.ai/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1f825ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install weaviate-client==4.18.2 --q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5368b2",
   "metadata": {},
   "source": [
    "## Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f725e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate.classes.config import Configure, Property, DataType\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests, json\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a396e",
   "metadata": {},
   "source": [
    "## Connect to Weaviate Cloud\n",
    "\n",
    "You can create a free 14-day sandbox on [Weaviate Cloud](https://console.weaviate.cloud)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8370ef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WEAVIATE_URL\"] = \"\"\n",
    "os.environ[\"WEAVIATE_API_KEY\"] = \"\"\n",
    "os.environ[\"CONTEXTUALAI_API_KEY\"] = \"\"\n",
    "\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=os.getenv(\"WEAVIATE_URL\"),\n",
    "    auth_credentials=weaviate.auth.AuthApiKey(os.getenv(\"WEAVIATE_API_KEY\")),\n",
    "    headers={\n",
    "    \"X-ContextualAI-Api-Key\": os.getenv(\"CONTEXTUALAI_API_KEY\"),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc54cb97",
   "metadata": {},
   "source": [
    "## Define Weaviate Collection\n",
    "\n",
    "You can create a new collection with the below cell block, or you can connect to your existing collection and skip the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bc835d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created collection: JeopardyQuestions.\n"
     ]
    }
   ],
   "source": [
    "# Note: in practice, you shouldn\"t rerun this cell, as it deletes your data\n",
    "# in \"JeopardyQuestion\", and then you need to re-import it again.\n",
    "\n",
    "collection_name = \"JeopardyQuestions\"\n",
    "\n",
    "# Delete the collection if it already exists\n",
    "if (client.collections.exists(collection_name)):\n",
    "    client.collections.delete(collection_name)\n",
    "\n",
    "client.collections.create(\n",
    "    \"JeopardyQuestions\",\n",
    "\n",
    "    vector_config=\n",
    "    Configure.Vectors.text2vec_weaviate(\n",
    "        model=\"Snowflake/snowflake-arctic-embed-l-v2.0\"\n",
    "    ),\n",
    "    generative_config=Configure.Generative.contextualai(\n",
    "        model=\"v2\"\n",
    "    ),\n",
    "\n",
    "    properties=[ # defining properties (data schema) is optional\n",
    "        Property(name=\"Question\", data_type=DataType.TEXT), \n",
    "        Property(name=\"Answer\", data_type=DataType.TEXT),\n",
    "        Property(name=\"Category\", data_type=DataType.TEXT, skip_vectorization=True),\n",
    "        Property(name=\"Value\", data_type=DataType.TEXT, skip_vectorization=True) \n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Successfully created collection: JeopardyQuestions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edeeb89",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "We will use the small jeopardy dataset as an example. It has 1,000 objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4715e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/weaviate/weaviate-examples/main/jeopardy_small_dataset/jeopardy_small.csv'\n",
    "resp = requests.get(url)\n",
    "\n",
    "df = pd.read_csv(StringIO(resp.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a2a210e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert complete.\n"
     ]
    }
   ],
   "source": [
    "# Get a collection object for \"JeopardyQuestion\"\n",
    "collection = client.collections.use(\"JeopardyQuestions\")\n",
    "\n",
    "# Insert data objects with batch import\n",
    "with collection.batch.dynamic() as batch:\n",
    "    for _, row in df.iterrows():\n",
    "        properties = {\n",
    "            \"question\": row['Question'],\n",
    "            \"answer\": row['Answer'],\n",
    "            \"category\": row[\"Category\"],\n",
    "            \"value\": row[\"Value\"]\n",
    "        }\n",
    "        batch.add_object(properties)\n",
    "\n",
    "failed_objects = collection.batch.failed_objects\n",
    "if failed_objects:\n",
    "    print(f\"Number of failed imports: {len(failed_objects)}\")\n",
    "else:\n",
    "    print(\"Insert complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bab966f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# count the number of objects\n",
    "\n",
    "collection = client.collections.use(\"JeopardyQuestions\")\n",
    "response = collection.aggregate.over_all(total_count=True)\n",
    "\n",
    "print(response.total_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e487b3",
   "metadata": {},
   "source": [
    "## Query Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767b2fa0",
   "metadata": {},
   "source": [
    "### Hybrid Search\n",
    "\n",
    "The `alpha` parameter determines the weight given to the sparse and dense search methods. `alpha = 0` is pure sparse (bm25) search, whereas `alpha = 1` is pure dense (vector) search. \n",
    "\n",
    "Alpha is an optional parameter. The default is set to `0.75`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39a86df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: cdb2d3ce-14ba-4fef-b695-b16578c4e09f\n",
      "Data: {\n",
      "  \"value\": \"NaN\",\n",
      "  \"question\": \"A part of this marine mammal was prized by medieval folk, who thought it belonged to a unicorn\",\n",
      "  \"answer\": \"the narwhal\",\n",
      "  \"category\": \"THE ANIMAL KINGDOM\"\n",
      "} \n",
      "\n",
      "ID: 3e51a440-fabf-49cb-bb55-08a288ab41fb\n",
      "Data: {\n",
      "  \"value\": \"$400\",\n",
      "  \"question\": \"You could say this Arctic mammal, Odobenus rosmarus, has a Wilford Brimley mustache\",\n",
      "  \"answer\": \"the walrus\",\n",
      "  \"category\": \"MAMMALS\"\n",
      "} \n",
      "\n",
      "ID: 1a769c18-0226-432b-9c3a-d5ce66149c6c\n",
      "Data: {\n",
      "  \"value\": \"$800\",\n",
      "  \"question\": \"Kodiak Island is the habitat of this type of bear, Ursus arctos middendorffi\",\n",
      "  \"answer\": \"Kodiak bear\",\n",
      "  \"category\": \"STUPID ANSWERS\"\n",
      "} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "jeopardy = client.collections.get(\"JeopardyQuestions\")\n",
    "\n",
    "response = jeopardy.query.hybrid(\n",
    "    query=\"unicorn-like artic animal\",\n",
    "    alpha=0.75,\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "for item in response.objects:\n",
    "    print(\"ID:\", item.uuid)\n",
    "    print(\"Data:\", json.dumps(item.properties, indent=2), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b233f3e7",
   "metadata": {},
   "source": [
    "### Generative Search\n",
    "We're using ContextualAI's generative model in Weaviate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24f0d11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated output: Let me explain what the provided information tells us about these animals and unicorn associations.\n",
      "\n",
      "According to the information, the narwhal is specifically identified as a marine mammal where 'a part of this marine mammal was prized by medieval folk, who thought it belonged to a unicorn.'[0,2]\n",
      "\n",
      "While we can't make direct claims about why people made this association, we can note that the documentation only explicitly links this unicorn-like perception to the narwhal, not the walrus.\n",
      "\n",
      "The walrus, identified by its scientific name Odobenus rosmarus, is described as 'this Arctic mammal' but is notably characterized by its distinctive facial feature, likened to a 'Wilford Brimley mustache'.[0,6]\n",
      "\n",
      "It's worth noting that while both are Arctic/Antarctic creatures, the documentation only makes the unicorn connection explicit for the narwhal, not providing similar historical beliefs about the walrus.\n"
     ]
    }
   ],
   "source": [
    "collection = client.collections.use(\"JeopardyQuestions\")\n",
    "\n",
    "response = collection.generate.hybrid(\n",
    "    query=\"unicorn-like artic animal\",\n",
    "    alpha=0.7, \n",
    "    grouped_task=\"Explain why people thought these animals were unicorn-like\",\n",
    "    limit=2\n",
    ")\n",
    "\n",
    "print(f\"Generated output: {response.generative.text}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
