{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/weaviate/recipes/blob/main/weaviate-features/services-research/late_chunking_berlin.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Late Chunking with Weaviate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook author: Danny Williams @ weaviate (Developer Growth)\n",
    "\n",
    "This notebook implements [late chunking](https://jina.ai/news/late-chunking-in-long-context-embedding-models/) with Weaviate. Late chunking is a change in the classical chunking framework where chunking happens _after_ token embeddings are output from the full document. This preserves contextual information from one chunk to another.\n",
    "\n",
    "\n",
    "\n",
    "### Setup\n",
    "\n",
    "First we install all required packages. We are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install weaviate-client torch numpy spacy transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the packages and connect to the Weaviate client. Important, you need some API keys within a `.env` file:\n",
    "- your Weaviate REST endpoint saved as `WEAVIATE_URL`\n",
    "- your Weaviate API key saved as `WEAVIATE_KEY`\n",
    "- if you want to run the final comparison in this notebook, an OpenAI API key saved as `OPENAI_API_KEY`, otherwise delete the `headers` argument in the `weaviate.connect_to_weaviate_cloud` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danny/Documents/Work/Other/recipes/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:112: UserWarning: Protobuf gencode version 5.27.2 is older than the runtime version 5.28.0 at grpc_health/v1/health.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "/Users/danny/Documents/Work/Other/recipes/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "# imports\n",
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "import weaviate.classes.config as wvcc\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "from spacy.language import Language\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# connect to weaviate\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=os.getenv(\"WEAVIATE_URL\"),                               \n",
    "    auth_credentials=wvc.init.Auth.api_key(os.getenv(\"WEAVIATE_KEY\")),\n",
    "    headers={\"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_API_KEY\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally just for future-proofing, the versions of these packages are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weaviate version 4.7.1\n",
      "Pytorch version 2.4.1\n",
      "Numpy version 1.26.4\n",
      "Spacy version 3.7.6\n",
      "Transformers version 4.44.2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Weaviate version {weaviate.__version__}\")\n",
    "print(f\"Pytorch version {torch.__version__}\")\n",
    "print(f\"Numpy version {np.__version__}\")\n",
    "print(f\"Spacy version {spacy.__version__}\")\n",
    "print(f\"Transformers version {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some general functions for chunking text into sentences, as well as the bulk of the operations behind late chunking.\n",
    "\n",
    "Late chunking is simply the same chunks we would have on the naively chunked text, but the chunk embedding is taken from the pooling of the token embeddings, rather than an independently embedded chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_chunker(document, batch_size=None):\n",
    "    \"\"\"\n",
    "    Given a document (string), return the sentences as chunks and span annotations (start and end indices of chunks).\n",
    "    Using spacy to do this sentence chunking.\n",
    "    \"\"\"\n",
    "\n",
    "    if batch_size is None:\n",
    "        batch_size = 10000 # no of characters\n",
    "\n",
    "    # Batch with spacy\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    nlp.add_pipe(\"sentencizer\", config={\"punct_chars\": None})\n",
    "    doc = nlp(document)\n",
    "\n",
    "    docs = []\n",
    "    for i in range(0, len(document), batch_size):\n",
    "        batch = document[i : i + batch_size]\n",
    "        docs.append(nlp(batch))\n",
    "\n",
    "    doc = Doc.from_docs(docs)\n",
    "\n",
    "    span_annotations = []\n",
    "    chunks = []\n",
    "    for i, sent in enumerate(doc.sents):\n",
    "        span_annotations.append((sent.start, sent.end))\n",
    "        chunks.append(sent.text)\n",
    "\n",
    "    return chunks, span_annotations\n",
    "\n",
    "\n",
    "def document_to_token_embeddings(model, tokenizer, document, batch_size=4096):\n",
    "    \"\"\"\n",
    "    Given a model and tokenizer from HuggingFace, return token embeddings of the input text document.\n",
    "    \"\"\"\n",
    "\n",
    "    if batch_size > 8192: # no of tokens\n",
    "        raise ValueError(\"Batch size is too large. Please use a batch size of 8192 or less.\")\n",
    "\n",
    "    tokenized_document = tokenizer(document, return_tensors=\"pt\")\n",
    "    tokens = tokenized_document.tokens()\n",
    "    \n",
    "    # Batch in sizes of batch_size\n",
    "    outputs = []\n",
    "    for i in range(0, len(tokens), batch_size):\n",
    "        \n",
    "        start = i\n",
    "        end   = min(i + batch_size, len(tokens))\n",
    "\n",
    "        # subset huggingface tokenizer outputs to i : i + batch_size\n",
    "        batch_inputs = {k: v[:, start:end] for k, v in tokenized_document.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_output = model(**batch_inputs)\n",
    "\n",
    "        outputs.append(model_output.last_hidden_state)\n",
    "\n",
    "    model_output = torch.cat(outputs, dim=1)\n",
    "    return model_output\n",
    "\n",
    "def late_chunking(token_embeddings, span_annotation, max_length=None):\n",
    "    \"\"\"\n",
    "    Given the token-level embeddings of document and their corresponding span annotations (start and end indices of chunks in terms of tokens),\n",
    "    late chunking pools the token embeddings for each chunk.\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    for embeddings, annotations in zip(token_embeddings, span_annotation):\n",
    "        if (\n",
    "            max_length is not None\n",
    "        ):  # remove annotations which go beyond the max-length of the model\n",
    "            annotations = [\n",
    "                (start, min(end, max_length - 1))\n",
    "                for (start, end) in annotations\n",
    "                if start < (max_length - 1)\n",
    "            ]\n",
    "        pooled_embeddings = []\n",
    "        for start, end in annotations:\n",
    "            \n",
    "            if (end - start) >= 1:\n",
    "                # print(f\"start: {start}, end: {end}\")\n",
    "                # print(f\"{[e[:5] for e in embeddings[start:end]]}\")\n",
    "                pooled_embeddings.append(\n",
    "                    embeddings[start:end].sum(dim=0) / (end - start)\n",
    "                )\n",
    "                    \n",
    "        pooled_embeddings = [\n",
    "            embedding.detach().cpu().numpy() for embedding in pooled_embeddings\n",
    "        ]\n",
    "        outputs.append(pooled_embeddings)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import into Weaviate\n",
    "\n",
    "We aim to perform late chunking, obtain the contextually-aware embeddings, and then import these into a Weaviate collection.\n",
    "\n",
    "First, create a Weaviate collection called `test_late_chunking`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if client.collections.exists(\"test_late_chunking\"):\n",
    "    client.collections.delete(\"test_late_chunking\")\n",
    "\n",
    "# important to specify the config as none here, because we will be supplying our own vector embeddings in the form of the late chunking embeddings\n",
    "late_chunking_collection = client.collections.create(\n",
    "    name=\"test_late_chunking\",\n",
    "    vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use a test document - the wikipedia page for Berlin (saved in a separate text file). We will later query this text using late chunking/naive chunking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 50 characters of the document:\n",
      "Berlin[a] is the capital and largest city of Germany, both by area and by population.[11] Its more than 3.85 million inhabitants[12] make it the Europ...\n"
     ]
    }
   ],
   "source": [
    "with open(\"berlin.txt\", \"r\") as f:\n",
    "    document = f.read()\n",
    "\n",
    "print(f\"First 50 characters of the document:\\n{document[:150]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load the `jina-embeddings-v2-base-en` model from Huggingface. Other embedding models can be used, but Jina's model has up to 8192 token length documents, which is important for late chunking as we want to encode large documents and separate them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('jinaai/jina-embeddings-v2-base-en', trust_remote_code=True)\n",
    "model     = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-en', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call our functions we defined earlier: First chunk the text as normal, to obtain the beginning and end points of the chunks. Then embed the full document. Then perform the late chunking step - take the average over all token embeddings that correspond to each chunk (based on the beginning/end points of the chunks). These form as our embeddings for the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks, span_annotations = sentence_chunker(document)\n",
    "token_embeddings = document_to_token_embeddings(model, tokenizer, document)\n",
    "chunk_embeddings = late_chunking(token_embeddings, [span_annotations])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can add this to our Weaviate collection by supplying our own vector embedding for each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data with manual embeddings\n",
    "data = []\n",
    "for i in range(len(chunks)):\n",
    "    data.append(wvc.data.DataObject(\n",
    "            properties={\n",
    "                \"content\": chunks[i]\n",
    "            },\n",
    "            vector = chunk_embeddings[i].tolist()\n",
    "    )\n",
    ")\n",
    "\n",
    "late_chunking_collection.data.insert_many(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Query\n",
    "\n",
    "First, define two functions to process queries. One using our Weaviate collection, and a different, slower search using cosine similarity running locally that we will use for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def late_chunking_query_function_weaviate(query, k = 3):\n",
    "    query_vector = model(**tokenizer(query, return_tensors=\"pt\")).last_hidden_state.mean(1).detach().cpu().numpy().flatten()\n",
    "\n",
    "    results = late_chunking_collection.query.near_vector(\n",
    "        near_vector=query_vector.tolist(),\n",
    "        limit = k\n",
    "    )\n",
    "\n",
    "    return [res.properties[\"content\"] for res in results.objects]\n",
    "\n",
    "def late_chunking_query_function_cosine_sim(query, k = 3):\n",
    "\n",
    "    cos_sim = lambda x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "\n",
    "    query_vector = model(**tokenizer(query, return_tensors=\"pt\")).last_hidden_state.mean(1).detach().cpu().numpy().flatten()\n",
    "\n",
    "    results = np.empty(len(chunk_embeddings))\n",
    "    for i, (chunk, embedding) in enumerate(zip(chunks, chunk_embeddings)):\n",
    "        results[i] = cos_sim(query_vector, embedding)\n",
    "\n",
    "    results_order = results.argsort()[::-1]\n",
    "    return np.array(chunks)[results_order].tolist()[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test both search functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Independent Evangelical Lutheran Church has eight parishes of different sizes in Berlin.[131] There are 36 Baptist congregations (within Union of Evangelical Free Church Congregations in Germany), 29 New Apostolic Churches, 15 United Methodist churches, eight Free Evangelical Congregations, four Churches of Christ, Scientist (1st, 2nd, 3rd, and 11th), six congregations of the Church of Jesus Christ of Latter-day Saints, an Old Catholic church, and an Anglican church in Berlin.',\n",
       " 'Each borough has several subdistricts or neighborhoods (Ortsteile), which have roots in much older municipalities that predate the formation of Greater Berlin on 1 October 1920.',\n",
       " 'The Senate consists of the Governing Mayor of Berlin (Regierender Bürgermeister), and up to ten senators holding ministerial positions, two of them holding the title of \"Mayor\" (Bürgermeister) as deputy to the Governing Mayor.[134]\\n\\n\\nCharlottenburg Town Hall\\n\\nRathaus Spandau\\nThe total annual budget of Berlin in 2015 exceeded €24.5 ($30.0) billion including a budget surplus of €205 ($240) million.[135] The German Federal city state of Berlin owns extensive assets, including administrative and government buildings, real estate companies, as well as stakes in the Olympic Stadium, swimming pools, housing companies, and numerous public enterprises and subsidiary companies.[136][137] The federal state of Berlin runs a real estate portal to advertise commercial spaces or land suitable for redevelopment.[138]\\n\\nThe Social Democratic Party (SPD) and The Left (Die Linke) took control of the city government after the 2001 state election and won another term in the 2006 state election.[139] From the 2016 state election until the 2023 state election, there was a coalition between the Social Democratic Party, the Greens and the Left Party.',\n",
       " 'Since April 2023, the government has been formed by a coalition between the Christian Democrats and the Social Democrats.[140]\\n\\nThe Governing Mayor is simultaneously Lord Mayor of the City of Berlin (Oberbürgermeister der Stadt) and Minister President of the State of Berlin (Ministerpräsident des Bundeslandes).',\n",
       " '24] About 2.7% of the population identify with other Christian denominations (mostly Eastern Orthodox, but also various Protestants).[125] According to the Berlin residents register, in 2018 14.9 percent were members of the Evangelical Church, and 8.5 percent were members of the Catholic Church.[103] The government keeps a register of members of these churches for tax purposes, because it collects church tax on behalf of the churches.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "late_chunking_query_function_weaviate(\"What are the different demographics of Berlin?\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Independent Evangelical Lutheran Church has eight parishes of different sizes in Berlin.[131] There are 36 Baptist congregations (within Union of Evangelical Free Church Congregations in Germany), 29 New Apostolic Churches, 15 United Methodist churches, eight Free Evangelical Congregations, four Churches of Christ, Scientist (1st, 2nd, 3rd, and 11th), six congregations of the Church of Jesus Christ of Latter-day Saints, an Old Catholic church, and an Anglican church in Berlin.',\n",
       " 'Each borough has several subdistricts or neighborhoods (Ortsteile), which have roots in much older municipalities that predate the formation of Greater Berlin on 1 October 1920.',\n",
       " 'The Senate consists of the Governing Mayor of Berlin (Regierender Bürgermeister), and up to ten senators holding ministerial positions, two of them holding the title of \"Mayor\" (Bürgermeister) as deputy to the Governing Mayor.[134]\\n\\n\\nCharlottenburg Town Hall\\n\\nRathaus Spandau\\nThe total annual budget of Berlin in 2015 exceeded €24.5 ($30.0) billion including a budget surplus of €205 ($240) million.[135] The German Federal city state of Berlin owns extensive assets, including administrative and government buildings, real estate companies, as well as stakes in the Olympic Stadium, swimming pools, housing companies, and numerous public enterprises and subsidiary companies.[136][137] The federal state of Berlin runs a real estate portal to advertise commercial spaces or land suitable for redevelopment.[138]\\n\\nThe Social Democratic Party (SPD) and The Left (Die Linke) took control of the city government after the 2001 state election and won another term in the 2006 state election.[139] From the 2016 state election until the 2023 state election, there was a coalition between the Social Democratic Party, the Greens and the Left Party.',\n",
       " 'Since April 2023, the government has been formed by a coalition between the Christian Democrats and the Social Democrats.[140]\\n\\nThe Governing Mayor is simultaneously Lord Mayor of the City of Berlin (Oberbürgermeister der Stadt) and Minister President of the State of Berlin (Ministerpräsident des Bundeslandes).',\n",
       " '24] About 2.7% of the population identify with other Christian denominations (mostly Eastern Orthodox, but also various Protestants).[125] According to the Berlin residents register, in 2018 14.9 percent were members of the Evangelical Church, and 8.5 percent were members of the Catholic Church.[103] The government keeps a register of members of these churches for tax purposes, because it collects church tax on behalf of the churches.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "late_chunking_query_function_cosine_sim(\"What are the different demographics of Berlin?\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both give the same results so we are confident that our vector search for late chunking works! We would expect something slightly different as Weaviate uses HNSW for a speedy search, and we have directly used cosine similarity, but in this case, they are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, let's look at what a naive chunking method implemented with Weaviate's search would give us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the weaviate collection chunked by sentences\n",
    "if client.collections.exists(\"test_naive_chunking\"):\n",
    "    client.collections.delete(\"test_naive_chunking\")\n",
    "\n",
    "naive_chunking_collection = client.collections.create(\n",
    "    name=\"test_naive_chunking\",\n",
    "    vectorizer_config=wvcc.Configure.Vectorizer.text2vec_openai(),\n",
    "            properties=[\n",
    "                    wvcc.Property(name=\"content\", data_type=wvcc.DataType.TEXT)\n",
    "            ]\n",
    ")\n",
    "\n",
    "naive_chunking_collection.data.insert_many([{\"content\": c} for c in chunks]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_chunking_query_function_weaviate(query, k=3):\n",
    "    results = naive_chunking_collection.query.near_text(\n",
    "        query = query,\n",
    "        limit = k\n",
    "    )\n",
    "\n",
    "    return [res.properties[\"content\"] for res in results.objects]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\n\\nDemographics\\nMain article: Demographics of Berlin\\n\\nBerlin population pyramid in 2022\\n\\nBerlin's population, 1880–2012\\nAt the end of 2018, the city-state of Berlin had 3.75 million registered inhabitants[103] in an area of 891.1 km2 (344.1 sq mi).[3] The city's population density was 4,206 inhabitants per km2.\",\n",
       " 'Foreign residents of Berlin originate from about 190 countries.[112] 48 percent of the residents under the age of 15 have a migration background in 2017.[113] Berlin in 2009 was estimated to have 100,000 to 250,000 unregistered inhabitants.[114] Boroughs of Berlin with a significant number of migrants or foreign born population are Mitte, Neukölln and Friedrichshain-Kreuzberg.[115] The number of Arabic speakers in Berlin could be higher than 150,000.',\n",
       " 'Around 130,000 jobs were added in this period.[150]\\n\\nImportant economic sectors in Berlin include life sciences, transportation, information and communication technologies, media and music, advertising and design, biotechnology, environmental services, construction, e-commerce, retail, hotel business, and medical engineering.[151]\\n\\nResearch and development have economic significance for the city.[152] Several major corporations like Volkswagen, Pfizer, and SAP operate innovation laboratories in the city.[153] The Science and Business Park in Adlershof is the largest technology park in Germany measured by revenue.[154] Within the Eurozone, Berlin has become a center for business relocation and international investments.[155][156]\\n\\nYear[157]\\t2010\\t2011\\t2012\\t2013\\t2014\\t2015\\t2016\\t2017\\t20',\n",
       " \"Of the estimated population of 30,000–45,000 Jewish residents,[130] approximately 12,000 are registered members of religious organizations.[125]\\n\\nBerlin is the seat of the Roman Catholic archbishop of Berlin and EKBO's elected chairperson is titled the bishop of EKBO.\",\n",
       " \"Polish, English, Russian, and Vietnamese have more native speakers in East Berlin.[121]\\n\\nReligion\\nMain article: Religion in Berlin\\nReligion in Berlin (2022)[122]\\n\\n  Not religious/other (72%)\\n  EKD Protestants (15%)\\n  Catholics (9%)\\n  Islam (4%)\\n  Jewish (1%)\\n  Other (0.5%)\\n\\n\\n\\n\\nClockwise from top left: Berlin Cathedral, New Synagogue, Şehitlik Mosque, and St. Hedwig's Cathedral\\nOn the report of the 2011 census, approximately 37 percent of the population reported being members of a legally-recognized church or religious organization.\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_chunking_query_function_weaviate(\"What are the different demographics of Berlin?\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the naive chunking query still gives us good results - it matches more specifically with the question. Whereas the late chunking example skips straight to the chunks it _knows_ to be relevant, because they contain contextual information within the embeddings themselves!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
