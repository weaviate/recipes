{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/weaviate/recipes/blob/main/weaviate-features/reranking/voyageai-ranking/simple-reranking/voyageai-ranking.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install weaviate-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate, os\n",
    "\n",
    "voyageai_key = os.environ[\"VOYAGEAI_API_KEY\"] # Replace with your Voyage key\n",
    "\n",
    "# Option 1: Connect to WCS cluster\n",
    "# client = weaviate.connect_to_wcs(\n",
    "#     cluster_url=os.getenv(\"WCS_DEMO_URL\"),  # Replace with your WCS URL\n",
    "#     auth_credentials=weaviate.auth.AuthApiKey(os.getenv(\"WCS_DEMO_KEY\")),  # Replace with your WCS key\n",
    "#     headers={\"X-VoyageAI-Api-Key\": voyageai_key}\n",
    "# )\n",
    "\n",
    "# Option 2: Connect to Weaviate Embedded\n",
    "client = weaviate.connect_to_embedded(\n",
    "    version=\"1.24.8\",\n",
    "    headers={\"X-VoyageAI-Api-Key\": voyageai_key}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a collection\n",
    "> Collection stores your data and vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate.classes.config as wc\n",
    "\n",
    "# Delete the collection if it already exists\n",
    "if (client.collections.exists(\"BlogPost\")):\n",
    "    client.collections.delete(\"BlogPost\")\n",
    "\n",
    "client.collections.create(\n",
    "    name=\"BlogPost\",\n",
    "    # Configure the vectorizer\n",
    "    vectorizer_config=wc.Configure.Vectorizer.text2vec_voyageai( # specify the vectorizer and model type you're using\n",
    "        model=\"voyage-large-2\", # defaults to embed-multilingual-v2.0 if not set\n",
    "        truncate=True, # defaults to RIGHT if not set \n",
    "    ),\n",
    "\n",
    "    # Configure the reranker here\n",
    "    reranker_config=wc.Configure.Reranker.voyageai(\n",
    "        model=\"rerank-lite-1\"\n",
    "    ),\n",
    "\n",
    "    properties=[ # defining properties (data schema) is optional\n",
    "        wc.Property(name=\"Content\", data_type=wc.DataType.TEXT),\n",
    "        wc.Property(name=\"URL\", data_type=wc.DataType.TEXT), \n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Successfully created collection: BlogPost.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogs = ['./ranking-models.mdx', './ref2vec-centroid.mdx'] \n",
    "\n",
    "data = {}\n",
    "\n",
    "# Loop through each file path and read the file\n",
    "for blog in blogs:\n",
    "    with open(blog, 'r') as file:\n",
    "        data[blog] = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually chunk up the document into smaller chunks. This results in the chunks being a bit messy, but this can be improved by using an external tool like LlamaIndex, Haystack, LangChain, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a collection object for \"BlogPost\"\n",
    "blogs = client.collections.get(\"BlogPost\")\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for source in data.keys():\n",
    "    for i in range(0,len(data[source]), 500):\n",
    "        item = {\n",
    "            \"source\": source,\n",
    "            \"content\": data[source][i:i+500]\n",
    "        }\n",
    "\n",
    "        chunks.append(item)\n",
    "\n",
    "        # when chunks reach 100, insert chunks Weaviate\n",
    "        if(len(chunks) >= 100):\n",
    "            blogs.data.insert_many(chunks)\n",
    "            chunks.clear()\n",
    "\n",
    "# insert remaining chunks\n",
    "if(len(chunks) > 0):\n",
    "    blogs.data.insert_many(chunks)\n",
    "    chunks.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Query without reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# note, you can reuse the collection object from the previous cell.\n",
    "# Get a collection object for \"BlogPost\"\n",
    "blogs = client.collections.get(\"BlogPost\")\n",
    "\n",
    "response = blogs.query.near_text(\n",
    "    \"Low hanging fruit to improve relevance\",\n",
    "    limit=5\n",
    ")\n",
    "\n",
    "for item in response.objects:\n",
    "    print(\"ID:\", item.uuid)\n",
    "    print(\"Data:\", json.dumps(item.properties, indent=2), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The first few results from the above query aren't exactly what we're looking for. Let's run the query again, but rerank the top 10 documents with the text in the content property. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Query with Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import weaviate.classes.query as wq\n",
    "\n",
    "# note, you can reuse the collection object from the previous cell.\n",
    "# Get a collection object for \"BlogPost\"\n",
    "blogs = client.collections.get(\"BlogPost\")\n",
    "\n",
    "response = blogs.query.near_text(\n",
    "    \"Low hanging fruit to improve relevance\",\n",
    "    limit=5,\n",
    "    rerank=wq.Rerank(\n",
    "        prop=\"content\",\n",
    "        query=\"Low hanging fruit\"\n",
    "    ),\n",
    "    return_metadata=wq.MetadataQuery(score=True)\n",
    ")\n",
    "\n",
    "for item in response.objects:\n",
    "    print(\"ID:\", item.uuid)\n",
    "    print(\"Data:\", json.dumps(item.properties, indent=2), \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
