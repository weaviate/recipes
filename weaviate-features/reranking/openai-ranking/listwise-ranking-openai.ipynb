{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/weaviate/recipes/blob/main/weaviate-features/reranking/openai-ranking/listwise-ranking-openai.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listwise Reranking using OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Listwise ranking](./listwise.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listwise reranking takes all the retrieved documents and query as input to the ranker. Listwise reranking uses prompt engineering to feed in the input of the retrieved documents + query and returns a structured output of the results [Doc B > Doc C > Doc A]. The objective of the LLM is to find the best document ordering that maximizes the retrieval metric (i.e. nDCG, precision)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Weaviate instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"startup\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-12-27T12:19:05-03:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-12-27T12:19:05-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-12-27T12:19:05-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"module offload-s3 is enabled\",\"time\":\"2024-12-27T12:19:05-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-12-27T12:19:05-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"open cluster service\",\"servers\":{\"Embedded_at_8079\":60173},\"time\":\"2024-12-27T12:19:05-03:00\"}\n",
      "{\"address\":\"192.168.28.99:60174\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"starting cloud rpc server ...\",\"time\":\"2024-12-27T12:19:05-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"starting raft sub-system ...\",\"time\":\"2024-12-27T12:19:05-03:00\"}\n",
      "{\"address\":\"192.168.28.99:60173\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"tcp transport\",\"tcpMaxPool\":3,\"tcpTimeout\":10000000000,\"time\":\"2024-12-27T12:19:05-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"loading local db\",\"time\":\"2024-12-27T12:19:05-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"local DB successfully loaded\",\"time\":\"2024-12-27T12:19:05-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"schema manager loaded\",\"n\":0,\"time\":\"2024-12-27T12:19:05-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"metadata_only_voters\":false,\"msg\":\"construct a new raft node\",\"name\":\"Embedded_at_8079\",\"time\":\"2024-12-27T12:19:05-03:00\"}\n",
      "{\"action\":\"raft\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"index\":840,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.28.99:58227}]]\",\"time\":\"2024-12-27T12:19:05-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"last_snapshot_index\":0,\"last_store_applied_index_on_start\":844,\"level\":\"info\",\"msg\":\"raft node constructed\",\"raft_applied_index\":0,\"raft_last_index\":844,\"time\":\"2024-12-27T12:19:05-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"hasState\":true,\"level\":\"info\",\"msg\":\"raft init\",\"time\":\"2024-12-27T12:19:05-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"attempting to join\",\"remoteNodes\":[\"192.168.28.99:60173\"],\"time\":\"2024-12-27T12:19:05-03:00\"}\n",
      "{\"action\":\"raft\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2024-12-27T12:19:05-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"attempted to join and failed\",\"remoteNode\":\"192.168.28.99:60173\",\"status\":8,\"time\":\"2024-12-27T12:19:05-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"attempting to join\",\"remoteNodes\":[\"192.168.28.99:60173\"],\"time\":\"2024-12-27T12:19:06-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"attempted to join and failed\",\"remoteNode\":\"192.168.28.99:60173\",\"status\":8,\"time\":\"2024-12-27T12:19:06-03:00\"}\n",
      "{\"action\":\"raft\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"last-leader-addr\":\"\",\"last-leader-id\":\"\",\"level\":\"warning\",\"msg\":\"raft heartbeat timeout reached, starting election\",\"time\":\"2024-12-27T12:19:07-03:00\"}\n",
      "{\"action\":\"raft\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":188,\"time\":\"2024-12-27T12:19:07-03:00\"}\n",
      "{\"action\":\"raft\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"raft pre-vote successful, starting election\",\"refused\":0,\"tally\":1,\"term\":188,\"time\":\"2024-12-27T12:19:07-03:00\",\"votesNeeded\":1}\n",
      "{\"action\":\"raft\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"raft election won\",\"tally\":1,\"term\":188,\"time\":\"2024-12-27T12:19:07-03:00\"}\n",
      "{\"action\":\"raft\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"leader\":{},\"level\":\"info\",\"msg\":\"raft entering leader state\",\"time\":\"2024-12-27T12:19:07-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"docker_image_tag\":\"localhost\",\"level\":\"info\",\"msg\":\"configured versions\",\"server_version\":\"1.26.6\",\"time\":\"2024-12-27T12:19:07-03:00\"}\n",
      "{\"action\":\"grpc_startup\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50050\",\"time\":\"2024-12-27T12:19:07-03:00\"}\n",
      "{\"action\":\"restapi_management\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"docker_image_tag\":\"localhost\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-12-27T12:19:07-03:00\"}\n",
      "{\"address\":\"192.168.28.99:60173\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"current Leader\",\"time\":\"2024-12-27T12:19:07-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"attempting to join\",\"remoteNodes\":[\"192.168.28.99:60173\"],\"time\":\"2024-12-27T12:19:07-03:00\"}\n",
      "{\"action\":\"raft\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"command\":0,\"level\":\"info\",\"msg\":\"raft updating configuration\",\"server-addr\":\"192.168.28.99:60173\",\"server-id\":\"Embedded_at_8079\",\"servers\":\"[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.28.99:60173}]]\",\"time\":\"2024-12-27T12:19:07-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"reload local db: update schema ...\",\"time\":\"2024-12-27T12:19:08-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"index\":\"MyCollection\",\"level\":\"info\",\"msg\":\"reload local index\",\"time\":\"2024-12-27T12:19:08-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"index\":\"BlogPost\",\"level\":\"info\",\"msg\":\"reload local index\",\"time\":\"2024-12-27T12:19:08-03:00\"}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"index\":\"FAQ_Answers\",\"level\":\"info\",\"msg\":\"reload local index\",\"time\":\"2024-12-27T12:19:08-03:00\"}\n",
      "{\"action\":\"telemetry_push\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:b5a11f64-c335-4a4a-929e-4a82377dcf5b Type:INIT Version:1.26.6 NumObjects:0 OS:darwin Arch:arm64 UsedModules:[generative-openai text2vec-openai]}\",\"time\":\"2024-12-27T12:19:08-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"MyCollection\",\"index\":\"mycollection\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/mycollection/SgZG5BZ5gAjb/lsm/property__id/segment-1735308659428598000\",\"shard\":\"SgZG5BZ5gAjb\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"MyCollection\",\"index\":\"mycollection\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/mycollection/SgZG5BZ5gAjb/lsm/property_content/segment-1735308659428051000\",\"shard\":\"SgZG5BZ5gAjb\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"MyCollection\",\"index\":\"mycollection\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/mycollection/SgZG5BZ5gAjb/lsm/property_content/segment-1735308681860851000\",\"shard\":\"SgZG5BZ5gAjb\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"MyCollection\",\"index\":\"mycollection\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/mycollection/SgZG5BZ5gAjb/lsm/property__id/segment-1735308681860851000\",\"shard\":\"SgZG5BZ5gAjb\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"MyCollection\",\"index\":\"mycollection\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/mycollection/SgZG5BZ5gAjb/lsm/objects/segment-1735308659426845000\",\"shard\":\"SgZG5BZ5gAjb\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"MyCollection\",\"index\":\"mycollection\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/mycollection/SgZG5BZ5gAjb/lsm/objects/segment-1735308681860851000\",\"shard\":\"SgZG5BZ5gAjb\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"MyCollection\",\"index\":\"mycollection\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/mycollection/SgZG5BZ5gAjb/lsm/property_content_searchable/segment-1735308659428314000\",\"shard\":\"SgZG5BZ5gAjb\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"MyCollection\",\"index\":\"mycollection\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/mycollection/SgZG5BZ5gAjb/lsm/property_content_searchable/segment-1735308681865661000\",\"shard\":\"SgZG5BZ5gAjb\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"hnsw_prefill_cache_async\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-12-27T12:19:09-03:00\",\"wait_for_cache_prefill\":false}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"Completed loading shard mycollection_SgZG5BZ5gAjb in 23.125709ms\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-12-27T12:19:09-03:00\",\"took\":221333}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property__id/segment-1735308659271205000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property_doc_id/segment-1735308659266438000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property_document_id/segment-1735308659270010000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property_text/segment-1735308659268867000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property_ref_doc_id/segment-1735308659265131000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property__id/segment-1735308682164480000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property_doc_id/segment-1735308682164479000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property__node_content/segment-1735308659267701000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property_text/segment-1735308682169157000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property_document_id/segment-1735308682164501000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property_ref_doc_id/segment-1735308682169156000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property__node_content/segment-1735308682169169000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property__node_type/segment-1735308659263146000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property__node_type/segment-1735308682169157000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/objects/segment-1735308659260627000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/objects/segment-1735308682169158000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property_text_searchable/segment-1735308659269437000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property_text_searchable/segment-1735308682178168000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property__node_content_searchable/segment-1735308659268281000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property_doc_id_searchable/segment-1735308659267046000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property_document_id_searchable/segment-1735308659270615000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property__node_content_searchable/segment-1735308682178159000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property_document_id_searchable/segment-1735308682173161000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property__node_type_searchable/segment-1735308659264255000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property_doc_id_searchable/segment-1735308682173163000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property__node_type_searchable/segment-1735308682178158000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property_ref_doc_id_searchable/segment-1735308659265805000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"class\":\"BlogPost\",\"index\":\"blogpost\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/dudanogueira/.local/share/weaviate/blogpost/pCCvvGK0UfZZ/lsm/property_ref_doc_id_searchable/segment-1735308682178158000\",\"shard\":\"pCCvvGK0UfZZ\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"hnsw_prefill_cache_async\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-12-27T12:19:09-03:00\",\"wait_for_cache_prefill\":false}\n",
      "{\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"level\":\"info\",\"msg\":\"Completed loading shard blogpost_pCCvvGK0UfZZ in 18.786333ms\",\"time\":\"2024-12-27T12:19:09-03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"build_git_commit\":\"ab0312d5d\",\"build_go_version\":\"go1.23.1\",\"build_image_tag\":\"localhost\",\"build_wv_version\":\"1.26.6\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-12-27T12:19:09-03:00\",\"took\":55041}\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "import os\n",
    "\n",
    "client = weaviate.connect_to_embedded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client Version: 4.10.2 Server Version: 1.26.6\n"
     ]
    }
   ],
   "source": [
    "print(\"Client Version:\", weaviate.__version__, \"Server Version:\", client.get_meta().get(\"version\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in FAQ json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"faq.json\", \"r\") as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "queries = [{\"question\": item[\"question\"], \"answer\": item[\"answer\"], \"number\": item[\"number\"]} for item in json_data[\"questions\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Weaviate Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the schema.\n"
     ]
    }
   ],
   "source": [
    "from weaviate import classes as wvc\n",
    "\n",
    "# resetting the schema. CAUTION: THIS WILL DELETE YOUR DATA \n",
    "client.collections.delete(\"FAQ_Answers\")\n",
    "\n",
    "collection = client.collections.create(\n",
    "    name=\"FAQ_Answers\",\n",
    "    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),\n",
    "    properties=[\n",
    "        wvc.config.Property(name=\"Answer\", data_type=wvc.config.DataType.TEXT),\n",
    "        wvc.config.Property(name=\"Number\", data_type=wvc.config.DataType.TEXT),\n",
    "    ]\n",
    ")\n",
    "print(\"Successfully created the schema.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload answers to Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Why would I use Weaviate as my vector database?', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.', 'number': '1'}\n",
      "{'question': 'What is the difference between Weaviate and for example Elasticsearch?', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.', 'number': '2'}\n",
      "{'question': 'Do I need to know about Docker (Compose) to use Weaviate?', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.', 'number': '3'}\n",
      "{'question': 'What happens when the Weaviate Docker container restarts? Is my data in the Weaviate database lost?', 'answer': 'There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there', 'number': '4'}\n",
      "{'question': \"Are there any 'best practices' or guidelines to consider when designing a schema?\", 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\", 'number': '5'}\n",
      "{'question': 'Is it possible to create one-to-many relationships in the schema?', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.', 'number': '6'}\n",
      "{'question': 'Do Weaviate classes have namespaces?', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.', 'number': '7'}\n",
      "{'question': 'Are there restrictions on UUID formatting? Do I have to adhere to any standards?', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\", 'number': '8'}\n",
      "{'question': 'If I do not specify a UUID during adding data objects, will Weaviate create one automatically?', 'answer': 'Yes, a UUID will be created if not specified.', 'number': '9'}\n",
      "{'question': 'Can I use Weaviate to create a traditional knowledge graph?', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.', 'number': '10'}\n",
      "{'question': 'Why does Weaviate have a schema and not an ontology?', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\", 'number': '11'}\n",
      "{'question': 'How can I retrieve the total object count in a class?', 'answer': 'Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here', 'number': '12'}\n",
      "{'question': \"How do I get the cosine similarity from Weaviate's certainty?\", 'answer': \"To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1\", 'number': '13'}\n",
      "{'question': 'What is the best way to iterate through objects? Can I do paginated API calls?', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.', 'number': '14'}\n",
      "{'question': \"How does Weaviate's vector and scalar filtering work?\", 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\", 'number': '15'}\n",
      "{'question': 'Can I request a feature in Weaviate?', 'answer': \"Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.\", 'number': '16'}\n"
     ]
    }
   ],
   "source": [
    "from weaviate.util import get_valid_uuid\n",
    "from uuid import uuid4\n",
    "\n",
    "for item in queries:\n",
    "  print(item)\n",
    "  properties = {\n",
    "    \"Answer\": item[\"answer\"],\n",
    "    \"Number\": item[\"number\"]\n",
    "  }\n",
    "  id = get_valid_uuid(uuid4())\n",
    "  collection.data.insert(properties, uuid=id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prompt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def openai_request(prompt):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "        {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"\n",
    "        You are a reranking agent. Each potential answer has a corresponding Answer id and you're tasked with ranking the questions based on their relevancy to the query.\n",
    "        The output should ONLY contain the ranked list and no additional comments.\n",
    "        \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }],\n",
    "        temperature=1,\n",
    "        max_tokens=2048,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATIONS 1\n",
      "Weaviate search results 10\n",
      "\n",
      "\n",
      "INPUT:\n",
      "QUERY: Why would I use Weaviate as my vector database?\n",
      "Please rerank these search results.\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "\n",
      "\n",
      "\n",
      "OPENAI 1st Rank = Answer id: 2]\n",
      "[Answer id: 1]\n",
      "[Answer id: 11]\n",
      "[Answer id: 10]\n",
      "[Answer id: 5]\n",
      "[Answer id: 7]\n",
      "[Answer id: 3]\n",
      "[Answer id: 14]\n",
      "[Answer id: 8]\n",
      "[Answer id: 13\n",
      "\n",
      "GROUND TRUTH = 1\n",
      "ITERATIONS 2\n",
      "Weaviate search results 10\n",
      "\n",
      "\n",
      "INPUT:\n",
      "QUERY: What is the difference between Weaviate and for example Elasticsearch?\n",
      "Please rerank these search results.\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "\n",
      "\n",
      "\n",
      "OPENAI 1st Rank = Answer id: 2]\n",
      "[Answer id: 1]\n",
      "[Answer id: 3]\n",
      "[Answer id: 5]\n",
      "[Answer id: 15]\n",
      "[Answer id: 11]\n",
      "[Answer id: 10]\n",
      "[Answer id: 7]\n",
      "[Answer id: 8]\n",
      "[Answer id: 14\n",
      "\n",
      "GROUND TRUTH = 2\n",
      "ITERATIONS 3\n",
      "Weaviate search results 10\n",
      "\n",
      "\n",
      "INPUT:\n",
      "QUERY: Do I need to know about Docker (Compose) to use Weaviate?\n",
      "Please rerank these search results.\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 4, Answer: There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 16, Answer: Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.]\n",
      "\n",
      "\n",
      "\n",
      "OPENAI 1st Rank = Answer id: 3] \n",
      "[Answer id: 1] \n",
      "[Answer id: 4] \n",
      "[Answer id: 2]\n",
      "[Answer id: 10]\n",
      "[Answer id: 11] \n",
      "[Answer id: 14]\n",
      "[Answer id: 8]\n",
      "[Answer id: 7]\n",
      "[Answer id: 16\n",
      "\n",
      "GROUND TRUTH = 3\n",
      "ITERATIONS 4\n",
      "Weaviate search results 10\n",
      "\n",
      "\n",
      "INPUT:\n",
      "QUERY: What happens when the Weaviate Docker container restarts? Is my data in the Weaviate database lost?\n",
      "Please rerank these search results.\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 4, Answer: There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 9, Answer: Yes, a UUID will be created if not specified.]\n",
      "\n",
      "\n",
      "\n",
      "OPENAI 1st Rank = Answer id: 4]\n",
      "[Answer id: 3]\n",
      "[Answer id: 1]\n",
      "[Answer id: 2]\n",
      "[Answer id: 7]\n",
      "[Answer id: 10]\n",
      "[Answer id: 11]\n",
      "[Answer id: 14]\n",
      "[Answer id: 8]\n",
      "[Answer id: 9\n",
      "\n",
      "GROUND TRUTH = 4\n",
      "ITERATIONS 5\n",
      "Weaviate search results 10\n",
      "\n",
      "\n",
      "INPUT:\n",
      "QUERY: Are there any 'best practices' or guidelines to consider when designing a schema?\n",
      "Please rerank these search results.\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 12, Answer: Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here]\n",
      "\n",
      "\n",
      "\n",
      "OPENAI 1st Rank = Answer id: 10]\n",
      "[Answer id: 5]\n",
      "[Answer id: 1]\n",
      "[Answer id: 11]\n",
      "[Answer id: 7]\n",
      "[Answer id: 6]\n",
      "[Answer id: 2]\n",
      "[Answer id: 15]\n",
      "[Answer id: 14]\n",
      "[Answer id: 12\n",
      "\n",
      "GROUND TRUTH = 5\n",
      "ITERATIONS 6\n",
      "Weaviate search results 10\n",
      "\n",
      "\n",
      "INPUT:\n",
      "QUERY: Is it possible to create one-to-many relationships in the schema?\n",
      "Please rerank these search results.\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 9, Answer: Yes, a UUID will be created if not specified.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "\n",
      "\n",
      "\n",
      "OPENAI 1st Rank = Answer id: 6]\n",
      "[Answer id: 10]\n",
      "[Answer id: 11]\n",
      "[Answer id: 7]\n",
      "[Answer id: 14]\n",
      "[Answer id: 1]\n",
      "[Answer id: 2]\n",
      "[Answer id: 5]\n",
      "[Answer id: 15]\n",
      "[Answer id: 9\n",
      "\n",
      "GROUND TRUTH = 6\n",
      "ITERATIONS 7\n",
      "Weaviate search results 10\n",
      "\n",
      "\n",
      "INPUT:\n",
      "QUERY: Do Weaviate classes have namespaces?\n",
      "Please rerank these search results.\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "\n",
      "\n",
      "\n",
      "OPENAI 1st Rank = Answer id: 7]\n",
      "[Answer id: 11]\n",
      "[Answer id: 1]\n",
      "[Answer id: 10]\n",
      "[Answer id: 2]\n",
      "[Answer id: 3]\n",
      "[Answer id: 6]\n",
      "[Answer id: 8]\n",
      "[Answer id: 14]\n",
      "[Answer id: 13\n",
      "\n",
      "GROUND TRUTH = 7\n",
      "ITERATIONS 8\n",
      "Weaviate search results 10\n",
      "\n",
      "\n",
      "INPUT:\n",
      "QUERY: Are there restrictions on UUID formatting? Do I have to adhere to any standards?\n",
      "Please rerank these search results.\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 9, Answer: Yes, a UUID will be created if not specified.]\n",
      "[Answer id: 12, Answer: Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "\n",
      "\n",
      "\n",
      "OPENAI 1st Rank = Answer id: 8\n",
      "\n",
      "GROUND TRUTH = 8\n",
      "ITERATIONS 9\n",
      "Weaviate search results 10\n",
      "\n",
      "\n",
      "INPUT:\n",
      "QUERY: If I do not specify a UUID during adding data objects, will Weaviate create one automatically?\n",
      "Please rerank these search results.\n",
      "[Answer id: 9, Answer: Yes, a UUID will be created if not specified.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 4, Answer: There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "\n",
      "\n",
      "\n",
      "OPENAI 1st Rank = Answer id: 8\n",
      "\n",
      "GROUND TRUTH = 9\n",
      "ITERATIONS 10\n",
      "Weaviate search results 10\n",
      "\n",
      "\n",
      "INPUT:\n",
      "QUERY: Can I use Weaviate to create a traditional knowledge graph?\n",
      "Please rerank these search results.\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "\n",
      "\n",
      "\n",
      "OPENAI 1st Rank = Answer id: 10]\n",
      "[Answer id: 11]\n",
      "[Answer id: 1]\n",
      "[Answer id: 2]\n",
      "[Answer id: 3]\n",
      "[Answer id: 6]\n",
      "[Answer id: 7]\n",
      "[Answer id: 8]\n",
      "[Answer id: 14]\n",
      "[Answer id: 15\n",
      "\n",
      "GROUND TRUTH = 10\n",
      "ITERATIONS 11\n",
      "Weaviate search results 10\n",
      "\n",
      "\n",
      "INPUT:\n",
      "QUERY: Why does Weaviate have a schema and not an ontology?\n",
      "Please rerank these search results.\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "\n",
      "\n",
      "\n",
      "OPENAI 1st Rank = Answer id: 11]\n",
      "[Answer id: 10]\n",
      "[Answer id: 1]\n",
      "[Answer id: 2]\n",
      "[Answer id: 3]\n",
      "[Answer id: 14]\n",
      "[Answer id: 8]\n",
      "[Answer id: 5]\n",
      "[Answer id: 6]\n",
      "[Answer id: 7\n",
      "\n",
      "GROUND TRUTH = 11\n",
      "ITERATIONS 12\n",
      "Weaviate search results 10\n",
      "\n",
      "\n",
      "INPUT:\n",
      "QUERY: How can I retrieve the total object count in a class?\n",
      "Please rerank these search results.\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 12, Answer: Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "[Answer id: 4, Answer: There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 16, Answer: Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.]\n",
      "\n",
      "\n",
      "\n",
      "OPENAI 1st Rank = Answer id: 14]\n",
      "[Answer id: 6]\n",
      "[Answer id: 7]\n",
      "[Answer id: 5]\n",
      "[Answer id: 12]\n",
      "[Answer id: 13]\n",
      "[Answer id: 4]\n",
      "[Answer id: 10]\n",
      "[Answer id: 11]\n",
      "[Answer id: 16\n",
      "\n",
      "GROUND TRUTH = 12\n",
      "ITERATIONS 13\n",
      "Weaviate search results 10\n",
      "\n",
      "\n",
      "INPUT:\n",
      "QUERY: How do I get the cosine similarity from Weaviate's certainty?\n",
      "Please rerank these search results.\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "\n",
      "\n",
      "\n",
      "OPENAI 1st Rank = Answer id: 13\n",
      "\n",
      "GROUND TRUTH = 13\n",
      "ITERATIONS 14\n",
      "Weaviate search results 10\n",
      "\n",
      "\n",
      "INPUT:\n",
      "QUERY: What is the best way to iterate through objects? Can I do paginated API calls?\n",
      "Please rerank these search results.\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 12, Answer: Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "\n",
      "\n",
      "\n",
      "OPENAI 1st Rank = Answer id: 14]\n",
      "[Answer id: 6]\n",
      "[Answer id: 12]\n",
      "[Answer id: 7]\n",
      "[Answer id: 10]\n",
      "[Answer id: 2]\n",
      "[Answer id: 11]\n",
      "[Answer id: 1]\n",
      "[Answer id: 5]\n",
      "[Answer id: 15\n",
      "\n",
      "GROUND TRUTH = 14\n",
      "ITERATIONS 15\n",
      "Weaviate search results 10\n",
      "\n",
      "\n",
      "INPUT:\n",
      "QUERY: How does Weaviate's vector and scalar filtering work?\n",
      "Please rerank these search results.\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "\n",
      "\n",
      "\n",
      "OPENAI 1st Rank = Answer id: 2]\n",
      "[Answer id: 15]\n",
      "[Answer id: 5]\n",
      "[Answer id: 13]\n",
      "[Answer id: 11]\n",
      "[Answer id: 10]\n",
      "[Answer id: 3]\n",
      "[Answer id: 1]\n",
      "[Answer id: 14]\n",
      "[Answer id: 8\n",
      "\n",
      "GROUND TRUTH = 15\n",
      "ITERATIONS 16\n",
      "Weaviate search results 10\n",
      "\n",
      "\n",
      "INPUT:\n",
      "QUERY: Can I request a feature in Weaviate?\n",
      "Please rerank these search results.\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 16, Answer: Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "\n",
      "\n",
      "\n",
      "OPENAI 1st Rank = Answer id: 16\n",
      "\n",
      "GROUND TRUTH = 16\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def parse_ranked_ids(ids):\n",
    "    elements = ids.split(',')\n",
    "\n",
    "    first_element = elements[0].strip('[]')\n",
    "\n",
    "    return first_element\n",
    "\n",
    "\n",
    "correct = 0\n",
    "it = 0\n",
    "for query_obj in queries:\n",
    "    it += 1\n",
    "    print(\"ITERATIONS\", it)\n",
    "    query = query_obj[\"question\"]\n",
    "    ground_truth = int(query_obj[\"number\"])\n",
    "\n",
    "    results = collection.query.near_text(\n",
    "        query=query,\n",
    "        limit=10\n",
    "    )\n",
    "    print(f\"Weaviate search results {len(results.objects)}\\n\")\n",
    "\n",
    "    reranking_template = f\"\\nINPUT:\\nQUERY: {query}\"\n",
    "    reranking_template += \"\\nPlease rerank these search results.\\n\"\n",
    "    for result in results.objects:\n",
    "        id, answer = result.properties[\"number\"], result.properties[\"answer\"]\n",
    "        reranking_template += f\"[Answer id: {id}, Answer: {answer}]\\n\"\n",
    "    print(reranking_template)\n",
    "    print(\"\\n\")\n",
    "    ranked_ids = openai_request(reranking_template) # send the query along with retrieved results to OpenAI\n",
    "    first_ranking = parse_ranked_ids(ranked_ids)\n",
    "    print(f\"OPENAI 1st Rank = {first_ranking}\\n\") # first ranking from gpt-4\n",
    "    print(f\"GROUND TRUTH = {ground_truth}\") # ground truth\n",
    "    if (first_ranking == ground_truth):\n",
    "        correct += 1\n",
    "\n",
    "print(correct / len(queries) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prompt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_request(prompt):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "        {\n",
    "        \"role\": \"system\", #systems prompt\n",
    "        \"content\": \"\"\"\n",
    "            You are a reranking agent! Each potential answer has a corresponding Answer id and you're tasked with ranking the answers based on their relevancy to the QUERY.\n",
    "            You SHOULD ONLY contain the ranked list and no additional comments, such as [8],[7],[3],[1],[5]. THIS IS VERY IMPORTANT!\n",
    "            Here is an example of the task you should perform:\n",
    "            INPUT:\n",
    "            QUERY: Why would I use Weaviate as my vector database?\n",
    "            Please rerank these search results.\n",
    "            [Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
    "            [Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
    "            [Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
    "            [Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
    "            [Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
    "            [Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
    "            [Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
    "            [Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
    "            [Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
    "            [Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
    "            \n",
    "\n",
    "            OUTPUT:\n",
    "            [1],[2] \n",
    "        \"\"\"\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"user\", # users prompt\n",
    "        \"content\": prompt\n",
    "        }],\n",
    "        temperature=1,\n",
    "        max_tokens=2048,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('7a32c7bd-7171-45f3-9d9d-549735e8b37b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '13', 'answer': \"To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Why would I use Weaviate as my vector database?\n",
      "Please rerank these search results.\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [2],[1],[11],[10],[5],[3],[7],[14],[13],[8]\n",
      "\n",
      "OPENAI 1st Rank = 2\n",
      "\n",
      "GROUND TRUTH = 1\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: What is the difference between Weaviate and for example Elasticsearch?\n",
      "Please rerank these search results.\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [2],[1],[15],[3],[11],[10],[7],[14],[5],[8]\n",
      "\n",
      "OPENAI 1st Rank = 2\n",
      "\n",
      "GROUND TRUTH = 2\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('c753f12d-3e10-4ed5-95ca-c9b18e8a9b51'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '4', 'answer': 'There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('b39bb168-1f95-476b-b928-d12058bfc6a0'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '16', 'answer': \"Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Do I need to know about Docker (Compose) to use Weaviate?\n",
      "Please rerank these search results.\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 4, Answer: There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 16, Answer: Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [3],[1],[4]\n",
      "\n",
      "OPENAI 1st Rank = 3\n",
      "\n",
      "GROUND TRUTH = 3\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('c753f12d-3e10-4ed5-95ca-c9b18e8a9b51'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '4', 'answer': 'There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('bdd07683-ca36-4142-a854-ca21e112cf28'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '9', 'answer': 'Yes, a UUID will be created if not specified.'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: What happens when the Weaviate Docker container restarts? Is my data in the Weaviate database lost?\n",
      "Please rerank these search results.\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 4, Answer: There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 9, Answer: Yes, a UUID will be created if not specified.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [4],[3],[1]\n",
      "\n",
      "OPENAI 1st Rank = 4\n",
      "\n",
      "GROUND TRUTH = 4\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('33e43661-b54b-4eaf-9d00-76dc55b8ec5b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '12', 'answer': 'Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Are there any 'best practices' or guidelines to consider when designing a schema?\n",
      "Please rerank these search results.\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 12, Answer: Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [11],[10],[7],[5],[6]\n",
      "\n",
      "OPENAI 1st Rank = 11\n",
      "\n",
      "GROUND TRUTH = 5\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('bdd07683-ca36-4142-a854-ca21e112cf28'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '9', 'answer': 'Yes, a UUID will be created if not specified.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Is it possible to create one-to-many relationships in the schema?\n",
      "Please rerank these search results.\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 9, Answer: Yes, a UUID will be created if not specified.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [6],[11],[10],[1],[5],[14],[7],[2],[15],[9]\n",
      "\n",
      "OPENAI 1st Rank = 6\n",
      "\n",
      "GROUND TRUTH = 6\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('7a32c7bd-7171-45f3-9d9d-549735e8b37b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '13', 'answer': \"To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Do Weaviate classes have namespaces?\n",
      "Please rerank these search results.\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [7],[6],[1],[3],[2],[11],[10],[14],[8],[13]\n",
      "\n",
      "OPENAI 1st Rank = 7\n",
      "\n",
      "GROUND TRUTH = 7\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('bdd07683-ca36-4142-a854-ca21e112cf28'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '9', 'answer': 'Yes, a UUID will be created if not specified.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('33e43661-b54b-4eaf-9d00-76dc55b8ec5b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '12', 'answer': 'Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Are there restrictions on UUID formatting? Do I have to adhere to any standards?\n",
      "Please rerank these search results.\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 9, Answer: Yes, a UUID will be created if not specified.]\n",
      "[Answer id: 12, Answer: Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [8],[9]\n",
      "\n",
      "OPENAI 1st Rank = 8\n",
      "\n",
      "GROUND TRUTH = 8\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('bdd07683-ca36-4142-a854-ca21e112cf28'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '9', 'answer': 'Yes, a UUID will be created if not specified.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('c753f12d-3e10-4ed5-95ca-c9b18e8a9b51'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '4', 'answer': 'There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: If I do not specify a UUID during adding data objects, will Weaviate create one automatically?\n",
      "Please rerank these search results.\n",
      "[Answer id: 9, Answer: Yes, a UUID will be created if not specified.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 4, Answer: There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [8],[9]\n",
      "\n",
      "OPENAI 1st Rank = 8\n",
      "\n",
      "GROUND TRUTH = 9\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Can I use Weaviate to create a traditional knowledge graph?\n",
      "Please rerank these search results.\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [10],[11],[1],[2],[14],[3],[7],[6],[15],[8]\n",
      "\n",
      "OPENAI 1st Rank = 10\n",
      "\n",
      "GROUND TRUTH = 10\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Why does Weaviate have a schema and not an ontology?\n",
      "Please rerank these search results.\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [11],[10],[1],[2],[3],[14],[8],[5],[6],[7]\n",
      "\n",
      "OPENAI 1st Rank = 11\n",
      "\n",
      "GROUND TRUTH = 11\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('33e43661-b54b-4eaf-9d00-76dc55b8ec5b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '12', 'answer': 'Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('7a32c7bd-7171-45f3-9d9d-549735e8b37b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '13', 'answer': \"To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('c753f12d-3e10-4ed5-95ca-c9b18e8a9b51'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '4', 'answer': 'There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('b39bb168-1f95-476b-b928-d12058bfc6a0'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '16', 'answer': \"Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: How can I retrieve the total object count in a class?\n",
      "Please rerank these search results.\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 12, Answer: Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "[Answer id: 4, Answer: There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 16, Answer: Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [14],[7],[5],[6],[10],[11],[4],[13],[12],[16]\n",
      "\n",
      "OPENAI 1st Rank = 14\n",
      "\n",
      "GROUND TRUTH = 12\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('7a32c7bd-7171-45f3-9d9d-549735e8b37b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '13', 'answer': \"To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: How do I get the cosine similarity from Weaviate's certainty?\n",
      "Please rerank these search results.\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [13],[2],[1],[10],[11],[14],[3],[5],[15],[8]\n",
      "\n",
      "OPENAI 1st Rank = 13\n",
      "\n",
      "GROUND TRUTH = 13\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('33e43661-b54b-4eaf-9d00-76dc55b8ec5b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '12', 'answer': 'Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: What is the best way to iterate through objects? Can I do paginated API calls?\n",
      "Please rerank these search results.\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 12, Answer: Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [14],[1],[2],[10],[5],[11],[6],[7],[15],[12]\n",
      "\n",
      "OPENAI 1st Rank = 14\n",
      "\n",
      "GROUND TRUTH = 14\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('7a32c7bd-7171-45f3-9d9d-549735e8b37b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '13', 'answer': \"To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: How does Weaviate's vector and scalar filtering work?\n",
      "Please rerank these search results.\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [15],[2],[1]\n",
      "\n",
      "OPENAI 1st Rank = 15\n",
      "\n",
      "GROUND TRUTH = 15\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('b39bb168-1f95-476b-b928-d12058bfc6a0'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '16', 'answer': \"Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('7a32c7bd-7171-45f3-9d9d-549735e8b37b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '13', 'answer': \"To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Can I request a feature in Weaviate?\n",
      "Please rerank these search results.\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 16, Answer: Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [16],[1],[2],[3],[10],[11],[14],[6],[8],[13]\n",
      "\n",
      "OPENAI 1st Rank = 16\n",
      "\n",
      "GROUND TRUTH = 16\n",
      "75.0\n"
     ]
    }
   ],
   "source": [
    "def parse_ranked_ids(ids):\n",
    "    elements = ids.split(',')\n",
    "\n",
    "    first_element = elements[0].strip('[]')\n",
    "\n",
    "    return int(first_element)\n",
    "\n",
    "\n",
    "correct = 0\n",
    "for query_obj in queries:\n",
    "    query = query_obj[\"question\"]\n",
    "    ground_truth = int(query_obj[\"number\"])\n",
    "\n",
    "    results = collection.query.near_text(\n",
    "        query=query,\n",
    "        limit=10\n",
    "    )\n",
    "    print(f\"Weaviate search results {results}\\n\")\n",
    "\n",
    "    reranking_template = f\"\\nINPUT: \\nQUERY: {query}\"\n",
    "    reranking_template += \"\\nPlease rerank these search results.\\n\"\n",
    "    for result in results.objects:\n",
    "        id, answer = result.properties[\"number\"], result.properties[\"answer\"]\n",
    "        reranking_template += f\"[Answer id: {id}, Answer: {answer}]\\n\"\n",
    "    print(reranking_template)\n",
    "    print(\"\\n\")\n",
    "    ranked_ids = openai_request(reranking_template) # send the query along with retrieved results to OpenAI\n",
    "    print(f\"RAW OUTPUT FROM OPENAI = {ranked_ids}\\n\")\n",
    "    first_ranking = parse_ranked_ids(ranked_ids)\n",
    "    print(f\"OPENAI 1st Rank = {first_ranking}\\n\") # first ranking from gpt-4\n",
    "    print(f\"GROUND TRUTH = {ground_truth}\") # ground truth\n",
    "    if (first_ranking == ground_truth):\n",
    "        correct += 1\n",
    "\n",
    "print(correct / len(queries) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prompt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_request(prompt):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "        {\n",
    "        \"role\": \"system\", #systems prompt\n",
    "        \"content\": \"\"\"\n",
    "        You are a reranking agent. Each potential answer has a corresponding Answer id and you're tasked with ranking the questions based on their relevancy to the QUERY.\n",
    "    VERY IMPORTANT!!! The output SHOULD ONLY contain the ranked list and no additional comments, such as [8],[7],[3],[1],[5]! THIS IS VERY IMPORTANT!\n",
    "    Here is an example of the task you should perform:\n",
    "    INPUT:\n",
    "    QUERY: Why would I use Weaviate as my vector database?\n",
    "    Please rerank these search results.\n",
    "    [Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
    "    [Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
    "    [Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
    "    [Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
    "    [Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
    "    [Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
    "    [Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
    "    [Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
    "    [Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
    "    [Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
    "\n",
    "    OUTPUT:\n",
    "    [1],[2] \n",
    "        \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", # users prompt\n",
    "            \"content\": prompt\n",
    "        }],\n",
    "        temperature=1,\n",
    "        max_tokens=2048,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('7a32c7bd-7171-45f3-9d9d-549735e8b37b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '13', 'answer': \"To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Why would I use Weaviate as my vector database?\n",
      "Please rerank these search results.\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [2],[1],[11],[10],[5],[3],[7],[14],[13],[8]\n",
      "\n",
      "OPENAI 1st Rank = 2\n",
      "\n",
      "GROUND TRUTH = 1\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: What is the difference between Weaviate and for example Elasticsearch?\n",
      "Please rerank these search results.\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [2],[1],[15],[5],[3]\n",
      "\n",
      "OPENAI 1st Rank = 2\n",
      "\n",
      "GROUND TRUTH = 2\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('c753f12d-3e10-4ed5-95ca-c9b18e8a9b51'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '4', 'answer': 'There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('b39bb168-1f95-476b-b928-d12058bfc6a0'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '16', 'answer': \"Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Do I need to know about Docker (Compose) to use Weaviate?\n",
      "Please rerank these search results.\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 4, Answer: There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 16, Answer: Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [3],[1],[4]\n",
      "\n",
      "OPENAI 1st Rank = 3\n",
      "\n",
      "GROUND TRUTH = 3\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('c753f12d-3e10-4ed5-95ca-c9b18e8a9b51'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '4', 'answer': 'There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('bdd07683-ca36-4142-a854-ca21e112cf28'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '9', 'answer': 'Yes, a UUID will be created if not specified.'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: What happens when the Weaviate Docker container restarts? Is my data in the Weaviate database lost?\n",
      "Please rerank these search results.\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 4, Answer: There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 9, Answer: Yes, a UUID will be created if not specified.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [4],[3],[1],[2],[7],[11],[10],[14],[8],[9]\n",
      "\n",
      "OPENAI 1st Rank = 4\n",
      "\n",
      "GROUND TRUTH = 4\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('33e43661-b54b-4eaf-9d00-76dc55b8ec5b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '12', 'answer': 'Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Are there any 'best practices' or guidelines to consider when designing a schema?\n",
      "Please rerank these search results.\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 12, Answer: Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [11],[10],[7],[6]\n",
      "\n",
      "OPENAI 1st Rank = 11\n",
      "\n",
      "GROUND TRUTH = 5\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('bdd07683-ca36-4142-a854-ca21e112cf28'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '9', 'answer': 'Yes, a UUID will be created if not specified.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Is it possible to create one-to-many relationships in the schema?\n",
      "Please rerank these search results.\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 9, Answer: Yes, a UUID will be created if not specified.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [6],[11],[10],[5],[7],[14],[1],[2],[15],[9]\n",
      "\n",
      "OPENAI 1st Rank = 6\n",
      "\n",
      "GROUND TRUTH = 6\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('7a32c7bd-7171-45f3-9d9d-549735e8b37b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '13', 'answer': \"To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Do Weaviate classes have namespaces?\n",
      "Please rerank these search results.\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [7],[1],[2],[3],[11],[10],[14],[6],[8],[13]\n",
      "\n",
      "OPENAI 1st Rank = 7\n",
      "\n",
      "GROUND TRUTH = 7\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('bdd07683-ca36-4142-a854-ca21e112cf28'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '9', 'answer': 'Yes, a UUID will be created if not specified.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('33e43661-b54b-4eaf-9d00-76dc55b8ec5b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '12', 'answer': 'Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Are there restrictions on UUID formatting? Do I have to adhere to any standards?\n",
      "Please rerank these search results.\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 9, Answer: Yes, a UUID will be created if not specified.]\n",
      "[Answer id: 12, Answer: Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [8],[9]\n",
      "\n",
      "OPENAI 1st Rank = 8\n",
      "\n",
      "GROUND TRUTH = 8\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('bdd07683-ca36-4142-a854-ca21e112cf28'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '9', 'answer': 'Yes, a UUID will be created if not specified.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('c753f12d-3e10-4ed5-95ca-c9b18e8a9b51'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '4', 'answer': 'There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: If I do not specify a UUID during adding data objects, will Weaviate create one automatically?\n",
      "Please rerank these search results.\n",
      "[Answer id: 9, Answer: Yes, a UUID will be created if not specified.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 4, Answer: There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [8],[9]\n",
      "\n",
      "OPENAI 1st Rank = 8\n",
      "\n",
      "GROUND TRUTH = 9\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Can I use Weaviate to create a traditional knowledge graph?\n",
      "Please rerank these search results.\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [10],[11],[1],[2],[14],[3],[8],[6],[15],[7]\n",
      "\n",
      "OPENAI 1st Rank = 10\n",
      "\n",
      "GROUND TRUTH = 10\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Why does Weaviate have a schema and not an ontology?\n",
      "Please rerank these search results.\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [11],[10],[1],[2]\n",
      "\n",
      "OPENAI 1st Rank = 11\n",
      "\n",
      "GROUND TRUTH = 11\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('33e43661-b54b-4eaf-9d00-76dc55b8ec5b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '12', 'answer': 'Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('7a32c7bd-7171-45f3-9d9d-549735e8b37b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '13', 'answer': \"To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('c753f12d-3e10-4ed5-95ca-c9b18e8a9b51'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '4', 'answer': 'There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('b39bb168-1f95-476b-b928-d12058bfc6a0'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '16', 'answer': \"Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: How can I retrieve the total object count in a class?\n",
      "Please rerank these search results.\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 12, Answer: Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "[Answer id: 4, Answer: There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 16, Answer: Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [14],[7],[5],[6],[10],[11],[4],[16],[13],[12]\n",
      "\n",
      "OPENAI 1st Rank = 14\n",
      "\n",
      "GROUND TRUTH = 12\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('7a32c7bd-7171-45f3-9d9d-549735e8b37b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '13', 'answer': \"To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: How do I get the cosine similarity from Weaviate's certainty?\n",
      "Please rerank these search results.\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [13],[1],[2],[14],[3],[10],[11],[5],[15],[8]\n",
      "\n",
      "OPENAI 1st Rank = 13\n",
      "\n",
      "GROUND TRUTH = 13\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('33e43661-b54b-4eaf-9d00-76dc55b8ec5b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '12', 'answer': 'Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: What is the best way to iterate through objects? Can I do paginated API calls?\n",
      "Please rerank these search results.\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 12, Answer: Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [14],[1],[10],[2],[5],[11],[6],[7],[15],[12]\n",
      "\n",
      "OPENAI 1st Rank = 14\n",
      "\n",
      "GROUND TRUTH = 14\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('7a32c7bd-7171-45f3-9d9d-549735e8b37b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '13', 'answer': \"To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: How does Weaviate's vector and scalar filtering work?\n",
      "Please rerank these search results.\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [2],[15],[1],[5],[11],[10],[14],[3],[8],[13]\n",
      "\n",
      "OPENAI 1st Rank = 2\n",
      "\n",
      "GROUND TRUTH = 15\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('b39bb168-1f95-476b-b928-d12058bfc6a0'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '16', 'answer': \"Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('7a32c7bd-7171-45f3-9d9d-549735e8b37b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '13', 'answer': \"To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Can I request a feature in Weaviate?\n",
      "Please rerank these search results.\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 16, Answer: Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [16],[1],[2],[10],[3],[14],[11],[6],[8],[13]\n",
      "\n",
      "OPENAI 1st Rank = 16\n",
      "\n",
      "GROUND TRUTH = 16\n",
      "68.75\n"
     ]
    }
   ],
   "source": [
    "def parse_ranked_ids(ids):\n",
    "    elements = ids.split(',')\n",
    "\n",
    "    first_element = elements[0].strip('[]')\n",
    "\n",
    "    return int(first_element)\n",
    "\n",
    "\n",
    "correct = 0\n",
    "for query_obj in queries:\n",
    "    query = query_obj[\"question\"]\n",
    "    ground_truth = int(query_obj[\"number\"])\n",
    "\n",
    "    results = collection.query.near_text(\n",
    "        query=query,\n",
    "        limit=10\n",
    "    )\n",
    "    print(f\"Weaviate search results {results}\\n\")\n",
    "    \n",
    "\n",
    "    reranking_template = f\"\\nINPUT: \\nQUERY: {query}\"\n",
    "    reranking_template += \"\\nPlease rerank these search results.\\n\"\n",
    "    for result in results.objects:\n",
    "        id, answer = result.properties[\"number\"], result.properties[\"answer\"]\n",
    "        reranking_template += f\"[Answer id: {id}, Answer: {answer}]\\n\"\n",
    "    print(reranking_template)\n",
    "    print(\"\\n\")\n",
    "    ranked_ids = openai_request(reranking_template) # send the query along with retrieved results to OpenAI\n",
    "    print(f\"RAW OUTPUT FROM OPENAI = {ranked_ids}\\n\")\n",
    "    first_ranking = parse_ranked_ids(ranked_ids)\n",
    "    print(f\"OPENAI 1st Rank = {first_ranking}\\n\") # first ranking from gpt-4\n",
    "    print(f\"GROUND TRUTH = {ground_truth}\") # ground truth\n",
    "    if (first_ranking == ground_truth):\n",
    "        correct += 1\n",
    "\n",
    "print(correct / len(queries) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prompt 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_request(prompt):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "        {\n",
    "        \"role\": \"system\", #systems prompt\n",
    "        \"content\": \"\"\"\n",
    "        You are a reranking agent. Each Answer has a corresponding Answer id and you're tasked with ranking the questions based on their relevancy to the QUERY.\n",
    "        The output should ONLY contain the ranked list and no additional comments. An example of your output looks like this [8],[7],[3],[1],[5]!\n",
    "        Here is an example of the task you will perform:\n",
    "        ```\n",
    "        INPUT:\n",
    "        QUERY: Why would I use Weaviate as my vector database?\n",
    "        Please rerank these search results.\n",
    "        [Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
    "        [Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
    "        [Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
    "\n",
    "        OUTPUT:\n",
    "        [14],[3] \n",
    "        ```\n",
    "        Please consider all answers first before making your final decision!\n",
    "\n",
    "        \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", # users prompt\n",
    "            \"content\": prompt\n",
    "        }],\n",
    "        temperature=1,\n",
    "        max_tokens=2048,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('7a32c7bd-7171-45f3-9d9d-549735e8b37b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '13', 'answer': \"To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Why would I use Weaviate as my vector database?\n",
      "Please rerank these search results.\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [2],[1],[10],[7],[11],[3],[14],[5],[13],[8]\n",
      "\n",
      "OPENAI 1st Rank = 2\n",
      "\n",
      "GROUND TRUTH = 1\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: What is the difference between Weaviate and for example Elasticsearch?\n",
      "Please rerank these search results.\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [2],[1],[10],[11],[15],[7],[5],[3],[14],[8]\n",
      "\n",
      "OPENAI 1st Rank = 2\n",
      "\n",
      "GROUND TRUTH = 2\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('c753f12d-3e10-4ed5-95ca-c9b18e8a9b51'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '4', 'answer': 'There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('b39bb168-1f95-476b-b928-d12058bfc6a0'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '16', 'answer': \"Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Do I need to know about Docker (Compose) to use Weaviate?\n",
      "Please rerank these search results.\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 4, Answer: There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 16, Answer: Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [3],[1],[4]\n",
      "\n",
      "OPENAI 1st Rank = 3\n",
      "\n",
      "GROUND TRUTH = 3\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('c753f12d-3e10-4ed5-95ca-c9b18e8a9b51'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '4', 'answer': 'There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('bdd07683-ca36-4142-a854-ca21e112cf28'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '9', 'answer': 'Yes, a UUID will be created if not specified.'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: What happens when the Weaviate Docker container restarts? Is my data in the Weaviate database lost?\n",
      "Please rerank these search results.\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 4, Answer: There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 9, Answer: Yes, a UUID will be created if not specified.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [4],[3],[1],[14],[2],[11],[10],[7],[8],[9]\n",
      "\n",
      "OPENAI 1st Rank = 4\n",
      "\n",
      "GROUND TRUTH = 4\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('33e43661-b54b-4eaf-9d00-76dc55b8ec5b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '12', 'answer': 'Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Are there any 'best practices' or guidelines to consider when designing a schema?\n",
      "Please rerank these search results.\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 12, Answer: Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [11],[10],[7],[6],[5],[1],[14],[15],[2],[12]\n",
      "\n",
      "OPENAI 1st Rank = 11\n",
      "\n",
      "GROUND TRUTH = 5\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('bdd07683-ca36-4142-a854-ca21e112cf28'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '9', 'answer': 'Yes, a UUID will be created if not specified.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Is it possible to create one-to-many relationships in the schema?\n",
      "Please rerank these search results.\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 9, Answer: Yes, a UUID will be created if not specified.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [6],[10],[11],[7]\n",
      "\n",
      "OPENAI 1st Rank = 6\n",
      "\n",
      "GROUND TRUTH = 6\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('7a32c7bd-7171-45f3-9d9d-549735e8b37b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '13', 'answer': \"To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Do Weaviate classes have namespaces?\n",
      "Please rerank these search results.\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [7],[6],[1],[2],[3],[10],[11],[14],[8],[13]\n",
      "\n",
      "OPENAI 1st Rank = 7\n",
      "\n",
      "GROUND TRUTH = 7\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('bdd07683-ca36-4142-a854-ca21e112cf28'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '9', 'answer': 'Yes, a UUID will be created if not specified.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('33e43661-b54b-4eaf-9d00-76dc55b8ec5b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '12', 'answer': 'Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Are there restrictions on UUID formatting? Do I have to adhere to any standards?\n",
      "Please rerank these search results.\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 9, Answer: Yes, a UUID will be created if not specified.]\n",
      "[Answer id: 12, Answer: Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [8],[9],[15],[12],[6],[1],[7],[10],[11],[5]\n",
      "\n",
      "OPENAI 1st Rank = 8\n",
      "\n",
      "GROUND TRUTH = 8\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('bdd07683-ca36-4142-a854-ca21e112cf28'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '9', 'answer': 'Yes, a UUID will be created if not specified.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('c753f12d-3e10-4ed5-95ca-c9b18e8a9b51'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '4', 'answer': 'There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: If I do not specify a UUID during adding data objects, will Weaviate create one automatically?\n",
      "Please rerank these search results.\n",
      "[Answer id: 9, Answer: Yes, a UUID will be created if not specified.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 4, Answer: There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [8],[9],[4],[2],[7],[14],[3],[1],[10],[11]\n",
      "\n",
      "OPENAI 1st Rank = 8\n",
      "\n",
      "GROUND TRUTH = 9\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Can I use Weaviate to create a traditional knowledge graph?\n",
      "Please rerank these search results.\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [10],[11],[1],[2],[6],[14],[7],[15],[3],[8]\n",
      "\n",
      "OPENAI 1st Rank = 10\n",
      "\n",
      "GROUND TRUTH = 10\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Why does Weaviate have a schema and not an ontology?\n",
      "Please rerank these search results.\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [11],[10],[1],[2],[14],[3],[7],[6],[5],[8]\n",
      "\n",
      "OPENAI 1st Rank = 11\n",
      "\n",
      "GROUND TRUTH = 11\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('33e43661-b54b-4eaf-9d00-76dc55b8ec5b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '12', 'answer': 'Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('7a32c7bd-7171-45f3-9d9d-549735e8b37b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '13', 'answer': \"To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('c753f12d-3e10-4ed5-95ca-c9b18e8a9b51'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '4', 'answer': 'There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('b39bb168-1f95-476b-b928-d12058bfc6a0'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '16', 'answer': \"Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: How can I retrieve the total object count in a class?\n",
      "Please rerank these search results.\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 12, Answer: Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "[Answer id: 4, Answer: There are three levels: You have no volume configured (the default in our Docker Compose files), if the container restarts (e.g. due to a crash, or because of docker stop/start) your data is kept. You have no volume configured (the default in our Docker Compose files), if the container is removed (e.g. from docker compose down or docker rm) your data is gone. If a volume is configured, your data is persisted regardless of what happens to the container. They can be completely removed or replaced, next time they start up with a volume, all your data will be there]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 16, Answer: Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [14],[6],[7]\n",
      "\n",
      "OPENAI 1st Rank = 14\n",
      "\n",
      "GROUND TRUTH = 12\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('7a32c7bd-7171-45f3-9d9d-549735e8b37b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '13', 'answer': \"To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: How do I get the cosine similarity from Weaviate's certainty?\n",
      "Please rerank these search results.\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [13],[2],[1],[5],[11],[10],[3],[14],[15],[8]\n",
      "\n",
      "OPENAI 1st Rank = 13\n",
      "\n",
      "GROUND TRUTH = 13\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('33e43661-b54b-4eaf-9d00-76dc55b8ec5b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '12', 'answer': 'Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f7f26081-e472-4d41-9379-e5a5f5bb5433'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '7', 'answer': 'Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.'}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: What is the best way to iterate through objects? Can I do paginated API calls?\n",
      "Please rerank these search results.\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 12, Answer: Sometimes, users work with custom terminology, which often comes in the form of abbreviations or jargon. You can find more information on how to use the endpoint here]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 7, Answer: Yes. Each class itself acts like namespaces. Additionally, you can use the multi-tenancy feature to create isolated storage for each tenant. This is especially useful for use cases where one cluster might be used to store data for multiple customers or users.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [14],[6],[2]\n",
      "\n",
      "OPENAI 1st Rank = 14\n",
      "\n",
      "GROUND TRUTH = 14\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('1578a3df-2653-4ad0-a839-e87af7be872b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '5', 'answer': \"As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('7a32c7bd-7171-45f3-9d9d-549735e8b37b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '13', 'answer': \"To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('4da88886-c097-4dbf-9815-31b77c6f5b8a'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '15', 'answer': \"It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: How does Weaviate's vector and scalar filtering work?\n",
      "Please rerank these search results.\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 5, Answer: As a rule of thumb, the smaller the units, the more accurate the search will be. Two objects of e.g. a sentence would most likely contain more information in their vector embedding than a common vector (which is essentially just the mean of sentences). At the same time more objects leads to a higher import time and (since each vector also makes up some data) more space. (E.g. when using transformers, a single vector is 768xfloat32 = 3KB. This can easily make a difference if you have millions, etc.) of vectors. As a rule of thumb, the more vectors you have the more memory you're going to need. So, basically, it's a set of tradeoffs. Personally we've had great success with using paragraphs as individual units, as there's little benefit in going even more granular, but it's still much more precise than whole chapters, etc. You can use cross-references to link e.g. chapters to paragraphs. Note that resolving a cross-references takes a slight performance penalty. Essentially resolving A1->B1 is the same cost as looking up both A1 and B1 indvidually. This cost however, will probably only matter at really large scale.]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "[Answer id: 15, Answer: It's a 2-step process: 1. The inverted index (which is built at import time) queries to produce an allowed list of the specified document ids. Then the ANN index is queried with this allow list (the list being one of the reasons for our custom implementation). 2. If we encounter a document id which would be a close match, but isn't on the allow list the id is treated as a candidate (i.e. we add it to our list of links to evaluate), but is never added to the result set. Since we only add allowed IDs to the set, we don't exit early, i.e. before the top k elements are reached.]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [2],[15],[5],[13],[11],[1],[10],[14],[3],[8]\n",
      "\n",
      "OPENAI 1st Rank = 2\n",
      "\n",
      "GROUND TRUTH = 15\n",
      "Weaviate search results QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('f2791143-c2ae-43d2-9917-1e57c0a25942'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '1', 'answer': 'Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('0ae59a26-a5d8-487d-803c-61e18d875a8d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '2', 'answer': 'Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('d0ef8536-2cea-4983-95e0-e8e63f90f69b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '3', 'answer': 'Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('6a89189c-cd22-4027-88e4-fbbd6588823d'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '14', 'answer': 'Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('27308607-c83f-405e-8d59-1445004cf382'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '10', 'answer': 'Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('9af93587-2b65-413a-927e-0467b6ebd676'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '11', 'answer': \"We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('35f3e15e-670b-4c17-b658-8d7d40b47255'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '8', 'answer': \"The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('b39bb168-1f95-476b-b928-d12058bfc6a0'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '16', 'answer': \"Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.\"}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('e087409a-4ff8-4fdb-989c-457c2e74edfb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '6', 'answer': 'Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.'}, references=None, vector={}, collection='FAQ_Answers'), Object(uuid=_WeaviateUUIDInt('7a32c7bd-7171-45f3-9d9d-549735e8b37b'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'number': '13', 'answer': \"To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1\"}, references=None, vector={}, collection='FAQ_Answers')])\n",
      "\n",
      "\n",
      "INPUT: \n",
      "QUERY: Can I request a feature in Weaviate?\n",
      "Please rerank these search results.\n",
      "[Answer id: 1, Answer: Our goal is three-folded. Firstly, we want to make it as easy as possible for others to create their own semantic systems or vector search engines (hence, our APIs are GraphQL based). Secondly, we have a strong focus on the semantic element (the knowledge in vector databases, if you will). Our ultimate goal is to have Weaviate help you manage, index, and understand your data so that you can build newer, better, and faster applications. And thirdly, we want you to be able to run it everywhere. This is the reason why Weaviate comes containerized.]\n",
      "[Answer id: 2, Answer: Other database systems like Elasticsearch rely on inverted indices, which makes search super fast. Weaviate also uses inverted indices to store data and values. But additionally, Weaviate is also a vector-native search database, which means that data is stored as vectors, which enables semantic search. This combination of data storage is unique, and enables fast, filtered and semantic search from end-to-end.]\n",
      "[Answer id: 3, Answer: Weaviate uses Docker images as a means to distribute releases and uses Docker Compose to tie a module-rich runtime together. If you are new to those technologies, we recommend reading the Docker Introduction for Weaviate Users.]\n",
      "[Answer id: 14, Answer: Yes, Weaviate supports cursor-based iteration as well as pagination through a result set. To iterate through all objects, you can use the after operator with both REST and GraphQL. For pagination through a result set, you can use the offset and limit operators for GraphQL API calls. Take a look at this page which describes how to use these operators, including tips on performance and limitations.]\n",
      "[Answer id: 10, Answer: Yes, you can! Weaviate support ontology, RDF-like definitions in its schema, and it runs out of the box. It is scalable, and the GraphQL API will allow you to query through your knowledge graph easily. But now you are here. We like to suggest you really try its semantic features. After all, you are creating a knowledge graph 😉.]\n",
      "[Answer id: 11, Answer: We use a schema because it focusses on the representation of your data (in our case in the GraphQL API) but you can use a Weaviate schema to express an ontology. One of Weaviate's core features is that it semantically interprets your schema (and with that your ontology) so that you can search for concepts rather than formally defined entities.]\n",
      "[Answer id: 8, Answer: The UUID must be presented as a string matching the Canonical Textual representation. If you don't specify a UUID, Weaviate will generate a v4 i.e. a random UUID. If you generate them yourself you could either use random ones or deterministically determine them based on some fields that you have. For this you'll need to use v3 or v5.]\n",
      "[Answer id: 16, Answer: Sure (also, feel free to issue a pull request 😉) you can add those requests here. The only thing you need is a GitHub account, and while you're there, make sure to give us a star 😇.]\n",
      "[Answer id: 6, Answer: Yes, it is possible to reference to one or more objects (Class -> one or more Classes) through cross-references. Referring to lists or arrays of primitives, this will be available soon.]\n",
      "[Answer id: 13, Answer: To obtain the cosine similarity from weaviate's certainty, you can do cosine_sim = 2*certainty - 1]\n",
      "\n",
      "\n",
      "\n",
      "RAW OUTPUT FROM OPENAI = [16],[1],[2],[3],[14],[10],[11],[8],[6],[13]\n",
      "\n",
      "OPENAI 1st Rank = 16\n",
      "\n",
      "GROUND TRUTH = 16\n",
      "68.75\n"
     ]
    }
   ],
   "source": [
    "def parse_ranked_ids(ids):\n",
    "    elements = ids.split(',')\n",
    "\n",
    "    first_element = elements[0].strip('[]')\n",
    "\n",
    "    return int(first_element)\n",
    "\n",
    "\n",
    "correct = 0\n",
    "for query_obj in queries:\n",
    "    query = query_obj[\"question\"]\n",
    "    ground_truth = int(query_obj[\"number\"])\n",
    "\n",
    "    results = collection.query.near_text(\n",
    "        query=query,\n",
    "        limit=10\n",
    "    )\n",
    "    print(f\"Weaviate search results {results}\\n\")\n",
    "    \n",
    "\n",
    "    reranking_template = f\"\\nINPUT: \\nQUERY: {query}\"\n",
    "    reranking_template += \"\\nPlease rerank these search results.\\n\"\n",
    "    for result in results.objects:\n",
    "        id, answer = result.properties[\"number\"], result.properties[\"answer\"]\n",
    "        reranking_template += f\"[Answer id: {id}, Answer: {answer}]\\n\"\n",
    "    print(reranking_template)\n",
    "    print(\"\\n\")\n",
    "    ranked_ids = openai_request(reranking_template) # send the query along with retrieved results to OpenAI\n",
    "    print(f\"RAW OUTPUT FROM OPENAI = {ranked_ids}\\n\")\n",
    "    first_ranking = parse_ranked_ids(ranked_ids)\n",
    "    print(f\"OPENAI 1st Rank = {first_ranking}\\n\") # first ranking from gpt-4\n",
    "    print(f\"GROUND TRUTH = {ground_truth}\") # ground truth\n",
    "    if (first_ranking == ground_truth):\n",
    "        correct += 1\n",
    "\n",
    "print(correct / len(queries) * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
