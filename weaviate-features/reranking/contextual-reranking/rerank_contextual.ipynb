{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e75878",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/weaviate/recipes/blob/main/integrations/data-platforms/aryn/weaviate_blog_post.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6068072",
   "metadata": {},
   "source": [
    "# Reranking with Contextual AI\n",
    "\n",
    "This notebook demonstrates how to use Contextual AI's reranking model (`ctxl-rerank-v2-instruct-multilingual`) with Weaviate to improve search result quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca28dae5",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "1. Weaviate Database >= `1.34.0`\n",
    "2. Weaviate Python Client >= `4.18.2`\n",
    "3. Contextual API key - you can grab one from [the console](https://app.contextual.ai/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1f825ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install weaviate-client==4.18.2 --q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5368b2",
   "metadata": {},
   "source": [
    "## Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f725e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate.classes.config import Configure, Property, DataType\n",
    "from weaviate.classes.query import Rerank\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests, json\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a396e",
   "metadata": {},
   "source": [
    "## Connect to Weaviate Cloud\n",
    "\n",
    "You can create a free 14-day sandbox on [Weaviate Cloud](https://console.weaviate.cloud)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8370ef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"WEAVIATE_URL\"] = \"\"\n",
    "# os.environ[\"WEAVIATE_API_KEY\"] = \"\"\n",
    "# os.environ[\"CONTEXTUALAI_API_KEY\"] = \"\"\n",
    "\n",
    "# client = weaviate.connect_to_weaviate_cloud(\n",
    "#     cluster_url=os.getenv(\"WEAVIATE_URL\"),\n",
    "#     auth_credentials=weaviate.auth.AuthApiKey(os.getenv(\"WEAVIATE_API_KEY\")),\n",
    "#     headers={\n",
    "#     \"X-ContextualAI-Api-Key\": os.getenv(\"CONTEXTUALAI_API_KEY\"),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "WEAVIATE_URL = \"mjcsoay1rizplybg7d21w.c0.us-west3.gcp.weaviate.cloud\"\n",
    "WEAVIATE_API_KEY = \"elJvQWM2Zlg4SSt0N2xZQV9jL002OXduWGxGTC9WUm1JRkFJVHVweGFoT2JYMXZLV0M0c0JPMHhyNnJvPV92MjAw\"\n",
    "CONTEXTUALAI_API_KEY = \"key-QGodBgkoMMAEHv8f4l9F3G_-63ZesNF-xyWsK_BDjQKKIIIbQ\"\n",
    "\n",
    "\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=WEAVIATE_URL,\n",
    "    auth_credentials=weaviate.auth.AuthApiKey(WEAVIATE_API_KEY),\n",
    "    headers={\n",
    "    \"X-ContextualAI-Api-Key\": CONTEXTUALAI_API_KEY\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc54cb97",
   "metadata": {},
   "source": [
    "## Define Weaviate Collection\n",
    "\n",
    "You can create a new collection with the below cell block, or you can connect to your existing collection and skip the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc835d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created collection: JeopardyQuestions.\n"
     ]
    }
   ],
   "source": [
    "# Note: in practice, you shouldn\"t rerun this cell, as it deletes your data\n",
    "# in \"JeopardyQuestion\", and then you need to re-import it again.\n",
    "\n",
    "collection_name = \"JeopardyQuestions\"\n",
    "\n",
    "# Delete the collection if it already exists\n",
    "if (client.collections.exists(collection_name)):\n",
    "    client.collections.delete(collection_name)\n",
    "\n",
    "client.collections.create(\n",
    "    \"JeopardyQuestions\",\n",
    "\n",
    "    vector_config=\n",
    "    Configure.Vectors.text2vec_weaviate(\n",
    "        model=\"Snowflake/snowflake-arctic-embed-l-v2.0\"\n",
    "    ),\n",
    "    reranker_config= \n",
    "    Configure.Reranker.contextualai(\n",
    "        model=\"ctxl-rerank-v2-instruct-multilingual\"\n",
    "    ),\n",
    "\n",
    "    properties=[ # defining properties (data schema) is optional\n",
    "        Property(name=\"Question\", data_type=DataType.TEXT), \n",
    "        Property(name=\"Answer\", data_type=DataType.TEXT),\n",
    "        Property(name=\"Category\", data_type=DataType.TEXT, skip_vectorization=True),\n",
    "        Property(name=\"Value\", data_type=DataType.TEXT, skip_vectorization=True) \n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Successfully created collection: JeopardyQuestions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edeeb89",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "We will use the small jeopardy dataset as an example. It has 1,000 objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4715e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/weaviate/weaviate-examples/main/jeopardy_small_dataset/jeopardy_small.csv'\n",
    "resp = requests.get(url)\n",
    "\n",
    "df = pd.read_csv(StringIO(resp.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a2a210e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert complete.\n"
     ]
    }
   ],
   "source": [
    "# Get a collection object for \"JeopardyQuestion\"\n",
    "collection = client.collections.use(\"JeopardyQuestions\")\n",
    "\n",
    "# Insert data objects with batch import\n",
    "with collection.batch.dynamic() as batch:\n",
    "    for _, row in df.iterrows():\n",
    "        properties = {\n",
    "            \"question\": row['Question'],\n",
    "            \"answer\": row['Answer'],\n",
    "            \"category\": row[\"Category\"],\n",
    "            \"value\": row[\"Value\"]\n",
    "        }\n",
    "        batch.add_object(properties)\n",
    "\n",
    "failed_objects = collection.batch.failed_objects\n",
    "if failed_objects:\n",
    "    print(f\"Number of failed imports: {len(failed_objects)}\")\n",
    "else:\n",
    "    print(\"Insert complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bab966f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# count the number of objects\n",
    "\n",
    "collection = client.collections.use(\"JeopardyQuestions\")\n",
    "response = collection.aggregate.over_all(total_count=True)\n",
    "\n",
    "print(response.total_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e487b3",
   "metadata": {},
   "source": [
    "## Query Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767b2fa0",
   "metadata": {},
   "source": [
    "### Hybrid Search\n",
    "\n",
    "The `alpha` parameter determines the weight given to the sparse and dense search methods. `alpha = 0` is pure sparse (bm25) search, whereas `alpha = 1` is pure dense (vector) search. \n",
    "\n",
    "Alpha is an optional parameter. The default is set to `0.75`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39a86df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: f59b284a-8c14-4bd6-b51e-cdd7038899e3\n",
      "Data: {\n",
      "  \"value\": \"NaN\",\n",
      "  \"question\": \"A part of this marine mammal was prized by medieval folk, who thought it belonged to a unicorn\",\n",
      "  \"answer\": \"the narwhal\",\n",
      "  \"category\": \"THE ANIMAL KINGDOM\"\n",
      "} \n",
      "\n",
      "ID: d5bde835-2125-4e48-996f-ce5a917cd2cc\n",
      "Data: {\n",
      "  \"value\": \"$400\",\n",
      "  \"question\": \"You could say this Arctic mammal, Odobenus rosmarus, has a Wilford Brimley mustache\",\n",
      "  \"answer\": \"the walrus\",\n",
      "  \"category\": \"MAMMALS\"\n",
      "} \n",
      "\n",
      "ID: 49618708-f547-421f-a8cb-09d35896efcb\n",
      "Data: {\n",
      "  \"value\": \"$800\",\n",
      "  \"question\": \"Kodiak Island is the habitat of this type of bear, Ursus arctos middendorffi\",\n",
      "  \"answer\": \"Kodiak bear\",\n",
      "  \"category\": \"STUPID ANSWERS\"\n",
      "} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "jeopardy = client.collections.get(\"JeopardyQuestions\")\n",
    "\n",
    "response = jeopardy.query.hybrid(\n",
    "    query=\"unicorn-like artic animal\",\n",
    "    alpha=0.75,\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "for item in response.objects:\n",
    "    print(\"ID:\", item.uuid)\n",
    "    print(\"Data:\", json.dumps(item.properties, indent=2), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b233f3e7",
   "metadata": {},
   "source": [
    "### Query with Reranker\n",
    "We're using ContextualAI's reranker model in Weaviate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24f0d11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: d5bde835-2125-4e48-996f-ce5a917cd2cc\n",
      "Data: {\n",
      "  \"value\": \"$400\",\n",
      "  \"question\": \"You could say this Arctic mammal, Odobenus rosmarus, has a Wilford Brimley mustache\",\n",
      "  \"answer\": \"the walrus\",\n",
      "  \"category\": \"MAMMALS\"\n",
      "} \n",
      "\n",
      "ID: f59b284a-8c14-4bd6-b51e-cdd7038899e3\n",
      "Data: {\n",
      "  \"value\": \"NaN\",\n",
      "  \"question\": \"A part of this marine mammal was prized by medieval folk, who thought it belonged to a unicorn\",\n",
      "  \"answer\": \"the narwhal\",\n",
      "  \"category\": \"THE ANIMAL KINGDOM\"\n",
      "} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "collection = client.collections.use(\"JeopardyQuestions\")\n",
    "\n",
    "response = collection.query.hybrid(\n",
    "    query=\"unicorn-like artic animal\",\n",
    "    alpha=0.7,\n",
    "    limit=2,\n",
    "    rerank=Rerank(\n",
    "        prop= \"question\", # property to rerank on\n",
    "        query=\"artic animal\" # rerank query. If none is provided, the original query is sent\n",
    "    )\n",
    ")\n",
    "\n",
    "for item in response.objects:\n",
    "    print(\"ID:\", item.uuid)\n",
    "    print(\"Data:\", json.dumps(item.properties, indent=2), \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
