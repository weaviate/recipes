{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bff826b22eef4b62a3bf87bcb42dadc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_adb3e36225214266b5431c948db100eb",
              "IPY_MODEL_772a318e3bd64df5b257a4c3b625701c",
              "IPY_MODEL_94aa4c00c2cf46e3af7dc6061c1dcdbb"
            ],
            "layout": "IPY_MODEL_c0c3eeb979774bf2bbed58c5783aff01"
          }
        },
        "adb3e36225214266b5431c948db100eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_018e1a2dc0d74236b20eba3b4245b1f0",
            "placeholder": "​",
            "style": "IPY_MODEL_a9718c3fa49c452a90761b0ac55fbc45",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "772a318e3bd64df5b257a4c3b625701c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40bb56434ac145e4b311cee56ba46765",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b71c0126e057429ca54a6a1f5da30754",
            "value": 3
          }
        },
        "94aa4c00c2cf46e3af7dc6061c1dcdbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a38a725a3524a6f8c2917bbc9027b21",
            "placeholder": "​",
            "style": "IPY_MODEL_7cc62803d32f4ffc8d6db82f7dcca8e5",
            "value": " 3/3 [00:02&lt;00:00,  1.23it/s]"
          }
        },
        "c0c3eeb979774bf2bbed58c5783aff01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "018e1a2dc0d74236b20eba3b4245b1f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9718c3fa49c452a90761b0ac55fbc45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40bb56434ac145e4b311cee56ba46765": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b71c0126e057429ca54a6a1f5da30754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a38a725a3524a6f8c2917bbc9027b21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cc62803d32f4ffc8d6db82f7dcca8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ColPali"
      ],
      "metadata": {
        "id": "RLIRZ1i-gAam"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: This was run on an A100 with Google Colab, you might need such a GPU to avoid OOM errors."
      ],
      "metadata": {
        "id": "xIsAgoLjtmaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image==1.17.0 > /dev/null\n",
        "!pip install peft==0.12.0 > /dev/null"
      ],
      "metadata": {
        "id": "NO3S10LqgY5U"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update > /dev/null\n",
        "!sudo apt-get install poppler-utils > /dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8XaDMa_gaOa",
        "outputId": "44696ecc-66ff-4d63-edf2-7b976e867370"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Gv7OSdRn_SN",
        "outputId": "3b63db68-f611-4cc2-cff2-ccb0d0b11019"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from typing import List, cast\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import LlamaTokenizerFast, PaliGemmaProcessor\n",
        "from transformers.models.paligemma.configuration_paligemma import PaliGemmaConfig\n",
        "from transformers.models.paligemma.modeling_paligemma import PaliGemmaForConditionalGeneration, PaliGemmaPreTrainedModel\n",
        "\n",
        "# Define ColPali model\n",
        "class ColPali(PaliGemmaPreTrainedModel):\n",
        "    def __init__(self, config: PaliGemmaConfig):\n",
        "        super(ColPali, self).__init__(config=config)\n",
        "        self.model = PaliGemmaForConditionalGeneration(config)\n",
        "        self.dim = 128\n",
        "        self.custom_text_proj = nn.Linear(self.model.config.text_config.hidden_size, self.dim)\n",
        "        self.main_input_name = \"doc_input_ids\"\n",
        "\n",
        "    def forward(self, *args, **kwargs) -> torch.Tensor:\n",
        "        outputs = self.model(*args, output_hidden_states=True, **kwargs)\n",
        "        last_hidden_states = outputs.hidden_states[-1]\n",
        "        proj = self.custom_text_proj(last_hidden_states)\n",
        "        proj = proj / proj.norm(dim=-1, keepdim=True)\n",
        "        proj = proj * kwargs[\"attention_mask\"].unsqueeze(-1)\n",
        "        return proj\n",
        "\n",
        "# Define input classes\n",
        "class ColPaliTextInput:\n",
        "    def __init__(self, input_ids, attention_mask):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_mask = attention_mask\n",
        "\n",
        "    def to(self, device):\n",
        "        return ColPaliTextInput(\n",
        "            input_ids=self.input_ids.to(device),\n",
        "            attention_mask=self.attention_mask.to(device),\n",
        "        )\n",
        "\n",
        "class ColPaliImageInput:\n",
        "    def __init__(self, input_ids, pixel_values, attention_mask):\n",
        "        self.input_ids = input_ids\n",
        "        self.pixel_values = pixel_values\n",
        "        self.attention_mask = attention_mask\n",
        "\n",
        "    def to(self, device):\n",
        "        return ColPaliImageInput(\n",
        "            input_ids=self.input_ids.to(device),\n",
        "            pixel_values=self.pixel_values.to(device),\n",
        "            attention_mask=self.attention_mask.to(device),\n",
        "        )\n",
        "\n",
        "# Define ColPaliProcessor\n",
        "class ColPaliProcessor:\n",
        "    def __init__(self, processor: PaliGemmaProcessor):\n",
        "        self.processor = processor\n",
        "        self.tokenizer = cast(LlamaTokenizerFast, self.processor.tokenizer)\n",
        "\n",
        "    @staticmethod\n",
        "    def from_pretrained(model_name: str) -> 'ColPaliProcessor':\n",
        "        return ColPaliProcessor(processor=PaliGemmaProcessor.from_pretrained(model_name))\n",
        "\n",
        "    def process_text(self, text: str | List[str], padding: str = \"longest\", return_tensors: str = \"pt\", add_special_tokens: bool = True) -> ColPaliTextInput:\n",
        "        if add_special_tokens:\n",
        "            if isinstance(text, str):\n",
        "                text = self.tokenizer.bos_token + text + \"\\n\"\n",
        "            elif isinstance(text, list):\n",
        "                text = [self.tokenizer.bos_token + t + \"\\n\" for t in text]\n",
        "            else:\n",
        "                raise ValueError(\"text must be a string or a list of strings.\")\n",
        "\n",
        "        batch_output = self.tokenizer(text, padding=padding, return_tensors=return_tensors, add_special_tokens=add_special_tokens)\n",
        "\n",
        "        return ColPaliTextInput(\n",
        "            input_ids=batch_output[\"input_ids\"],\n",
        "            attention_mask=batch_output[\"attention_mask\"],\n",
        "        )\n",
        "\n",
        "    def process_image(self, image: Image.Image | List[Image.Image], padding: str = \"longest\", do_convert_rgb: bool = True, return_tensors: str = \"pt\", add_special_prompt: bool = True) -> ColPaliImageInput:\n",
        "        special_prompt = \"Describe the image.\" if add_special_prompt else None\n",
        "        if isinstance(image, Image.Image):\n",
        "            text_input = [special_prompt]\n",
        "        elif isinstance(image, list):\n",
        "            text_input = [special_prompt] * len(image)\n",
        "        else:\n",
        "            raise ValueError(\"image must be a PIL Image or a list of PIL Images.\")\n",
        "\n",
        "        batch_output = self.processor(\n",
        "            text=text_input,\n",
        "            images=image,\n",
        "            padding=padding,\n",
        "            do_convert_rgb=do_convert_rgb,\n",
        "            return_tensors=return_tensors,\n",
        "        )\n",
        "\n",
        "        return ColPaliImageInput(\n",
        "            input_ids=batch_output[\"input_ids\"],\n",
        "            pixel_values=batch_output[\"pixel_values\"],\n",
        "            attention_mask=batch_output[\"attention_mask\"],\n",
        "        )\n",
        "\n",
        "    def decode(self, *args, **kwargs):\n",
        "        return self.tokenizer.decode(*args, **kwargs)\n",
        "\n",
        "    def batch_decode(self, *args, **kwargs):\n",
        "        return self.tokenizer.batch_decode(*args, **kwargs)\n",
        "\n",
        "# Helper functions\n",
        "def convert_pdf_to_images(pdf_file: str, save_folder: str) -> List[Image.Image]:\n",
        "    images = convert_from_path(pdf_file)\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    saved_images = []\n",
        "    for i, image in enumerate(images):\n",
        "        image_path = os.path.join(save_folder, f\"page_{i+1}.jpg\")\n",
        "        image.save(image_path, \"JPEG\")\n",
        "        saved_images.append(Image.open(image_path))\n",
        "    return saved_images\n",
        "\n",
        "def process_pdfs_with_colpali(pdf_files, output_dir, model, processor):\n",
        "    all_embeddings = []\n",
        "    all_page_info = []\n",
        "\n",
        "    for pdf_file in pdf_files:\n",
        "        pdf_images = convert_pdf_to_images(pdf_file, os.path.join(output_dir, \"pdf_images\"))\n",
        "\n",
        "        for page_num, image in enumerate(pdf_images):\n",
        "            image_input = processor.process_image(image).to(model.device)\n",
        "            with torch.no_grad():\n",
        "                page_embedding = model(**vars(image_input))\n",
        "\n",
        "            # Average over sequence dimension if necessary\n",
        "            if len(page_embedding.shape) == 3:\n",
        "                page_embedding = page_embedding.mean(dim=1)\n",
        "\n",
        "            all_embeddings.append(page_embedding.cpu().numpy().squeeze())\n",
        "            all_page_info.append({\"pdf\": pdf_file, \"page\": page_num})\n",
        "\n",
        "    embeddings_array = np.array(all_embeddings)\n",
        "\n",
        "    np.save(Path(output_dir) / \"embeddings.npy\", embeddings_array)\n",
        "    np.save(Path(output_dir) / \"page_info.npy\", all_page_info)\n",
        "\n",
        "    return embeddings_array, all_page_info\n",
        "\n",
        "def answer_query_with_colpali(query, embeddings_array, page_info, model, processor):\n",
        "    query_input = processor.process_text(query).to(model.device)\n",
        "    with torch.no_grad():\n",
        "        query_embedding = model(**vars(query_input))\n",
        "\n",
        "    # Reshape embeddings if necessary\n",
        "    if len(embeddings_array.shape) == 3:\n",
        "        embeddings_array = embeddings_array.mean(axis=1)  # Average over sequence dimension\n",
        "    if len(query_embedding.shape) == 3:\n",
        "        query_embedding = query_embedding.mean(axis=1)  # Average over sequence dimension\n",
        "\n",
        "    # Ensure both embeddings are 2D\n",
        "    embeddings_array = embeddings_array.squeeze()\n",
        "    query_embedding = query_embedding.cpu().numpy().squeeze()\n",
        "\n",
        "    # Compute similarity scores\n",
        "    similarity_scores = np.dot(embeddings_array, query_embedding.T)\n",
        "\n",
        "    K = 5\n",
        "    top_k_indices = np.argsort(similarity_scores.flatten())[-K:][::-1]\n",
        "\n",
        "    top_results = [\n",
        "        {\"score\": similarity_scores.flatten()[i], \"info\": page_info[i]}\n",
        "        for i in top_k_indices\n",
        "    ]\n",
        "\n",
        "    return top_results"
      ],
      "metadata": {
        "id": "HUzkSg5xn1CR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model_path = \"google/paligemma-3b-mix-448\"\n",
        "lora_path = \"vidore/colpali\"\n",
        "\n",
        "model = ColPali.from_pretrained(model_path)\n",
        "model.load_adapter(lora_path, adapter_name=\"colpali\")\n",
        "model.to(device)\n",
        "\n",
        "processor = ColPaliProcessor.from_pretrained(model_path)\n",
        "\n",
        "pdf_files = [\"ALTO.pdf\", \"MIPRO.pdf\", \"STORM.pdf\"]\n",
        "output_dir = \"colpali_output\"\n",
        "\n",
        "# Process PDFs and save embeddings\n",
        "embeddings, page_info = process_pdfs_with_colpali(pdf_files, output_dir, model, processor)\n",
        "\n",
        "# Answer a query\n",
        "query = \"How does MIPRO compare to Bayesian Bootstrap?\" # The answer should be contained im MIPRO.pdf\n",
        "results = answer_query_with_colpali(query, embeddings, page_info, model, processor)\n",
        "\n",
        "# Print results\n",
        "for result in results:\n",
        "  print(f\"Score: {result['score']}, PDF: {result['info']['pdf']}, Page: {result['info']['page']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "bff826b22eef4b62a3bf87bcb42dadc2",
            "adb3e36225214266b5431c948db100eb",
            "772a318e3bd64df5b257a4c3b625701c",
            "94aa4c00c2cf46e3af7dc6061c1dcdbb",
            "c0c3eeb979774bf2bbed58c5783aff01",
            "018e1a2dc0d74236b20eba3b4245b1f0",
            "a9718c3fa49c452a90761b0ac55fbc45",
            "40bb56434ac145e4b311cee56ba46765",
            "b71c0126e057429ca54a6a1f5da30754",
            "1a38a725a3524a6f8c2917bbc9027b21",
            "7cc62803d32f4ffc8d6db82f7dcca8e5"
          ]
        },
        "id": "HohchBLXn3FS",
        "outputId": "b1ed7617-3275-4515-af51-6a29b05d16dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bff826b22eef4b62a3bf87bcb42dadc2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ColPali were not initialized from the model checkpoint at google/paligemma-3b-mix-448 and are newly initialized: ['custom_text_proj.bias', 'custom_text_proj.weight', 'language_model.lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.407981812953949, PDF: MIPRO.pdf, Page: 4\n",
            "Score: 0.38309675455093384, PDF: ALTO.pdf, Page: 5\n",
            "Score: 0.3767203688621521, PDF: MIPRO.pdf, Page: 5\n",
            "Score: 0.3727259337902069, PDF: MIPRO.pdf, Page: 7\n",
            "Score: 0.3650705814361572, PDF: MIPRO.pdf, Page: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How is streaming used in Compound AI Systems?\" # The answer should be contained in ALTO.pdf\n",
        "results = answer_query_with_colpali(query, embeddings, page_info, model, processor)\n",
        "\n",
        "# Print results\n",
        "for result in results:\n",
        "  print(f\"Score: {result['score']}, PDF: {result['info']['pdf']}, Page: {result['info']['page']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcGmrwfZtwz6",
        "outputId": "a9c02083-b2c3-4590-c874-bc48d791763b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.3940265476703644, PDF: ALTO.pdf, Page: 5\n",
            "Score: 0.36726292967796326, PDF: MIPRO.pdf, Page: 0\n",
            "Score: 0.36110228300094604, PDF: ALTO.pdf, Page: 1\n",
            "Score: 0.3595043420791626, PDF: ALTO.pdf, Page: 0\n",
            "Score: 0.35756224393844604, PDF: STORM.pdf, Page: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-sPOCQOWt2Up"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
