{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-vector embeddings with ModernColBERT\n",
    "This recipe explores how to use [LightOn's GTE-ModernColBERT-v1](https://huggingface.co/lightonai/GTE-ModernColBERT-v1) model to generate multi-vector embeddings for text data and use them in Weaviate. \n",
    "\n",
    "Multi-vector embeddings represent each object or query using multiple vectors instead of a single vector. This approach enables more precise searching through \"late interaction\", a technique that matches individual parts of texts rather than comparing them as whole units.\n",
    "\n",
    "Note, this Notebook requires Weaviate `v1.30.1` abd  Weaviate client `v4.14.1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "Before starting this tutorial, ensure you have the following:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pylate\n",
    "!pip install -U weaviate-client\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1.1. Connect to Weaviate\n",
    "First, connect to your Weaviate instance using your preferred client library. In this example, we assume you are connecting to a local Weaviate instance. For other types of instances, replace the connection details as needed (connection examples).\n",
    "\n",
    "You can start a local Weaviate instance with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7deacc244c58eb5a3b10f9fba098fdbe17f970fe0258ab5c9f69882fb74f629a\n"
     ]
    }
   ],
   "source": [
    "!docker run --detach -p 8080:8080 -p 50051:50051 cr.weaviate.io/semitechnologies/weaviate:1.30.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then connect to your local Weaviate instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "# Option 1: Connect to your local Weaviate instance deployed with Docker\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "# Option 2: Connet to an embedded Weaviate instance\n",
    "# client = weaviate.connect_to_embedded()\n",
    "\n",
    "# Option 3: Connect to your Weaviate Client Service cluster\n",
    "# client = weaviate.connect_to_wcs(\n",
    "#     cluster_id=\"WCS-CLUSTER-ID\", # Replace with your WCS cluster ID\n",
    "#     auth_credentials=weaviate.AuthApiKey(\n",
    "#       api_key=\"WCS-API-KEY\" # Replace with your WCS API KEY\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define collection\n",
    "Next, we define a collection called \"DemoCollection\". Note that we do not use a model integration, as we will provide the embeddings manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weaviate.collections.collection.sync.Collection at 0x10d0b55b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from weaviate.classes.config import Configure, Property, DataType\n",
    "from weaviate.util import generate_uuid5\n",
    "from weaviate.classes.config import Configure\n",
    "\n",
    "collection_name = \"DemoCollection\"\n",
    "\n",
    "# Check if collection exists before deleting\n",
    "if client.collections.exists(collection_name):\n",
    "    client.collections.delete(collection_name)  # THIS WILL DELETE THE SPECIFIED COLLECTION AND ALL ITS OBJECTS\n",
    "    \n",
    "client.collections.create(\n",
    "    collection_name,\n",
    "    vectorizer_config=[\n",
    "        # User-provided embeddings\n",
    "        Configure.NamedVectors.none(\n",
    "            name=\"multi_vector\",\n",
    "            vector_index_config=Configure.VectorIndex.hnsw(\n",
    "                # Enable multi-vector index with default settings\n",
    "                multi_vector=Configure.VectorIndex.MultiVector.multi_vector()\n",
    "            )\n",
    "        ),\n",
    "    ],\n",
    "    properties=[\n",
    "        Property(name=\"text\", \n",
    "                 data_type=DataType.TEXT, \n",
    "                 vectorize_property_name=False  # Explicitly disable property name vectorization\n",
    "                 ),\n",
    "        Property(name=\"docid\", \n",
    "                 data_type=DataType.TEXT,\n",
    "                 vectorize_property_name=False  # Explicitly disable property name vectorization\n",
    "                 ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can double-check that you're using the MaxSim operator for the multi-vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"multi_vector\": {\n",
      "    \"aggregation\": \"maxSim\"\n",
      "  },\n",
      "  \"quantizer\": null,\n",
      "  \"cleanup_interval_seconds\": 300,\n",
      "  \"distance_metric\": \"cosine\",\n",
      "  \"dynamic_ef_min\": 100,\n",
      "  \"dynamic_ef_max\": 500,\n",
      "  \"dynamic_ef_factor\": 8,\n",
      "  \"ef\": -1,\n",
      "  \"ef_construction\": 128,\n",
      "  \"filter_strategy\": \"sweeping\",\n",
      "  \"flat_search_cutoff\": 40000,\n",
      "  \"max_connections\": 32,\n",
      "  \"skip\": false,\n",
      "  \"vector_cache_max_objects\": 1000000000000\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Get collection\n",
    "collection = client.collections.get(collection_name)\n",
    "\n",
    "config = collection.config.get().vector_config['multi_vector'].vector_index_config\n",
    "\n",
    "print(json.dumps(config.__dict__, indent=2, default=lambda o: o.__dict__ if hasattr(o, '__dict__') else str(o)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3. Import data\n",
    "\n",
    "Now, we can import the data. For this example, we will import a few arbitrary text objects.\n",
    "\n",
    "Note that in this example, each object is sent to Weaviate along with the corresponding multi-vector embedding. In the example, we obtain LightOn's ModernColBERT embeddings, but it could be any multi-vector embeddings.\n",
    "\n",
    "Load ModernColBERT embedding model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leonie/Documents/code/recipes/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/leonie/Documents/code/recipes/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pylate import models\n",
    "\n",
    "# Load the ModernColBERT model\n",
    "model = models.ColBERT(\n",
    "    model_name_or_path=\"lightonai/GTE-ModernColBERT-v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example dataset\n",
    "documents = [\n",
    "    {\"id\": \"doc1\", \"text\": \"Weaviate is a vector database that is great for AI app builders.\"},\n",
    "    {\"id\": \"doc2\", \"text\": \"PyTorch is a deep learning framework that is great for AI model builders.\"},\n",
    "    {\"id\": \"doc3\", \"text\": \"For people building AI driven products, Weaviate is a good database for their tech stack.\"},\n",
    "]\n",
    "\n",
    "\n",
    "# Import data\n",
    "with collection.batch.fixed_size(batch_size=10) as batch:\n",
    "    for doc in documents:\n",
    "        # Iterate through the dataset & add to batch\n",
    "        batch.add_object(\n",
    "            properties={\"text\": doc[\"text\"], \"docid\": doc[\"id\"]},\n",
    "            uuid=generate_uuid5(doc[\"id\"]),\n",
    "            vector={\"multi_vector\": model.encode(doc[\"text\"], is_query=False)},  # Provide the embedding manually\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Check for errors in batch imports\n",
    "if collection.batch.failed_objects:\n",
    "    print(f\"Number of failed imports: {len(collection.batch.failed_objects)}\")\n",
    "    print(f\"First failed object: {collection.batch.failed_objects[0]}\")\n",
    "\n",
    "print(len(collection))  # This should print `3``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrieve an object and inspect the shape of its embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This embedding's shape is (17, 128)\n",
      "This embedding's shape is (20, 128)\n",
      "This embedding's shape is (18, 128)\n"
     ]
    }
   ],
   "source": [
    "response = collection.query.fetch_objects(limit=3, include_vector=True)\n",
    "\n",
    "for obj in response.objects:\n",
    "    print(f\"This embedding's shape is ({len(obj.vector['multi_vector'])}, {len(obj.vector['multi_vector'][0])})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note this in contrast to a single vector, which would be a list of floats.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4. Perform vector search query\n",
    "Now that we have imported the data, we can perform searches using the multi-vector embeddings. \n",
    "\n",
    "You can perform a manual vector search, by specifying the query embedding. In this example, we convert the query into a vector using the same model used to generate the object embeddings.\n",
    "\n",
    "This ensures that the query embedding is compatible with the object embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Weaviate is a vector database that is great for AI app builders.', 'docid': 'doc1'}\n",
      "-29.469009399414062\n",
      "{'text': 'For people building AI driven products, Weaviate is a good database for their tech stack.', 'docid': 'doc3'}\n",
      "-29.417606353759766\n",
      "{'text': 'PyTorch is a deep learning framework that is great for AI model builders.', 'docid': 'doc2'}\n",
      "-28.900041580200195\n"
     ]
    }
   ],
   "source": [
    "query = \"A good database for AI app builders\"\n",
    "response = collection.query.near_vector(\n",
    "    near_vector=model.encode(query, is_query=True),  # Raw ColBERT embedding, in [[e11, e12, e13, ...], [e21, e22, e23, ...], ...] shape\n",
    "    target_vector=\"multi_vector\",\n",
    "    return_metadata=weaviate.classes.query.MetadataQuery(\n",
    "            distance=True,\n",
    "        ),\n",
    ")\n",
    "\n",
    "for result in response.objects:\n",
    "    print(result.properties)\n",
    "    print(result.metadata.distance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional resources\n",
    "You might also enjoy the following resources:\n",
    "\n",
    "- Tutorial: [Weaviate multi-vector embeddings](https://weaviate.io/developers/weaviate/tutorials/multi-vector-embeddings)\n",
    "- Blog: [An Overview of Late Interaction Retrieval Models: ColBERT, ColPali, and ColQwen](https://weaviate.io/blog/late-interaction-overview)\n",
    "- Recipe notebooks [on multi-vector embeddings](https://github.com/weaviate/recipes/tree/main/weaviate-features/multi-vector)\n",
    "\n",
    ":::info\n",
    "Multi-vector support is added in Weaviate v1.29 as a **technical preview**.\n",
    "\n",
    "This means that the feature is still under development and may change in future releases, including potential breaking changes. Currently, quantization is not supported for multi-vector embeddings.\n",
    "\n",
    "We do not recommend using this feature in production environments at this time.\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
